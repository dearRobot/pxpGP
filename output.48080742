Job started on: g005
SLURM_JOB_ID: 48080742
Running pxpGP 1 with agents: 16
[92mRank 0 - sparse dataset size is: 126, local dataset: torch.Size([2025, 2]), [0m
[92mRank 0 - Training local sparse GP model with 2025 samples[0m
Epoch 1/200 - Loss: 3.544
Epoch 11/200 - Loss: 0.797
Epoch 21/200 - Loss: 0.037
Converged at epoch 22 with loss -0.073
[92mRank 0 - Lengthscale: [[0.29806322 0.26355657]] [0m
[92mRank 0 - Outputscale: 2.1333534717559814 [0m
[92mRank 0 - Noise: 0.11826243251562119 [0m
Rank 0 - Augmented dataset size: 4041
Rank 0: After warm start model parameters:
Rank: 0, Lengthscale: [[0.29806322 0.26355657]]
Rank: 0, Outputscale: 2.1333534717559814
Rank: 0, Noise: 0.11826243251562119
decpxADMM initialized with rho: 0.85, lip: 1.0, tol_abs: 1e-05, tol_rel: 0.001, rank: 0, world_size: 16
[92mRank 0 - Training global model with dec-pxADMM optimizer[0m
rank 0, epoch 9, loss: 0.33995315432548523, rho: 0.4250, lip: 1.0000
rank 0, epoch 19, loss: 0.3550224006175995, rho: 0.1062, lip: 1.0000
Rank 0 - Training time: 32.74 seconds
[92mRank 0 - Testing RMSE: 0.3758[0m
[92mRank: 0, Lengthscale: [[0.30557373 0.32338256]] [0m
[92mRank: 0, Outputscale: 1.7528998851776123 [0m
[92mRank: 0, Noise: 0.10049070417881012 [0m
Run 1 completed successfully
Running pxpGP 2 with agents: 16
[92mRank 0 - sparse dataset size is: 126, local dataset: torch.Size([2025, 2]), [0m
[92mRank 0 - Training local sparse GP model with 2025 samples[0m
Epoch 1/200 - Loss: 2.620
Epoch 11/200 - Loss: 0.779
Epoch 21/200 - Loss: 0.034
Converged at epoch 22 with loss -0.061
[92mRank 0 - Lengthscale: [[0.45848313 0.32735068]] [0m
[92mRank 0 - Outputscale: 2.3932528495788574 [0m
[92mRank 0 - Noise: 0.12097500264644623 [0m
Rank 0 - Augmented dataset size: 4041
Rank 0: After warm start model parameters:
Rank: 0, Lengthscale: [[0.45848313 0.32735068]]
Rank: 0, Outputscale: 2.3932528495788574
Rank: 0, Noise: 0.12097503244876862
decpxADMM initialized with rho: 0.85, lip: 1.0, tol_abs: 1e-05, tol_rel: 0.001, rank: 0, world_size: 16
[92mRank 0 - Training global model with dec-pxADMM optimizer[0m
rank 0, epoch 9, loss: 0.41105788946151733, rho: 0.4250, lip: 1.0000
rank 0, epoch 19, loss: 0.4195536971092224, rho: 0.1062, lip: 1.0000
Rank 0 - Training time: 31.33 seconds
[92mRank 0 - Testing RMSE: 0.3892[0m
[92mRank: 0, Lengthscale: [[0.38211828 0.27958134]] [0m
[92mRank: 0, Outputscale: 1.7093544006347656 [0m
[92mRank: 0, Noise: 0.11258400976657867 [0m
Run 2 completed successfully
Running pxpGP 3 with agents: 16
[92mRank 0 - sparse dataset size is: 126, local dataset: torch.Size([2025, 2]), [0m
[92mRank 0 - Training local sparse GP model with 2025 samples[0m
Epoch 1/200 - Loss: 2.932
Epoch 11/200 - Loss: 0.778
Epoch 21/200 - Loss: 0.013
Converged at epoch 22 with loss -0.105
[92mRank 0 - Lengthscale: [[0.4382743  0.42885295]] [0m
[92mRank 0 - Outputscale: 2.0226938724517822 [0m
[92mRank 0 - Noise: 0.11515475064516068 [0m
Rank 0 - Augmented dataset size: 4041
Rank 0: After warm start model parameters:
Rank: 0, Lengthscale: [[0.43827432 0.42885295]]
Rank: 0, Outputscale: 2.0226938724517822
Rank: 0, Noise: 0.11515475064516068
decpxADMM initialized with rho: 0.85, lip: 1.0, tol_abs: 1e-05, tol_rel: 0.001, rank: 0, world_size: 16
[92mRank 0 - Training global model with dec-pxADMM optimizer[0m
rank 0, epoch 9, loss: 0.4025329649448395, rho: 0.2125, lip: 1.0000
rank 0, epoch 19, loss: 0.39643457531929016, rho: 0.1062, lip: 1.0000
Rank 0 - Training time: 30.24 seconds
[92mRank 0 - Testing RMSE: 0.3114[0m
[92mRank: 0, Lengthscale: [[0.46217895 0.32130948]] [0m
[92mRank: 0, Outputscale: 1.900322437286377 [0m
[92mRank: 0, Noise: 0.11029638350009918 [0m
Run 3 completed successfully
Running pxpGP 4 with agents: 16
[92mRank 0 - sparse dataset size is: 126, local dataset: torch.Size([2025, 2]), [0m
[92mRank 0 - Training local sparse GP model with 2025 samples[0m
Epoch 1/200 - Loss: 3.098
Epoch 11/200 - Loss: 0.754
Epoch 21/200 - Loss: 0.397
Converged at epoch 22 with loss -0.035
[92mRank 0 - Lengthscale: [[0.3378241  0.44242266]] [0m
[92mRank 0 - Outputscale: 2.0911331176757812 [0m
[92mRank 0 - Noise: 0.12394027411937714 [0m
Rank 0 - Augmented dataset size: 4041
Rank 0: After warm start model parameters:
Rank: 0, Lengthscale: [[0.33782414 0.44242266]]
Rank: 0, Outputscale: 2.0911331176757812
Rank: 0, Noise: 0.12394027411937714
decpxADMM initialized with rho: 0.85, lip: 1.0, tol_abs: 1e-05, tol_rel: 0.001, rank: 0, world_size: 16
[92mRank 0 - Training global model with dec-pxADMM optimizer[0m
rank 0, epoch 9, loss: 0.4329938292503357, rho: 0.2125, lip: 1.0000
rank 0, epoch 19, loss: 0.44029685854911804, rho: 0.1062, lip: 1.0000
Rank 0 - Training time: 29.63 seconds
[92mRank 0 - Testing RMSE: 0.3419[0m
[92mRank: 0, Lengthscale: [[0.5366069  0.20001142]] [0m
[92mRank: 0, Outputscale: 1.4870997667312622 [0m
[92mRank: 0, Noise: 0.12207219004631042 [0m
Run 4 completed successfully
Running pxpGP 5 with agents: 16
[92mRank 0 - sparse dataset size is: 126, local dataset: torch.Size([2025, 2]), [0m
[92mRank 0 - Training local sparse GP model with 2025 samples[0m
Epoch 1/200 - Loss: 2.341
Epoch 11/200 - Loss: 0.704
Epoch 21/200 - Loss: -0.074
Converged at epoch 21 with loss -0.074
[92mRank 0 - Lengthscale: [[0.5580495 0.4035857]] [0m
[92mRank 0 - Outputscale: 1.805556058883667 [0m
[92mRank 0 - Noise: 0.12212362140417099 [0m
Rank 0 - Augmented dataset size: 4041
Rank 0: After warm start model parameters:
Rank: 0, Lengthscale: [[0.5580495 0.4035857]]
Rank: 0, Outputscale: 1.805556058883667
Rank: 0, Noise: 0.12212362140417099
decpxADMM initialized with rho: 0.85, lip: 1.0, tol_abs: 1e-05, tol_rel: 0.001, rank: 0, world_size: 16
[92mRank 0 - Training global model with dec-pxADMM optimizer[0m
rank 0, epoch 9, loss: 0.26409634947776794, rho: 0.2125, lip: 1.0000
rank 0, epoch 19, loss: 0.2734803855419159, rho: 0.1062, lip: 1.0000
Rank 0 - Training time: 32.78 seconds
[92mRank 0 - Testing RMSE: 0.2532[0m
[92mRank: 0, Lengthscale: [[0.41245067 0.2874498 ]] [0m
[92mRank: 0, Outputscale: 1.6007221937179565 [0m
[92mRank: 0, Noise: 0.0807679072022438 [0m
Run 5 completed successfully
Running pxpGP 6 with agents: 16
[92mRank 0 - sparse dataset size is: 126, local dataset: torch.Size([2025, 2]), [0m
[92mRank 0 - Training local sparse GP model with 2025 samples[0m
Epoch 1/200 - Loss: 2.454
Epoch 11/200 - Loss: 0.721
Epoch 21/200 - Loss: 0.003
Converged at epoch 22 with loss -0.166
[92mRank 0 - Lengthscale: [[0.5228096 0.435875 ]] [0m
[92mRank 0 - Outputscale: 1.7979114055633545 [0m
[92mRank 0 - Noise: 0.10163842141628265 [0m
Rank 0 - Augmented dataset size: 4041
Rank 0: After warm start model parameters:
Rank: 0, Lengthscale: [[0.5228096 0.435875 ]]
Rank: 0, Outputscale: 1.7979114055633545
Rank: 0, Noise: 0.10163842141628265
decpxADMM initialized with rho: 0.85, lip: 1.0, tol_abs: 1e-05, tol_rel: 0.001, rank: 0, world_size: 16
[92mRank 0 - Training global model with dec-pxADMM optimizer[0m
rank 0, epoch 9, loss: 0.41568779945373535, rho: 0.2125, lip: 1.0000
rank 0, epoch 19, loss: 0.41633716225624084, rho: 0.1062, lip: 1.0000
Rank 0 - Training time: 32.20 seconds
[92mRank 0 - Testing RMSE: 0.3705[0m
[92mRank: 0, Lengthscale: [[0.45969498 0.27188864]] [0m
[92mRank: 0, Outputscale: 1.8429782390594482 [0m
[92mRank: 0, Noise: 0.1105048730969429 [0m
Run 6 completed successfully
Running pxpGP 7 with agents: 16
[92mRank 0 - sparse dataset size is: 126, local dataset: torch.Size([2025, 2]), [0m
[92mRank 0 - Training local sparse GP model with 2025 samples[0m
Epoch 1/200 - Loss: 3.299
Epoch 11/200 - Loss: 0.707
Epoch 21/200 - Loss: -0.085
Converged at epoch 21 with loss -0.085
[92mRank 0 - Lengthscale: [[0.5469109 0.3384805]] [0m
[92mRank 0 - Outputscale: 1.7647206783294678 [0m
[92mRank 0 - Noise: 0.12186330556869507 [0m
Rank 0 - Augmented dataset size: 4041
Rank 0: After warm start model parameters:
Rank: 0, Lengthscale: [[0.5469109  0.33848047]]
Rank: 0, Outputscale: 1.7647206783294678
Rank: 0, Noise: 0.12186328321695328
decpxADMM initialized with rho: 0.85, lip: 1.0, tol_abs: 1e-05, tol_rel: 0.001, rank: 0, world_size: 16
[92mRank 0 - Training global model with dec-pxADMM optimizer[0m
rank 0, epoch 9, loss: 0.40493249893188477, rho: 0.2125, lip: 1.0000
rank 0, epoch 19, loss: 0.4108906090259552, rho: 0.1062, lip: 1.0000
Rank 0 - Training time: 30.70 seconds
[92mRank 0 - Testing RMSE: 0.3120[0m
[92mRank: 0, Lengthscale: [[0.51973456 0.25995785]] [0m
[92mRank: 0, Outputscale: 2.0351791381835938 [0m
[92mRank: 0, Noise: 0.11528346687555313 [0m
Run 7 completed successfully
Running pxpGP 8 with agents: 16
[92mRank 0 - sparse dataset size is: 126, local dataset: torch.Size([2025, 2]), [0m
[92mRank 0 - Training local sparse GP model with 2025 samples[0m
Epoch 1/200 - Loss: 2.974
Epoch 11/200 - Loss: 0.776
Epoch 21/200 - Loss: -0.007
Converged at epoch 21 with loss -0.007
[92mRank 0 - Lengthscale: [[0.36698082 0.38425443]] [0m
[92mRank 0 - Outputscale: 1.9452877044677734 [0m
[92mRank 0 - Noise: 0.14121855795383453 [0m
Rank 0 - Augmented dataset size: 4041
Rank 0: After warm start model parameters:
Rank: 0, Lengthscale: [[0.36698082 0.38425443]]
Rank: 0, Outputscale: 1.9452877044677734
Rank: 0, Noise: 0.14121854305267334
decpxADMM initialized with rho: 0.85, lip: 1.0, tol_abs: 1e-05, tol_rel: 0.001, rank: 0, world_size: 16
[92mRank 0 - Training global model with dec-pxADMM optimizer[0m
rank 0, epoch 9, loss: 0.3654608130455017, rho: 0.2125, lip: 1.0000
rank 0, epoch 19, loss: 0.4079166352748871, rho: 0.1062, lip: 1.0000
Rank 0 - Training time: 32.57 seconds
[92mRank 0 - Testing RMSE: 0.3563[0m
[92mRank: 0, Lengthscale: [[0.24825832 0.26163772]] [0m
[92mRank: 0, Outputscale: 1.1072317361831665 [0m
[92mRank: 0, Noise: 0.10275860875844955 [0m
Run 8 completed successfully
Running pxpGP 9 with agents: 16
[92mRank 0 - sparse dataset size is: 126, local dataset: torch.Size([2025, 2]), [0m
[92mRank 0 - Training local sparse GP model with 2025 samples[0m
Epoch 1/200 - Loss: 2.679
Epoch 11/200 - Loss: 0.733
Epoch 21/200 - Loss: -0.020
Converged at epoch 21 with loss -0.020
[92mRank 0 - Lengthscale: [[0.60032105 0.4090614 ]] [0m
[92mRank 0 - Outputscale: 1.9779796600341797 [0m
[92mRank 0 - Noise: 0.1325676292181015 [0m
Rank 0 - Augmented dataset size: 4041
Rank 0: After warm start model parameters:
Rank: 0, Lengthscale: [[0.6003211 0.4090614]]
Rank: 0, Outputscale: 1.9779796600341797
Rank: 0, Noise: 0.1325676292181015
decpxADMM initialized with rho: 0.85, lip: 1.0, tol_abs: 1e-05, tol_rel: 0.001, rank: 0, world_size: 16
[92mRank 0 - Training global model with dec-pxADMM optimizer[0m
rank 0, epoch 9, loss: 0.3558359444141388, rho: 0.2125, lip: 1.0000
rank 0, epoch 19, loss: 0.3713471293449402, rho: 0.1062, lip: 1.0000
Rank 0 - Training time: 33.22 seconds
[92mRank 0 - Testing RMSE: 0.3226[0m
[92mRank: 0, Lengthscale: [[0.3604794 0.3322264]] [0m
[92mRank: 0, Outputscale: 1.4303926229476929 [0m
[92mRank: 0, Noise: 0.091899573802948 [0m
Run 9 completed successfully
Running pxpGP 10 with agents: 16
[92mRank 0 - sparse dataset size is: 126, local dataset: torch.Size([2025, 2]), [0m
[92mRank 0 - Training local sparse GP model with 2025 samples[0m
Epoch 1/200 - Loss: 3.168
Epoch 11/200 - Loss: 0.747
Epoch 21/200 - Loss: -0.022
Converged at epoch 21 with loss -0.022
[92mRank 0 - Lengthscale: [[0.5791446  0.32817012]] [0m
[92mRank 0 - Outputscale: 1.9195106029510498 [0m
[92mRank 0 - Noise: 0.13761116564273834 [0m
Rank 0 - Augmented dataset size: 4041
Rank 0: After warm start model parameters:
Rank: 0, Lengthscale: [[0.5791446  0.32817012]]
Rank: 0, Outputscale: 1.9195106029510498
Rank: 0, Noise: 0.13761116564273834
decpxADMM initialized with rho: 0.85, lip: 1.0, tol_abs: 1e-05, tol_rel: 0.001, rank: 0, world_size: 16
[92mRank 0 - Training global model with dec-pxADMM optimizer[0m
rank 0, epoch 9, loss: 0.3554900586605072, rho: 0.2125, lip: 1.0000
rank 0, epoch 19, loss: 0.36933088302612305, rho: 0.1062, lip: 1.0000
Rank 0 - Training time: 31.20 seconds
[92mRank 0 - Testing RMSE: 0.3779[0m
[92mRank: 0, Lengthscale: [[0.3682386  0.26726693]] [0m
[92mRank: 0, Outputscale: 1.2071633338928223 [0m
[92mRank: 0, Noise: 0.09921727329492569 [0m
Run 10 completed successfully
Running gapxGP 1 with agents: 16
decpxADMM initialized with rho: 0.75, lip: 1.0, tol_abs: 1e-05, tol_rel: 0.001, rank: 0, world_size: 16
Rank 0 - Epoch 2/24 loss: 0.8015022873878479
Rank 0 - Epoch 10/24 loss: 0.5254830718040466
Rank 0 - Epoch 20/24 loss: 0.07153046131134033
[92mRank 0 - Testing RMSE: 0.0780[0m
[92mRank: 0, Lengthscale: [[0.6291234  0.42014712]] [0m
[92mRank: 0, Outputscale: 0.8133225440979004 [0m
[92mRank: 0, Noise: 0.09311382472515106 [0m
Run 1 completed successfully
Running gapxGP 2 with agents: 16
decpxADMM initialized with rho: 0.75, lip: 1.0, tol_abs: 1e-05, tol_rel: 0.001, rank: 0, world_size: 16
Rank 0 - Epoch 2/24 loss: 0.8061209917068481
Rank 0 - Epoch 10/24 loss: 0.5265270471572876
Rank 0 - Epoch 20/24 loss: 0.06794954091310501
[92mRank 0 - Testing RMSE: 0.0779[0m
[92mRank: 0, Lengthscale: [[0.62477595 0.4178025 ]] [0m
[92mRank: 0, Outputscale: 0.8144876956939697 [0m
[92mRank: 0, Noise: 0.09306640923023224 [0m
Run 2 completed successfully
Running gapxGP 3 with agents: 16
decpxADMM initialized with rho: 0.75, lip: 1.0, tol_abs: 1e-05, tol_rel: 0.001, rank: 0, world_size: 16
Rank 0 - Epoch 2/24 loss: 0.8038157820701599
Rank 0 - Epoch 10/24 loss: 0.5231889486312866
Rank 0 - Epoch 20/24 loss: 0.07059798389673233
[92mRank 0 - Testing RMSE: 0.0747[0m
[92mRank: 0, Lengthscale: [[0.62989104 0.4183458 ]] [0m
[92mRank: 0, Outputscale: 0.814105749130249 [0m
[92mRank: 0, Noise: 0.0929681584239006 [0m
Run 3 completed successfully
Running gapxGP 4 with agents: 16
decpxADMM initialized with rho: 0.75, lip: 1.0, tol_abs: 1e-05, tol_rel: 0.001, rank: 0, world_size: 16
Rank 0 - Epoch 2/24 loss: 0.8050578236579895
Rank 0 - Epoch 10/24 loss: 0.5231019258499146
Rank 0 - Epoch 20/24 loss: 0.06714902818202972
[92mRank 0 - Testing RMSE: 0.0693[0m
[92mRank: 0, Lengthscale: [[0.63106704 0.41748878]] [0m
[92mRank: 0, Outputscale: 0.8142156600952148 [0m
[92mRank: 0, Noise: 0.09269005805253983 [0m
Run 4 completed successfully
Running gapxGP 5 with agents: 16
decpxADMM initialized with rho: 0.75, lip: 1.0, tol_abs: 1e-05, tol_rel: 0.001, rank: 0, world_size: 16
Rank 0 - Epoch 2/24 loss: 0.8065584897994995
Rank 0 - Epoch 10/24 loss: 0.5272980332374573
Rank 0 - Epoch 20/24 loss: 0.06626344472169876
[92mRank 0 - Testing RMSE: 0.0727[0m
[92mRank: 0, Lengthscale: [[0.6271448  0.41635746]] [0m
[92mRank: 0, Outputscale: 0.8147938847541809 [0m
[92mRank: 0, Noise: 0.09294304996728897 [0m
Run 5 completed successfully
Running gapxGP 6 with agents: 16
decpxADMM initialized with rho: 0.75, lip: 1.0, tol_abs: 1e-05, tol_rel: 0.001, rank: 0, world_size: 16
Rank 0 - Epoch 2/24 loss: 0.8035030961036682
Rank 0 - Epoch 10/24 loss: 0.5247462391853333
Rank 0 - Epoch 20/24 loss: 0.06954272836446762
[92mRank 0 - Testing RMSE: 0.0737[0m
[92mRank: 0, Lengthscale: [[0.6299807  0.42005917]] [0m
[92mRank: 0, Outputscale: 0.8134269714355469 [0m
[92mRank: 0, Noise: 0.09290830045938492 [0m
Run 6 completed successfully
Running gapxGP 7 with agents: 16
decpxADMM initialized with rho: 0.75, lip: 1.0, tol_abs: 1e-05, tol_rel: 0.001, rank: 0, world_size: 16
Rank 0 - Epoch 2/24 loss: 0.8019176721572876
Rank 0 - Epoch 10/24 loss: 0.5245690941810608
Rank 0 - Epoch 20/24 loss: 0.06548893451690674
[92mRank 0 - Testing RMSE: 0.0759[0m
[92mRank: 0, Lengthscale: [[0.63058215 0.4190885 ]] [0m
[92mRank: 0, Outputscale: 0.8137552738189697 [0m
[92mRank: 0, Noise: 0.09300925582647324 [0m
Run 7 completed successfully
Running gapxGP 8 with agents: 16
decpxADMM initialized with rho: 0.75, lip: 1.0, tol_abs: 1e-05, tol_rel: 0.001, rank: 0, world_size: 16
Rank 0 - Epoch 2/24 loss: 0.8015307784080505
Rank 0 - Epoch 10/24 loss: 0.5247397422790527
Rank 0 - Epoch 20/24 loss: 0.07323850691318512
[92mRank 0 - Testing RMSE: 0.0755[0m
[92mRank: 0, Lengthscale: [[0.63135564 0.41936234]] [0m
[92mRank: 0, Outputscale: 0.8130077719688416 [0m
[92mRank: 0, Noise: 0.09333685040473938 [0m
Run 8 completed successfully
Running gapxGP 9 with agents: 16
decpxADMM initialized with rho: 0.75, lip: 1.0, tol_abs: 1e-05, tol_rel: 0.001, rank: 0, world_size: 16
Rank 0 - Epoch 2/24 loss: 0.8006665110588074
Rank 0 - Epoch 10/24 loss: 0.5270847678184509
Rank 0 - Epoch 20/24 loss: 0.07111264765262604
[92mRank 0 - Testing RMSE: 0.0754[0m
[92mRank: 0, Lengthscale: [[0.6257788  0.42129573]] [0m
[92mRank: 0, Outputscale: 0.8133490681648254 [0m
[92mRank: 0, Noise: 0.09330879896879196 [0m
Run 9 completed successfully
Running gapxGP 10 with agents: 16
decpxADMM initialized with rho: 0.75, lip: 1.0, tol_abs: 1e-05, tol_rel: 0.001, rank: 0, world_size: 16
Rank 0 - Epoch 2/24 loss: 0.8030943274497986
Rank 0 - Epoch 10/24 loss: 0.5247974395751953
Rank 0 - Epoch 20/24 loss: 0.06975319236516953
[92mRank 0 - Testing RMSE: 0.0757[0m
[92mRank: 0, Lengthscale: [[0.6258086  0.41984627]] [0m
[92mRank: 0, Outputscale: 0.8136985301971436 [0m
[92mRank: 0, Noise: 0.09314322471618652 [0m
Run 10 completed successfully
Running apxGP 1 with agents: 16
decpxADMM initialized with rho: 0.85, lip: 1.0, tol_abs: 1e-05, tol_rel: 0.001, rank: 0, world_size: 16
Rank 0 - Epoch 2/32 loss: 0.7402534484863281
Rank 0 - Epoch 10/32 loss: 0.47199681401252747
Rank 0 - Epoch 20/32 loss: 0.04967116191983223
Rank 0 - Epoch 30/32 loss: -0.4485252797603607
Training complete.
[92mRank 0 - Testing RMSE: 3.2030[0m
[92mRank: 0, Lengthscale: [[0.6538938  0.49593666]] [0m
[92mRank: 0, Outputscale: 0.7635380029678345 [0m
[92mRank: 0, Noise: 0.04548428952693939 [0m
Run 1 completed successfully
Running apxGP 2 with agents: 16
decpxADMM initialized with rho: 0.85, lip: 1.0, tol_abs: 1e-05, tol_rel: 0.001, rank: 0, world_size: 16
Rank 0 - Epoch 2/32 loss: 0.7402613162994385
Rank 0 - Epoch 10/32 loss: 0.47197335958480835
Rank 0 - Epoch 20/32 loss: 0.04963499307632446
Rank 0 - Epoch 30/32 loss: -0.4489116668701172
Training complete.
[92mRank 0 - Testing RMSE: 3.2030[0m
[92mRank: 0, Lengthscale: [[0.65384686 0.49589086]] [0m
[92mRank: 0, Outputscale: 0.7635464072227478 [0m
[92mRank: 0, Noise: 0.04548298567533493 [0m
Run 2 completed successfully
Running apxGP 3 with agents: 16
decpxADMM initialized with rho: 0.85, lip: 1.0, tol_abs: 1e-05, tol_rel: 0.001, rank: 0, world_size: 16
Rank 0 - Epoch 2/32 loss: 0.7402549982070923
Rank 0 - Epoch 10/32 loss: 0.4719780385494232
Rank 0 - Epoch 20/32 loss: 0.049642711877822876
Rank 0 - Epoch 30/32 loss: -0.44883474707603455
Training complete.
[92mRank 0 - Testing RMSE: 3.2030[0m
[92mRank: 0, Lengthscale: [[0.65379524 0.49589795]] [0m
[92mRank: 0, Outputscale: 0.7635540962219238 [0m
[92mRank: 0, Noise: 0.04548220708966255 [0m
Run 3 completed successfully
Running apxGP 4 with agents: 16
decpxADMM initialized with rho: 0.85, lip: 1.0, tol_abs: 1e-05, tol_rel: 0.001, rank: 0, world_size: 16
Rank 0 - Epoch 2/32 loss: 0.7402560114860535
Rank 0 - Epoch 10/32 loss: 0.47199490666389465
Rank 0 - Epoch 20/32 loss: 0.049663204699754715
Rank 0 - Epoch 30/32 loss: -0.4489242136478424
Training complete.
[92mRank 0 - Testing RMSE: 3.2030[0m
[92mRank: 0, Lengthscale: [[0.6537512  0.49589038]] [0m
[92mRank: 0, Outputscale: 0.7635620832443237 [0m
[92mRank: 0, Noise: 0.04548109695315361 [0m
Run 4 completed successfully
Running apxGP 5 with agents: 16
decpxADMM initialized with rho: 0.85, lip: 1.0, tol_abs: 1e-05, tol_rel: 0.001, rank: 0, world_size: 16
Rank 0 - Epoch 2/32 loss: 0.7402560114860535
Rank 0 - Epoch 10/32 loss: 0.4719763994216919
Rank 0 - Epoch 20/32 loss: 0.049631137400865555
Rank 0 - Epoch 30/32 loss: -0.448635458946228
Training complete.
[92mRank 0 - Testing RMSE: 3.2029[0m
[92mRank: 0, Lengthscale: [[0.65387577 0.4958743 ]] [0m
[92mRank: 0, Outputscale: 0.7635493874549866 [0m
[92mRank: 0, Noise: 0.04548295959830284 [0m
Run 5 completed successfully
Running apxGP 6 with agents: 16
decpxADMM initialized with rho: 0.85, lip: 1.0, tol_abs: 1e-05, tol_rel: 0.001, rank: 0, world_size: 16
Rank 0 - Epoch 2/32 loss: 0.7402638792991638
Rank 0 - Epoch 10/32 loss: 0.47196587920188904
Rank 0 - Epoch 20/32 loss: 0.0496409609913826
Rank 0 - Epoch 30/32 loss: -0.4488605558872223
Training complete.
[92mRank 0 - Testing RMSE: 3.2030[0m
[92mRank: 0, Lengthscale: [[0.65382195 0.49584103]] [0m
[92mRank: 0, Outputscale: 0.7635583281517029 [0m
[92mRank: 0, Noise: 0.04548179358243942 [0m
Run 6 completed successfully
Running apxGP 7 with agents: 16
decpxADMM initialized with rho: 0.85, lip: 1.0, tol_abs: 1e-05, tol_rel: 0.001, rank: 0, world_size: 16
Rank 0 - Epoch 2/32 loss: 0.7402549982070923
Rank 0 - Epoch 10/32 loss: 0.4719652533531189
Rank 0 - Epoch 20/32 loss: 0.04962926730513573
Rank 0 - Epoch 30/32 loss: -0.4485490322113037
Training complete.
[92mRank 0 - Testing RMSE: 3.2030[0m
[92mRank: 0, Lengthscale: [[0.65384537 0.4958569 ]] [0m
[92mRank: 0, Outputscale: 0.763556182384491 [0m
[92mRank: 0, Noise: 0.04548168182373047 [0m
Run 7 completed successfully
Running apxGP 8 with agents: 16
decpxADMM initialized with rho: 0.85, lip: 1.0, tol_abs: 1e-05, tol_rel: 0.001, rank: 0, world_size: 16
Rank 0 - Epoch 2/32 loss: 0.7402565479278564
Rank 0 - Epoch 10/32 loss: 0.4719657599925995
Rank 0 - Epoch 20/32 loss: 0.04963523522019386
Rank 0 - Epoch 30/32 loss: -0.44873636960983276
Training complete.
[92mRank 0 - Testing RMSE: 3.2029[0m
[92mRank: 0, Lengthscale: [[0.653848   0.49580508]] [0m
[92mRank: 0, Outputscale: 0.763556718826294 [0m
[92mRank: 0, Noise: 0.0454818494617939 [0m
Run 8 completed successfully
Running apxGP 9 with agents: 16
decpxADMM initialized with rho: 0.85, lip: 1.0, tol_abs: 1e-05, tol_rel: 0.001, rank: 0, world_size: 16
Rank 0 - Epoch 2/32 loss: 0.7402650117874146
Rank 0 - Epoch 10/32 loss: 0.4719737470149994
Rank 0 - Epoch 20/32 loss: 0.04962305724620819
Rank 0 - Epoch 30/32 loss: -0.44878557324409485
Training complete.
[92mRank 0 - Testing RMSE: 3.2030[0m
[92mRank: 0, Lengthscale: [[0.6538606  0.49588132]] [0m
[92mRank: 0, Outputscale: 0.7635506987571716 [0m
[92mRank: 0, Noise: 0.045482926070690155 [0m
Run 9 completed successfully
Running apxGP 10 with agents: 16
decpxADMM initialized with rho: 0.85, lip: 1.0, tol_abs: 1e-05, tol_rel: 0.001, rank: 0, world_size: 16
Rank 0 - Epoch 2/32 loss: 0.7402694225311279
Rank 0 - Epoch 10/32 loss: 0.47199052572250366
Rank 0 - Epoch 20/32 loss: 0.049603767693042755
Rank 0 - Epoch 30/32 loss: -0.4488697052001953
Training complete.
[92mRank 0 - Testing RMSE: 3.2030[0m
[92mRank: 0, Lengthscale: [[0.6538233  0.49588093]] [0m
[92mRank: 0, Outputscale: 0.7635518312454224 [0m
[92mRank: 0, Noise: 0.04548269137740135 [0m
Run 10 completed successfully
Running cGP 1 with agents: 16
decADMM initialized with rho: 0.85, max_iter: 5, lr: 0.0001, rank: 0, world_size: 16
Rank 0 - Epoch 2/32 loss: 0.7957143187522888
Rank 0 - Epoch 10/32 loss: 0.7900830507278442
Rank 0 - Epoch 20/32 loss: 0.7830316424369812
Rank 0 - Epoch 30/32 loss: 0.7759549617767334
Training complete.
[92mRank 0 - Testing RMSE: 3.1054[0m
[92mRank: 0, Lengthscale: [[0.66623247 0.6659221 ]] [0m
[92mRank: 0, Outputscale: 0.6664977073669434 [0m
[92mRank: 0, Noise: 0.6637153625488281 [0m
Run 1 completed successfully
Running cGP 2 with agents: 16
decADMM initialized with rho: 0.85, max_iter: 5, lr: 0.0001, rank: 0, world_size: 16
Rank 0 - Epoch 2/32 loss: 0.7957176566123962
Rank 0 - Epoch 10/32 loss: 0.7900955677032471
Rank 0 - Epoch 20/32 loss: 0.7830361127853394
Rank 0 - Epoch 30/32 loss: 0.7759606242179871
Training complete.
[92mRank 0 - Testing RMSE: 3.1054[0m
[92mRank: 0, Lengthscale: [[0.66623247 0.6659221 ]] [0m
[92mRank: 0, Outputscale: 0.6664977073669434 [0m
[92mRank: 0, Noise: 0.6637153625488281 [0m
Run 2 completed successfully
Running cGP 3 with agents: 16
decADMM initialized with rho: 0.85, max_iter: 5, lr: 0.0001, rank: 0, world_size: 16
Rank 0 - Epoch 2/32 loss: 0.7957191467285156
Rank 0 - Epoch 10/32 loss: 0.79009610414505
Rank 0 - Epoch 20/32 loss: 0.7830515503883362
Rank 0 - Epoch 30/32 loss: 0.7759692072868347
Training complete.
[92mRank 0 - Testing RMSE: 3.1054[0m
[92mRank: 0, Lengthscale: [[0.66623247 0.6659221 ]] [0m
[92mRank: 0, Outputscale: 0.6664977073669434 [0m
[92mRank: 0, Noise: 0.6637153625488281 [0m
Run 3 completed successfully
Running cGP 4 with agents: 16
decADMM initialized with rho: 0.85, max_iter: 5, lr: 0.0001, rank: 0, world_size: 16
Rank 0 - Epoch 2/32 loss: 0.7957237362861633
Rank 0 - Epoch 10/32 loss: 0.7900906801223755
Rank 0 - Epoch 20/32 loss: 0.7830319404602051
Rank 0 - Epoch 30/32 loss: 0.7759645581245422
Training complete.
[92mRank 0 - Testing RMSE: 3.1054[0m
[92mRank: 0, Lengthscale: [[0.66623247 0.6659221 ]] [0m
[92mRank: 0, Outputscale: 0.6664977073669434 [0m
[92mRank: 0, Noise: 0.6637153625488281 [0m
Run 4 completed successfully
Running cGP 5 with agents: 16
decADMM initialized with rho: 0.85, max_iter: 5, lr: 0.0001, rank: 0, world_size: 16
Rank 0 - Epoch 2/32 loss: 0.795716404914856
Rank 0 - Epoch 10/32 loss: 0.7900979518890381
Rank 0 - Epoch 20/32 loss: 0.783029317855835
Rank 0 - Epoch 30/32 loss: 0.7759706377983093
Training complete.
[92mRank 0 - Testing RMSE: 3.1054[0m
[92mRank: 0, Lengthscale: [[0.66623247 0.6659221 ]] [0m
[92mRank: 0, Outputscale: 0.6664977073669434 [0m
[92mRank: 0, Noise: 0.6637153625488281 [0m
Run 5 completed successfully
Running cGP 6 with agents: 16
decADMM initialized with rho: 0.85, max_iter: 5, lr: 0.0001, rank: 0, world_size: 16
Rank 0 - Epoch 2/32 loss: 0.7957305908203125
Rank 0 - Epoch 10/32 loss: 0.7900933027267456
Rank 0 - Epoch 20/32 loss: 0.7830343842506409
Rank 0 - Epoch 30/32 loss: 0.7759597897529602
Training complete.
[92mRank 0 - Testing RMSE: 3.1054[0m
[92mRank: 0, Lengthscale: [[0.66623247 0.6659221 ]] [0m
[92mRank: 0, Outputscale: 0.6664977073669434 [0m
[92mRank: 0, Noise: 0.6637153625488281 [0m
Run 6 completed successfully
Running cGP 7 with agents: 16
decADMM initialized with rho: 0.85, max_iter: 5, lr: 0.0001, rank: 0, world_size: 16
Rank 0 - Epoch 2/32 loss: 0.7957158088684082
Rank 0 - Epoch 10/32 loss: 0.7900885939598083
Rank 0 - Epoch 20/32 loss: 0.7830407023429871
Rank 0 - Epoch 30/32 loss: 0.7759684920310974
Training complete.
[92mRank 0 - Testing RMSE: 3.1054[0m
[92mRank: 0, Lengthscale: [[0.66623247 0.6659221 ]] [0m
[92mRank: 0, Outputscale: 0.6664977073669434 [0m
[92mRank: 0, Noise: 0.6637153625488281 [0m
Run 7 completed successfully
Running cGP 8 with agents: 16
decADMM initialized with rho: 0.85, max_iter: 5, lr: 0.0001, rank: 0, world_size: 16
Rank 0 - Epoch 2/32 loss: 0.7957159876823425
Rank 0 - Epoch 10/32 loss: 0.790098249912262
Rank 0 - Epoch 20/32 loss: 0.7830439209938049
Rank 0 - Epoch 30/32 loss: 0.7759645581245422
Training complete.
[92mRank 0 - Testing RMSE: 3.1054[0m
[92mRank: 0, Lengthscale: [[0.66623247 0.6659221 ]] [0m
[92mRank: 0, Outputscale: 0.6664977073669434 [0m
[92mRank: 0, Noise: 0.6637153625488281 [0m
Run 8 completed successfully
Running cGP 9 with agents: 16
decADMM initialized with rho: 0.85, max_iter: 5, lr: 0.0001, rank: 0, world_size: 16
Rank 0 - Epoch 2/32 loss: 0.7957245111465454
Rank 0 - Epoch 10/32 loss: 0.7901005744934082
Rank 0 - Epoch 20/32 loss: 0.7830459475517273
Rank 0 - Epoch 30/32 loss: 0.7759642601013184
Training complete.
[92mRank 0 - Testing RMSE: 3.1054[0m
[92mRank: 0, Lengthscale: [[0.66623247 0.6659221 ]] [0m
[92mRank: 0, Outputscale: 0.6664977073669434 [0m
[92mRank: 0, Noise: 0.6637153625488281 [0m
Run 9 completed successfully
Running cGP 10 with agents: 16
decADMM initialized with rho: 0.85, max_iter: 5, lr: 0.0001, rank: 0, world_size: 16
Rank 0 - Epoch 2/32 loss: 0.7957167029380798
Rank 0 - Epoch 10/32 loss: 0.7900978922843933
Rank 0 - Epoch 20/32 loss: 0.7830365300178528
Rank 0 - Epoch 30/32 loss: 0.7759643793106079
Training complete.
[92mRank 0 - Testing RMSE: 3.1054[0m
[92mRank: 0, Lengthscale: [[0.66623247 0.6659221 ]] [0m
[92mRank: 0, Outputscale: 0.6664977073669434 [0m
[92mRank: 0, Noise: 0.6637153625488281 [0m
Run 10 completed successfully
Running pxpGP 1 with agents: 36
[92mRank 0 - sparse dataset size is: 25, local dataset: torch.Size([900, 2]), [0m
[92mRank 0 - Training local sparse GP model with 900 samples[0m
Epoch 1/200 - Loss: 11.755
Epoch 11/200 - Loss: 1.182
Epoch 21/200 - Loss: 0.947
Epoch 31/200 - Loss: 0.740
Epoch 41/200 - Loss: 0.509
Epoch 51/200 - Loss: 0.165
Converged at epoch 56 with loss -0.029
[92mRank 0 - Lengthscale: [[0.5788373  0.25718567]] [0m
[92mRank 0 - Outputscale: 2.197270393371582 [0m
[92mRank 0 - Noise: 0.13111406564712524 [0m
Rank 0 - Augmented dataset size: 1800
Rank 0: After warm start model parameters:
Rank: 0, Lengthscale: [[0.5788372 0.2571857]]
Rank: 0, Outputscale: 2.197270393371582
Rank: 0, Noise: 0.13111406564712524
decpxADMM initialized with rho: 0.85, lip: 1.0, tol_abs: 1e-05, tol_rel: 0.001, rank: 0, world_size: 36
[92mRank 0 - Training global model with dec-pxADMM optimizer[0m
rank 0, epoch 9, loss: 0.6214447617530823, rho: 0.4250, lip: 1.0000
rank 0, epoch 19, loss: 0.6300837993621826, rho: 0.0531, lip: 1.0000
rank 0, epoch 29, loss: 0.6349239349365234, rho: 0.0531, lip: 1.0000
rank 0, epoch 39, loss: 0.6266373991966248, rho: 0.0531, lip: 1.0000
rank 0, epoch 49, loss: 0.6210788488388062, rho: 0.0531, lip: 1.0000
Rank 0 - Training time: 102.63 seconds
[92mRank 0 - Testing RMSE: 0.3925[0m
[92mRank: 0, Lengthscale: [[0.725662   0.25557524]] [0m
[92mRank: 0, Outputscale: 1.952700138092041 [0m
[92mRank: 0, Noise: 0.15302196145057678 [0m
Run 1 completed successfully
Running pxpGP 2 with agents: 36
[92mRank 0 - sparse dataset size is: 25, local dataset: torch.Size([900, 2]), [0m
[92mRank 0 - Training local sparse GP model with 900 samples[0m
Epoch 1/200 - Loss: 12.374
Epoch 11/200 - Loss: 0.994
Epoch 21/200 - Loss: 0.851
Epoch 31/200 - Loss: 0.651
Epoch 41/200 - Loss: 0.379
Epoch 51/200 - Loss: 0.025
Converged at epoch 52 with loss -0.008
[92mRank 0 - Lengthscale: [[0.7340956  0.37573266]] [0m
[92mRank 0 - Outputscale: 1.7638039588928223 [0m
[92mRank 0 - Noise: 0.14105084538459778 [0m
Rank 0 - Augmented dataset size: 1800
Rank 0: After warm start model parameters:
Rank: 0, Lengthscale: [[0.7340955 0.3757327]]
Rank: 0, Outputscale: 1.7638039588928223
Rank: 0, Noise: 0.14105086028575897
decpxADMM initialized with rho: 0.85, lip: 1.0, tol_abs: 1e-05, tol_rel: 0.001, rank: 0, world_size: 36
[92mRank 0 - Training global model with dec-pxADMM optimizer[0m
rank 0, epoch 9, loss: 0.5582901239395142, rho: 0.2125, lip: 1.0000
rank 0, epoch 19, loss: 0.5703850388526917, rho: 0.0531, lip: 1.0000
rank 0, epoch 29, loss: 0.5849647521972656, rho: 0.0531, lip: 1.0000
rank 0, epoch 39, loss: 0.5756843686103821, rho: 0.0531, lip: 1.0000
rank 0, epoch 49, loss: 0.5799295902252197, rho: 0.0266, lip: 1.0000
Rank 0 - Training time: 65.29 seconds
[92mRank 0 - Testing RMSE: 0.3719[0m
[92mRank: 0, Lengthscale: [[0.5694363  0.37992525]] [0m
[92mRank: 0, Outputscale: 0.8798928260803223 [0m
[92mRank: 0, Noise: 0.14432211220264435 [0m
Run 2 completed successfully
Running pxpGP 3 with agents: 36
[92mRank 0 - sparse dataset size is: 25, local dataset: torch.Size([900, 2]), [0m
[92mRank 0 - Training local sparse GP model with 900 samples[0m
Epoch 1/200 - Loss: 13.168
Epoch 11/200 - Loss: 1.143
Epoch 21/200 - Loss: 0.991
Epoch 31/200 - Loss: 0.772
Epoch 41/200 - Loss: 0.529
Epoch 51/200 - Loss: 0.194
Converged at epoch 57 with loss -0.032
[92mRank 0 - Lengthscale: [[0.360219  0.2831605]] [0m
[92mRank 0 - Outputscale: 2.2203571796417236 [0m
[92mRank 0 - Noise: 0.12795241177082062 [0m
Rank 0 - Augmented dataset size: 1800
Rank 0: After warm start model parameters:
Rank: 0, Lengthscale: [[0.360219  0.2831605]]
Rank: 0, Outputscale: 2.2203571796417236
Rank: 0, Noise: 0.1279524266719818
decpxADMM initialized with rho: 0.85, lip: 1.0, tol_abs: 1e-05, tol_rel: 0.001, rank: 0, world_size: 36
[92mRank 0 - Training global model with dec-pxADMM optimizer[0m
rank 0, epoch 9, loss: 0.6350702047348022, rho: 0.4250, lip: 1.0000
rank 0, epoch 19, loss: 0.6546028852462769, rho: 0.1062, lip: 1.0000
rank 0, epoch 29, loss: 0.645984947681427, rho: 0.1062, lip: 1.0000
rank 0, epoch 39, loss: 0.6329575181007385, rho: 0.1062, lip: 1.0000
rank 0, epoch 49, loss: 0.6316045522689819, rho: 0.0266, lip: 1.0000
Rank 0 - Training time: 78.82 seconds
[92mRank 0 - Testing RMSE: 0.3993[0m
[92mRank: 0, Lengthscale: [[0.69487387 0.34490097]] [0m
[92mRank: 0, Outputscale: 0.9130701422691345 [0m
[92mRank: 0, Noise: 0.15680918097496033 [0m
Run 3 completed successfully
Running pxpGP 4 with agents: 36
[92mRank 0 - sparse dataset size is: 25, local dataset: torch.Size([900, 2]), [0m
[92mRank 0 - Training local sparse GP model with 900 samples[0m
Epoch 1/200 - Loss: 11.812
Epoch 11/200 - Loss: 1.166
Epoch 21/200 - Loss: 0.953
Epoch 31/200 - Loss: 0.746
Epoch 41/200 - Loss: 0.486
Epoch 51/200 - Loss: 0.142
Converged at epoch 55 with loss -0.015
[92mRank 0 - Lengthscale: [[0.7225464 0.2564942]] [0m
[92mRank 0 - Outputscale: 2.35599684715271 [0m
[92mRank 0 - Noise: 0.1369205266237259 [0m
Rank 0 - Augmented dataset size: 1800
Rank 0: After warm start model parameters:
Rank: 0, Lengthscale: [[0.7225464 0.2564942]]
Rank: 0, Outputscale: 2.35599684715271
Rank: 0, Noise: 0.1369205117225647
decpxADMM initialized with rho: 0.85, lip: 1.0, tol_abs: 1e-05, tol_rel: 0.001, rank: 0, world_size: 36
[92mRank 0 - Training global model with dec-pxADMM optimizer[0m
rank 0, epoch 9, loss: 0.6265493035316467, rho: 0.4250, lip: 1.0000
rank 0, epoch 19, loss: 0.6724558472633362, rho: 0.2125, lip: 1.0000
rank 0, epoch 29, loss: 0.6434239149093628, rho: 0.1062, lip: 1.0000
rank 0, epoch 39, loss: 0.6191397309303284, rho: 0.1062, lip: 1.0000
rank 0, epoch 49, loss: 0.6196475028991699, rho: 0.0266, lip: 1.0000
Rank 0 - Training time: 93.99 seconds
[92mRank 0 - Testing RMSE: 0.3674[0m
[92mRank: 0, Lengthscale: [[0.8268551 0.3082589]] [0m
[92mRank: 0, Outputscale: 1.18985915184021 [0m
[92mRank: 0, Noise: 0.15174925327301025 [0m
Run 4 completed successfully
Running pxpGP 5 with agents: 36
[92mRank 0 - sparse dataset size is: 25, local dataset: torch.Size([900, 2]), [0m
[92mRank 0 - Training local sparse GP model with 900 samples[0m
Epoch 1/200 - Loss: 10.625
Epoch 11/200 - Loss: 1.064
Epoch 21/200 - Loss: 0.963
Epoch 31/200 - Loss: 0.862
Epoch 41/200 - Loss: 0.479
Epoch 51/200 - Loss: 0.150
Converged at epoch 56 with loss -0.032
[92mRank 0 - Lengthscale: [[0.35212418 0.40372416]] [0m
[92mRank 0 - Outputscale: 2.2486019134521484 [0m
[92mRank 0 - Noise: 0.13013572990894318 [0m
Rank 0 - Augmented dataset size: 1800
Rank 0: After warm start model parameters:
Rank: 0, Lengthscale: [[0.35212415 0.40372416]]
Rank: 0, Outputscale: 2.2486019134521484
Rank: 0, Noise: 0.13013572990894318
decpxADMM initialized with rho: 0.85, lip: 1.0, tol_abs: 1e-05, tol_rel: 0.001, rank: 0, world_size: 36
[92mRank 0 - Training global model with dec-pxADMM optimizer[0m
rank 0, epoch 9, loss: 0.7116786241531372, rho: 0.4250, lip: 1.0000
rank 0, epoch 19, loss: 0.7121882438659668, rho: 0.1062, lip: 1.0000
rank 0, epoch 29, loss: 0.7163097858428955, rho: 0.1062, lip: 1.0000
rank 0, epoch 39, loss: 0.7225816249847412, rho: 0.1062, lip: 1.0000
rank 0, epoch 49, loss: 0.7312847375869751, rho: 0.0531, lip: 1.0000
Rank 0 - Training time: 95.18 seconds
[92mRank 0 - Testing RMSE: 0.4664[0m
[92mRank: 0, Lengthscale: [[0.2592717  0.40902242]] [0m
[92mRank: 0, Outputscale: 1.6345043182373047 [0m
[92mRank: 0, Noise: 0.1659432351589203 [0m
Run 5 completed successfully
Running pxpGP 6 with agents: 36
[92mRank 0 - sparse dataset size is: 25, local dataset: torch.Size([900, 2]), [0m
[92mRank 0 - Training local sparse GP model with 900 samples[0m
Epoch 1/200 - Loss: 10.394
Epoch 11/200 - Loss: 0.988
Epoch 21/200 - Loss: 0.856
Epoch 31/200 - Loss: 0.664
Epoch 41/200 - Loss: 0.407
Epoch 51/200 - Loss: 0.067
Converged at epoch 53 with loss -0.007
[92mRank 0 - Lengthscale: [[0.68666106 0.39941436]] [0m
[92mRank 0 - Outputscale: 1.7768516540527344 [0m
[92mRank 0 - Noise: 0.1421874463558197 [0m
Rank 0 - Augmented dataset size: 1800
Rank 0: After warm start model parameters:
Rank: 0, Lengthscale: [[0.68666106 0.39941433]]
Rank: 0, Outputscale: 1.7768516540527344
Rank: 0, Noise: 0.1421874314546585
decpxADMM initialized with rho: 0.85, lip: 1.0, tol_abs: 1e-05, tol_rel: 0.001, rank: 0, world_size: 36
[92mRank 0 - Training global model with dec-pxADMM optimizer[0m
rank 0, epoch 9, loss: 0.5857089757919312, rho: 0.2125, lip: 1.0000
rank 0, epoch 19, loss: 0.5959532260894775, rho: 0.1062, lip: 1.0000
rank 0, epoch 29, loss: 0.6060024499893188, rho: 0.1062, lip: 1.0000
rank 0, epoch 39, loss: 0.6014634966850281, rho: 0.0531, lip: 1.0000
rank 0, epoch 49, loss: 0.6164000630378723, rho: 0.0531, lip: 1.0000
Rank 0 - Training time: 65.45 seconds
[92mRank 0 - Testing RMSE: 0.3737[0m
[92mRank: 0, Lengthscale: [[0.38257164 0.43152657]] [0m
[92mRank: 0, Outputscale: 0.8131837844848633 [0m
[92mRank: 0, Noise: 0.13816621899604797 [0m
Run 6 completed successfully
Running pxpGP 7 with agents: 36
[92mRank 0 - sparse dataset size is: 25, local dataset: torch.Size([900, 2]), [0m
[92mRank 0 - Training local sparse GP model with 900 samples[0m
Epoch 1/200 - Loss: 11.772
Epoch 11/200 - Loss: 1.214
Epoch 21/200 - Loss: 0.932
Epoch 31/200 - Loss: 0.778
Epoch 41/200 - Loss: 0.513
Epoch 51/200 - Loss: 0.176
Converged at epoch 56 with loss -0.031
[92mRank 0 - Lengthscale: [[0.42648202 0.33954263]] [0m
[92mRank 0 - Outputscale: 2.2251508235931396 [0m
[92mRank 0 - Noise: 0.12988385558128357 [0m
Rank 0 - Augmented dataset size: 1800
Rank 0: After warm start model parameters:
Rank: 0, Lengthscale: [[0.42648202 0.33954263]]
Rank: 0, Outputscale: 2.2251508235931396
Rank: 0, Noise: 0.12988385558128357
decpxADMM initialized with rho: 0.85, lip: 1.0, tol_abs: 1e-05, tol_rel: 0.001, rank: 0, world_size: 36
[92mRank 0 - Training global model with dec-pxADMM optimizer[0m
rank 0, epoch 9, loss: 0.572790801525116, rho: 0.4250, lip: 1.0000
rank 0, epoch 19, loss: 0.5748395323753357, rho: 0.1062, lip: 1.0000
rank 0, epoch 29, loss: 0.562627375125885, rho: 0.1062, lip: 1.0000
rank 0, epoch 39, loss: 0.5784611701965332, rho: 0.0531, lip: 1.0000
rank 0, epoch 49, loss: 0.5828077793121338, rho: 0.0531, lip: 1.0000
Rank 0 - Training time: 65.09 seconds
[92mRank 0 - Testing RMSE: 0.3566[0m
[92mRank: 0, Lengthscale: [[0.6235566  0.35008976]] [0m
[92mRank: 0, Outputscale: 0.9946645498275757 [0m
[92mRank: 0, Noise: 0.14242888987064362 [0m
Run 7 completed successfully
Running pxpGP 8 with agents: 36
[92mRank 0 - sparse dataset size is: 25, local dataset: torch.Size([900, 2]), [0m
[92mRank 0 - Training local sparse GP model with 900 samples[0m
Epoch 1/200 - Loss: 12.416
Epoch 11/200 - Loss: 0.985
Epoch 21/200 - Loss: 0.863
Epoch 31/200 - Loss: 0.670
Epoch 41/200 - Loss: 0.407
Epoch 51/200 - Loss: 0.068
Converged at epoch 53 with loss -0.008
[92mRank 0 - Lengthscale: [[0.6962245  0.36191562]] [0m
[92mRank 0 - Outputscale: 1.7029907703399658 [0m
[92mRank 0 - Noise: 0.14201277494430542 [0m
Rank 0 - Augmented dataset size: 1800
Rank 0: After warm start model parameters:
Rank: 0, Lengthscale: [[0.6962245  0.36191562]]
Rank: 0, Outputscale: 1.7029907703399658
Rank: 0, Noise: 0.1420127898454666
decpxADMM initialized with rho: 0.85, lip: 1.0, tol_abs: 1e-05, tol_rel: 0.001, rank: 0, world_size: 36
[92mRank 0 - Training global model with dec-pxADMM optimizer[0m
rank 0, epoch 9, loss: 0.5124931931495667, rho: 0.2125, lip: 1.0000
rank 0, epoch 19, loss: 0.5230447053909302, rho: 0.1062, lip: 1.0000
rank 0, epoch 29, loss: 0.5311524271965027, rho: 0.1062, lip: 1.0000
rank 0, epoch 39, loss: 0.5140131115913391, rho: 0.0531, lip: 1.0000
rank 0, epoch 49, loss: 0.5184649229049683, rho: 0.0531, lip: 1.0000
Rank 0 - Training time: 100.55 seconds
[92mRank 0 - Testing RMSE: 0.3598[0m
[92mRank: 0, Lengthscale: [[0.66409546 0.33519125]] [0m
[92mRank: 0, Outputscale: 1.0139628648757935 [0m
[92mRank: 0, Noise: 0.12204912304878235 [0m
Run 8 completed successfully
Running pxpGP 9 with agents: 36
[92mRank 0 - sparse dataset size is: 25, local dataset: torch.Size([900, 2]), [0m
[92mRank 0 - Training local sparse GP model with 900 samples[0m
Epoch 1/200 - Loss: 10.982
Epoch 11/200 - Loss: 1.033
Epoch 21/200 - Loss: 0.895
Epoch 31/200 - Loss: 0.725
Epoch 41/200 - Loss: 0.478
Epoch 51/200 - Loss: 0.139
Converged at epoch 55 with loss -0.018
[92mRank 0 - Lengthscale: [[0.44466293 0.321495  ]] [0m
[92mRank 0 - Outputscale: 2.0494940280914307 [0m
[92mRank 0 - Noise: 0.13029706478118896 [0m
Rank 0 - Augmented dataset size: 1800
Rank 0: After warm start model parameters:
Rank: 0, Lengthscale: [[0.44466293 0.321495  ]]
Rank: 0, Outputscale: 2.0494940280914307
Rank: 0, Noise: 0.13029706478118896
decpxADMM initialized with rho: 0.85, lip: 1.0, tol_abs: 1e-05, tol_rel: 0.001, rank: 0, world_size: 36
[92mRank 0 - Training global model with dec-pxADMM optimizer[0m
rank 0, epoch 9, loss: 0.46488919854164124, rho: 0.2125, lip: 1.0000
rank 0, epoch 19, loss: 0.4647824466228485, rho: 0.1062, lip: 1.0000
rank 0, epoch 29, loss: 0.47183936834335327, rho: 0.1062, lip: 1.0000
rank 0, epoch 39, loss: 0.46072471141815186, rho: 0.0531, lip: 1.0000
rank 0, epoch 49, loss: 0.46010202169418335, rho: 0.0531, lip: 1.0000
Rank 0 - Training time: 87.24 seconds
[92mRank 0 - Testing RMSE: 0.3580[0m
[92mRank: 0, Lengthscale: [[0.6195989  0.35149217]] [0m
[92mRank: 0, Outputscale: 1.1738996505737305 [0m
[92mRank: 0, Noise: 0.1145457848906517 [0m
Run 9 completed successfully
Running pxpGP 10 with agents: 36
[92mRank 0 - sparse dataset size is: 25, local dataset: torch.Size([900, 2]), [0m
[92mRank 0 - Training local sparse GP model with 900 samples[0m
Epoch 1/200 - Loss: 11.747
Epoch 11/200 - Loss: 1.121
Epoch 21/200 - Loss: 1.002
Epoch 31/200 - Loss: 0.766
Epoch 41/200 - Loss: 0.498
Epoch 51/200 - Loss: 0.162
Converged at epoch 56 with loss -0.031
[92mRank 0 - Lengthscale: [[0.72016495 0.1847857 ]] [0m
[92mRank 0 - Outputscale: 2.293586492538452 [0m
[92mRank 0 - Noise: 0.1311914175748825 [0m
Rank 0 - Augmented dataset size: 1800
Rank 0: After warm start model parameters:
Rank: 0, Lengthscale: [[0.7201649  0.18478571]]
Rank: 0, Outputscale: 2.293586492538452
Rank: 0, Noise: 0.1311914175748825
decpxADMM initialized with rho: 0.85, lip: 1.0, tol_abs: 1e-05, tol_rel: 0.001, rank: 0, world_size: 36
[92mRank 0 - Training global model with dec-pxADMM optimizer[0m
rank 0, epoch 9, loss: 0.6352298855781555, rho: 0.2125, lip: 1.0000
rank 0, epoch 19, loss: 0.6747802495956421, rho: 0.0531, lip: 1.0000
rank 0, epoch 29, loss: 0.7364975214004517, rho: 0.0531, lip: 1.0000
rank 0, epoch 39, loss: 0.7482911348342896, rho: 0.0531, lip: 1.0000
rank 0, epoch 49, loss: 0.7273915410041809, rho: 0.0531, lip: 1.0000
Rank 0 - Training time: 72.49 seconds
[92mRank 0 - Testing RMSE: 0.3739[0m
[92mRank: 0, Lengthscale: [[0.74311894 0.35080087]] [0m
[92mRank: 0, Outputscale: 0.6033537983894348 [0m
[92mRank: 0, Noise: 0.1785576343536377 [0m
Run 10 completed successfully
Running gapxGP 1 with agents: 36
decpxADMM initialized with rho: 0.75, lip: 1.0, tol_abs: 1e-05, tol_rel: 0.001, rank: 0, world_size: 36
Rank 0 - Epoch 2/54 loss: 0.8751411437988281
Rank 0 - Epoch 10/54 loss: 0.6130646467208862
Rank 0 - Epoch 20/54 loss: 0.21315312385559082
Rank 0 - Epoch 30/54 loss: -0.27991437911987305
Rank 0 - Epoch 40/54 loss: -0.7870509624481201
Rank 0 - Epoch 50/54 loss: -1.2890195846557617
[92mRank 0 - Testing RMSE: 0.0448[0m
[92mRank: 0, Lengthscale: [[0.6108383  0.35726076]] [0m
[92mRank: 0, Outputscale: 1.120125412940979 [0m
[92mRank: 0, Noise: 0.004060475155711174 [0m
Run 1 completed successfully
Running gapxGP 2 with agents: 36
decpxADMM initialized with rho: 0.75, lip: 1.0, tol_abs: 1e-05, tol_rel: 0.001, rank: 0, world_size: 36
Rank 0 - Epoch 2/54 loss: 0.875965416431427
Rank 0 - Epoch 10/54 loss: 0.6182526350021362
Rank 0 - Epoch 20/54 loss: 0.208359032869339
Rank 0 - Epoch 30/54 loss: -0.2956187427043915
Rank 0 - Epoch 40/54 loss: -0.7936521172523499
Rank 0 - Epoch 50/54 loss: -1.3059550523757935
[92mRank 0 - Testing RMSE: 0.0572[0m
[92mRank: 0, Lengthscale: [[0.61623967 0.35723186]] [0m
[92mRank: 0, Outputscale: 1.1226882934570312 [0m
[92mRank: 0, Noise: 0.004012032877653837 [0m
Run 2 completed successfully
Running gapxGP 3 with agents: 36
decpxADMM initialized with rho: 0.75, lip: 1.0, tol_abs: 1e-05, tol_rel: 0.001, rank: 0, world_size: 36
Rank 0 - Epoch 2/54 loss: 0.8685539960861206
Rank 0 - Epoch 10/54 loss: 0.6101386547088623
Rank 0 - Epoch 20/54 loss: 0.20273835957050323
Rank 0 - Epoch 30/54 loss: -0.2783428132534027
Rank 0 - Epoch 40/54 loss: -0.783716082572937
Rank 0 - Epoch 50/54 loss: -1.2601207494735718
[92mRank 0 - Testing RMSE: 0.0522[0m
[92mRank: 0, Lengthscale: [[0.6090879  0.35925516]] [0m
[92mRank: 0, Outputscale: 1.115809440612793 [0m
[92mRank: 0, Noise: 0.004026892129331827 [0m
Run 3 completed successfully
Running gapxGP 4 with agents: 36
decpxADMM initialized with rho: 0.75, lip: 1.0, tol_abs: 1e-05, tol_rel: 0.001, rank: 0, world_size: 36
Rank 0 - Epoch 2/54 loss: 0.878351628780365
Rank 0 - Epoch 10/54 loss: 0.6148201823234558
Rank 0 - Epoch 20/54 loss: 0.21320277452468872
Rank 0 - Epoch 30/54 loss: -0.2829214930534363
Rank 0 - Epoch 40/54 loss: -0.7919145226478577
Rank 0 - Epoch 50/54 loss: -1.276299238204956
[92mRank 0 - Testing RMSE: 0.0573[0m
[92mRank: 0, Lengthscale: [[0.6084136  0.35683602]] [0m
[92mRank: 0, Outputscale: 1.1233477592468262 [0m
[92mRank: 0, Noise: 0.004004957620054483 [0m
Run 4 completed successfully
Running gapxGP 5 with agents: 36
decpxADMM initialized with rho: 0.75, lip: 1.0, tol_abs: 1e-05, tol_rel: 0.001, rank: 0, world_size: 36
Rank 0 - Epoch 2/54 loss: 0.8744783401489258
Rank 0 - Epoch 10/54 loss: 0.6170273423194885
Rank 0 - Epoch 20/54 loss: 0.20380976796150208
Rank 0 - Epoch 30/54 loss: -0.2909304201602936
Rank 0 - Epoch 40/54 loss: -0.7995727062225342
Rank 0 - Epoch 50/54 loss: -1.2785096168518066
[92mRank 0 - Testing RMSE: 0.0586[0m
[92mRank: 0, Lengthscale: [[0.6126671  0.36008587]] [0m
[92mRank: 0, Outputscale: 1.12251877784729 [0m
[92mRank: 0, Noise: 0.004013247322291136 [0m
Run 5 completed successfully
Running gapxGP 6 with agents: 36
decpxADMM initialized with rho: 0.75, lip: 1.0, tol_abs: 1e-05, tol_rel: 0.001, rank: 0, world_size: 36
Rank 0 - Epoch 2/54 loss: 0.8765931725502014
Rank 0 - Epoch 10/54 loss: 0.6204981803894043
Rank 0 - Epoch 20/54 loss: 0.2162829488515854
Rank 0 - Epoch 30/54 loss: -0.2711925804615021
Rank 0 - Epoch 40/54 loss: -0.7914796471595764
Rank 0 - Epoch 50/54 loss: -1.2546377182006836
[92mRank 0 - Testing RMSE: 0.0501[0m
[92mRank: 0, Lengthscale: [[0.6080391  0.35734674]] [0m
[92mRank: 0, Outputscale: 1.119394063949585 [0m
[92mRank: 0, Noise: 0.004063703119754791 [0m
Run 6 completed successfully
Running gapxGP 7 with agents: 36
decpxADMM initialized with rho: 0.75, lip: 1.0, tol_abs: 1e-05, tol_rel: 0.001, rank: 0, world_size: 36
Rank 0 - Epoch 2/54 loss: 0.8776863813400269
Rank 0 - Epoch 10/54 loss: 0.6158359050750732
Rank 0 - Epoch 20/54 loss: 0.2109387367963791
Rank 0 - Epoch 30/54 loss: -0.2843008041381836
Rank 0 - Epoch 40/54 loss: -0.7912297248840332
Rank 0 - Epoch 50/54 loss: -1.2602198123931885
[92mRank 0 - Testing RMSE: 0.0518[0m
[92mRank: 0, Lengthscale: [[0.6130285 0.3598916]] [0m
[92mRank: 0, Outputscale: 1.1208481788635254 [0m
[92mRank: 0, Noise: 0.004035404417663813 [0m
Run 7 completed successfully
Running gapxGP 8 with agents: 36
decpxADMM initialized with rho: 0.75, lip: 1.0, tol_abs: 1e-05, tol_rel: 0.001, rank: 0, world_size: 36
Rank 0 - Epoch 2/54 loss: 0.8761274218559265
Rank 0 - Epoch 10/54 loss: 0.6140189170837402
Rank 0 - Epoch 20/54 loss: 0.2119191586971283
Rank 0 - Epoch 30/54 loss: -0.28340277075767517
Rank 0 - Epoch 40/54 loss: -0.8018336892127991
Rank 0 - Epoch 50/54 loss: -1.2694319486618042
[92mRank 0 - Testing RMSE: 0.0534[0m
[92mRank: 0, Lengthscale: [[0.61118215 0.3617437 ]] [0m
[92mRank: 0, Outputscale: 1.1204798221588135 [0m
[92mRank: 0, Noise: 0.004032307770103216 [0m
Run 8 completed successfully
Running gapxGP 9 with agents: 36
decpxADMM initialized with rho: 0.75, lip: 1.0, tol_abs: 1e-05, tol_rel: 0.001, rank: 0, world_size: 36
Rank 0 - Epoch 2/54 loss: 0.8733950853347778
Rank 0 - Epoch 10/54 loss: 0.6153650879859924
Rank 0 - Epoch 20/54 loss: 0.2183251976966858
Rank 0 - Epoch 30/54 loss: -0.2710888683795929
Rank 0 - Epoch 40/54 loss: -0.8000286817550659
Rank 0 - Epoch 50/54 loss: -1.2662945985794067
[92mRank 0 - Testing RMSE: 0.0522[0m
[92mRank: 0, Lengthscale: [[0.6083158 0.3578424]] [0m
[92mRank: 0, Outputscale: 1.1196779012680054 [0m
[92mRank: 0, Noise: 0.004064223729074001 [0m
Run 9 completed successfully
Running gapxGP 10 with agents: 36
decpxADMM initialized with rho: 0.75, lip: 1.0, tol_abs: 1e-05, tol_rel: 0.001, rank: 0, world_size: 36
Rank 0 - Epoch 2/54 loss: 0.872301459312439
Rank 0 - Epoch 10/54 loss: 0.6120374798774719
Rank 0 - Epoch 20/54 loss: 0.21394909918308258
Rank 0 - Epoch 30/54 loss: -0.27784571051597595
Rank 0 - Epoch 40/54 loss: -0.7894653081893921
Rank 0 - Epoch 50/54 loss: -1.276518702507019
[92mRank 0 - Testing RMSE: 0.0456[0m
[92mRank: 0, Lengthscale: [[0.61180586 0.35717016]] [0m
[92mRank: 0, Outputscale: 1.1205323934555054 [0m
[92mRank: 0, Noise: 0.0040606483817100525 [0m
Run 10 completed successfully
Running apxGP 1 with agents: 36
decpxADMM initialized with rho: 0.85, lip: 1.0, tol_abs: 1e-05, tol_rel: 0.001, rank: 0, world_size: 36
Rank 0 - Epoch 2/72 loss: 0.7387057542800903
Rank 0 - Epoch 10/72 loss: 0.46895959973335266
Rank 0 - Epoch 20/72 loss: 0.055526189506053925
Rank 0 - Epoch 30/72 loss: -0.4246537387371063
Rank 0 - Epoch 40/72 loss: -0.9572516679763794
Rank 0 - Epoch 50/72 loss: -1.4907739162445068
Rank 0 - Epoch 60/72 loss: -2.0029823780059814
Rank 0 - Epoch 70/72 loss: -2.4689598083496094
Training complete.
[92mRank 0 - Testing RMSE: 3.3016[0m
[92mRank: 0, Lengthscale: [[0.6054058  0.36946172]] [0m
[92mRank: 0, Outputscale: 0.9061048030853271 [0m
[92mRank: 0, Noise: 0.0007692366489209235 [0m
Run 1 completed successfully
Running apxGP 2 with agents: 36
decpxADMM initialized with rho: 0.85, lip: 1.0, tol_abs: 1e-05, tol_rel: 0.001, rank: 0, world_size: 36
Rank 0 - Epoch 2/72 loss: 0.738706111907959
Rank 0 - Epoch 10/72 loss: 0.4689601957798004
Rank 0 - Epoch 20/72 loss: 0.055524833500385284
Rank 0 - Epoch 30/72 loss: -0.42465928196907043
Rank 0 - Epoch 40/72 loss: -0.9572611451148987
Rank 0 - Epoch 50/72 loss: -1.4907945394515991
Rank 0 - Epoch 60/72 loss: -2.002814292907715
Rank 0 - Epoch 70/72 loss: -2.469386339187622
Training complete.
[92mRank 0 - Testing RMSE: 3.3017[0m
[92mRank: 0, Lengthscale: [[0.6051024  0.36936274]] [0m
[92mRank: 0, Outputscale: 0.906158983707428 [0m
[92mRank: 0, Noise: 0.000769187172409147 [0m
Run 2 completed successfully
Running apxGP 3 with agents: 36
decpxADMM initialized with rho: 0.85, lip: 1.0, tol_abs: 1e-05, tol_rel: 0.001, rank: 0, world_size: 36
Rank 0 - Epoch 2/72 loss: 0.7387061715126038
Rank 0 - Epoch 10/72 loss: 0.46895989775657654
Rank 0 - Epoch 20/72 loss: 0.05552429333329201
Rank 0 - Epoch 30/72 loss: -0.424652636051178
Rank 0 - Epoch 40/72 loss: -0.9572497606277466
Rank 0 - Epoch 50/72 loss: -1.4908632040023804
Rank 0 - Epoch 60/72 loss: -2.0023386478424072
Rank 0 - Epoch 70/72 loss: -2.468376398086548
Training complete.
[92mRank 0 - Testing RMSE: 3.2606[0m
[92mRank: 0, Lengthscale: [[0.6049581  0.36905378]] [0m
[92mRank: 0, Outputscale: 0.9062458276748657 [0m
[92mRank: 0, Noise: 0.0007689894991926849 [0m
Run 3 completed successfully
Running apxGP 4 with agents: 36
decpxADMM initialized with rho: 0.85, lip: 1.0, tol_abs: 1e-05, tol_rel: 0.001, rank: 0, world_size: 36
Rank 0 - Epoch 2/72 loss: 0.7387059926986694
Rank 0 - Epoch 10/72 loss: 0.468960702419281
Rank 0 - Epoch 20/72 loss: 0.05552442744374275
Rank 0 - Epoch 30/72 loss: -0.42465412616729736
Rank 0 - Epoch 40/72 loss: -0.9572492241859436
Rank 0 - Epoch 50/72 loss: -1.490809679031372
Rank 0 - Epoch 60/72 loss: -2.0024638175964355
Rank 0 - Epoch 70/72 loss: -2.467618227005005
Training complete.
[92mRank 0 - Testing RMSE: 3.3009[0m
[92mRank: 0, Lengthscale: [[0.6052306  0.36939022]] [0m
[92mRank: 0, Outputscale: 0.9061425924301147 [0m
[92mRank: 0, Noise: 0.0007691652281209826 [0m
Run 4 completed successfully
Running apxGP 5 with agents: 36
decpxADMM initialized with rho: 0.85, lip: 1.0, tol_abs: 1e-05, tol_rel: 0.001, rank: 0, world_size: 36
Rank 0 - Epoch 2/72 loss: 0.7387056946754456
Rank 0 - Epoch 10/72 loss: 0.468960165977478
Rank 0 - Epoch 20/72 loss: 0.055523477494716644
Rank 0 - Epoch 30/72 loss: -0.4246506094932556
Rank 0 - Epoch 40/72 loss: -0.9572587013244629
Rank 0 - Epoch 50/72 loss: -1.4908968210220337
Rank 0 - Epoch 60/72 loss: -2.0026779174804688
Rank 0 - Epoch 70/72 loss: -2.4677441120147705
Training complete.
[92mRank 0 - Testing RMSE: 3.3002[0m
[92mRank: 0, Lengthscale: [[0.6055918  0.36928704]] [0m
[92mRank: 0, Outputscale: 0.90611732006073 [0m
[92mRank: 0, Noise: 0.0007692726794630289 [0m
Run 5 completed successfully
Running apxGP 6 with agents: 36
decpxADMM initialized with rho: 0.85, lip: 1.0, tol_abs: 1e-05, tol_rel: 0.001, rank: 0, world_size: 36
Rank 0 - Epoch 2/72 loss: 0.7387060523033142
Rank 0 - Epoch 10/72 loss: 0.4689599871635437
Rank 0 - Epoch 20/72 loss: 0.05552266538143158
Rank 0 - Epoch 30/72 loss: -0.4246552288532257
Rank 0 - Epoch 40/72 loss: -0.9572693109512329
Rank 0 - Epoch 50/72 loss: -1.4907532930374146
Rank 0 - Epoch 60/72 loss: -2.002915859222412
Rank 0 - Epoch 70/72 loss: -2.468808889389038
Training complete.
[92mRank 0 - Testing RMSE: 3.3008[0m
[92mRank: 0, Lengthscale: [[0.6052728  0.36911815]] [0m
[92mRank: 0, Outputscale: 0.9061909317970276 [0m
[92mRank: 0, Noise: 0.0007690631318837404 [0m
Run 6 completed successfully
Running apxGP 7 with agents: 36
decpxADMM initialized with rho: 0.85, lip: 1.0, tol_abs: 1e-05, tol_rel: 0.001, rank: 0, world_size: 36
Rank 0 - Epoch 2/72 loss: 0.7387060523033142
Rank 0 - Epoch 10/72 loss: 0.46896064281463623
Rank 0 - Epoch 20/72 loss: 0.05552490055561066
Rank 0 - Epoch 30/72 loss: -0.42465290427207947
Rank 0 - Epoch 40/72 loss: -0.9572664499282837
Rank 0 - Epoch 50/72 loss: -1.4908759593963623
Rank 0 - Epoch 60/72 loss: -2.0027918815612793
Rank 0 - Epoch 70/72 loss: -2.469618320465088
Training complete.
[92mRank 0 - Testing RMSE: 3.3019[0m
[92mRank: 0, Lengthscale: [[0.605289  0.3696012]] [0m
[92mRank: 0, Outputscale: 0.9060847163200378 [0m
[92mRank: 0, Noise: 0.0007692174986004829 [0m
Run 7 completed successfully
Running apxGP 8 with agents: 36
decpxADMM initialized with rho: 0.85, lip: 1.0, tol_abs: 1e-05, tol_rel: 0.001, rank: 0, world_size: 36
Rank 0 - Epoch 2/72 loss: 0.7387061715126038
Rank 0 - Epoch 10/72 loss: 0.4689604640007019
Rank 0 - Epoch 20/72 loss: 0.05552408844232559
Rank 0 - Epoch 30/72 loss: -0.4246496558189392
Rank 0 - Epoch 40/72 loss: -0.9572539329528809
Rank 0 - Epoch 50/72 loss: -1.4907804727554321
Rank 0 - Epoch 60/72 loss: -2.0020365715026855
Rank 0 - Epoch 70/72 loss: -2.468174695968628
Training complete.
[92mRank 0 - Testing RMSE: 3.3018[0m
[92mRank: 0, Lengthscale: [[0.6049693  0.36896545]] [0m
[92mRank: 0, Outputscale: 0.9062142968177795 [0m
[92mRank: 0, Noise: 0.0007690650527365506 [0m
Run 8 completed successfully
Running apxGP 9 with agents: 36
decpxADMM initialized with rho: 0.85, lip: 1.0, tol_abs: 1e-05, tol_rel: 0.001, rank: 0, world_size: 36
Rank 0 - Epoch 2/72 loss: 0.7387059926986694
Rank 0 - Epoch 10/72 loss: 0.46895986795425415
Rank 0 - Epoch 20/72 loss: 0.055524494498968124
Rank 0 - Epoch 30/72 loss: -0.4246525168418884
Rank 0 - Epoch 40/72 loss: -0.9572685956954956
Rank 0 - Epoch 50/72 loss: -1.4907779693603516
Rank 0 - Epoch 60/72 loss: -2.002526044845581
Rank 0 - Epoch 70/72 loss: -2.468594551086426
Training complete.
[92mRank 0 - Testing RMSE: 3.2605[0m
[92mRank: 0, Lengthscale: [[0.6050698  0.36937493]] [0m
[92mRank: 0, Outputscale: 0.9061704874038696 [0m
[92mRank: 0, Noise: 0.000769125996157527 [0m
Run 9 completed successfully
Running apxGP 10 with agents: 36
decpxADMM initialized with rho: 0.85, lip: 1.0, tol_abs: 1e-05, tol_rel: 0.001, rank: 0, world_size: 36
Rank 0 - Epoch 2/72 loss: 0.7387062311172485
Rank 0 - Epoch 10/72 loss: 0.468959778547287
Rank 0 - Epoch 20/72 loss: 0.05552666634321213
Rank 0 - Epoch 30/72 loss: -0.42465347051620483
Rank 0 - Epoch 40/72 loss: -0.9572554230690002
Rank 0 - Epoch 50/72 loss: -1.4907866716384888
Rank 0 - Epoch 60/72 loss: -2.0022239685058594
Rank 0 - Epoch 70/72 loss: -2.469733715057373
Training complete.
[92mRank 0 - Testing RMSE: 3.3011[0m
[92mRank: 0, Lengthscale: [[0.6050302  0.36920866]] [0m
[92mRank: 0, Outputscale: 0.906185507774353 [0m
[92mRank: 0, Noise: 0.0007691007340326905 [0m
Run 10 completed successfully
Running cGP 1 with agents: 36
decADMM initialized with rho: 0.85, max_iter: 5, lr: 0.0001, rank: 0, world_size: 36
Rank 0 - Epoch 2/72 loss: 0.8017228245735168
Rank 0 - Epoch 10/72 loss: 0.7921579480171204
Rank 0 - Epoch 20/72 loss: 0.7859084606170654
Rank 0 - Epoch 30/72 loss: 0.7747172713279724
Rank 0 - Epoch 40/72 loss: 0.7687931060791016
Rank 0 - Epoch 50/72 loss: 0.7657227516174316
Rank 0 - Epoch 60/72 loss: 0.7547752261161804
Rank 0 - Epoch 70/72 loss: 0.7528828978538513
Training complete.
[92mRank 0 - Testing RMSE: 3.5951[0m
[92mRank: 0, Lengthscale: [[0.6339295 0.6333183]] [0m
[92mRank: 0, Outputscale: 0.6342712044715881 [0m
[92mRank: 0, Noise: 0.6279333233833313 [0m
Run 1 completed successfully
Running cGP 2 with agents: 36
decADMM initialized with rho: 0.85, max_iter: 5, lr: 0.0001, rank: 0, world_size: 36
Rank 0 - Epoch 2/72 loss: 0.7947655320167542
Rank 0 - Epoch 10/72 loss: 0.7914739847183228
Rank 0 - Epoch 20/72 loss: 0.7844724059104919
Rank 0 - Epoch 30/72 loss: 0.7774569988250732
Rank 0 - Epoch 40/72 loss: 0.7745897173881531
Rank 0 - Epoch 50/72 loss: 0.7667218446731567
Rank 0 - Epoch 60/72 loss: 0.758655846118927
Rank 0 - Epoch 70/72 loss: 0.7539169788360596
Training complete.
[92mRank 0 - Testing RMSE: 3.5951[0m
[92mRank: 0, Lengthscale: [[0.63393176 0.6333185 ]] [0m
[92mRank: 0, Outputscale: 0.6342717409133911 [0m
[92mRank: 0, Noise: 0.6279394626617432 [0m
Run 2 completed successfully
Running cGP 3 with agents: 36
decADMM initialized with rho: 0.85, max_iter: 5, lr: 0.0001, rank: 0, world_size: 36
Rank 0 - Epoch 2/72 loss: 0.7964761853218079
Rank 0 - Epoch 10/72 loss: 0.7894307374954224
Rank 0 - Epoch 20/72 loss: 0.7850195169448853
Rank 0 - Epoch 30/72 loss: 0.780259370803833
Rank 0 - Epoch 40/72 loss: 0.7724266052246094
Rank 0 - Epoch 50/72 loss: 0.7636956572532654
Rank 0 - Epoch 60/72 loss: 0.7574204802513123
Rank 0 - Epoch 70/72 loss: 0.7500172257423401
Training complete.
[92mRank 0 - Testing RMSE: 3.5951[0m
[92mRank: 0, Lengthscale: [[0.63393176 0.633313  ]] [0m
[92mRank: 0, Outputscale: 0.6342707872390747 [0m
[92mRank: 0, Noise: 0.6279382109642029 [0m
Run 3 completed successfully
Running cGP 4 with agents: 36
decADMM initialized with rho: 0.85, max_iter: 5, lr: 0.0001, rank: 0, world_size: 36
Rank 0 - Epoch 2/72 loss: 0.7929515242576599
Rank 0 - Epoch 10/72 loss: 0.7918573021888733
Rank 0 - Epoch 20/72 loss: 0.7860243320465088
Rank 0 - Epoch 30/72 loss: 0.7757138013839722
Rank 0 - Epoch 40/72 loss: 0.7681487202644348
Rank 0 - Epoch 50/72 loss: 0.7640975117683411
Rank 0 - Epoch 60/72 loss: 0.7591731548309326
Rank 0 - Epoch 70/72 loss: 0.7487310767173767
Training complete.
[92mRank 0 - Testing RMSE: 3.5951[0m
[92mRank: 0, Lengthscale: [[0.63392866 0.6333154 ]] [0m
[92mRank: 0, Outputscale: 0.6342713236808777 [0m
[92mRank: 0, Noise: 0.6279394626617432 [0m
Run 4 completed successfully
Running cGP 5 with agents: 36
decADMM initialized with rho: 0.85, max_iter: 5, lr: 0.0001, rank: 0, world_size: 36
Rank 0 - Epoch 2/72 loss: 0.7944630980491638
Rank 0 - Epoch 10/72 loss: 0.7880160808563232
Rank 0 - Epoch 20/72 loss: 0.7824699282646179
Rank 0 - Epoch 30/72 loss: 0.7753340005874634
Rank 0 - Epoch 40/72 loss: 0.7753158211708069
Rank 0 - Epoch 50/72 loss: 0.7646335959434509
Rank 0 - Epoch 60/72 loss: 0.7583470940589905
Rank 0 - Epoch 70/72 loss: 0.7511071562767029
Training complete.
[92mRank 0 - Testing RMSE: 3.5951[0m
[92mRank: 0, Lengthscale: [[0.633933  0.6333151]] [0m
[92mRank: 0, Outputscale: 0.6342712044715881 [0m
[92mRank: 0, Noise: 0.6279299259185791 [0m
Run 5 completed successfully
Running cGP 6 with agents: 36
decADMM initialized with rho: 0.85, max_iter: 5, lr: 0.0001, rank: 0, world_size: 36
Rank 0 - Epoch 2/72 loss: 0.7951120138168335
Rank 0 - Epoch 10/72 loss: 0.7909970283508301
Rank 0 - Epoch 20/72 loss: 0.7864547967910767
Rank 0 - Epoch 30/72 loss: 0.7786924242973328
Rank 0 - Epoch 40/72 loss: 0.7714194059371948
Rank 0 - Epoch 50/72 loss: 0.7607492804527283
Rank 0 - Epoch 60/72 loss: 0.7584252953529358
Rank 0 - Epoch 70/72 loss: 0.7501544952392578
Training complete.
[92mRank 0 - Testing RMSE: 3.5951[0m
[92mRank: 0, Lengthscale: [[0.6339306 0.6333189]] [0m
[92mRank: 0, Outputscale: 0.6342717409133911 [0m
[92mRank: 0, Noise: 0.6279310584068298 [0m
Run 6 completed successfully
Running cGP 7 with agents: 36
decADMM initialized with rho: 0.85, max_iter: 5, lr: 0.0001, rank: 0, world_size: 36
Rank 0 - Epoch 2/72 loss: 0.7978233098983765
Rank 0 - Epoch 10/72 loss: 0.7933152914047241
Rank 0 - Epoch 20/72 loss: 0.7818048596382141
Rank 0 - Epoch 30/72 loss: 0.7774689197540283
Rank 0 - Epoch 40/72 loss: 0.7728878855705261
Rank 0 - Epoch 50/72 loss: 0.7682587504386902
Rank 0 - Epoch 60/72 loss: 0.7564324140548706
Rank 0 - Epoch 70/72 loss: 0.7529723644256592
Training complete.
[92mRank 0 - Testing RMSE: 3.5951[0m
[92mRank: 0, Lengthscale: [[0.6339298 0.633318 ]] [0m
[92mRank: 0, Outputscale: 0.6342718601226807 [0m
[92mRank: 0, Noise: 0.6279330849647522 [0m
Run 7 completed successfully
Running cGP 8 with agents: 36
decADMM initialized with rho: 0.85, max_iter: 5, lr: 0.0001, rank: 0, world_size: 36
Rank 0 - Epoch 2/72 loss: 0.795473039150238
Rank 0 - Epoch 10/72 loss: 0.7898021340370178
Rank 0 - Epoch 20/72 loss: 0.7817285060882568
Rank 0 - Epoch 30/72 loss: 0.7778857946395874
Rank 0 - Epoch 40/72 loss: 0.7705624103546143
Rank 0 - Epoch 50/72 loss: 0.7619791626930237
Rank 0 - Epoch 60/72 loss: 0.7557212114334106
Rank 0 - Epoch 70/72 loss: 0.7481974959373474
Training complete.
[92mRank 0 - Testing RMSE: 3.5951[0m
[92mRank: 0, Lengthscale: [[0.63392514 0.6333186 ]] [0m
[92mRank: 0, Outputscale: 0.6342710852622986 [0m
[92mRank: 0, Noise: 0.6279373168945312 [0m
Run 8 completed successfully
Running cGP 9 with agents: 36
decADMM initialized with rho: 0.85, max_iter: 5, lr: 0.0001, rank: 0, world_size: 36
Rank 0 - Epoch 2/72 loss: 0.7925064563751221
Rank 0 - Epoch 10/72 loss: 0.785677433013916
Rank 0 - Epoch 20/72 loss: 0.7856530547142029
Rank 0 - Epoch 30/72 loss: 0.7750358581542969
Rank 0 - Epoch 40/72 loss: 0.7735207080841064
Rank 0 - Epoch 50/72 loss: 0.7657060027122498
Rank 0 - Epoch 60/72 loss: 0.7563720941543579
Rank 0 - Epoch 70/72 loss: 0.7484551072120667
Training complete.
[92mRank 0 - Testing RMSE: 3.5951[0m
[92mRank: 0, Lengthscale: [[0.63393116 0.6333181 ]] [0m
[92mRank: 0, Outputscale: 0.6342710256576538 [0m
[92mRank: 0, Noise: 0.6279304027557373 [0m
Run 9 completed successfully
Running cGP 10 with agents: 36
decADMM initialized with rho: 0.85, max_iter: 5, lr: 0.0001, rank: 0, world_size: 36
Rank 0 - Epoch 2/72 loss: 0.7939286231994629
Rank 0 - Epoch 10/72 loss: 0.7947270274162292
Rank 0 - Epoch 20/72 loss: 0.7838425636291504
Rank 0 - Epoch 30/72 loss: 0.7754924893379211
Rank 0 - Epoch 40/72 loss: 0.7713704705238342
Rank 0 - Epoch 50/72 loss: 0.7631668448448181
Rank 0 - Epoch 60/72 loss: 0.7571133971214294
Rank 0 - Epoch 70/72 loss: 0.7487533688545227
Training complete.
[92mRank 0 - Testing RMSE: 3.5951[0m
[92mRank: 0, Lengthscale: [[0.6339303 0.6333111]] [0m
[92mRank: 0, Outputscale: 0.6342716217041016 [0m
[92mRank: 0, Noise: 0.6279388070106506 [0m
Run 10 completed successfully
Running pxpGP 1 with agents: 49
[92mRank 0 - sparse dataset size is: 13, local dataset: torch.Size([676, 2]), [0m
[92mRank 0 - Training local sparse GP model with 676 samples[0m
Epoch 1/200 - Loss: 14.052
Epoch 11/200 - Loss: 1.450
Epoch 21/200 - Loss: 1.233
Epoch 31/200 - Loss: 1.011
Epoch 41/200 - Loss: 0.864
Epoch 51/200 - Loss: 0.657
Epoch 61/200 - Loss: 0.471
Epoch 71/200 - Loss: 0.212
Converged at epoch 79 with loss -0.004
[92mRank 0 - Lengthscale: [[0.50537324 0.32439122]] [0m
[92mRank 0 - Outputscale: 2.4082484245300293 [0m
[92mRank 0 - Noise: 0.1353272944688797 [0m
Rank 0 - Augmented dataset size: 1313
Rank 0: After warm start model parameters:
Rank: 0, Lengthscale: [[0.50537324 0.32439122]]
Rank: 0, Outputscale: 2.4082484245300293
Rank: 0, Noise: 0.1353272944688797
decpxADMM initialized with rho: 0.85, lip: 1.0, tol_abs: 1e-05, tol_rel: 0.001, rank: 0, world_size: 49
[92mRank 0 - Training global model with dec-pxADMM optimizer[0m
rank 0, epoch 9, loss: 0.7486794590950012, rho: 0.4250, lip: 1.0000
rank 0, epoch 19, loss: 0.7352261543273926, rho: 0.1062, lip: 1.0000
rank 0, epoch 29, loss: 0.7362812757492065, rho: 0.0531, lip: 1.0000
rank 0, epoch 39, loss: 0.7273196578025818, rho: 0.0531, lip: 1.0000
rank 0, epoch 49, loss: 0.726524829864502, rho: 0.0531, lip: 1.0000
rank 0, epoch 59, loss: 0.7431119680404663, rho: 0.0531, lip: 1.0000
rank 0, epoch 69, loss: 0.7474918365478516, rho: 0.0531, lip: 1.0000
Rank 0 - Training time: 66.05 seconds
[92mRank 0 - Testing RMSE: 0.4144[0m
[92mRank: 0, Lengthscale: [[0.5644641 0.4049233]] [0m
[92mRank: 0, Outputscale: 1.4276028871536255 [0m
[92mRank: 0, Noise: 0.19302105903625488 [0m
Run 1 completed successfully
Running pxpGP 2 with agents: 49
[92mRank 0 - sparse dataset size is: 13, local dataset: torch.Size([676, 2]), [0m
[92mRank 0 - Training local sparse GP model with 676 samples[0m
Epoch 1/200 - Loss: 14.234
Epoch 11/200 - Loss: 1.442
Epoch 21/200 - Loss: 1.230
Epoch 31/200 - Loss: 0.972
Epoch 41/200 - Loss: 0.836
Epoch 51/200 - Loss: 0.680
Epoch 61/200 - Loss: 0.575
Epoch 71/200 - Loss: 0.344
Epoch 81/200 - Loss: 0.047
Converged at epoch 84 with loss -0.037
[92mRank 0 - Lengthscale: [[0.2866724  0.43109983]] [0m
[92mRank 0 - Outputscale: 2.317039966583252 [0m
[92mRank 0 - Noise: 0.12657584249973297 [0m
Rank 0 - Augmented dataset size: 1313
Rank 0: After warm start model parameters:
Rank: 0, Lengthscale: [[0.2866724  0.43109983]]
Rank: 0, Outputscale: 2.317039966583252
Rank: 0, Noise: 0.12657584249973297
decpxADMM initialized with rho: 0.85, lip: 1.0, tol_abs: 1e-05, tol_rel: 0.001, rank: 0, world_size: 49
[92mRank 0 - Training global model with dec-pxADMM optimizer[0m
rank 0, epoch 9, loss: 0.7430819869041443, rho: 0.2125, lip: 1.0000
rank 0, epoch 19, loss: 0.7371789813041687, rho: 0.2125, lip: 1.0000
rank 0, epoch 29, loss: 0.7249271273612976, rho: 0.0531, lip: 1.0000
rank 0, epoch 39, loss: 0.7434027791023254, rho: 0.0531, lip: 1.0000
rank 0, epoch 49, loss: 0.7358704209327698, rho: 0.0531, lip: 1.0000
rank 0, epoch 59, loss: 0.7416959404945374, rho: 0.0133, lip: 1.0000
rank 0, epoch 69, loss: 0.7492103576660156, rho: 0.0133, lip: 1.0000
Rank 0 - Training time: 101.32 seconds
[92mRank 0 - Testing RMSE: 0.4716[0m
[92mRank: 0, Lengthscale: [[0.24631597 0.41765395]] [0m
[92mRank: 0, Outputscale: 1.2885431051254272 [0m
[92mRank: 0, Noise: 0.16770930588245392 [0m
Run 2 completed successfully
Running pxpGP 3 with agents: 49
[92mRank 0 - sparse dataset size is: 13, local dataset: torch.Size([676, 2]), [0m
[92mRank 0 - Training local sparse GP model with 676 samples[0m
Epoch 1/200 - Loss: 14.368
Epoch 11/200 - Loss: 1.294
Epoch 21/200 - Loss: 1.086
Epoch 31/200 - Loss: 1.012
Epoch 41/200 - Loss: 0.830
Epoch 51/200 - Loss: 0.700
Epoch 61/200 - Loss: 0.492
Epoch 71/200 - Loss: 0.273
Converged at epoch 80 with loss -0.003
[92mRank 0 - Lengthscale: [[0.6460175  0.22470054]] [0m
[92mRank 0 - Outputscale: 2.4470932483673096 [0m
[92mRank 0 - Noise: 0.13309232890605927 [0m
Rank 0 - Augmented dataset size: 1313
Rank 0: After warm start model parameters:
Rank: 0, Lengthscale: [[0.6460175  0.22470054]]
Rank: 0, Outputscale: 2.4470932483673096
Rank: 0, Noise: 0.13309232890605927
decpxADMM initialized with rho: 0.85, lip: 1.0, tol_abs: 1e-05, tol_rel: 0.001, rank: 0, world_size: 49
[92mRank 0 - Training global model with dec-pxADMM optimizer[0m
rank 0, epoch 9, loss: 0.7661594152450562, rho: 0.4250, lip: 1.0000
rank 0, epoch 19, loss: 0.771172821521759, rho: 0.1062, lip: 1.0000
rank 0, epoch 29, loss: 0.7533009648323059, rho: 0.0531, lip: 1.0000
rank 0, epoch 39, loss: 0.740282416343689, rho: 0.0531, lip: 1.0000
rank 0, epoch 49, loss: 0.7489481568336487, rho: 0.0531, lip: 1.0000
rank 0, epoch 59, loss: 0.7583690285682678, rho: 0.0531, lip: 1.0000
rank 0, epoch 69, loss: 0.7797123789787292, rho: 0.0531, lip: 1.0000
Rank 0 - Training time: 81.45 seconds
[92mRank 0 - Testing RMSE: 0.4118[0m
[92mRank: 0, Lengthscale: [[0.5745793  0.33530968]] [0m
[92mRank: 0, Outputscale: 1.354585886001587 [0m
[92mRank: 0, Noise: 0.18803784251213074 [0m
Run 3 completed successfully
Running pxpGP 4 with agents: 49
[92mRank 0 - sparse dataset size is: 13, local dataset: torch.Size([676, 2]), [0m
[92mRank 0 - Training local sparse GP model with 676 samples[0m
Epoch 1/200 - Loss: 14.041
Epoch 11/200 - Loss: 1.232
Epoch 21/200 - Loss: 1.153
Epoch 31/200 - Loss: 1.040
Epoch 41/200 - Loss: 0.961
Epoch 51/200 - Loss: 0.708
Epoch 61/200 - Loss: 0.522
Epoch 71/200 - Loss: 0.263
Epoch 81/200 - Loss: -0.013
Converged at epoch 81 with loss -0.013
[92mRank 0 - Lengthscale: [[0.50472516 0.3149699 ]] [0m
[92mRank 0 - Outputscale: 2.4403188228607178 [0m
[92mRank 0 - Noise: 0.12926363945007324 [0m
Rank 0 - Augmented dataset size: 1313
Rank 0: After warm start model parameters:
Rank: 0, Lengthscale: [[0.50472516 0.3149699 ]]
Rank: 0, Outputscale: 2.4403188228607178
Rank: 0, Noise: 0.12926365435123444
decpxADMM initialized with rho: 0.85, lip: 1.0, tol_abs: 1e-05, tol_rel: 0.001, rank: 0, world_size: 49
[92mRank 0 - Training global model with dec-pxADMM optimizer[0m
rank 0, epoch 9, loss: 0.7171000242233276, rho: 0.4250, lip: 1.0000
rank 0, epoch 19, loss: 0.7043890357017517, rho: 0.1062, lip: 1.0000
rank 0, epoch 29, loss: 0.7000591158866882, rho: 0.0531, lip: 1.0000
rank 0, epoch 39, loss: 0.6990339756011963, rho: 0.0531, lip: 1.0000
rank 0, epoch 49, loss: 0.6998662948608398, rho: 0.0531, lip: 1.0000
rank 0, epoch 59, loss: 0.6999742984771729, rho: 0.0531, lip: 1.0000
rank 0, epoch 69, loss: 0.6983003616333008, rho: 0.0531, lip: 1.0000
Rank 0 - Training time: 103.12 seconds
[92mRank 0 - Testing RMSE: 0.3754[0m
[92mRank: 0, Lengthscale: [[0.65102834 0.35671633]] [0m
[92mRank: 0, Outputscale: 1.8090569972991943 [0m
[92mRank: 0, Noise: 0.18985508382320404 [0m
Run 4 completed successfully
Running pxpGP 5 with agents: 49
[92mRank 0 - sparse dataset size is: 13, local dataset: torch.Size([676, 2]), [0m
[92mRank 0 - Training local sparse GP model with 676 samples[0m
Epoch 1/200 - Loss: 13.426
Epoch 11/200 - Loss: 1.263
Epoch 21/200 - Loss: 1.098
Epoch 31/200 - Loss: 1.029
Epoch 41/200 - Loss: 0.893
Epoch 51/200 - Loss: 0.656
Epoch 61/200 - Loss: 0.455
Epoch 71/200 - Loss: 0.207
Converged at epoch 80 with loss -0.036
[92mRank 0 - Lengthscale: [[0.5660973  0.22780499]] [0m
[92mRank 0 - Outputscale: 2.4542620182037354 [0m
[92mRank 0 - Noise: 0.12339495867490768 [0m
Rank 0 - Augmented dataset size: 1313
Rank 0: After warm start model parameters:
Rank: 0, Lengthscale: [[0.5660973  0.22780499]]
Rank: 0, Outputscale: 2.4542620182037354
Rank: 0, Noise: 0.12339498102664948
decpxADMM initialized with rho: 0.85, lip: 1.0, tol_abs: 1e-05, tol_rel: 0.001, rank: 0, world_size: 49
[92mRank 0 - Training global model with dec-pxADMM optimizer[0m
rank 0, epoch 9, loss: 0.7251163125038147, rho: 0.4250, lip: 1.0000
rank 0, epoch 19, loss: 0.7256506085395813, rho: 0.1062, lip: 1.0000
rank 0, epoch 29, loss: 0.7273054718971252, rho: 0.1062, lip: 1.0000
rank 0, epoch 39, loss: 0.7294736504554749, rho: 0.0266, lip: 1.0000
rank 0, epoch 49, loss: 0.7255148887634277, rho: 0.0266, lip: 1.0000
rank 0, epoch 59, loss: 0.733145534992218, rho: 0.0266, lip: 1.0000
rank 0, epoch 69, loss: 0.7225334644317627, rho: 0.0266, lip: 1.0000
Rank 0 - Training time: 74.63 seconds
[92mRank 0 - Testing RMSE: 0.4165[0m
[92mRank: 0, Lengthscale: [[0.6476086  0.29329416]] [0m
[92mRank: 0, Outputscale: 1.8170291185379028 [0m
[92mRank: 0, Noise: 0.18065689504146576 [0m
Run 5 completed successfully
Running pxpGP 6 with agents: 49
[92mRank 0 - sparse dataset size is: 13, local dataset: torch.Size([676, 2]), [0m
[92mRank 0 - Training local sparse GP model with 676 samples[0m
Epoch 1/200 - Loss: 13.678
Epoch 11/200 - Loss: 1.202
Epoch 21/200 - Loss: 1.279
Epoch 31/200 - Loss: 0.990
Epoch 41/200 - Loss: 0.851
Epoch 51/200 - Loss: 0.658
Epoch 61/200 - Loss: 0.456
Epoch 71/200 - Loss: 0.223
Converged at epoch 80 with loss -0.003
[92mRank 0 - Lengthscale: [[0.5521999  0.24550821]] [0m
[92mRank 0 - Outputscale: 2.371030807495117 [0m
[92mRank 0 - Noise: 0.1317778080701828 [0m
Rank 0 - Augmented dataset size: 1313
Rank 0: After warm start model parameters:
Rank: 0, Lengthscale: [[0.55219984 0.24550821]]
Rank: 0, Outputscale: 2.371030807495117
Rank: 0, Noise: 0.1317778080701828
decpxADMM initialized with rho: 0.85, lip: 1.0, tol_abs: 1e-05, tol_rel: 0.001, rank: 0, world_size: 49
[92mRank 0 - Training global model with dec-pxADMM optimizer[0m
rank 0, epoch 9, loss: 0.7323564291000366, rho: 0.4250, lip: 1.0000
rank 0, epoch 19, loss: 0.7176746726036072, rho: 0.2125, lip: 1.0000
rank 0, epoch 29, loss: 0.7218863368034363, rho: 0.0531, lip: 1.0000
rank 0, epoch 39, loss: 0.734126091003418, rho: 0.0531, lip: 1.0000
rank 0, epoch 49, loss: 0.7302003502845764, rho: 0.0266, lip: 1.0000
rank 0, epoch 59, loss: 0.7375679612159729, rho: 0.0266, lip: 1.0000
rank 0, epoch 69, loss: 0.7359909415245056, rho: 0.0266, lip: 1.0000
Rank 0 - Training time: 90.21 seconds
[92mRank 0 - Testing RMSE: 0.3837[0m
[92mRank: 0, Lengthscale: [[0.6553677  0.36718774]] [0m
[92mRank: 0, Outputscale: 1.6606043577194214 [0m
[92mRank: 0, Noise: 0.18791073560714722 [0m
Run 6 completed successfully
Running pxpGP 7 with agents: 49
[92mRank 0 - sparse dataset size is: 13, local dataset: torch.Size([676, 2]), [0m
[92mRank 0 - Training local sparse GP model with 676 samples[0m
Epoch 1/200 - Loss: 13.943
Epoch 11/200 - Loss: 1.173
Epoch 21/200 - Loss: 1.087
Epoch 31/200 - Loss: 0.955
Epoch 41/200 - Loss: 0.814
Epoch 51/200 - Loss: 0.667
Epoch 61/200 - Loss: 0.436
Epoch 71/200 - Loss: 0.209
Converged at epoch 78 with loss -0.004
[92mRank 0 - Lengthscale: [[0.5490711  0.27610072]] [0m
[92mRank 0 - Outputscale: 2.4989304542541504 [0m
[92mRank 0 - Noise: 0.13475525379180908 [0m
Rank 0 - Augmented dataset size: 1313
Rank 0: After warm start model parameters:
Rank: 0, Lengthscale: [[0.5490711  0.27610072]]
Rank: 0, Outputscale: 2.4989304542541504
Rank: 0, Noise: 0.13475525379180908
decpxADMM initialized with rho: 0.85, lip: 1.0, tol_abs: 1e-05, tol_rel: 0.001, rank: 0, world_size: 49
[92mRank 0 - Training global model with dec-pxADMM optimizer[0m
rank 0, epoch 9, loss: 0.7420754432678223, rho: 0.4250, lip: 1.0000
rank 0, epoch 19, loss: 0.737644612789154, rho: 0.0531, lip: 1.0000
rank 0, epoch 29, loss: 0.7380870580673218, rho: 0.0531, lip: 1.0000
rank 0, epoch 39, loss: 0.7373664975166321, rho: 0.0531, lip: 1.0000
rank 0, epoch 49, loss: 0.7360951900482178, rho: 0.0531, lip: 1.0000
rank 0, epoch 59, loss: 0.7417632341384888, rho: 0.0531, lip: 1.0000
rank 0, epoch 69, loss: 0.751761257648468, rho: 0.0531, lip: 1.0000
Rank 0 - Training time: 100.71 seconds
[92mRank 0 - Testing RMSE: 0.4129[0m
[92mRank: 0, Lengthscale: [[0.50017285 0.4399826 ]] [0m
[92mRank: 0, Outputscale: 1.0761226415634155 [0m
[92mRank: 0, Noise: 0.1876259595155716 [0m
Run 7 completed successfully
Running pxpGP 8 with agents: 49
[92mRank 0 - sparse dataset size is: 13, local dataset: torch.Size([676, 2]), [0m
[92mRank 0 - Training local sparse GP model with 676 samples[0m
Epoch 1/200 - Loss: 12.860
Epoch 11/200 - Loss: 1.690
Epoch 21/200 - Loss: 1.077
Epoch 31/200 - Loss: 0.948
Epoch 41/200 - Loss: 0.824
Epoch 51/200 - Loss: 0.635
Epoch 61/200 - Loss: 0.452
Epoch 71/200 - Loss: 0.188
Converged at epoch 78 with loss -0.004
[92mRank 0 - Lengthscale: [[0.7460426  0.26150742]] [0m
[92mRank 0 - Outputscale: 2.6485681533813477 [0m
[92mRank 0 - Noise: 0.13265955448150635 [0m
Rank 0 - Augmented dataset size: 1313
Rank 0: After warm start model parameters:
Rank: 0, Lengthscale: [[0.7460426  0.26150742]]
Rank: 0, Outputscale: 2.6485681533813477
Rank: 0, Noise: 0.13265953958034515
decpxADMM initialized with rho: 0.85, lip: 1.0, tol_abs: 1e-05, tol_rel: 0.001, rank: 0, world_size: 49
[92mRank 0 - Training global model with dec-pxADMM optimizer[0m
rank 0, epoch 9, loss: 0.7051225900650024, rho: 0.4250, lip: 1.0000
rank 0, epoch 19, loss: 0.6772837042808533, rho: 0.1062, lip: 1.0000
rank 0, epoch 29, loss: 0.6783192753791809, rho: 0.1062, lip: 1.0000
rank 0, epoch 39, loss: 0.6736093759536743, rho: 0.0531, lip: 1.0000
rank 0, epoch 49, loss: 0.6771016120910645, rho: 0.0531, lip: 1.0000
rank 0, epoch 59, loss: 0.673724353313446, rho: 0.0531, lip: 1.0000
rank 0, epoch 69, loss: 0.6858810186386108, rho: 0.0531, lip: 1.0000
Rank 0 - Training time: 111.61 seconds
[92mRank 0 - Testing RMSE: 0.3929[0m
[92mRank: 0, Lengthscale: [[0.65441495 0.31718913]] [0m
[92mRank: 0, Outputscale: 2.006911516189575 [0m
[92mRank: 0, Noise: 0.15890420973300934 [0m
Run 8 completed successfully
Running pxpGP 9 with agents: 49
[92mRank 0 - sparse dataset size is: 13, local dataset: torch.Size([676, 2]), [0m
[92mRank 0 - Training local sparse GP model with 676 samples[0m
Epoch 1/200 - Loss: 13.919
Epoch 11/200 - Loss: 1.223
Epoch 21/200 - Loss: 1.087
Epoch 31/200 - Loss: 0.998
Epoch 41/200 - Loss: 0.834
Epoch 51/200 - Loss: 0.683
Epoch 61/200 - Loss: 0.486
Epoch 71/200 - Loss: 0.227
Converged at epoch 80 with loss -0.009
[92mRank 0 - Lengthscale: [[0.70922214 0.21242878]] [0m
[92mRank 0 - Outputscale: 2.515235424041748 [0m
[92mRank 0 - Noise: 0.1309947967529297 [0m
Rank 0 - Augmented dataset size: 1313
Rank 0: After warm start model parameters:
Rank: 0, Lengthscale: [[0.70922214 0.21242878]]
Rank: 0, Outputscale: 2.515235424041748
Rank: 0, Noise: 0.1309947967529297
decpxADMM initialized with rho: 0.85, lip: 1.0, tol_abs: 1e-05, tol_rel: 0.001, rank: 0, world_size: 49
[92mRank 0 - Training global model with dec-pxADMM optimizer[0m
rank 0, epoch 9, loss: 0.7189168930053711, rho: 0.4250, lip: 1.0000
rank 0, epoch 19, loss: 0.7140179872512817, rho: 0.1062, lip: 1.0000
rank 0, epoch 29, loss: 0.7142240405082703, rho: 0.0531, lip: 1.0000
rank 0, epoch 39, loss: 0.7082425355911255, rho: 0.0531, lip: 1.0000
rank 0, epoch 49, loss: 0.7168723940849304, rho: 0.0531, lip: 1.0000
rank 0, epoch 59, loss: 0.7159711122512817, rho: 0.0531, lip: 1.0000
rank 0, epoch 69, loss: 0.7330353260040283, rho: 0.0531, lip: 1.0000
Rank 0 - Training time: 93.05 seconds
[92mRank 0 - Testing RMSE: 0.4371[0m
[92mRank: 0, Lengthscale: [[0.7240555 0.3058889]] [0m
[92mRank: 0, Outputscale: 2.3138298988342285 [0m
[92mRank: 0, Noise: 0.18241344392299652 [0m
Run 9 completed successfully
Running pxpGP 10 with agents: 49
[92mRank 0 - sparse dataset size is: 13, local dataset: torch.Size([676, 2]), [0m
[92mRank 0 - Training local sparse GP model with 676 samples[0m
Epoch 1/200 - Loss: 13.470
Epoch 11/200 - Loss: 1.526
Epoch 21/200 - Loss: 1.108
Epoch 31/200 - Loss: 1.026
Epoch 41/200 - Loss: 0.826
Epoch 51/200 - Loss: 0.696
Epoch 61/200 - Loss: 0.463
Epoch 71/200 - Loss: 0.222
Converged at epoch 80 with loss -0.012
[92mRank 0 - Lengthscale: [[0.58471316 0.21076934]] [0m
[92mRank 0 - Outputscale: 2.442798137664795 [0m
[92mRank 0 - Noise: 0.12804989516735077 [0m
Rank 0 - Augmented dataset size: 1313
Rank 0: After warm start model parameters:
Rank: 0, Lengthscale: [[0.58471316 0.21076933]]
Rank: 0, Outputscale: 2.442798137664795
Rank: 0, Noise: 0.12804989516735077
decpxADMM initialized with rho: 0.85, lip: 1.0, tol_abs: 1e-05, tol_rel: 0.001, rank: 0, world_size: 49
[92mRank 0 - Training global model with dec-pxADMM optimizer[0m
rank 0, epoch 9, loss: 0.7154306769371033, rho: 0.4250, lip: 1.0000
rank 0, epoch 19, loss: 0.7100484371185303, rho: 0.1062, lip: 1.0000
rank 0, epoch 29, loss: 0.7132121324539185, rho: 0.1062, lip: 1.0000
rank 0, epoch 39, loss: 0.7221372723579407, rho: 0.0531, lip: 1.0000
rank 0, epoch 49, loss: 0.7027207612991333, rho: 0.0531, lip: 1.0000
rank 0, epoch 59, loss: 0.7150525450706482, rho: 0.0266, lip: 1.0000
rank 0, epoch 69, loss: 0.7251886129379272, rho: 0.0266, lip: 1.0000
Rank 0 - Training time: 92.87 seconds
[92mRank 0 - Testing RMSE: 0.3963[0m
[92mRank: 0, Lengthscale: [[0.65149385 0.26958328]] [0m
[92mRank: 0, Outputscale: 1.7743995189666748 [0m
[92mRank: 0, Noise: 0.17145280539989471 [0m
Run 10 completed successfully
Running gapxGP 1 with agents: 49
decpxADMM initialized with rho: 0.75, lip: 1.0, tol_abs: 1e-05, tol_rel: 0.001, rank: 0, world_size: 49
Rank 0 - Epoch 2/73 loss: 0.9123272895812988
Rank 0 - Epoch 10/73 loss: 0.6647505164146423
Rank 0 - Epoch 20/73 loss: 0.28099125623703003
Rank 0 - Epoch 30/73 loss: -0.19053879380226135
Rank 0 - Epoch 40/73 loss: -0.6749838590621948
Rank 0 - Epoch 50/73 loss: -1.138229250907898
Rank 0 - Epoch 60/73 loss: -1.5351927280426025
Rank 0 - Epoch 70/73 loss: -1.8072317838668823
[92mRank 0 - Testing RMSE: 0.0611[0m
[92mRank: 0, Lengthscale: [[0.62441146 0.36286443]] [0m
[92mRank: 0, Outputscale: 1.3446595668792725 [0m
[92mRank: 0, Noise: 0.000778386602178216 [0m
Run 1 completed successfully
Running gapxGP 2 with agents: 49
decpxADMM initialized with rho: 0.75, lip: 1.0, tol_abs: 1e-05, tol_rel: 0.001, rank: 0, world_size: 49
Rank 0 - Epoch 2/73 loss: 0.9084987044334412
Rank 0 - Epoch 10/73 loss: 0.6607308983802795
Rank 0 - Epoch 20/73 loss: 0.28064095973968506
Rank 0 - Epoch 30/73 loss: -0.18277710676193237
Rank 0 - Epoch 40/73 loss: -0.6697462797164917
Rank 0 - Epoch 50/73 loss: -1.1512616872787476
Rank 0 - Epoch 60/73 loss: -1.565553069114685
Rank 0 - Epoch 70/73 loss: -1.7828619480133057
[92mRank 0 - Testing RMSE: 0.0528[0m
[92mRank: 0, Lengthscale: [[0.61867195 0.37487388]] [0m
[92mRank: 0, Outputscale: 1.3425613641738892 [0m
[92mRank: 0, Noise: 0.0007769407238811255 [0m
Run 2 completed successfully
Running gapxGP 3 with agents: 49
decpxADMM initialized with rho: 0.75, lip: 1.0, tol_abs: 1e-05, tol_rel: 0.001, rank: 0, world_size: 49
Rank 0 - Epoch 2/73 loss: 0.9139069318771362
Rank 0 - Epoch 10/73 loss: 0.6673961281776428
Rank 0 - Epoch 20/73 loss: 0.2744528353214264
Rank 0 - Epoch 30/73 loss: -0.18678458034992218
Rank 0 - Epoch 40/73 loss: -0.6879430413246155
Rank 0 - Epoch 50/73 loss: -1.1569772958755493
Rank 0 - Epoch 60/73 loss: -1.5149331092834473
Rank 0 - Epoch 70/73 loss: -1.8227261304855347
[92mRank 0 - Testing RMSE: 0.0453[0m
[92mRank: 0, Lengthscale: [[0.6157211  0.36753333]] [0m
[92mRank: 0, Outputscale: 1.3458367586135864 [0m
[92mRank: 0, Noise: 0.0007671150960959494 [0m
Run 3 completed successfully
Running gapxGP 4 with agents: 49
decpxADMM initialized with rho: 0.75, lip: 1.0, tol_abs: 1e-05, tol_rel: 0.001, rank: 0, world_size: 49
Rank 0 - Epoch 2/73 loss: 0.9159539341926575
Rank 0 - Epoch 10/73 loss: 0.6659615635871887
Rank 0 - Epoch 20/73 loss: 0.2685117721557617
Rank 0 - Epoch 30/73 loss: -0.17688053846359253
Rank 0 - Epoch 40/73 loss: -0.6744409203529358
Rank 0 - Epoch 50/73 loss: -1.127245306968689
Rank 0 - Epoch 60/73 loss: -1.5259801149368286
Rank 0 - Epoch 70/73 loss: -1.8326354026794434
[92mRank 0 - Testing RMSE: 0.0515[0m
[92mRank: 0, Lengthscale: [[0.61917174 0.36130527]] [0m
[92mRank: 0, Outputscale: 1.3431264162063599 [0m
[92mRank: 0, Noise: 0.0007745795883238316 [0m
Run 4 completed successfully
Running gapxGP 5 with agents: 49
decpxADMM initialized with rho: 0.75, lip: 1.0, tol_abs: 1e-05, tol_rel: 0.001, rank: 0, world_size: 49
Rank 0 - Epoch 2/73 loss: 0.9116408228874207
Rank 0 - Epoch 10/73 loss: 0.6656311750411987
Rank 0 - Epoch 20/73 loss: 0.28958815336227417
Rank 0 - Epoch 30/73 loss: -0.18952880799770355
Rank 0 - Epoch 40/73 loss: -0.6612428426742554
Rank 0 - Epoch 50/73 loss: -1.116951584815979
Rank 0 - Epoch 60/73 loss: -1.527509331703186
Rank 0 - Epoch 70/73 loss: -1.789144515991211
[92mRank 0 - Testing RMSE: 0.0557[0m
[92mRank: 0, Lengthscale: [[0.6188093  0.36499318]] [0m
[92mRank: 0, Outputscale: 1.3425791263580322 [0m
[92mRank: 0, Noise: 0.0007810603128746152 [0m
Run 5 completed successfully
Running gapxGP 6 with agents: 49
decpxADMM initialized with rho: 0.75, lip: 1.0, tol_abs: 1e-05, tol_rel: 0.001, rank: 0, world_size: 49
Rank 0 - Epoch 2/73 loss: 0.9104382991790771
Rank 0 - Epoch 10/73 loss: 0.6588419079780579
Rank 0 - Epoch 20/73 loss: 0.2701980769634247
Rank 0 - Epoch 30/73 loss: -0.18380314111709595
Rank 0 - Epoch 40/73 loss: -0.6684077978134155
Rank 0 - Epoch 50/73 loss: -1.1495847702026367
Rank 0 - Epoch 60/73 loss: -1.533783197402954
Rank 0 - Epoch 70/73 loss: -1.815682053565979
[92mRank 0 - Testing RMSE: 0.0541[0m
[92mRank: 0, Lengthscale: [[0.6168688  0.36859483]] [0m
[92mRank: 0, Outputscale: 1.3428661823272705 [0m
[92mRank: 0, Noise: 0.0007734496030025184 [0m
Run 6 completed successfully
Running gapxGP 7 with agents: 49
decpxADMM initialized with rho: 0.75, lip: 1.0, tol_abs: 1e-05, tol_rel: 0.001, rank: 0, world_size: 49
Rank 0 - Epoch 2/73 loss: 0.9131941199302673
Rank 0 - Epoch 10/73 loss: 0.6697068214416504
Rank 0 - Epoch 20/73 loss: 0.2780907154083252
Rank 0 - Epoch 30/73 loss: -0.18740253150463104
Rank 0 - Epoch 40/73 loss: -0.6684316992759705
Rank 0 - Epoch 50/73 loss: -1.1404072046279907
Rank 0 - Epoch 60/73 loss: -1.524082064628601
Rank 0 - Epoch 70/73 loss: -1.7557010650634766
[92mRank 0 - Testing RMSE: 0.0565[0m
[92mRank: 0, Lengthscale: [[0.61211467 0.35990703]] [0m
[92mRank: 0, Outputscale: 1.3473577499389648 [0m
[92mRank: 0, Noise: 0.0007760845473967493 [0m
Run 7 completed successfully
Running gapxGP 8 with agents: 49
decpxADMM initialized with rho: 0.75, lip: 1.0, tol_abs: 1e-05, tol_rel: 0.001, rank: 0, world_size: 49
Rank 0 - Epoch 2/73 loss: 0.9144825339317322
Rank 0 - Epoch 10/73 loss: 0.6646575331687927
Rank 0 - Epoch 20/73 loss: 0.2855316698551178
Rank 0 - Epoch 30/73 loss: -0.17791926860809326
Rank 0 - Epoch 40/73 loss: -0.6630042195320129
Rank 0 - Epoch 50/73 loss: -1.1408576965332031
Rank 0 - Epoch 60/73 loss: -1.5104970932006836
Rank 0 - Epoch 70/73 loss: -1.781400442123413
[92mRank 0 - Testing RMSE: 0.0504[0m
[92mRank: 0, Lengthscale: [[0.6192968 0.3630279]] [0m
[92mRank: 0, Outputscale: 1.3437875509262085 [0m
[92mRank: 0, Noise: 0.0007812473340891302 [0m
Run 8 completed successfully
Running gapxGP 9 with agents: 49
decpxADMM initialized with rho: 0.75, lip: 1.0, tol_abs: 1e-05, tol_rel: 0.001, rank: 0, world_size: 49
Rank 0 - Epoch 2/73 loss: 0.9138798713684082
Rank 0 - Epoch 10/73 loss: 0.6665531396865845
Rank 0 - Epoch 20/73 loss: 0.2757725715637207
Rank 0 - Epoch 30/73 loss: -0.18593467772006989
Rank 0 - Epoch 40/73 loss: -0.686909019947052
Rank 0 - Epoch 50/73 loss: -1.1448743343353271
Rank 0 - Epoch 60/73 loss: -1.5397509336471558
Rank 0 - Epoch 70/73 loss: -1.7821499109268188
[92mRank 0 - Testing RMSE: 0.0551[0m
[92mRank: 0, Lengthscale: [[0.6180159  0.35676128]] [0m
[92mRank: 0, Outputscale: 1.3436338901519775 [0m
[92mRank: 0, Noise: 0.0007738584536127746 [0m
Run 9 completed successfully
Running gapxGP 10 with agents: 49
decpxADMM initialized with rho: 0.75, lip: 1.0, tol_abs: 1e-05, tol_rel: 0.001, rank: 0, world_size: 49
Rank 0 - Epoch 2/73 loss: 0.9097216129302979
Rank 0 - Epoch 10/73 loss: 0.6602195501327515
Rank 0 - Epoch 20/73 loss: 0.274869441986084
Rank 0 - Epoch 30/73 loss: -0.186119943857193
Rank 0 - Epoch 40/73 loss: -0.6678513884544373
Rank 0 - Epoch 50/73 loss: -1.121358036994934
Rank 0 - Epoch 60/73 loss: -1.5373591184616089
Rank 0 - Epoch 70/73 loss: -1.7553844451904297
[92mRank 0 - Testing RMSE: 0.0461[0m
[92mRank: 0, Lengthscale: [[0.6079296  0.36233118]] [0m
[92mRank: 0, Outputscale: 1.3443632125854492 [0m
[92mRank: 0, Noise: 0.000775162479840219 [0m
Run 10 completed successfully
Running apxGP 1 with agents: 49
decpxADMM initialized with rho: 0.85, lip: 1.0, tol_abs: 1e-05, tol_rel: 0.001, rank: 0, world_size: 49
Rank 0 - Epoch 2/98 loss: 0.7501490712165833
Rank 0 - Epoch 10/98 loss: 0.47852054238319397
Rank 0 - Epoch 20/98 loss: 0.05085618793964386
Rank 0 - Epoch 30/98 loss: -0.4313848316669464
Rank 0 - Epoch 40/98 loss: -0.9444073438644409
Rank 0 - Epoch 50/98 loss: -1.472633957862854
Rank 0 - Epoch 60/98 loss: -1.9868745803833008
Rank 0 - Epoch 70/98 loss: -2.457679271697998
Rank 0 - Epoch 80/98 loss: -2.8360512256622314
Rank 0 - Epoch 90/98 loss: -3.088148593902588
Training complete.
[92mRank 0 - Testing RMSE: 3.1695[0m
[92mRank: 0, Lengthscale: [[0.5889734  0.35926288]] [0m
[92mRank: 0, Outputscale: 1.0129797458648682 [0m
[92mRank: 0, Noise: 0.00019354006508365273 [0m
Run 1 completed successfully
Running apxGP 2 with agents: 49
decpxADMM initialized with rho: 0.85, lip: 1.0, tol_abs: 1e-05, tol_rel: 0.001, rank: 0, world_size: 49
Rank 0 - Epoch 2/98 loss: 0.7501490712165833
Rank 0 - Epoch 10/98 loss: 0.47852054238319397
Rank 0 - Epoch 20/98 loss: 0.05085618793964386
Rank 0 - Epoch 30/98 loss: -0.4313848316669464
Rank 0 - Epoch 40/98 loss: -0.9444073438644409
Rank 0 - Epoch 50/98 loss: -1.472633957862854
Rank 0 - Epoch 60/98 loss: -1.9868745803833008
Rank 0 - Epoch 70/98 loss: -2.457679271697998
Rank 0 - Epoch 80/98 loss: -2.8360512256622314
Rank 0 - Epoch 90/98 loss: -3.088148593902588
Training complete.
[92mRank 0 - Testing RMSE: 3.1695[0m
[92mRank: 0, Lengthscale: [[0.5889734  0.35926288]] [0m
[92mRank: 0, Outputscale: 1.0129797458648682 [0m
[92mRank: 0, Noise: 0.00019354006508365273 [0m
Run 2 completed successfully
Running apxGP 3 with agents: 49
decpxADMM initialized with rho: 0.85, lip: 1.0, tol_abs: 1e-05, tol_rel: 0.001, rank: 0, world_size: 49
Rank 0 - Epoch 2/98 loss: 0.7501490712165833
Rank 0 - Epoch 10/98 loss: 0.47852054238319397
Rank 0 - Epoch 20/98 loss: 0.05085618793964386
Rank 0 - Epoch 30/98 loss: -0.4313848316669464
Rank 0 - Epoch 40/98 loss: -0.9444073438644409
Rank 0 - Epoch 50/98 loss: -1.472633957862854
Rank 0 - Epoch 60/98 loss: -1.9868745803833008
Rank 0 - Epoch 70/98 loss: -2.457679271697998
Rank 0 - Epoch 80/98 loss: -2.8360512256622314
Rank 0 - Epoch 90/98 loss: -3.088148593902588
Training complete.
[92mRank 0 - Testing RMSE: 3.1695[0m
[92mRank: 0, Lengthscale: [[0.5889734  0.35926288]] [0m
[92mRank: 0, Outputscale: 1.0129797458648682 [0m
[92mRank: 0, Noise: 0.00019354006508365273 [0m
Run 3 completed successfully
Running apxGP 4 with agents: 49
decpxADMM initialized with rho: 0.85, lip: 1.0, tol_abs: 1e-05, tol_rel: 0.001, rank: 0, world_size: 49
Rank 0 - Epoch 2/98 loss: 0.7501490712165833
Rank 0 - Epoch 10/98 loss: 0.47852054238319397
Rank 0 - Epoch 20/98 loss: 0.05085618793964386
Rank 0 - Epoch 30/98 loss: -0.4313848316669464
Rank 0 - Epoch 40/98 loss: -0.9444073438644409
Rank 0 - Epoch 50/98 loss: -1.472633957862854
Rank 0 - Epoch 60/98 loss: -1.9868745803833008
Rank 0 - Epoch 70/98 loss: -2.457679271697998
Rank 0 - Epoch 80/98 loss: -2.8360512256622314
Rank 0 - Epoch 90/98 loss: -3.088148593902588
Training complete.
[92mRank 0 - Testing RMSE: 3.1695[0m
[92mRank: 0, Lengthscale: [[0.5889734  0.35926288]] [0m
[92mRank: 0, Outputscale: 1.0129797458648682 [0m
[92mRank: 0, Noise: 0.00019354006508365273 [0m
Run 4 completed successfully
Running apxGP 5 with agents: 49
decpxADMM initialized with rho: 0.85, lip: 1.0, tol_abs: 1e-05, tol_rel: 0.001, rank: 0, world_size: 49
Rank 0 - Epoch 2/98 loss: 0.7501490712165833
Rank 0 - Epoch 10/98 loss: 0.47852054238319397
Rank 0 - Epoch 20/98 loss: 0.05085618793964386
Rank 0 - Epoch 30/98 loss: -0.4313848316669464
Rank 0 - Epoch 40/98 loss: -0.9444073438644409
Rank 0 - Epoch 50/98 loss: -1.472633957862854
Rank 0 - Epoch 60/98 loss: -1.9868745803833008
Rank 0 - Epoch 70/98 loss: -2.457679271697998
Rank 0 - Epoch 80/98 loss: -2.8360512256622314
Rank 0 - Epoch 90/98 loss: -3.088148593902588
Training complete.
[92mRank 0 - Testing RMSE: 3.1695[0m
[92mRank: 0, Lengthscale: [[0.5889734  0.35926288]] [0m
[92mRank: 0, Outputscale: 1.0129797458648682 [0m
[92mRank: 0, Noise: 0.00019354006508365273 [0m
Run 5 completed successfully
Running apxGP 6 with agents: 49
decpxADMM initialized with rho: 0.85, lip: 1.0, tol_abs: 1e-05, tol_rel: 0.001, rank: 0, world_size: 49
Rank 0 - Epoch 2/98 loss: 0.7501490712165833
Rank 0 - Epoch 10/98 loss: 0.47852054238319397
Rank 0 - Epoch 20/98 loss: 0.05085618793964386
Rank 0 - Epoch 30/98 loss: -0.4313848316669464
Rank 0 - Epoch 40/98 loss: -0.9444073438644409
Rank 0 - Epoch 50/98 loss: -1.472633957862854
Rank 0 - Epoch 60/98 loss: -1.9868745803833008
Rank 0 - Epoch 70/98 loss: -2.457679271697998
Rank 0 - Epoch 80/98 loss: -2.8360512256622314
Rank 0 - Epoch 90/98 loss: -3.088148593902588
Training complete.
[92mRank 0 - Testing RMSE: 3.1695[0m
[92mRank: 0, Lengthscale: [[0.5889734  0.35926288]] [0m
[92mRank: 0, Outputscale: 1.0129797458648682 [0m
[92mRank: 0, Noise: 0.00019354006508365273 [0m
Run 6 completed successfully
Running apxGP 7 with agents: 49
decpxADMM initialized with rho: 0.85, lip: 1.0, tol_abs: 1e-05, tol_rel: 0.001, rank: 0, world_size: 49
Rank 0 - Epoch 2/98 loss: 0.7501490712165833
Rank 0 - Epoch 10/98 loss: 0.47852054238319397
Rank 0 - Epoch 20/98 loss: 0.05085618793964386
Rank 0 - Epoch 30/98 loss: -0.4313848316669464
Rank 0 - Epoch 40/98 loss: -0.9444073438644409
Rank 0 - Epoch 50/98 loss: -1.472633957862854
Rank 0 - Epoch 60/98 loss: -1.9868745803833008
Rank 0 - Epoch 70/98 loss: -2.457679271697998
Rank 0 - Epoch 80/98 loss: -2.8360512256622314
Rank 0 - Epoch 90/98 loss: -3.088148593902588
Training complete.
[92mRank 0 - Testing RMSE: 3.1695[0m
[92mRank: 0, Lengthscale: [[0.5889734  0.35926288]] [0m
[92mRank: 0, Outputscale: 1.0129797458648682 [0m
[92mRank: 0, Noise: 0.00019354006508365273 [0m
Run 7 completed successfully
Running apxGP 8 with agents: 49
decpxADMM initialized with rho: 0.85, lip: 1.0, tol_abs: 1e-05, tol_rel: 0.001, rank: 0, world_size: 49
Rank 0 - Epoch 2/98 loss: 0.7501490712165833
Rank 0 - Epoch 10/98 loss: 0.47852054238319397
Rank 0 - Epoch 20/98 loss: 0.05085618793964386
Rank 0 - Epoch 30/98 loss: -0.4313848316669464
Rank 0 - Epoch 40/98 loss: -0.9444073438644409
Rank 0 - Epoch 50/98 loss: -1.472633957862854
Rank 0 - Epoch 60/98 loss: -1.9868745803833008
Rank 0 - Epoch 70/98 loss: -2.457679271697998
Rank 0 - Epoch 80/98 loss: -2.8360512256622314
Rank 0 - Epoch 90/98 loss: -3.088148593902588
Training complete.
[92mRank 0 - Testing RMSE: 3.1695[0m
[92mRank: 0, Lengthscale: [[0.5889734  0.35926288]] [0m
[92mRank: 0, Outputscale: 1.0129797458648682 [0m
[92mRank: 0, Noise: 0.00019354006508365273 [0m
Run 8 completed successfully
Running apxGP 9 with agents: 49
decpxADMM initialized with rho: 0.85, lip: 1.0, tol_abs: 1e-05, tol_rel: 0.001, rank: 0, world_size: 49
Rank 0 - Epoch 2/98 loss: 0.7501490712165833
Rank 0 - Epoch 10/98 loss: 0.47852054238319397
Rank 0 - Epoch 20/98 loss: 0.05085618793964386
Rank 0 - Epoch 30/98 loss: -0.4313848316669464
Rank 0 - Epoch 40/98 loss: -0.9444073438644409
Rank 0 - Epoch 50/98 loss: -1.472633957862854
Rank 0 - Epoch 60/98 loss: -1.9868745803833008
Rank 0 - Epoch 70/98 loss: -2.457679271697998
Rank 0 - Epoch 80/98 loss: -2.8360512256622314
Rank 0 - Epoch 90/98 loss: -3.088148593902588
Training complete.
[92mRank 0 - Testing RMSE: 3.1695[0m
[92mRank: 0, Lengthscale: [[0.5889734  0.35926288]] [0m
[92mRank: 0, Outputscale: 1.0129797458648682 [0m
[92mRank: 0, Noise: 0.00019354006508365273 [0m
Run 9 completed successfully
Running apxGP 10 with agents: 49
decpxADMM initialized with rho: 0.85, lip: 1.0, tol_abs: 1e-05, tol_rel: 0.001, rank: 0, world_size: 49
Rank 0 - Epoch 2/98 loss: 0.7501490712165833
Rank 0 - Epoch 10/98 loss: 0.47852054238319397
Rank 0 - Epoch 20/98 loss: 0.05085618793964386
Rank 0 - Epoch 30/98 loss: -0.4313848316669464
Rank 0 - Epoch 40/98 loss: -0.9444073438644409
Rank 0 - Epoch 50/98 loss: -1.472633957862854
Rank 0 - Epoch 60/98 loss: -1.9868745803833008
Rank 0 - Epoch 70/98 loss: -2.457679271697998
Rank 0 - Epoch 80/98 loss: -2.8360512256622314
Rank 0 - Epoch 90/98 loss: -3.088148593902588
Training complete.
[92mRank 0 - Testing RMSE: 3.1695[0m
[92mRank: 0, Lengthscale: [[0.5889734  0.35926288]] [0m
[92mRank: 0, Outputscale: 1.0129797458648682 [0m
[92mRank: 0, Noise: 0.00019354006508365273 [0m
Run 10 completed successfully
Running cGP 1 with agents: 49
decADMM initialized with rho: 0.85, max_iter: 5, lr: 0.0001, rank: 0, world_size: 49
Rank 0 - Epoch 2/98 loss: 0.8069456219673157
Rank 0 - Epoch 10/98 loss: 0.8017060160636902
Rank 0 - Epoch 20/98 loss: 0.7951552867889404
Rank 0 - Epoch 30/98 loss: 0.7886052131652832
Rank 0 - Epoch 40/98 loss: 0.78205806016922
Rank 0 - Epoch 50/98 loss: 0.7755167484283447
Rank 0 - Epoch 60/98 loss: 0.7689835429191589
Rank 0 - Epoch 70/98 loss: 0.7624611258506775
Rank 0 - Epoch 80/98 loss: 0.7559521198272705
Rank 0 - Epoch 90/98 loss: 0.749458909034729
Training complete.
[92mRank 0 - Testing RMSE: 3.7078[0m
[92mRank: 0, Lengthscale: [[0.61346596 0.6123863 ]] [0m
[92mRank: 0, Outputscale: 0.6141249537467957 [0m
[92mRank: 0, Noise: 0.6053975820541382 [0m
Run 1 completed successfully
Running cGP 2 with agents: 49
decADMM initialized with rho: 0.85, max_iter: 5, lr: 0.0001, rank: 0, world_size: 49
Rank 0 - Epoch 2/98 loss: 0.8069456219673157
Rank 0 - Epoch 10/98 loss: 0.8017060160636902
Rank 0 - Epoch 20/98 loss: 0.7951552867889404
Rank 0 - Epoch 30/98 loss: 0.7886052131652832
Rank 0 - Epoch 40/98 loss: 0.78205806016922
Rank 0 - Epoch 50/98 loss: 0.7755167484283447
Rank 0 - Epoch 60/98 loss: 0.7689835429191589
Rank 0 - Epoch 70/98 loss: 0.7624611258506775
Rank 0 - Epoch 80/98 loss: 0.7559521198272705
Rank 0 - Epoch 90/98 loss: 0.749458909034729
Training complete.
[92mRank 0 - Testing RMSE: 3.7078[0m
[92mRank: 0, Lengthscale: [[0.61346596 0.6123863 ]] [0m
[92mRank: 0, Outputscale: 0.6141249537467957 [0m
[92mRank: 0, Noise: 0.6053975820541382 [0m
Run 2 completed successfully
Running cGP 3 with agents: 49
decADMM initialized with rho: 0.85, max_iter: 5, lr: 0.0001, rank: 0, world_size: 49
Rank 0 - Epoch 2/98 loss: 0.8069456219673157
Rank 0 - Epoch 10/98 loss: 0.8017060160636902
Rank 0 - Epoch 20/98 loss: 0.7951552867889404
Rank 0 - Epoch 30/98 loss: 0.7886052131652832
Rank 0 - Epoch 40/98 loss: 0.78205806016922
Rank 0 - Epoch 50/98 loss: 0.7755167484283447
Rank 0 - Epoch 60/98 loss: 0.7689835429191589
Rank 0 - Epoch 70/98 loss: 0.7624611258506775
Rank 0 - Epoch 80/98 loss: 0.7559521198272705
Rank 0 - Epoch 90/98 loss: 0.749458909034729
Training complete.
[92mRank 0 - Testing RMSE: 3.7078[0m
[92mRank: 0, Lengthscale: [[0.61346596 0.6123863 ]] [0m
[92mRank: 0, Outputscale: 0.6141249537467957 [0m
[92mRank: 0, Noise: 0.6053975820541382 [0m
Run 3 completed successfully
Running cGP 4 with agents: 49
decADMM initialized with rho: 0.85, max_iter: 5, lr: 0.0001, rank: 0, world_size: 49
Rank 0 - Epoch 2/98 loss: 0.8069456219673157
Rank 0 - Epoch 10/98 loss: 0.8017060160636902
Rank 0 - Epoch 20/98 loss: 0.7951552867889404
Rank 0 - Epoch 30/98 loss: 0.7886052131652832
Rank 0 - Epoch 40/98 loss: 0.78205806016922
Rank 0 - Epoch 50/98 loss: 0.7755167484283447
Rank 0 - Epoch 60/98 loss: 0.7689835429191589
Rank 0 - Epoch 70/98 loss: 0.7624611258506775
Rank 0 - Epoch 80/98 loss: 0.7559521198272705
Rank 0 - Epoch 90/98 loss: 0.749458909034729
Training complete.
[92mRank 0 - Testing RMSE: 3.7078[0m
[92mRank: 0, Lengthscale: [[0.61346596 0.6123863 ]] [0m
[92mRank: 0, Outputscale: 0.6141249537467957 [0m
[92mRank: 0, Noise: 0.6053975820541382 [0m
Run 4 completed successfully
Running cGP 5 with agents: 49
decADMM initialized with rho: 0.85, max_iter: 5, lr: 0.0001, rank: 0, world_size: 49
Rank 0 - Epoch 2/98 loss: 0.8069456219673157
Rank 0 - Epoch 10/98 loss: 0.8017060160636902
Rank 0 - Epoch 20/98 loss: 0.7951552867889404
Rank 0 - Epoch 30/98 loss: 0.7886052131652832
Rank 0 - Epoch 40/98 loss: 0.78205806016922
Rank 0 - Epoch 50/98 loss: 0.7755167484283447
Rank 0 - Epoch 60/98 loss: 0.7689835429191589
Rank 0 - Epoch 70/98 loss: 0.7624611258506775
Rank 0 - Epoch 80/98 loss: 0.7559521198272705
Rank 0 - Epoch 90/98 loss: 0.749458909034729
Training complete.
[92mRank 0 - Testing RMSE: 3.7078[0m
[92mRank: 0, Lengthscale: [[0.61346596 0.6123863 ]] [0m
[92mRank: 0, Outputscale: 0.6141249537467957 [0m
[92mRank: 0, Noise: 0.6053975820541382 [0m
Run 5 completed successfully
Running cGP 6 with agents: 49
decADMM initialized with rho: 0.85, max_iter: 5, lr: 0.0001, rank: 0, world_size: 49
Rank 0 - Epoch 2/98 loss: 0.8069456219673157
Rank 0 - Epoch 10/98 loss: 0.8017060160636902
Rank 0 - Epoch 20/98 loss: 0.7951552867889404
Rank 0 - Epoch 30/98 loss: 0.7886052131652832
Rank 0 - Epoch 40/98 loss: 0.78205806016922
Rank 0 - Epoch 50/98 loss: 0.7755167484283447
Rank 0 - Epoch 60/98 loss: 0.7689835429191589
Rank 0 - Epoch 70/98 loss: 0.7624611258506775
Rank 0 - Epoch 80/98 loss: 0.7559521198272705
Rank 0 - Epoch 90/98 loss: 0.749458909034729
Training complete.
[92mRank 0 - Testing RMSE: 3.7078[0m
[92mRank: 0, Lengthscale: [[0.61346596 0.6123863 ]] [0m
[92mRank: 0, Outputscale: 0.6141249537467957 [0m
[92mRank: 0, Noise: 0.6053975820541382 [0m
Run 6 completed successfully
Running cGP 7 with agents: 49
decADMM initialized with rho: 0.85, max_iter: 5, lr: 0.0001, rank: 0, world_size: 49
Rank 0 - Epoch 2/98 loss: 0.8069456219673157
Rank 0 - Epoch 10/98 loss: 0.8017060160636902
Rank 0 - Epoch 20/98 loss: 0.7951552867889404
Rank 0 - Epoch 30/98 loss: 0.7886052131652832
Rank 0 - Epoch 40/98 loss: 0.78205806016922
Rank 0 - Epoch 50/98 loss: 0.7755167484283447
Rank 0 - Epoch 60/98 loss: 0.7689835429191589
Rank 0 - Epoch 70/98 loss: 0.7624611258506775
Rank 0 - Epoch 80/98 loss: 0.7559521198272705
Rank 0 - Epoch 90/98 loss: 0.749458909034729
Training complete.
[92mRank 0 - Testing RMSE: 3.7078[0m
[92mRank: 0, Lengthscale: [[0.61346596 0.6123863 ]] [0m
[92mRank: 0, Outputscale: 0.6141249537467957 [0m
[92mRank: 0, Noise: 0.6053975820541382 [0m
Run 7 completed successfully
Running cGP 8 with agents: 49
decADMM initialized with rho: 0.85, max_iter: 5, lr: 0.0001, rank: 0, world_size: 49
Rank 0 - Epoch 2/98 loss: 0.8069456219673157
Rank 0 - Epoch 10/98 loss: 0.8017060160636902
Rank 0 - Epoch 20/98 loss: 0.7951552867889404
Rank 0 - Epoch 30/98 loss: 0.7886052131652832
Rank 0 - Epoch 40/98 loss: 0.78205806016922
Rank 0 - Epoch 50/98 loss: 0.7755167484283447
Rank 0 - Epoch 60/98 loss: 0.7689835429191589
Rank 0 - Epoch 70/98 loss: 0.7624611258506775
Rank 0 - Epoch 80/98 loss: 0.7559521198272705
Rank 0 - Epoch 90/98 loss: 0.749458909034729
Training complete.
[92mRank 0 - Testing RMSE: 3.7078[0m
[92mRank: 0, Lengthscale: [[0.61346596 0.6123863 ]] [0m
[92mRank: 0, Outputscale: 0.6141249537467957 [0m
[92mRank: 0, Noise: 0.6053975820541382 [0m
Run 8 completed successfully
Running cGP 9 with agents: 49
decADMM initialized with rho: 0.85, max_iter: 5, lr: 0.0001, rank: 0, world_size: 49
Rank 0 - Epoch 2/98 loss: 0.8069456219673157
Rank 0 - Epoch 10/98 loss: 0.8017060160636902
Rank 0 - Epoch 20/98 loss: 0.7951552867889404
Rank 0 - Epoch 30/98 loss: 0.7886052131652832
Rank 0 - Epoch 40/98 loss: 0.78205806016922
Rank 0 - Epoch 50/98 loss: 0.7755167484283447
Rank 0 - Epoch 60/98 loss: 0.7689835429191589
Rank 0 - Epoch 70/98 loss: 0.7624611258506775
Rank 0 - Epoch 80/98 loss: 0.7559521198272705
Rank 0 - Epoch 90/98 loss: 0.749458909034729
Training complete.
[92mRank 0 - Testing RMSE: 3.7078[0m
[92mRank: 0, Lengthscale: [[0.61346596 0.6123863 ]] [0m
[92mRank: 0, Outputscale: 0.6141249537467957 [0m
[92mRank: 0, Noise: 0.6053975820541382 [0m
Run 9 completed successfully
Running cGP 10 with agents: 49
decADMM initialized with rho: 0.85, max_iter: 5, lr: 0.0001, rank: 0, world_size: 49
Rank 0 - Epoch 2/98 loss: 0.8069456219673157
Rank 0 - Epoch 10/98 loss: 0.8017060160636902
Rank 0 - Epoch 20/98 loss: 0.7951552867889404
Rank 0 - Epoch 30/98 loss: 0.7886052131652832
Rank 0 - Epoch 40/98 loss: 0.78205806016922
Rank 0 - Epoch 50/98 loss: 0.7755167484283447
Rank 0 - Epoch 60/98 loss: 0.7689835429191589
Rank 0 - Epoch 70/98 loss: 0.7624611258506775
Rank 0 - Epoch 80/98 loss: 0.7559521198272705
Rank 0 - Epoch 90/98 loss: 0.749458909034729
Training complete.
[92mRank 0 - Testing RMSE: 3.7078[0m
[92mRank: 0, Lengthscale: [[0.61346596 0.6123863 ]] [0m
[92mRank: 0, Outputscale: 0.6141249537467957 [0m
[92mRank: 0, Noise: 0.6053975820541382 [0m
Run 10 completed successfully
Running pxpGP 1 with agents: 64
[92mRank 0 - sparse dataset size is: 8, local dataset: torch.Size([529, 2]), [0m
[92mRank 0 - Training local sparse GP model with 529 samples[0m
Epoch 1/200 - Loss: 16.681
Epoch 11/200 - Loss: 1.325
Epoch 21/200 - Loss: 1.142
Epoch 31/200 - Loss: 1.046
Epoch 41/200 - Loss: 0.939
Epoch 51/200 - Loss: 0.809
Epoch 61/200 - Loss: 0.685
Epoch 71/200 - Loss: 0.552
Epoch 81/200 - Loss: 0.368
Epoch 91/200 - Loss: 0.182
Converged at epoch 100 with loss -0.016
[92mRank 0 - Lengthscale: [[0.55792737 0.52449846]] [0m
[92mRank 0 - Outputscale: 2.480970621109009 [0m
[92mRank 0 - Noise: 0.1361471563577652 [0m
Rank 0 - Augmented dataset size: 1041
Rank 0: After warm start model parameters:
Rank: 0, Lengthscale: [[0.55792737 0.52449846]]
Rank: 0, Outputscale: 2.480970621109009
Rank: 0, Noise: 0.1361471563577652
decpxADMM initialized with rho: 0.85, lip: 1.0, tol_abs: 1e-05, tol_rel: 0.001, rank: 0, world_size: 64
[92mRank 0 - Training global model with dec-pxADMM optimizer[0m
rank 0, epoch 9, loss: 0.6679672598838806, rho: 0.2125, lip: 1.0000
rank 0, epoch 19, loss: 0.655488133430481, rho: 0.2125, lip: 1.0000
rank 0, epoch 29, loss: 0.6560715436935425, rho: 0.1062, lip: 1.0000
rank 0, epoch 39, loss: 0.6583071351051331, rho: 0.0266, lip: 1.0000
rank 0, epoch 49, loss: 0.6464134454727173, rho: 0.0266, lip: 1.0000
rank 0, epoch 59, loss: 0.6490316987037659, rho: 0.0266, lip: 1.0000
rank 0, epoch 69, loss: 0.6444237232208252, rho: 0.0266, lip: 1.0000
rank 0, epoch 79, loss: 0.6520240902900696, rho: 0.0266, lip: 1.0000
rank 0, epoch 89, loss: 0.6561670303344727, rho: 0.0133, lip: 1.0000
Rank 0 - Training time: 101.93 seconds
[92mRank 0 - Testing RMSE: 0.3565[0m
[92mRank: 0, Lengthscale: [[0.5854528  0.32941216]] [0m
[92mRank: 0, Outputscale: 3.021298885345459 [0m
[92mRank: 0, Noise: 0.15744614601135254 [0m
Run 1 completed successfully
Running pxpGP 2 with agents: 64
[92mRank 0 - sparse dataset size is: 8, local dataset: torch.Size([529, 2]), [0m
[92mRank 0 - Training local sparse GP model with 529 samples[0m
Epoch 1/200 - Loss: 14.629
Epoch 11/200 - Loss: 1.170
Epoch 21/200 - Loss: 1.110
Epoch 31/200 - Loss: 0.996
Epoch 41/200 - Loss: 0.896
Epoch 51/200 - Loss: 0.802
Epoch 61/200 - Loss: 0.684
Epoch 71/200 - Loss: 0.512
Epoch 81/200 - Loss: 0.335
Epoch 91/200 - Loss: 0.145
Converged at epoch 98 with loss -0.015
[92mRank 0 - Lengthscale: [[0.75141263 0.55770355]] [0m
[92mRank 0 - Outputscale: 2.5912954807281494 [0m
[92mRank 0 - Noise: 0.1360408067703247 [0m
Rank 0 - Augmented dataset size: 1041
Rank 0: After warm start model parameters:
Rank: 0, Lengthscale: [[0.75141263 0.5577036 ]]
Rank: 0, Outputscale: 2.5912954807281494
Rank: 0, Noise: 0.1360408067703247
decpxADMM initialized with rho: 0.85, lip: 1.0, tol_abs: 1e-05, tol_rel: 0.001, rank: 0, world_size: 64
[92mRank 0 - Training global model with dec-pxADMM optimizer[0m
rank 0, epoch 9, loss: 0.6420229077339172, rho: 0.2125, lip: 1.0000
rank 0, epoch 19, loss: 0.6101064085960388, rho: 0.2125, lip: 1.0000
rank 0, epoch 29, loss: 0.658062756061554, rho: 0.1062, lip: 1.0000
rank 0, epoch 39, loss: 0.6787942051887512, rho: 0.1062, lip: 1.0000
rank 0, epoch 49, loss: 0.6420060992240906, rho: 0.1062, lip: 1.0000
rank 0, epoch 59, loss: 0.6720991134643555, rho: 0.0531, lip: 1.0000
rank 0, epoch 69, loss: 0.6479535102844238, rho: 0.0531, lip: 1.0000
rank 0, epoch 79, loss: 0.6468747854232788, rho: 0.0531, lip: 1.0000
rank 0, epoch 89, loss: 0.641441822052002, rho: 0.0266, lip: 1.0000
Rank 0 - Training time: 159.85 seconds
[92mRank 0 - Testing RMSE: 0.4832[0m
[92mRank: 0, Lengthscale: [[0.610394  0.0944106]] [0m
[92mRank: 0, Outputscale: 2.634692430496216 [0m
[92mRank: 0, Noise: 0.09788684546947479 [0m
Run 2 completed successfully
Running pxpGP 3 with agents: 64
[92mRank 0 - sparse dataset size is: 8, local dataset: torch.Size([529, 2]), [0m
[92mRank 0 - Training local sparse GP model with 529 samples[0m
Epoch 1/200 - Loss: 16.635
Epoch 11/200 - Loss: 1.230
Epoch 21/200 - Loss: 1.129
Epoch 31/200 - Loss: 0.986
Epoch 41/200 - Loss: 0.908
Epoch 51/200 - Loss: 0.804
Epoch 61/200 - Loss: 0.674
Epoch 71/200 - Loss: 0.531
Epoch 81/200 - Loss: 0.358
Epoch 91/200 - Loss: 0.155
Converged at epoch 99 with loss -0.005
[92mRank 0 - Lengthscale: [[0.8157865  0.56794083]] [0m
[92mRank 0 - Outputscale: 2.569390296936035 [0m
[92mRank 0 - Noise: 0.13661040365695953 [0m
Rank 0 - Augmented dataset size: 1041
Rank 0: After warm start model parameters:
Rank: 0, Lengthscale: [[0.8157865  0.56794083]]
Rank: 0, Outputscale: 2.569390296936035
Rank: 0, Noise: 0.13661038875579834
decpxADMM initialized with rho: 0.85, lip: 1.0, tol_abs: 1e-05, tol_rel: 0.001, rank: 0, world_size: 64
[92mRank 0 - Training global model with dec-pxADMM optimizer[0m
rank 0, epoch 9, loss: 0.6522597074508667, rho: 0.4250, lip: 1.0000
rank 0, epoch 19, loss: 0.6331877112388611, rho: 0.2125, lip: 1.0000
rank 0, epoch 29, loss: 0.6812204718589783, rho: 0.1062, lip: 1.0000
rank 0, epoch 39, loss: 0.6489662528038025, rho: 0.1062, lip: 1.0000
rank 0, epoch 49, loss: 0.6507914662361145, rho: 0.0531, lip: 1.0000
rank 0, epoch 59, loss: 0.6317893862724304, rho: 0.0266, lip: 1.0000
rank 0, epoch 69, loss: 0.6340875029563904, rho: 0.0266, lip: 1.0000
rank 0, epoch 79, loss: 0.6463126540184021, rho: 0.0266, lip: 1.0000
rank 0, epoch 89, loss: 0.629908561706543, rho: 0.0266, lip: 1.0000
Rank 0 - Training time: 123.12 seconds
[92mRank 0 - Testing RMSE: 0.3914[0m
[92mRank: 0, Lengthscale: [[0.50693744 0.20626773]] [0m
[92mRank: 0, Outputscale: 1.262562870979309 [0m
[92mRank: 0, Noise: 0.14045216143131256 [0m
Run 3 completed successfully
Running pxpGP 4 with agents: 64
[92mRank 0 - sparse dataset size is: 8, local dataset: torch.Size([529, 2]), [0m
[92mRank 0 - Training local sparse GP model with 529 samples[0m
Epoch 1/200 - Loss: 16.498
Epoch 11/200 - Loss: 1.253
Epoch 21/200 - Loss: 1.151
Epoch 31/200 - Loss: 0.996
Epoch 41/200 - Loss: 0.964
Epoch 51/200 - Loss: 0.796
Epoch 61/200 - Loss: 0.674
Epoch 71/200 - Loss: 0.523
Epoch 81/200 - Loss: 0.351
Epoch 91/200 - Loss: 0.210
Converged at epoch 100 with loss -0.026
[92mRank 0 - Lengthscale: [[0.5746296 0.5576865]] [0m
[92mRank 0 - Outputscale: 2.4915361404418945 [0m
[92mRank 0 - Noise: 0.1335557997226715 [0m
Rank 0 - Augmented dataset size: 1041
Rank 0: After warm start model parameters:
Rank: 0, Lengthscale: [[0.5746296 0.5576865]]
Rank: 0, Outputscale: 2.4915361404418945
Rank: 0, Noise: 0.1335557997226715
decpxADMM initialized with rho: 0.85, lip: 1.0, tol_abs: 1e-05, tol_rel: 0.001, rank: 0, world_size: 64
[92mRank 0 - Training global model with dec-pxADMM optimizer[0m
rank 0, epoch 9, loss: 0.6640744209289551, rho: 0.2125, lip: 1.0000
rank 0, epoch 19, loss: 0.6495965719223022, rho: 0.1062, lip: 1.0000
rank 0, epoch 29, loss: 0.6758692860603333, rho: 0.1062, lip: 1.0000
rank 0, epoch 39, loss: 0.6452134847640991, rho: 0.0531, lip: 1.0000
rank 0, epoch 49, loss: 0.6635283827781677, rho: 0.0531, lip: 1.0000
rank 0, epoch 59, loss: 0.6491969227790833, rho: 0.0266, lip: 1.0000
rank 0, epoch 69, loss: 0.6568748354911804, rho: 0.0266, lip: 1.0000
rank 0, epoch 79, loss: 0.6626317501068115, rho: 0.0266, lip: 1.0000
rank 0, epoch 89, loss: 0.6600568294525146, rho: 0.0133, lip: 1.0000
Rank 0 - Training time: 112.66 seconds
[92mRank 0 - Testing RMSE: 0.3980[0m
[92mRank: 0, Lengthscale: [[0.60413575 0.24296384]] [0m
[92mRank: 0, Outputscale: 1.455309510231018 [0m
[92mRank: 0, Noise: 0.1477418839931488 [0m
Run 4 completed successfully
Running pxpGP 5 with agents: 64
[92mRank 0 - sparse dataset size is: 8, local dataset: torch.Size([529, 2]), [0m
[92mRank 0 - Training local sparse GP model with 529 samples[0m
Epoch 1/200 - Loss: 15.643
Epoch 11/200 - Loss: 1.214
Epoch 21/200 - Loss: 1.117
Epoch 31/200 - Loss: 0.980
Epoch 41/200 - Loss: 0.920
Epoch 51/200 - Loss: 0.796
Epoch 61/200 - Loss: 0.673
Epoch 71/200 - Loss: 0.516
Epoch 81/200 - Loss: 0.344
Epoch 91/200 - Loss: 0.144
Converged at epoch 98 with loss -0.006
[92mRank 0 - Lengthscale: [[0.9236067  0.51740086]] [0m
[92mRank 0 - Outputscale: 2.5021791458129883 [0m
[92mRank 0 - Noise: 0.13944905996322632 [0m
Rank 0 - Augmented dataset size: 1041
Rank 0: After warm start model parameters:
Rank: 0, Lengthscale: [[0.92360675 0.51740086]]
Rank: 0, Outputscale: 2.5021791458129883
Rank: 0, Noise: 0.1394490748643875
decpxADMM initialized with rho: 0.85, lip: 1.0, tol_abs: 1e-05, tol_rel: 0.001, rank: 0, world_size: 64
[92mRank 0 - Training global model with dec-pxADMM optimizer[0m
rank 0, epoch 9, loss: 0.7923240661621094, rho: 0.2125, lip: 1.0000
rank 0, epoch 19, loss: 0.763203501701355, rho: 0.2125, lip: 1.0000
rank 0, epoch 29, loss: 0.7933889031410217, rho: 0.1062, lip: 1.0000
rank 0, epoch 39, loss: 0.7889077067375183, rho: 0.0531, lip: 1.0000
rank 0, epoch 49, loss: 0.77854323387146, rho: 0.0531, lip: 1.0000
rank 0, epoch 59, loss: 0.7884819507598877, rho: 0.0266, lip: 1.0000
rank 0, epoch 69, loss: 0.8028485774993896, rho: 0.0266, lip: 1.0000
rank 0, epoch 79, loss: 0.8118045330047607, rho: 0.0266, lip: 1.0000
rank 0, epoch 89, loss: 0.8165887594223022, rho: 0.0266, lip: 1.0000
Rank 0 - Training time: 174.03 seconds
[92mRank 0 - Testing RMSE: 0.6996[0m
[92mRank: 0, Lengthscale: [[0.18609898 0.13953409]] [0m
[92mRank: 0, Outputscale: 2.6583313941955566 [0m
[92mRank: 0, Noise: 0.1086624413728714 [0m
Run 5 completed successfully
Running pxpGP 6 with agents: 64
[92mRank 0 - sparse dataset size is: 8, local dataset: torch.Size([529, 2]), [0m
[92mRank 0 - Training local sparse GP model with 529 samples[0m
Epoch 1/200 - Loss: 15.624
Epoch 11/200 - Loss: 1.458
Epoch 21/200 - Loss: 1.090
Epoch 31/200 - Loss: 0.993
Epoch 41/200 - Loss: 0.908
Epoch 51/200 - Loss: 0.807
Epoch 61/200 - Loss: 0.670
Epoch 71/200 - Loss: 0.522
Epoch 81/200 - Loss: 0.350
Epoch 91/200 - Loss: 0.152
Converged at epoch 98 with loss -0.002
[92mRank 0 - Lengthscale: [[0.88405204 0.5377934 ]] [0m
[92mRank 0 - Outputscale: 2.515169620513916 [0m
[92mRank 0 - Noise: 0.1401422917842865 [0m
Rank 0 - Augmented dataset size: 1041
Rank 0: After warm start model parameters:
Rank: 0, Lengthscale: [[0.88405204 0.5377934 ]]
Rank: 0, Outputscale: 2.515169620513916
Rank: 0, Noise: 0.1401422917842865
decpxADMM initialized with rho: 0.85, lip: 1.0, tol_abs: 1e-05, tol_rel: 0.001, rank: 0, world_size: 64
[92mRank 0 - Training global model with dec-pxADMM optimizer[0m
rank 0, epoch 9, loss: 0.6787859201431274, rho: 0.4250, lip: 1.0000
rank 0, epoch 19, loss: 0.6337618231773376, rho: 0.2125, lip: 1.0000
rank 0, epoch 29, loss: 0.6820502877235413, rho: 0.1062, lip: 1.0000
rank 0, epoch 39, loss: 0.6663350462913513, rho: 0.0531, lip: 1.0000
rank 0, epoch 49, loss: 0.6458680033683777, rho: 0.0531, lip: 1.0000
rank 0, epoch 59, loss: 0.6500158309936523, rho: 0.0531, lip: 1.0000
rank 0, epoch 69, loss: 0.6640649437904358, rho: 0.0531, lip: 1.0000
rank 0, epoch 79, loss: 0.6604899764060974, rho: 0.0531, lip: 1.0000
rank 0, epoch 89, loss: 0.6493000388145447, rho: 0.0266, lip: 1.0000
Rank 0 - Training time: 161.62 seconds
[92mRank 0 - Testing RMSE: 0.4153[0m
[92mRank: 0, Lengthscale: [[0.54714227 0.20940968]] [0m
[92mRank: 0, Outputscale: 1.987600326538086 [0m
[92mRank: 0, Noise: 0.13799285888671875 [0m
Run 6 completed successfully
Running pxpGP 7 with agents: 64
[92mRank 0 - sparse dataset size is: 8, local dataset: torch.Size([529, 2]), [0m
[92mRank 0 - Training local sparse GP model with 529 samples[0m
Epoch 1/200 - Loss: 16.629
Epoch 11/200 - Loss: 1.210
Epoch 21/200 - Loss: 1.095
Epoch 31/200 - Loss: 1.026
Epoch 41/200 - Loss: 0.907
Epoch 51/200 - Loss: 0.796
Epoch 61/200 - Loss: 0.669
Epoch 71/200 - Loss: 0.519
Epoch 81/200 - Loss: 0.351
Epoch 91/200 - Loss: 0.156
Converged at epoch 99 with loss -0.010
[92mRank 0 - Lengthscale: [[0.8489286  0.57277894]] [0m
[92mRank 0 - Outputscale: 2.5602633953094482 [0m
[92mRank 0 - Noise: 0.13581006228923798 [0m
Rank 0 - Augmented dataset size: 1041
Rank 0: After warm start model parameters:
Rank: 0, Lengthscale: [[0.8489286  0.57277894]]
Rank: 0, Outputscale: 2.560263156890869
Rank: 0, Noise: 0.13581006228923798
decpxADMM initialized with rho: 0.85, lip: 1.0, tol_abs: 1e-05, tol_rel: 0.001, rank: 0, world_size: 64
[92mRank 0 - Training global model with dec-pxADMM optimizer[0m
rank 0, epoch 9, loss: 0.7426742315292358, rho: 0.2125, lip: 1.0000
rank 0, epoch 19, loss: 0.6924666166305542, rho: 0.2125, lip: 1.0000
rank 0, epoch 29, loss: 0.7205179929733276, rho: 0.1062, lip: 1.0000
rank 0, epoch 39, loss: 0.723154604434967, rho: 0.1062, lip: 1.0000
rank 0, epoch 49, loss: 0.7156142592430115, rho: 0.0531, lip: 1.0000
rank 0, epoch 59, loss: 0.7220494747161865, rho: 0.0531, lip: 1.0000
rank 0, epoch 69, loss: 0.7210577130317688, rho: 0.0531, lip: 1.0000
rank 0, epoch 79, loss: 0.7162790894508362, rho: 0.0531, lip: 1.0000
rank 0, epoch 89, loss: 0.7099370360374451, rho: 0.0531, lip: 1.0000
Rank 0 - Training time: 158.39 seconds
[92mRank 0 - Testing RMSE: 0.5495[0m
[92mRank: 0, Lengthscale: [[0.1739911  0.23007853]] [0m
[92mRank: 0, Outputscale: 1.8718584775924683 [0m
[92mRank: 0, Noise: 0.10366468876600266 [0m
Run 7 completed successfully
Running pxpGP 8 with agents: 64
[92mRank 0 - sparse dataset size is: 8, local dataset: torch.Size([529, 2]), [0m
[92mRank 0 - Training local sparse GP model with 529 samples[0m
Epoch 1/200 - Loss: 15.958
Epoch 11/200 - Loss: 1.298
Epoch 21/200 - Loss: 1.132
Epoch 31/200 - Loss: 0.980
Epoch 41/200 - Loss: 0.921
Epoch 51/200 - Loss: 0.812
Epoch 61/200 - Loss: 0.674
Epoch 71/200 - Loss: 0.527
Epoch 81/200 - Loss: 0.341
Epoch 91/200 - Loss: 0.144
Converged at epoch 98 with loss -0.012
[92mRank 0 - Lengthscale: [[0.717876  0.5485709]] [0m
[92mRank 0 - Outputscale: 2.5168099403381348 [0m
[92mRank 0 - Noise: 0.13697102665901184 [0m
Rank 0 - Augmented dataset size: 1041
Rank 0: After warm start model parameters:
Rank: 0, Lengthscale: [[0.7178761 0.5485709]]
Rank: 0, Outputscale: 2.5168099403381348
Rank: 0, Noise: 0.13697102665901184
decpxADMM initialized with rho: 0.85, lip: 1.0, tol_abs: 1e-05, tol_rel: 0.001, rank: 0, world_size: 64
[92mRank 0 - Training global model with dec-pxADMM optimizer[0m
rank 0, epoch 9, loss: 0.7007874250411987, rho: 0.2125, lip: 1.0000
rank 0, epoch 19, loss: 0.6577880382537842, rho: 0.2125, lip: 1.0000
rank 0, epoch 29, loss: 0.6626147627830505, rho: 0.1062, lip: 1.0000
rank 0, epoch 39, loss: 0.6705695390701294, rho: 0.0531, lip: 1.0000
rank 0, epoch 49, loss: 0.6825572848320007, rho: 0.0531, lip: 1.0000
rank 0, epoch 59, loss: 0.6705390810966492, rho: 0.0266, lip: 1.0000
rank 0, epoch 69, loss: 0.6872095465660095, rho: 0.0266, lip: 1.0000
rank 0, epoch 79, loss: 0.6950312852859497, rho: 0.0266, lip: 1.0000
rank 0, epoch 89, loss: 0.684051513671875, rho: 0.0266, lip: 1.0000
Rank 0 - Training time: 149.51 seconds
[92mRank 0 - Testing RMSE: 0.4934[0m
[92mRank: 0, Lengthscale: [[0.21797925 0.35277838]] [0m
[92mRank: 0, Outputscale: 3.1623897552490234 [0m
[92mRank: 0, Noise: 0.12874193489551544 [0m
Run 8 completed successfully
Running pxpGP 9 with agents: 64
[92mRank 0 - sparse dataset size is: 8, local dataset: torch.Size([529, 2]), [0m
[92mRank 0 - Training local sparse GP model with 529 samples[0m
Epoch 1/200 - Loss: 16.289
Epoch 11/200 - Loss: 1.315
Epoch 21/200 - Loss: 1.130
Epoch 31/200 - Loss: 1.034
Epoch 41/200 - Loss: 0.904
Epoch 51/200 - Loss: 0.800
Epoch 61/200 - Loss: 0.674
Epoch 71/200 - Loss: 0.529
Epoch 81/200 - Loss: 0.356
Epoch 91/200 - Loss: 0.152
Converged at epoch 100 with loss -0.030
[92mRank 0 - Lengthscale: [[0.912088  0.5451577]] [0m
[92mRank 0 - Outputscale: 2.5488643646240234 [0m
[92mRank 0 - Noise: 0.12960855662822723 [0m
Rank 0 - Augmented dataset size: 1041
Rank 0: After warm start model parameters:
Rank: 0, Lengthscale: [[0.912088  0.5451577]]
Rank: 0, Outputscale: 2.5488643646240234
Rank: 0, Noise: 0.12960854172706604
decpxADMM initialized with rho: 0.85, lip: 1.0, tol_abs: 1e-05, tol_rel: 0.001, rank: 0, world_size: 64
[92mRank 0 - Training global model with dec-pxADMM optimizer[0m
rank 0, epoch 9, loss: 0.7074052095413208, rho: 0.4250, lip: 1.0000
rank 0, epoch 19, loss: 0.6771025061607361, rho: 0.2125, lip: 1.0000
rank 0, epoch 29, loss: 0.7048020958900452, rho: 0.2125, lip: 1.0000
rank 0, epoch 39, loss: 0.7030549645423889, rho: 0.1062, lip: 1.0000
rank 0, epoch 49, loss: 0.72027987241745, rho: 0.0531, lip: 1.0000
rank 0, epoch 59, loss: 0.7058811187744141, rho: 0.0266, lip: 1.0000
rank 0, epoch 69, loss: 0.7022128105163574, rho: 0.0266, lip: 1.0000
rank 0, epoch 79, loss: 0.6963488459587097, rho: 0.0266, lip: 1.0000
rank 0, epoch 89, loss: 0.6979139447212219, rho: 0.0266, lip: 1.0000
Rank 0 - Training time: 158.15 seconds
[92mRank 0 - Testing RMSE: 0.4892[0m
[92mRank: 0, Lengthscale: [[0.35883448 0.17757729]] [0m
[92mRank: 0, Outputscale: 1.7379549741744995 [0m
[92mRank: 0, Noise: 0.1270884871482849 [0m
Run 9 completed successfully
Running pxpGP 10 with agents: 64
[92mRank 0 - sparse dataset size is: 8, local dataset: torch.Size([529, 2]), [0m
[92mRank 0 - Training local sparse GP model with 529 samples[0m
Epoch 1/200 - Loss: 15.367
Epoch 11/200 - Loss: 1.202
Epoch 21/200 - Loss: 1.090
Epoch 31/200 - Loss: 0.998
Epoch 41/200 - Loss: 0.896
Epoch 51/200 - Loss: 0.794
Epoch 61/200 - Loss: 0.679
Epoch 71/200 - Loss: 0.522
Epoch 81/200 - Loss: 0.347
Epoch 91/200 - Loss: 0.154
Converged at epoch 98 with loss -0.002
[92mRank 0 - Lengthscale: [[0.74712646 0.52023995]] [0m
[92mRank 0 - Outputscale: 2.530010223388672 [0m
[92mRank 0 - Noise: 0.13889794051647186 [0m
Rank 0 - Augmented dataset size: 1041
Rank 0: After warm start model parameters:
Rank: 0, Lengthscale: [[0.74712646 0.52023995]]
Rank: 0, Outputscale: 2.530010223388672
Rank: 0, Noise: 0.13889794051647186
decpxADMM initialized with rho: 0.85, lip: 1.0, tol_abs: 1e-05, tol_rel: 0.001, rank: 0, world_size: 64
[92mRank 0 - Training global model with dec-pxADMM optimizer[0m
rank 0, epoch 9, loss: 0.7052852511405945, rho: 0.4250, lip: 1.0000
rank 0, epoch 19, loss: 0.6814911961555481, rho: 0.2125, lip: 1.0000
rank 0, epoch 29, loss: 0.6524083614349365, rho: 0.0531, lip: 1.0000
rank 0, epoch 39, loss: 0.6636627316474915, rho: 0.0531, lip: 1.0000
rank 0, epoch 49, loss: 0.6688106060028076, rho: 0.0531, lip: 1.0000
rank 0, epoch 59, loss: 0.6694982051849365, rho: 0.0266, lip: 1.0000
rank 0, epoch 69, loss: 0.6749449372291565, rho: 0.0266, lip: 1.0000
rank 0, epoch 79, loss: 0.6601348519325256, rho: 0.0266, lip: 1.0000
rank 0, epoch 89, loss: 0.6746192574501038, rho: 0.0266, lip: 1.0000
Rank 0 - Training time: 97.75 seconds
[92mRank 0 - Testing RMSE: 0.3619[0m
[92mRank: 0, Lengthscale: [[0.48028722 0.3786534 ]] [0m
[92mRank: 0, Outputscale: 2.035795211791992 [0m
[92mRank: 0, Noise: 0.16112418472766876 [0m
Run 10 completed successfully
Running gapxGP 1 with agents: 64
decpxADMM initialized with rho: 0.75, lip: 1.0, tol_abs: 1e-05, tol_rel: 0.001, rank: 0, world_size: 64
Rank 0 - Epoch 2/96 loss: 0.950190007686615
Rank 0 - Epoch 10/96 loss: 0.7067489624023438
Rank 0 - Epoch 20/96 loss: 0.3443616032600403
Rank 0 - Epoch 30/96 loss: -0.08615712076425552
Rank 0 - Epoch 40/96 loss: -0.5562343001365662
Rank 0 - Epoch 50/96 loss: -1.0046145915985107
Rank 0 - Epoch 60/96 loss: -1.3631597757339478
Rank 0 - Epoch 70/96 loss: -1.6059998273849487
Rank 0 - Epoch 80/96 loss: -1.7612954378128052
Rank 0 - Epoch 90/96 loss: -1.9227839708328247
[92mRank 0 - Testing RMSE: 0.0520[0m
[92mRank: 0, Lengthscale: [[0.6251521  0.35344762]] [0m
[92mRank: 0, Outputscale: 1.5695629119873047 [0m
[92mRank: 0, Noise: 0.0002414245973341167 [0m
Run 1 completed successfully
Running gapxGP 2 with agents: 64
decpxADMM initialized with rho: 0.75, lip: 1.0, tol_abs: 1e-05, tol_rel: 0.001, rank: 0, world_size: 64
Rank 0 - Epoch 2/96 loss: 0.9471381306648254
Rank 0 - Epoch 10/96 loss: 0.707709550857544
Rank 0 - Epoch 20/96 loss: 0.36002352833747864
Rank 0 - Epoch 30/96 loss: -0.09310945868492126
Rank 0 - Epoch 40/96 loss: -0.5449474453926086
Rank 0 - Epoch 50/96 loss: -1.024208903312683
Rank 0 - Epoch 60/96 loss: -1.3769803047180176
Rank 0 - Epoch 70/96 loss: -1.6626611948013306
Rank 0 - Epoch 80/96 loss: -1.8003485202789307
Rank 0 - Epoch 90/96 loss: -1.8743840456008911
[92mRank 0 - Testing RMSE: 0.0516[0m
[92mRank: 0, Lengthscale: [[0.63878846 0.37385938]] [0m
[92mRank: 0, Outputscale: 1.5706956386566162 [0m
[92mRank: 0, Noise: 0.00024206002126447856 [0m
Run 2 completed successfully
Running gapxGP 3 with agents: 64
decpxADMM initialized with rho: 0.75, lip: 1.0, tol_abs: 1e-05, tol_rel: 0.001, rank: 0, world_size: 64
Rank 0 - Epoch 2/96 loss: 0.9480401873588562
Rank 0 - Epoch 10/96 loss: 0.7129068374633789
Rank 0 - Epoch 20/96 loss: 0.3515437841415405
Rank 0 - Epoch 30/96 loss: -0.07935202866792679
Rank 0 - Epoch 40/96 loss: -0.5495550632476807
Rank 0 - Epoch 50/96 loss: -0.998465895652771
Rank 0 - Epoch 60/96 loss: -1.3761249780654907
Rank 0 - Epoch 70/96 loss: -1.65876305103302
Rank 0 - Epoch 80/96 loss: -1.7524902820587158
Rank 0 - Epoch 90/96 loss: -1.7613533735275269
[92mRank 0 - Testing RMSE: 0.0535[0m
[92mRank: 0, Lengthscale: [[0.6157168  0.36330763]] [0m
[92mRank: 0, Outputscale: 1.5702524185180664 [0m
[92mRank: 0, Noise: 0.0002422441029921174 [0m
Run 3 completed successfully
Running gapxGP 4 with agents: 64
decpxADMM initialized with rho: 0.75, lip: 1.0, tol_abs: 1e-05, tol_rel: 0.001, rank: 0, world_size: 64
Rank 0 - Epoch 2/96 loss: 0.9440038800239563
Rank 0 - Epoch 10/96 loss: 0.7087479829788208
Rank 0 - Epoch 20/96 loss: 0.3458028733730316
Rank 0 - Epoch 30/96 loss: -0.09211138635873795
Rank 0 - Epoch 40/96 loss: -0.5623550415039062
Rank 0 - Epoch 50/96 loss: -1.0085290670394897
Rank 0 - Epoch 60/96 loss: -1.387037992477417
Rank 0 - Epoch 70/96 loss: -1.6398980617523193
Rank 0 - Epoch 80/96 loss: -1.8095289468765259
Rank 0 - Epoch 90/96 loss: -1.812605619430542
[92mRank 0 - Testing RMSE: 0.0566[0m
[92mRank: 0, Lengthscale: [[0.64442354 0.3555892 ]] [0m
[92mRank: 0, Outputscale: 1.5737311840057373 [0m
[92mRank: 0, Noise: 0.0002403892867732793 [0m
Run 4 completed successfully
Running gapxGP 5 with agents: 64
decpxADMM initialized with rho: 0.75, lip: 1.0, tol_abs: 1e-05, tol_rel: 0.001, rank: 0, world_size: 64
Rank 0 - Epoch 2/96 loss: 0.9484884738922119
Rank 0 - Epoch 10/96 loss: 0.7090198397636414
Rank 0 - Epoch 20/96 loss: 0.3561415672302246
Rank 0 - Epoch 30/96 loss: -0.08411914855241776
Rank 0 - Epoch 40/96 loss: -0.5393907427787781
Rank 0 - Epoch 50/96 loss: -0.9953306317329407
Rank 0 - Epoch 60/96 loss: -1.3602488040924072
Rank 0 - Epoch 70/96 loss: -1.6433677673339844
Rank 0 - Epoch 80/96 loss: -1.7481043338775635
Rank 0 - Epoch 90/96 loss: -1.9543079137802124
[92mRank 0 - Testing RMSE: 0.0457[0m
[92mRank: 0, Lengthscale: [[0.6111808  0.39565098]] [0m
[92mRank: 0, Outputscale: 1.5705387592315674 [0m
[92mRank: 0, Noise: 0.00024169578682631254 [0m
Run 5 completed successfully
Running gapxGP 6 with agents: 64
decpxADMM initialized with rho: 0.75, lip: 1.0, tol_abs: 1e-05, tol_rel: 0.001, rank: 0, world_size: 64
Rank 0 - Epoch 2/96 loss: 0.9413800835609436
Rank 0 - Epoch 10/96 loss: 0.7022130489349365
Rank 0 - Epoch 20/96 loss: 0.3346831798553467
Rank 0 - Epoch 30/96 loss: -0.09154050052165985
Rank 0 - Epoch 40/96 loss: -0.5422109961509705
Rank 0 - Epoch 50/96 loss: -0.9972634315490723
Rank 0 - Epoch 60/96 loss: -1.3569815158843994
Rank 0 - Epoch 70/96 loss: -1.6065003871917725
Rank 0 - Epoch 80/96 loss: -1.7464187145233154
Rank 0 - Epoch 90/96 loss: -1.845019817352295
[92mRank 0 - Testing RMSE: 0.0519[0m
[92mRank: 0, Lengthscale: [[0.5954641 0.3431348]] [0m
[92mRank: 0, Outputscale: 1.5667097568511963 [0m
[92mRank: 0, Noise: 0.00024233214207924902 [0m
Run 6 completed successfully
Running gapxGP 7 with agents: 64
decpxADMM initialized with rho: 0.75, lip: 1.0, tol_abs: 1e-05, tol_rel: 0.001, rank: 0, world_size: 64
Rank 0 - Epoch 2/96 loss: 0.9458628296852112
Rank 0 - Epoch 10/96 loss: 0.7017584443092346
Rank 0 - Epoch 20/96 loss: 0.3462325930595398
Rank 0 - Epoch 30/96 loss: -0.07760581374168396
Rank 0 - Epoch 40/96 loss: -0.5525093078613281
Rank 0 - Epoch 50/96 loss: -0.9939337968826294
Rank 0 - Epoch 60/96 loss: -1.3750054836273193
Rank 0 - Epoch 70/96 loss: -1.6030848026275635
Rank 0 - Epoch 80/96 loss: -1.7308062314987183
Rank 0 - Epoch 90/96 loss: -1.8332937955856323
[92mRank 0 - Testing RMSE: 0.0542[0m
[92mRank: 0, Lengthscale: [[0.57722336 0.34259886]] [0m
[92mRank: 0, Outputscale: 1.575024962425232 [0m
[92mRank: 0, Noise: 0.00024177783052437007 [0m
Run 7 completed successfully
Running gapxGP 8 with agents: 64
decpxADMM initialized with rho: 0.75, lip: 1.0, tol_abs: 1e-05, tol_rel: 0.001, rank: 0, world_size: 64
Rank 0 - Epoch 2/96 loss: 0.9424558281898499
Rank 0 - Epoch 10/96 loss: 0.703829288482666
Rank 0 - Epoch 20/96 loss: 0.33906057476997375
Rank 0 - Epoch 30/96 loss: -0.08947239816188812
Rank 0 - Epoch 40/96 loss: -0.5548542737960815
Rank 0 - Epoch 50/96 loss: -1.0016231536865234
Rank 0 - Epoch 60/96 loss: -1.3625329732894897
Rank 0 - Epoch 70/96 loss: -1.623013973236084
Rank 0 - Epoch 80/96 loss: -1.7344964742660522
Rank 0 - Epoch 90/96 loss: -1.7982101440429688
[92mRank 0 - Testing RMSE: 0.0549[0m
[92mRank: 0, Lengthscale: [[0.62531215 0.3738837 ]] [0m
[92mRank: 0, Outputscale: 1.5640826225280762 [0m
[92mRank: 0, Noise: 0.0002419121447019279 [0m
Run 8 completed successfully
Running gapxGP 9 with agents: 64
decpxADMM initialized with rho: 0.75, lip: 1.0, tol_abs: 1e-05, tol_rel: 0.001, rank: 0, world_size: 64
Rank 0 - Epoch 2/96 loss: 0.943293571472168
Rank 0 - Epoch 10/96 loss: 0.7048810720443726
Rank 0 - Epoch 20/96 loss: 0.34788277745246887
Rank 0 - Epoch 30/96 loss: -0.08927658945322037
Rank 0 - Epoch 40/96 loss: -0.5467107892036438
Rank 0 - Epoch 50/96 loss: -1.0087214708328247
Rank 0 - Epoch 60/96 loss: -1.4026538133621216
Rank 0 - Epoch 70/96 loss: -1.6599043607711792
Rank 0 - Epoch 80/96 loss: -1.7801151275634766
Rank 0 - Epoch 90/96 loss: -1.9149360656738281
[92mRank 0 - Testing RMSE: 0.0488[0m
[92mRank: 0, Lengthscale: [[0.62202543 0.39380714]] [0m
[92mRank: 0, Outputscale: 1.5716166496276855 [0m
[92mRank: 0, Noise: 0.000240915862377733 [0m
Run 9 completed successfully
Running gapxGP 10 with agents: 64
decpxADMM initialized with rho: 0.75, lip: 1.0, tol_abs: 1e-05, tol_rel: 0.001, rank: 0, world_size: 64
Rank 0 - Epoch 2/96 loss: 0.9470584392547607
Rank 0 - Epoch 10/96 loss: 0.7091296315193176
Rank 0 - Epoch 20/96 loss: 0.3402746617794037
Rank 0 - Epoch 30/96 loss: -0.08870594203472137
Rank 0 - Epoch 40/96 loss: -0.5730564594268799
Rank 0 - Epoch 50/96 loss: -1.0032298564910889
Rank 0 - Epoch 60/96 loss: -1.3995800018310547
Rank 0 - Epoch 70/96 loss: -1.67659330368042
Rank 0 - Epoch 80/96 loss: -1.7713671922683716
Rank 0 - Epoch 90/96 loss: -1.8817532062530518
[92mRank 0 - Testing RMSE: 0.0504[0m
[92mRank: 0, Lengthscale: [[0.6222838  0.35571277]] [0m
[92mRank: 0, Outputscale: 1.573907494544983 [0m
[92mRank: 0, Noise: 0.00023932632757350802 [0m
Run 10 completed successfully
Running apxGP 1 with agents: 64
decpxADMM initialized with rho: 0.85, lip: 1.0, tol_abs: 1e-05, tol_rel: 0.001, rank: 0, world_size: 64
Rank 0 - Epoch 2/128 loss: 0.76444011926651
Rank 0 - Epoch 10/128 loss: 0.4960300624370575
Rank 0 - Epoch 20/128 loss: 0.07156481593847275
Rank 0 - Epoch 30/128 loss: -0.41611945629119873
Rank 0 - Epoch 40/128 loss: -0.9335482716560364
Rank 0 - Epoch 50/128 loss: -1.4623953104019165
Rank 0 - Epoch 60/128 loss: -1.9673418998718262
Rank 0 - Epoch 70/128 loss: -2.4244511127471924
Rank 0 - Epoch 80/128 loss: -2.801919460296631
Rank 0 - Epoch 90/128 loss: -3.0643062591552734
Rank 0 - Epoch 100/128 loss: -3.220837354660034
Rank 0 - Epoch 110/128 loss: -3.310511350631714
Rank 0 - Epoch 120/128 loss: -3.363896369934082
Training complete.
[92mRank 0 - Testing RMSE: 3.0974[0m
[92mRank: 0, Lengthscale: [[0.58372974 0.35832614]] [0m
[92mRank: 0, Outputscale: 1.1445685625076294 [0m
[92mRank: 0, Noise: 0.00013111051521264017 [0m
Run 1 completed successfully
Running apxGP 2 with agents: 64
decpxADMM initialized with rho: 0.85, lip: 1.0, tol_abs: 1e-05, tol_rel: 0.001, rank: 0, world_size: 64
Rank 0 - Epoch 2/128 loss: 0.76444011926651
Rank 0 - Epoch 10/128 loss: 0.4960300624370575
Rank 0 - Epoch 20/128 loss: 0.07156481593847275
Rank 0 - Epoch 30/128 loss: -0.41611945629119873
Rank 0 - Epoch 40/128 loss: -0.9335482716560364
Rank 0 - Epoch 50/128 loss: -1.4623953104019165
Rank 0 - Epoch 60/128 loss: -1.9673418998718262
Rank 0 - Epoch 70/128 loss: -2.4244511127471924
Rank 0 - Epoch 80/128 loss: -2.801919460296631
Rank 0 - Epoch 90/128 loss: -3.0643062591552734
Rank 0 - Epoch 100/128 loss: -3.220837354660034
Rank 0 - Epoch 110/128 loss: -3.310511350631714
Rank 0 - Epoch 120/128 loss: -3.363896369934082
Training complete.
[92mRank 0 - Testing RMSE: 3.0974[0m
[92mRank: 0, Lengthscale: [[0.58372974 0.35832614]] [0m
[92mRank: 0, Outputscale: 1.1445685625076294 [0m
[92mRank: 0, Noise: 0.00013111051521264017 [0m
Run 2 completed successfully
Running apxGP 3 with agents: 64
decpxADMM initialized with rho: 0.85, lip: 1.0, tol_abs: 1e-05, tol_rel: 0.001, rank: 0, world_size: 64
Rank 0 - Epoch 2/128 loss: 0.76444011926651
Rank 0 - Epoch 10/128 loss: 0.4960300624370575
Rank 0 - Epoch 20/128 loss: 0.07156481593847275
Rank 0 - Epoch 30/128 loss: -0.41611945629119873
Rank 0 - Epoch 40/128 loss: -0.9335482716560364
Rank 0 - Epoch 50/128 loss: -1.4623953104019165
Rank 0 - Epoch 60/128 loss: -1.9673418998718262
Rank 0 - Epoch 70/128 loss: -2.4244511127471924
Rank 0 - Epoch 80/128 loss: -2.801919460296631
Rank 0 - Epoch 90/128 loss: -3.0643062591552734
Rank 0 - Epoch 100/128 loss: -3.220837354660034
Rank 0 - Epoch 110/128 loss: -3.310511350631714
Rank 0 - Epoch 120/128 loss: -3.363896369934082
Training complete.
[92mRank 0 - Testing RMSE: 3.0974[0m
[92mRank: 0, Lengthscale: [[0.58372974 0.35832614]] [0m
[92mRank: 0, Outputscale: 1.1445685625076294 [0m
[92mRank: 0, Noise: 0.00013111051521264017 [0m
Run 3 completed successfully
Running apxGP 4 with agents: 64
decpxADMM initialized with rho: 0.85, lip: 1.0, tol_abs: 1e-05, tol_rel: 0.001, rank: 0, world_size: 64
Rank 0 - Epoch 2/128 loss: 0.76444011926651
Rank 0 - Epoch 10/128 loss: 0.4960300624370575
Rank 0 - Epoch 20/128 loss: 0.07156481593847275
Rank 0 - Epoch 30/128 loss: -0.41611945629119873
Rank 0 - Epoch 40/128 loss: -0.9335482716560364
Rank 0 - Epoch 50/128 loss: -1.4623953104019165
Rank 0 - Epoch 60/128 loss: -1.9673418998718262
Rank 0 - Epoch 70/128 loss: -2.4244511127471924
Rank 0 - Epoch 80/128 loss: -2.801919460296631
Rank 0 - Epoch 90/128 loss: -3.0643062591552734
Rank 0 - Epoch 100/128 loss: -3.220837354660034
Rank 0 - Epoch 110/128 loss: -3.310511350631714
Rank 0 - Epoch 120/128 loss: -3.363896369934082
Training complete.
[92mRank 0 - Testing RMSE: 3.0974[0m
[92mRank: 0, Lengthscale: [[0.58372974 0.35832614]] [0m
[92mRank: 0, Outputscale: 1.1445685625076294 [0m
[92mRank: 0, Noise: 0.00013111051521264017 [0m
Run 4 completed successfully
Running apxGP 5 with agents: 64
decpxADMM initialized with rho: 0.85, lip: 1.0, tol_abs: 1e-05, tol_rel: 0.001, rank: 0, world_size: 64
Rank 0 - Epoch 2/128 loss: 0.76444011926651
Rank 0 - Epoch 10/128 loss: 0.4960300624370575
Rank 0 - Epoch 20/128 loss: 0.07156481593847275
Rank 0 - Epoch 30/128 loss: -0.41611945629119873
Rank 0 - Epoch 40/128 loss: -0.9335482716560364
Rank 0 - Epoch 50/128 loss: -1.4623953104019165
Rank 0 - Epoch 60/128 loss: -1.9673418998718262
Rank 0 - Epoch 70/128 loss: -2.4244511127471924
Rank 0 - Epoch 80/128 loss: -2.801919460296631
Rank 0 - Epoch 90/128 loss: -3.0643062591552734
Rank 0 - Epoch 100/128 loss: -3.220837354660034
Rank 0 - Epoch 110/128 loss: -3.310511350631714
Rank 0 - Epoch 120/128 loss: -3.363896369934082
Training complete.
[92mRank 0 - Testing RMSE: 3.0974[0m
[92mRank: 0, Lengthscale: [[0.58372974 0.35832614]] [0m
[92mRank: 0, Outputscale: 1.1445685625076294 [0m
[92mRank: 0, Noise: 0.00013111051521264017 [0m
Run 5 completed successfully
Running apxGP 6 with agents: 64
decpxADMM initialized with rho: 0.85, lip: 1.0, tol_abs: 1e-05, tol_rel: 0.001, rank: 0, world_size: 64
Rank 0 - Epoch 2/128 loss: 0.76444011926651
Rank 0 - Epoch 10/128 loss: 0.4960300624370575
Rank 0 - Epoch 20/128 loss: 0.07156481593847275
Rank 0 - Epoch 30/128 loss: -0.41611945629119873
Rank 0 - Epoch 40/128 loss: -0.9335482716560364
Rank 0 - Epoch 50/128 loss: -1.4623953104019165
Rank 0 - Epoch 60/128 loss: -1.9673418998718262
Rank 0 - Epoch 70/128 loss: -2.4244511127471924
Rank 0 - Epoch 80/128 loss: -2.801919460296631
Rank 0 - Epoch 90/128 loss: -3.0643062591552734
Rank 0 - Epoch 100/128 loss: -3.220837354660034
Rank 0 - Epoch 110/128 loss: -3.310511350631714
Rank 0 - Epoch 120/128 loss: -3.363896369934082
Training complete.
[92mRank 0 - Testing RMSE: 3.0974[0m
[92mRank: 0, Lengthscale: [[0.58372974 0.35832614]] [0m
[92mRank: 0, Outputscale: 1.1445685625076294 [0m
[92mRank: 0, Noise: 0.00013111051521264017 [0m
Run 6 completed successfully
Running apxGP 7 with agents: 64
decpxADMM initialized with rho: 0.85, lip: 1.0, tol_abs: 1e-05, tol_rel: 0.001, rank: 0, world_size: 64
Rank 0 - Epoch 2/128 loss: 0.76444011926651
Rank 0 - Epoch 10/128 loss: 0.4960300624370575
Rank 0 - Epoch 20/128 loss: 0.07156481593847275
Rank 0 - Epoch 30/128 loss: -0.41611945629119873
Rank 0 - Epoch 40/128 loss: -0.9335482716560364
Rank 0 - Epoch 50/128 loss: -1.4623953104019165
Rank 0 - Epoch 60/128 loss: -1.9673418998718262
Rank 0 - Epoch 70/128 loss: -2.4244511127471924
Rank 0 - Epoch 80/128 loss: -2.801919460296631
Rank 0 - Epoch 90/128 loss: -3.0643062591552734
Rank 0 - Epoch 100/128 loss: -3.220837354660034
Rank 0 - Epoch 110/128 loss: -3.310511350631714
Rank 0 - Epoch 120/128 loss: -3.363896369934082
Training complete.
[92mRank 0 - Testing RMSE: 3.0974[0m
[92mRank: 0, Lengthscale: [[0.58372974 0.35832614]] [0m
[92mRank: 0, Outputscale: 1.1445685625076294 [0m
[92mRank: 0, Noise: 0.00013111051521264017 [0m
Run 7 completed successfully
Running apxGP 8 with agents: 64
decpxADMM initialized with rho: 0.85, lip: 1.0, tol_abs: 1e-05, tol_rel: 0.001, rank: 0, world_size: 64
Rank 0 - Epoch 2/128 loss: 0.76444011926651
Rank 0 - Epoch 10/128 loss: 0.4960300624370575
Rank 0 - Epoch 20/128 loss: 0.07156481593847275
Rank 0 - Epoch 30/128 loss: -0.41611945629119873
Rank 0 - Epoch 40/128 loss: -0.9335482716560364
Rank 0 - Epoch 50/128 loss: -1.4623953104019165
Rank 0 - Epoch 60/128 loss: -1.9673418998718262
Rank 0 - Epoch 70/128 loss: -2.4244511127471924
Rank 0 - Epoch 80/128 loss: -2.801919460296631
Rank 0 - Epoch 90/128 loss: -3.0643062591552734
Rank 0 - Epoch 100/128 loss: -3.220837354660034
Rank 0 - Epoch 110/128 loss: -3.310511350631714
Rank 0 - Epoch 120/128 loss: -3.363896369934082
Training complete.
[92mRank 0 - Testing RMSE: 3.0974[0m
[92mRank: 0, Lengthscale: [[0.58372974 0.35832614]] [0m
[92mRank: 0, Outputscale: 1.1445685625076294 [0m
[92mRank: 0, Noise: 0.00013111051521264017 [0m
Run 8 completed successfully
Running apxGP 9 with agents: 64
decpxADMM initialized with rho: 0.85, lip: 1.0, tol_abs: 1e-05, tol_rel: 0.001, rank: 0, world_size: 64
Rank 0 - Epoch 2/128 loss: 0.76444011926651
Rank 0 - Epoch 10/128 loss: 0.4960300624370575
Rank 0 - Epoch 20/128 loss: 0.07156481593847275
Rank 0 - Epoch 30/128 loss: -0.41611945629119873
Rank 0 - Epoch 40/128 loss: -0.9335482716560364
Rank 0 - Epoch 50/128 loss: -1.4623953104019165
Rank 0 - Epoch 60/128 loss: -1.9673418998718262
Rank 0 - Epoch 70/128 loss: -2.4244511127471924
Rank 0 - Epoch 80/128 loss: -2.801919460296631
Rank 0 - Epoch 90/128 loss: -3.0643062591552734
Rank 0 - Epoch 100/128 loss: -3.220837354660034
Rank 0 - Epoch 110/128 loss: -3.310511350631714
Rank 0 - Epoch 120/128 loss: -3.363896369934082
Training complete.
[92mRank 0 - Testing RMSE: 3.0974[0m
[92mRank: 0, Lengthscale: [[0.58372974 0.35832614]] [0m
[92mRank: 0, Outputscale: 1.1445685625076294 [0m
[92mRank: 0, Noise: 0.00013111051521264017 [0m
Run 9 completed successfully
Running apxGP 10 with agents: 64
decpxADMM initialized with rho: 0.85, lip: 1.0, tol_abs: 1e-05, tol_rel: 0.001, rank: 0, world_size: 64
Rank 0 - Epoch 2/128 loss: 0.76444011926651
Rank 0 - Epoch 10/128 loss: 0.4960300624370575
Rank 0 - Epoch 20/128 loss: 0.07156481593847275
Rank 0 - Epoch 30/128 loss: -0.41611945629119873
Rank 0 - Epoch 40/128 loss: -0.9335482716560364
Rank 0 - Epoch 50/128 loss: -1.4623953104019165
Rank 0 - Epoch 60/128 loss: -1.9673418998718262
Rank 0 - Epoch 70/128 loss: -2.4244511127471924
Rank 0 - Epoch 80/128 loss: -2.801919460296631
Rank 0 - Epoch 90/128 loss: -3.0643062591552734
Rank 0 - Epoch 100/128 loss: -3.220837354660034
Rank 0 - Epoch 110/128 loss: -3.310511350631714
Rank 0 - Epoch 120/128 loss: -3.363896369934082
Training complete.
[92mRank 0 - Testing RMSE: 3.0974[0m
[92mRank: 0, Lengthscale: [[0.58372974 0.35832614]] [0m
[92mRank: 0, Outputscale: 1.1445685625076294 [0m
[92mRank: 0, Noise: 0.00013111051521264017 [0m
Run 10 completed successfully
Running cGP 1 with agents: 64
decADMM initialized with rho: 0.85, max_iter: 5, lr: 0.0001, rank: 0, world_size: 64
Rank 0 - Epoch 2/128 loss: 0.8205555081367493
Rank 0 - Epoch 10/128 loss: 0.8154574036598206
Rank 0 - Epoch 20/128 loss: 0.8090762495994568
Rank 0 - Epoch 30/128 loss: 0.8026881814002991
Rank 0 - Epoch 40/128 loss: 0.7962955236434937
Rank 0 - Epoch 50/128 loss: 0.7899008989334106
Rank 0 - Epoch 60/128 loss: 0.7835071086883545
Rank 0 - Epoch 70/128 loss: 0.7771168947219849
Rank 0 - Epoch 80/128 loss: 0.7707334756851196
Rank 0 - Epoch 90/128 loss: 0.7643601298332214
Rank 0 - Epoch 100/128 loss: 0.7579997181892395
Rank 0 - Epoch 110/128 loss: 0.7516559958457947
Rank 0 - Epoch 120/128 loss: 0.7453321814537048
Training complete.
[92mRank 0 - Testing RMSE: 3.7711[0m
[92mRank: 0, Lengthscale: [[0.5903808 0.5890832]] [0m
[92mRank: 0, Outputscale: 0.5915473103523254 [0m
[92mRank: 0, Noise: 0.5801658630371094 [0m
Run 1 completed successfully
Running cGP 2 with agents: 64
decADMM initialized with rho: 0.85, max_iter: 5, lr: 0.0001, rank: 0, world_size: 64
Rank 0 - Epoch 2/128 loss: 0.8205555081367493
Rank 0 - Epoch 10/128 loss: 0.8154574036598206
Rank 0 - Epoch 20/128 loss: 0.8090762495994568
Rank 0 - Epoch 30/128 loss: 0.8026881814002991
Rank 0 - Epoch 40/128 loss: 0.7962955236434937
Rank 0 - Epoch 50/128 loss: 0.7899008989334106
Rank 0 - Epoch 60/128 loss: 0.7835071086883545
Rank 0 - Epoch 70/128 loss: 0.7771168947219849
Rank 0 - Epoch 80/128 loss: 0.7707334756851196
Rank 0 - Epoch 90/128 loss: 0.7643601298332214
Rank 0 - Epoch 100/128 loss: 0.7579997181892395
Rank 0 - Epoch 110/128 loss: 0.7516559958457947
Rank 0 - Epoch 120/128 loss: 0.7453321814537048
Training complete.
[92mRank 0 - Testing RMSE: 3.7711[0m
[92mRank: 0, Lengthscale: [[0.5903808 0.5890832]] [0m
[92mRank: 0, Outputscale: 0.5915473103523254 [0m
[92mRank: 0, Noise: 0.5801658630371094 [0m
Run 2 completed successfully
Running cGP 3 with agents: 64
decADMM initialized with rho: 0.85, max_iter: 5, lr: 0.0001, rank: 0, world_size: 64
Rank 0 - Epoch 2/128 loss: 0.8205555081367493
Rank 0 - Epoch 10/128 loss: 0.8154574036598206
Rank 0 - Epoch 20/128 loss: 0.8090762495994568
Rank 0 - Epoch 30/128 loss: 0.8026881814002991
Rank 0 - Epoch 40/128 loss: 0.7962955236434937
Rank 0 - Epoch 50/128 loss: 0.7899008989334106
Rank 0 - Epoch 60/128 loss: 0.7835071086883545
Rank 0 - Epoch 70/128 loss: 0.7771168947219849
Rank 0 - Epoch 80/128 loss: 0.7707334756851196
Rank 0 - Epoch 90/128 loss: 0.7643601298332214
Rank 0 - Epoch 100/128 loss: 0.7579997181892395
Rank 0 - Epoch 110/128 loss: 0.7516559958457947
Rank 0 - Epoch 120/128 loss: 0.7453321814537048
Training complete.
[92mRank 0 - Testing RMSE: 3.7711[0m
[92mRank: 0, Lengthscale: [[0.5903808 0.5890832]] [0m
[92mRank: 0, Outputscale: 0.5915473103523254 [0m
[92mRank: 0, Noise: 0.5801658630371094 [0m
Run 3 completed successfully
Running cGP 4 with agents: 64
decADMM initialized with rho: 0.85, max_iter: 5, lr: 0.0001, rank: 0, world_size: 64
Rank 0 - Epoch 2/128 loss: 0.8205555081367493
Rank 0 - Epoch 10/128 loss: 0.8154574036598206
Rank 0 - Epoch 20/128 loss: 0.8090762495994568
Rank 0 - Epoch 30/128 loss: 0.8026881814002991
Rank 0 - Epoch 40/128 loss: 0.7962955236434937
Rank 0 - Epoch 50/128 loss: 0.7899008989334106
Rank 0 - Epoch 60/128 loss: 0.7835071086883545
Rank 0 - Epoch 70/128 loss: 0.7771168947219849
Rank 0 - Epoch 80/128 loss: 0.7707334756851196
Rank 0 - Epoch 90/128 loss: 0.7643601298332214
Rank 0 - Epoch 100/128 loss: 0.7579997181892395
Rank 0 - Epoch 110/128 loss: 0.7516559958457947
Rank 0 - Epoch 120/128 loss: 0.7453321814537048
Training complete.
[92mRank 0 - Testing RMSE: 3.7711[0m
[92mRank: 0, Lengthscale: [[0.5903808 0.5890832]] [0m
[92mRank: 0, Outputscale: 0.5915473103523254 [0m
[92mRank: 0, Noise: 0.5801658630371094 [0m
Run 4 completed successfully
Running cGP 5 with agents: 64
decADMM initialized with rho: 0.85, max_iter: 5, lr: 0.0001, rank: 0, world_size: 64
Rank 0 - Epoch 2/128 loss: 0.8205555081367493
Rank 0 - Epoch 10/128 loss: 0.8154574036598206
Rank 0 - Epoch 20/128 loss: 0.8090762495994568
Rank 0 - Epoch 30/128 loss: 0.8026881814002991
Rank 0 - Epoch 40/128 loss: 0.7962955236434937
Rank 0 - Epoch 50/128 loss: 0.7899008989334106
Rank 0 - Epoch 60/128 loss: 0.7835071086883545
Rank 0 - Epoch 70/128 loss: 0.7771168947219849
Rank 0 - Epoch 80/128 loss: 0.7707334756851196
Rank 0 - Epoch 90/128 loss: 0.7643601298332214
Rank 0 - Epoch 100/128 loss: 0.7579997181892395
Rank 0 - Epoch 110/128 loss: 0.7516559958457947
Rank 0 - Epoch 120/128 loss: 0.7453321814537048
Training complete.
[92mRank 0 - Testing RMSE: 3.7711[0m
[92mRank: 0, Lengthscale: [[0.5903808 0.5890832]] [0m
[92mRank: 0, Outputscale: 0.5915473103523254 [0m
[92mRank: 0, Noise: 0.5801658630371094 [0m
Run 5 completed successfully
Running cGP 6 with agents: 64
decADMM initialized with rho: 0.85, max_iter: 5, lr: 0.0001, rank: 0, world_size: 64
Rank 0 - Epoch 2/128 loss: 0.8205555081367493
Rank 0 - Epoch 10/128 loss: 0.8154574036598206
Rank 0 - Epoch 20/128 loss: 0.8090762495994568
Rank 0 - Epoch 30/128 loss: 0.8026881814002991
Rank 0 - Epoch 40/128 loss: 0.7962955236434937
Rank 0 - Epoch 50/128 loss: 0.7899008989334106
Rank 0 - Epoch 60/128 loss: 0.7835071086883545
Rank 0 - Epoch 70/128 loss: 0.7771168947219849
Rank 0 - Epoch 80/128 loss: 0.7707334756851196
Rank 0 - Epoch 90/128 loss: 0.7643601298332214
Rank 0 - Epoch 100/128 loss: 0.7579997181892395
Rank 0 - Epoch 110/128 loss: 0.7516559958457947
Rank 0 - Epoch 120/128 loss: 0.7453321814537048
Training complete.
[92mRank 0 - Testing RMSE: 3.7711[0m
[92mRank: 0, Lengthscale: [[0.5903808 0.5890832]] [0m
[92mRank: 0, Outputscale: 0.5915473103523254 [0m
[92mRank: 0, Noise: 0.5801658630371094 [0m
Run 6 completed successfully
Running cGP 7 with agents: 64
decADMM initialized with rho: 0.85, max_iter: 5, lr: 0.0001, rank: 0, world_size: 64
Rank 0 - Epoch 2/128 loss: 0.8205555081367493
Rank 0 - Epoch 10/128 loss: 0.8154574036598206
Rank 0 - Epoch 20/128 loss: 0.8090762495994568
Rank 0 - Epoch 30/128 loss: 0.8026881814002991
Rank 0 - Epoch 40/128 loss: 0.7962955236434937
Rank 0 - Epoch 50/128 loss: 0.7899008989334106
Rank 0 - Epoch 60/128 loss: 0.7835071086883545
Rank 0 - Epoch 70/128 loss: 0.7771168947219849
Rank 0 - Epoch 80/128 loss: 0.7707334756851196
Rank 0 - Epoch 90/128 loss: 0.7643601298332214
Rank 0 - Epoch 100/128 loss: 0.7579997181892395
Rank 0 - Epoch 110/128 loss: 0.7516559958457947
Rank 0 - Epoch 120/128 loss: 0.7453321814537048
Training complete.
[92mRank 0 - Testing RMSE: 3.7711[0m
[92mRank: 0, Lengthscale: [[0.5903808 0.5890832]] [0m
[92mRank: 0, Outputscale: 0.5915473103523254 [0m
[92mRank: 0, Noise: 0.5801658630371094 [0m
Run 7 completed successfully
Running cGP 8 with agents: 64
decADMM initialized with rho: 0.85, max_iter: 5, lr: 0.0001, rank: 0, world_size: 64
Rank 0 - Epoch 2/128 loss: 0.8205555081367493
Rank 0 - Epoch 10/128 loss: 0.8154574036598206
Rank 0 - Epoch 20/128 loss: 0.8090762495994568
Rank 0 - Epoch 30/128 loss: 0.8026881814002991
Rank 0 - Epoch 40/128 loss: 0.7962955236434937
Rank 0 - Epoch 50/128 loss: 0.7899008989334106
Rank 0 - Epoch 60/128 loss: 0.7835071086883545
Rank 0 - Epoch 70/128 loss: 0.7771168947219849
Rank 0 - Epoch 80/128 loss: 0.7707334756851196
Rank 0 - Epoch 90/128 loss: 0.7643601298332214
Rank 0 - Epoch 100/128 loss: 0.7579997181892395
Rank 0 - Epoch 110/128 loss: 0.7516559958457947
Rank 0 - Epoch 120/128 loss: 0.7453321814537048
Training complete.
[92mRank 0 - Testing RMSE: 3.7711[0m
[92mRank: 0, Lengthscale: [[0.5903808 0.5890832]] [0m
[92mRank: 0, Outputscale: 0.5915473103523254 [0m
[92mRank: 0, Noise: 0.5801658630371094 [0m
Run 8 completed successfully
Running cGP 9 with agents: 64
decADMM initialized with rho: 0.85, max_iter: 5, lr: 0.0001, rank: 0, world_size: 64
Rank 0 - Epoch 2/128 loss: 0.8205555081367493
Rank 0 - Epoch 10/128 loss: 0.8154574036598206
Rank 0 - Epoch 20/128 loss: 0.8090762495994568
Rank 0 - Epoch 30/128 loss: 0.8026881814002991
Rank 0 - Epoch 40/128 loss: 0.7962955236434937
Rank 0 - Epoch 50/128 loss: 0.7899008989334106
Rank 0 - Epoch 60/128 loss: 0.7835071086883545
Rank 0 - Epoch 70/128 loss: 0.7771168947219849
Rank 0 - Epoch 80/128 loss: 0.7707334756851196
Rank 0 - Epoch 90/128 loss: 0.7643601298332214
Rank 0 - Epoch 100/128 loss: 0.7579997181892395
Rank 0 - Epoch 110/128 loss: 0.7516559958457947
Rank 0 - Epoch 120/128 loss: 0.7453321814537048
Training complete.
[92mRank 0 - Testing RMSE: 3.7711[0m
[92mRank: 0, Lengthscale: [[0.5903808 0.5890832]] [0m
[92mRank: 0, Outputscale: 0.5915473103523254 [0m
[92mRank: 0, Noise: 0.5801658630371094 [0m
Run 9 completed successfully
Running cGP 10 with agents: 64
decADMM initialized with rho: 0.85, max_iter: 5, lr: 0.0001, rank: 0, world_size: 64
Rank 0 - Epoch 2/128 loss: 0.8205555081367493
Rank 0 - Epoch 10/128 loss: 0.8154574036598206
Rank 0 - Epoch 20/128 loss: 0.8090762495994568
Rank 0 - Epoch 30/128 loss: 0.8026881814002991
Rank 0 - Epoch 40/128 loss: 0.7962955236434937
Rank 0 - Epoch 50/128 loss: 0.7899008989334106
Rank 0 - Epoch 60/128 loss: 0.7835071086883545
Rank 0 - Epoch 70/128 loss: 0.7771168947219849
Rank 0 - Epoch 80/128 loss: 0.7707334756851196
Rank 0 - Epoch 90/128 loss: 0.7643601298332214
Rank 0 - Epoch 100/128 loss: 0.7579997181892395
Rank 0 - Epoch 110/128 loss: 0.7516559958457947
Rank 0 - Epoch 120/128 loss: 0.7453321814537048
Training complete.
[92mRank 0 - Testing RMSE: 3.7711[0m
[92mRank: 0, Lengthscale: [[0.5903808 0.5890832]] [0m
[92mRank: 0, Outputscale: 0.5915473103523254 [0m
[92mRank: 0, Noise: 0.5801658630371094 [0m
Run 10 completed successfully
Running pxpGP 1 with agents: 100
[92mRank 0 - sparse dataset size is: 3, local dataset: torch.Size([324, 2]), [0m
[92mRank 0 - Training local sparse GP model with 324 samples[0m
Epoch 1/200 - Loss: 13.530
Epoch 11/200 - Loss: 1.198
Epoch 21/200 - Loss: 1.073
Epoch 31/200 - Loss: 1.001
Epoch 41/200 - Loss: 0.938
Epoch 51/200 - Loss: 0.861
Epoch 61/200 - Loss: 0.754
Epoch 71/200 - Loss: 0.642
Epoch 81/200 - Loss: 0.511
Epoch 91/200 - Loss: 0.341
Epoch 101/200 - Loss: 0.236
Epoch 111/200 - Loss: -0.006
Converged at epoch 111 with loss -0.006
[92mRank 0 - Lengthscale: [[1.0131004  0.44132996]] [0m
[92mRank 0 - Outputscale: 2.587354898452759 [0m
[92mRank 0 - Noise: 0.12956111133098602 [0m
Rank 0 - Augmented dataset size: 624
Rank 0: After warm start model parameters:
Rank: 0, Lengthscale: [[1.0131004  0.44132996]]
Rank: 0, Outputscale: 2.587354898452759
Rank: 0, Noise: 0.12956111133098602
decpxADMM initialized with rho: 0.85, lip: 1.0, tol_abs: 1e-05, tol_rel: 0.001, rank: 0, world_size: 100
[92mRank 0 - Training global model with dec-pxADMM optimizer[0m
rank 0, epoch 9, loss: 0.6734561920166016, rho: 0.1062, lip: 1.0000
rank 0, epoch 19, loss: 0.6486420035362244, rho: 0.1062, lip: 1.0000
rank 0, epoch 29, loss: 0.5614199042320251, rho: 0.0531, lip: 1.0000
rank 0, epoch 39, loss: 0.5536922812461853, rho: 0.0531, lip: 1.0000
rank 0, epoch 49, loss: 0.5462021827697754, rho: 0.0266, lip: 1.0000
rank 0, epoch 59, loss: 0.5406290888786316, rho: 0.0266, lip: 1.0000
rank 0, epoch 69, loss: 0.5386548638343811, rho: 0.0266, lip: 1.0000
rank 0, epoch 79, loss: 0.5374777317047119, rho: 0.0266, lip: 1.0000
rank 0, epoch 89, loss: 0.5368307828903198, rho: 0.0133, lip: 1.0000
rank 0, epoch 99, loss: 0.5364512801170349, rho: 0.0133, lip: 1.0000
Run 1 failed, retrying...
Running pxpGP 2 with agents: 100
[92mRank 0 - sparse dataset size is: 3, local dataset: torch.Size([324, 2]), [0m
[92mRank 0 - Training local sparse GP model with 324 samples[0m
Epoch 1/200 - Loss: 17.040
Epoch 11/200 - Loss: 1.141
Epoch 21/200 - Loss: 1.057
Epoch 31/200 - Loss: 0.998
Epoch 41/200 - Loss: 0.927
Epoch 51/200 - Loss: 0.848
Epoch 61/200 - Loss: 0.739
Epoch 71/200 - Loss: 0.624
Epoch 81/200 - Loss: 0.494
Epoch 91/200 - Loss: 0.354
Epoch 101/200 - Loss: 0.174
Epoch 111/200 - Loss: 0.069
Converged at epoch 115 with loss -0.092
[92mRank 0 - Lengthscale: [[1.0004148  0.44423372]] [0m
[92mRank 0 - Outputscale: 2.5653655529022217 [0m
[92mRank 0 - Noise: 0.11462860554456711 [0m
Rank 0 - Augmented dataset size: 624
Rank 0: After warm start model parameters:
Rank: 0, Lengthscale: [[1.0004148  0.44423372]]
Rank: 0, Outputscale: 2.5653655529022217
Rank: 0, Noise: 0.11462860554456711
decpxADMM initialized with rho: 0.85, lip: 1.0, tol_abs: 1e-05, tol_rel: 0.001, rank: 0, world_size: 100
[92mRank 0 - Training global model with dec-pxADMM optimizer[0m
rank 0, epoch 9, loss: 0.650580108165741, rho: 0.1062, lip: 1.0000
rank 0, epoch 19, loss: 0.608547568321228, rho: 0.1062, lip: 1.0000
rank 0, epoch 29, loss: 0.5413716435432434, rho: 0.1062, lip: 1.0000
rank 0, epoch 39, loss: 0.5589583516120911, rho: 0.1062, lip: 1.0000
rank 0, epoch 49, loss: 0.5563021898269653, rho: 0.0531, lip: 1.0000
rank 0, epoch 59, loss: 0.5491479635238647, rho: 0.0531, lip: 1.0000
rank 0, epoch 69, loss: 0.5399536490440369, rho: 0.0266, lip: 1.0000
rank 0, epoch 79, loss: 0.5341880321502686, rho: 0.0266, lip: 1.0000
rank 0, epoch 89, loss: 0.5294665098190308, rho: 0.0133, lip: 1.0000
rank 0, epoch 99, loss: 0.526240348815918, rho: 0.0133, lip: 1.0000
rank 0, epoch 109, loss: 0.5257874727249146, rho: 0.0133, lip: 1.0000
rank 0, epoch 119, loss: 0.5365466475486755, rho: 0.0133, lip: 1.0000
rank 0, epoch 129, loss: 0.5897300243377686, rho: 0.0133, lip: 1.0000
rank 0, epoch 139, loss: 0.6192928552627563, rho: 0.0266, lip: 1.0000
rank 0, epoch 149, loss: 0.5438947081565857, rho: 0.0266, lip: 1.0000
Rank 0 - Training time: 187.05 seconds
[92mRank 0 - Testing RMSE: 0.3033[0m
[92mRank: 0, Lengthscale: [[0.36000794 0.47285408]] [0m
[92mRank: 0, Outputscale: 2.191027879714966 [0m
[92mRank: 0, Noise: 0.09560886770486832 [0m
Run 2 completed successfully
Running pxpGP 3 with agents: 100
[92mRank 0 - sparse dataset size is: 3, local dataset: torch.Size([324, 2]), [0m
[92mRank 0 - Training local sparse GP model with 324 samples[0m
Epoch 1/200 - Loss: 17.354
Epoch 11/200 - Loss: 1.177
Epoch 21/200 - Loss: 1.053
Epoch 31/200 - Loss: 1.002
Epoch 41/200 - Loss: 0.925
Epoch 51/200 - Loss: 0.842
Epoch 61/200 - Loss: 0.753
Epoch 71/200 - Loss: 0.679
Epoch 81/200 - Loss: 0.504
Epoch 91/200 - Loss: 0.352
Epoch 101/200 - Loss: 0.161
Epoch 111/200 - Loss: 0.051
Converged at epoch 113 with loss -0.024
[92mRank 0 - Lengthscale: [[1.0171459 0.4440224]] [0m
[92mRank 0 - Outputscale: 2.563659191131592 [0m
[92mRank 0 - Noise: 0.12363622337579727 [0m
Rank 0 - Augmented dataset size: 624
Rank 0: After warm start model parameters:
Rank: 0, Lengthscale: [[1.0171459  0.44402242]]
Rank: 0, Outputscale: 2.563659191131592
Rank: 0, Noise: 0.12363620102405548
decpxADMM initialized with rho: 0.85, lip: 1.0, tol_abs: 1e-05, tol_rel: 0.001, rank: 0, world_size: 100
[92mRank 0 - Training global model with dec-pxADMM optimizer[0m
rank 0, epoch 9, loss: 0.6574786901473999, rho: 0.1062, lip: 1.0000
rank 0, epoch 19, loss: 0.6810540556907654, rho: 0.1062, lip: 1.0000
rank 0, epoch 29, loss: 0.5457619428634644, rho: 0.0531, lip: 1.0000
rank 0, epoch 39, loss: 0.53520268201828, rho: 0.0531, lip: 1.0000
rank 0, epoch 49, loss: 0.5311504006385803, rho: 0.0266, lip: 1.0000
rank 0, epoch 59, loss: 0.529536247253418, rho: 0.0266, lip: 1.0000
rank 0, epoch 69, loss: 0.5292834043502808, rho: 0.0266, lip: 1.0000
rank 0, epoch 79, loss: 0.5291203856468201, rho: 0.0266, lip: 1.0000
rank 0, epoch 89, loss: 0.528856098651886, rho: 0.0066, lip: 1.0000
rank 0, epoch 99, loss: 0.5286334753036499, rho: 0.0066, lip: 1.0000
rank 0, epoch 109, loss: 0.5285527110099792, rho: 0.0066, lip: 1.0000
rank 0, epoch 119, loss: 0.5284845232963562, rho: 0.0066, lip: 1.0000
rank 0, epoch 129, loss: 0.5283113121986389, rho: 0.0066, lip: 1.0000
rank 0, epoch 139, loss: 0.5282736420631409, rho: 0.0066, lip: 1.0000
Run 3 failed, retrying...
Running pxpGP 4 with agents: 100
[92mRank 0 - sparse dataset size is: 3, local dataset: torch.Size([324, 2]), [0m
[92mRank 0 - Training local sparse GP model with 324 samples[0m
Epoch 1/200 - Loss: 19.814
Epoch 11/200 - Loss: 1.173
Epoch 21/200 - Loss: 1.060
Epoch 31/200 - Loss: 1.001
Epoch 41/200 - Loss: 0.928
Epoch 51/200 - Loss: 0.859
Epoch 61/200 - Loss: 0.751
Epoch 71/200 - Loss: 0.629
Epoch 81/200 - Loss: 0.500
Epoch 91/200 - Loss: 0.359
Epoch 101/200 - Loss: 0.185
Epoch 111/200 - Loss: 0.094
Converged at epoch 113 with loss -0.002
[92mRank 0 - Lengthscale: [[1.018012   0.45045966]] [0m
[92mRank 0 - Outputscale: 2.5623855590820312 [0m
[92mRank 0 - Noise: 0.12546934187412262 [0m
Rank 0 - Augmented dataset size: 624
Rank 0: After warm start model parameters:
Rank: 0, Lengthscale: [[1.018012   0.45045966]]
Rank: 0, Outputscale: 2.5623855590820312
Rank: 0, Noise: 0.12546934187412262
decpxADMM initialized with rho: 0.85, lip: 1.0, tol_abs: 1e-05, tol_rel: 0.001, rank: 0, world_size: 100
[92mRank 0 - Training global model with dec-pxADMM optimizer[0m
rank 0, epoch 9, loss: 0.6616766452789307, rho: 0.1062, lip: 1.0000
rank 0, epoch 19, loss: 0.6106576323509216, rho: 0.1062, lip: 1.0000
rank 0, epoch 29, loss: 0.5509584546089172, rho: 0.0531, lip: 1.0000
rank 0, epoch 39, loss: 0.554815411567688, rho: 0.0531, lip: 1.0000
rank 0, epoch 49, loss: 0.5491605997085571, rho: 0.0266, lip: 1.0000
rank 0, epoch 59, loss: 0.5438346266746521, rho: 0.0266, lip: 1.0000
rank 0, epoch 69, loss: 0.5418323278427124, rho: 0.0266, lip: 1.0000
rank 0, epoch 79, loss: 0.540952742099762, rho: 0.0266, lip: 1.0000
rank 0, epoch 89, loss: 0.5408053994178772, rho: 0.0266, lip: 1.0000
rank 0, epoch 99, loss: 0.5410686731338501, rho: 0.0266, lip: 1.0000
Run 4 failed, retrying...
Running pxpGP 5 with agents: 100
[92mRank 0 - sparse dataset size is: 3, local dataset: torch.Size([324, 2]), [0m
[92mRank 0 - Training local sparse GP model with 324 samples[0m
Epoch 1/200 - Loss: 16.535
Epoch 11/200 - Loss: 1.154
Epoch 21/200 - Loss: 1.050
Epoch 31/200 - Loss: 0.999
Epoch 41/200 - Loss: 0.950
Epoch 51/200 - Loss: 0.843
Epoch 61/200 - Loss: 0.762
Epoch 71/200 - Loss: 0.646
Epoch 81/200 - Loss: 0.496
Epoch 91/200 - Loss: 0.361
Epoch 101/200 - Loss: 0.200
Epoch 111/200 - Loss: 0.007
Converged at epoch 113 with loss -0.043
[92mRank 0 - Lengthscale: [[1.0069351 0.4447787]] [0m
[92mRank 0 - Outputscale: 2.5771303176879883 [0m
[92mRank 0 - Noise: 0.12082304805517197 [0m
Rank 0 - Augmented dataset size: 624
Rank 0: After warm start model parameters:
Rank: 0, Lengthscale: [[1.0069351 0.4447787]]
Rank: 0, Outputscale: 2.5771303176879883
Rank: 0, Noise: 0.12082304805517197
decpxADMM initialized with rho: 0.85, lip: 1.0, tol_abs: 1e-05, tol_rel: 0.001, rank: 0, world_size: 100
[92mRank 0 - Training global model with dec-pxADMM optimizer[0m
rank 0, epoch 9, loss: 0.6608182787895203, rho: 0.1062, lip: 1.0000
rank 0, epoch 19, loss: 0.6326912045478821, rho: 0.1062, lip: 1.0000
rank 0, epoch 29, loss: 0.5398940443992615, rho: 0.0531, lip: 1.0000
rank 0, epoch 39, loss: 0.5331952571868896, rho: 0.0531, lip: 1.0000
rank 0, epoch 49, loss: 0.5313159227371216, rho: 0.0266, lip: 1.0000
rank 0, epoch 59, loss: 0.5290209650993347, rho: 0.0266, lip: 1.0000
rank 0, epoch 69, loss: 0.528112530708313, rho: 0.0266, lip: 1.0000
rank 0, epoch 79, loss: 0.527421236038208, rho: 0.0133, lip: 1.0000
rank 0, epoch 89, loss: 0.5270369052886963, rho: 0.0066, lip: 1.0000
rank 0, epoch 99, loss: 0.5267114639282227, rho: 0.0066, lip: 1.0000
rank 0, epoch 109, loss: 0.5264033079147339, rho: 0.0066, lip: 1.0000
rank 0, epoch 119, loss: 0.5259174108505249, rho: 0.0066, lip: 1.0000
rank 0, epoch 129, loss: 0.5252583622932434, rho: 0.0066, lip: 1.0000
rank 0, epoch 139, loss: 0.5247789621353149, rho: 0.0066, lip: 1.0000
rank 0, epoch 149, loss: 0.5244463682174683, rho: 0.0066, lip: 1.0000
Rank 0 - Training time: 163.00 seconds
[92mRank 0 - Testing RMSE: 0.2655[0m
[92mRank: 0, Lengthscale: [[0.6051693  0.42017686]] [0m
[92mRank: 0, Outputscale: 3.0938053131103516 [0m
[92mRank: 0, Noise: 0.09275240451097488 [0m
Run 5 completed successfully
Running pxpGP 6 with agents: 100
[92mRank 0 - sparse dataset size is: 3, local dataset: torch.Size([324, 2]), [0m
[92mRank 0 - Training local sparse GP model with 324 samples[0m
Epoch 1/200 - Loss: 17.692
Epoch 11/200 - Loss: 1.147
Epoch 21/200 - Loss: 1.051
Epoch 31/200 - Loss: 1.002
Epoch 41/200 - Loss: 0.929
Epoch 51/200 - Loss: 0.854
Epoch 61/200 - Loss: 0.770
Epoch 71/200 - Loss: 0.643
Epoch 81/200 - Loss: 0.507
Epoch 91/200 - Loss: 0.352
Epoch 101/200 - Loss: 0.205
Epoch 111/200 - Loss: 0.038
Converged at epoch 114 with loss -0.010
[92mRank 0 - Lengthscale: [[1.0447742 0.4603048]] [0m
[92mRank 0 - Outputscale: 2.565295457839966 [0m
[92mRank 0 - Noise: 0.12245972454547882 [0m
Rank 0 - Augmented dataset size: 624
Rank 0: After warm start model parameters:
Rank: 0, Lengthscale: [[1.0447742 0.4603048]]
Rank: 0, Outputscale: 2.565295457839966
Rank: 0, Noise: 0.12245972454547882
decpxADMM initialized with rho: 0.85, lip: 1.0, tol_abs: 1e-05, tol_rel: 0.001, rank: 0, world_size: 100
[92mRank 0 - Training global model with dec-pxADMM optimizer[0m
rank 0, epoch 9, loss: 0.6722784042358398, rho: 0.1062, lip: 1.0000
rank 0, epoch 19, loss: 0.6632721424102783, rho: 0.1062, lip: 1.0000
rank 0, epoch 29, loss: 0.5608285665512085, rho: 0.0531, lip: 1.0000
rank 0, epoch 39, loss: 0.5701912045478821, rho: 0.0531, lip: 1.0000
rank 0, epoch 49, loss: 0.5686982274055481, rho: 0.0266, lip: 1.0000
rank 0, epoch 59, loss: 0.56426602602005, rho: 0.0266, lip: 1.0000
rank 0, epoch 69, loss: 0.5611912608146667, rho: 0.0266, lip: 1.0000
rank 0, epoch 79, loss: 0.5587998628616333, rho: 0.0266, lip: 1.0000
Run 6 failed, retrying...
Running pxpGP 7 with agents: 100
[92mRank 0 - sparse dataset size is: 3, local dataset: torch.Size([324, 2]), [0m
[92mRank 0 - Training local sparse GP model with 324 samples[0m
Epoch 1/200 - Loss: 16.079
Epoch 11/200 - Loss: 1.158
Epoch 21/200 - Loss: 1.052
Epoch 31/200 - Loss: 0.996
Epoch 41/200 - Loss: 0.936
Epoch 51/200 - Loss: 0.845
Epoch 61/200 - Loss: 0.747
Epoch 71/200 - Loss: 0.629
Epoch 81/200 - Loss: 0.483
Epoch 91/200 - Loss: 0.349
Epoch 101/200 - Loss: 0.247
Epoch 111/200 - Loss: 0.057
Converged at epoch 116 with loss -0.096
[92mRank 0 - Lengthscale: [[1.0282878 0.4540896]] [0m
[92mRank 0 - Outputscale: 2.571255922317505 [0m
[92mRank 0 - Noise: 0.10919899493455887 [0m
Rank 0 - Augmented dataset size: 624
Rank 0: After warm start model parameters:
Rank: 0, Lengthscale: [[1.0282878 0.4540896]]
Rank: 0, Outputscale: 2.571255922317505
Rank: 0, Noise: 0.10919899493455887
decpxADMM initialized with rho: 0.85, lip: 1.0, tol_abs: 1e-05, tol_rel: 0.001, rank: 0, world_size: 100
[92mRank 0 - Training global model with dec-pxADMM optimizer[0m
rank 0, epoch 9, loss: 0.6703912019729614, rho: 0.1062, lip: 1.0000
rank 0, epoch 19, loss: 0.6551299095153809, rho: 0.1062, lip: 1.0000
rank 0, epoch 29, loss: 0.5599789023399353, rho: 0.0531, lip: 1.0000
rank 0, epoch 39, loss: 0.5650334358215332, rho: 0.0531, lip: 1.0000
rank 0, epoch 49, loss: 0.5609740018844604, rho: 0.0266, lip: 1.0000
rank 0, epoch 59, loss: 0.5558797121047974, rho: 0.0266, lip: 1.0000
Run 7 failed, retrying...
Running pxpGP 8 with agents: 100
[92mRank 0 - sparse dataset size is: 3, local dataset: torch.Size([324, 2]), [0m
[92mRank 0 - Training local sparse GP model with 324 samples[0m
Epoch 1/200 - Loss: 16.135
Epoch 11/200 - Loss: 1.222
Epoch 21/200 - Loss: 1.047
Epoch 31/200 - Loss: 0.995
Epoch 41/200 - Loss: 0.936
Epoch 51/200 - Loss: 0.855
Epoch 61/200 - Loss: 0.773
Epoch 71/200 - Loss: 0.644
Epoch 81/200 - Loss: 0.497
Epoch 91/200 - Loss: 0.389
Epoch 101/200 - Loss: 0.188
Epoch 111/200 - Loss: 0.001
Converged at epoch 113 with loss -0.020
[92mRank 0 - Lengthscale: [[1.0464027  0.45780653]] [0m
[92mRank 0 - Outputscale: 2.5613746643066406 [0m
[92mRank 0 - Noise: 0.12420465797185898 [0m
Rank 0 - Augmented dataset size: 624
Rank 0: After warm start model parameters:
Rank: 0, Lengthscale: [[1.0464027  0.45780653]]
Rank: 0, Outputscale: 2.5613746643066406
Rank: 0, Noise: 0.12420465797185898
decpxADMM initialized with rho: 0.85, lip: 1.0, tol_abs: 1e-05, tol_rel: 0.001, rank: 0, world_size: 100
[92mRank 0 - Training global model with dec-pxADMM optimizer[0m
rank 0, epoch 9, loss: 0.7070389986038208, rho: 0.1062, lip: 1.0000
rank 0, epoch 19, loss: 0.733629047870636, rho: 0.1062, lip: 1.0000
rank 0, epoch 29, loss: 0.5962788462638855, rho: 0.1062, lip: 1.0000
rank 0, epoch 39, loss: 0.6152987480163574, rho: 0.1062, lip: 1.0000
rank 0, epoch 49, loss: 0.6128012537956238, rho: 0.0531, lip: 1.0000
rank 0, epoch 59, loss: 0.6054496169090271, rho: 0.0531, lip: 1.0000
Run 8 failed, retrying...
Running pxpGP 9 with agents: 100
[92mRank 0 - sparse dataset size is: 3, local dataset: torch.Size([324, 2]), [0m
[92mRank 0 - Training local sparse GP model with 324 samples[0m
Epoch 1/200 - Loss: 20.042
Epoch 11/200 - Loss: 1.155
Epoch 21/200 - Loss: 1.094
Epoch 31/200 - Loss: 1.000
Epoch 41/200 - Loss: 0.924
Epoch 51/200 - Loss: 0.850
Epoch 61/200 - Loss: 0.788
Epoch 71/200 - Loss: 0.630
Epoch 81/200 - Loss: 0.499
Epoch 91/200 - Loss: 0.434
Epoch 101/200 - Loss: 0.218
Epoch 111/200 - Loss: 0.025
Converged at epoch 114 with loss -0.038
[92mRank 0 - Lengthscale: [[1.0257849  0.45797625]] [0m
[92mRank 0 - Outputscale: 2.563392162322998 [0m
[92mRank 0 - Noise: 0.12067406624555588 [0m
Rank 0 - Augmented dataset size: 624
Rank 0: After warm start model parameters:
Rank: 0, Lengthscale: [[1.0257849  0.45797625]]
Rank: 0, Outputscale: 2.563392162322998
Rank: 0, Noise: 0.12067406624555588
decpxADMM initialized with rho: 0.85, lip: 1.0, tol_abs: 1e-05, tol_rel: 0.001, rank: 0, world_size: 100
[92mRank 0 - Training global model with dec-pxADMM optimizer[0m
rank 0, epoch 9, loss: 0.6630436182022095, rho: 0.1062, lip: 1.0000
rank 0, epoch 19, loss: 0.6629206538200378, rho: 0.1062, lip: 1.0000
rank 0, epoch 29, loss: 0.5640309453010559, rho: 0.0531, lip: 1.0000
rank 0, epoch 39, loss: 0.5704755783081055, rho: 0.0531, lip: 1.0000
rank 0, epoch 49, loss: 0.5631013512611389, rho: 0.0266, lip: 1.0000
rank 0, epoch 59, loss: 0.5572241544723511, rho: 0.0266, lip: 1.0000
rank 0, epoch 69, loss: 0.5545295476913452, rho: 0.0266, lip: 1.0000
rank 0, epoch 79, loss: 0.5525678992271423, rho: 0.0266, lip: 1.0000
Run 9 failed, retrying...
Running pxpGP 10 with agents: 100
[92mRank 0 - sparse dataset size is: 3, local dataset: torch.Size([324, 2]), [0m
[92mRank 0 - Training local sparse GP model with 324 samples[0m
Epoch 1/200 - Loss: 16.352
Epoch 11/200 - Loss: 1.278
Epoch 21/200 - Loss: 1.062
Epoch 31/200 - Loss: 1.003
Epoch 41/200 - Loss: 0.930
Epoch 51/200 - Loss: 0.855
Epoch 61/200 - Loss: 0.746
Epoch 71/200 - Loss: 0.648
Epoch 81/200 - Loss: 0.502
Epoch 91/200 - Loss: 0.344
Epoch 101/200 - Loss: 0.207
Epoch 111/200 - Loss: -0.003
Converged at epoch 111 with loss -0.003
[92mRank 0 - Lengthscale: [[1.0200495  0.43881133]] [0m
[92mRank 0 - Outputscale: 2.564354181289673 [0m
[92mRank 0 - Noise: 0.13077333569526672 [0m
Rank 0 - Augmented dataset size: 624
Rank 0: After warm start model parameters:
Rank: 0, Lengthscale: [[1.0200495  0.43881133]]
Rank: 0, Outputscale: 2.564354419708252
Rank: 0, Noise: 0.13077333569526672
decpxADMM initialized with rho: 0.85, lip: 1.0, tol_abs: 1e-05, tol_rel: 0.001, rank: 0, world_size: 100
[92mRank 0 - Training global model with dec-pxADMM optimizer[0m
rank 0, epoch 9, loss: 0.6292731165885925, rho: 0.1062, lip: 1.0000
rank 0, epoch 19, loss: 0.5888237357139587, rho: 0.1062, lip: 1.0000
rank 0, epoch 29, loss: 0.5452521443367004, rho: 0.0531, lip: 1.0000
rank 0, epoch 39, loss: 0.5535017848014832, rho: 0.0531, lip: 1.0000
rank 0, epoch 49, loss: 0.5557419061660767, rho: 0.0266, lip: 1.0000
rank 0, epoch 59, loss: 0.5619062781333923, rho: 0.0266, lip: 1.0000
rank 0, epoch 69, loss: 0.560718297958374, rho: 0.0266, lip: 1.0000
rank 0, epoch 79, loss: 0.5522083640098572, rho: 0.0266, lip: 1.0000
rank 0, epoch 89, loss: 0.5485374331474304, rho: 0.0133, lip: 1.0000
rank 0, epoch 99, loss: 0.5451825261116028, rho: 0.0133, lip: 1.0000
Run 10 failed, retrying...
Running gapxGP 1 with agents: 100
decpxADMM initialized with rho: 0.75, lip: 1.0, tol_abs: 1e-05, tol_rel: 0.001, rank: 0, world_size: 100
Rank 0 - Epoch 2/150 loss: 1.0345075130462646
Rank 0 - Epoch 10/150 loss: 0.8080834746360779
Rank 0 - Epoch 20/150 loss: 0.4922429323196411
Rank 0 - Epoch 30/150 loss: 0.1331261247396469
Rank 0 - Epoch 40/150 loss: -0.2806766927242279
Rank 0 - Epoch 50/150 loss: -0.6812089681625366
Rank 0 - Epoch 60/150 loss: -1.0633585453033447
Rank 0 - Epoch 70/150 loss: -1.413651943206787
Rank 0 - Epoch 80/150 loss: -1.7222068309783936
Rank 0 - Epoch 90/150 loss: -1.9703524112701416
Rank 0 - Epoch 100/150 loss: -2.1504948139190674
Rank 0 - Epoch 110/150 loss: -2.2695252895355225
Rank 0 - Epoch 120/150 loss: -2.2941911220550537
Rank 0 - Epoch 130/150 loss: -2.357480525970459
Rank 0 - Epoch 140/150 loss: -2.3536057472229004
Run 1 failed, retrying...
Running gapxGP 2 with agents: 100
decpxADMM initialized with rho: 0.75, lip: 1.0, tol_abs: 1e-05, tol_rel: 0.001, rank: 0, world_size: 100
Rank 0 - Epoch 2/150 loss: 1.0389670133590698
Rank 0 - Epoch 10/150 loss: 0.8094752430915833
Rank 0 - Epoch 20/150 loss: 0.4879663586616516
Rank 0 - Epoch 30/150 loss: 0.11471208930015564
Rank 0 - Epoch 40/150 loss: -0.2966051995754242
Rank 0 - Epoch 50/150 loss: -0.6983756422996521
Rank 0 - Epoch 60/150 loss: -1.077603816986084
Rank 0 - Epoch 70/150 loss: -1.4271775484085083
Rank 0 - Epoch 80/150 loss: -1.7348620891571045
Rank 0 - Epoch 90/150 loss: -1.982465147972107
Rank 0 - Epoch 100/150 loss: -2.1611735820770264
Rank 0 - Epoch 110/150 loss: -2.2790162563323975
Rank 0 - Epoch 120/150 loss: -2.2052762508392334
Rank 0 - Epoch 130/150 loss: -2.2327864170074463
Rank 0 - Epoch 140/150 loss: -2.304321765899658
Rank 0 - Epoch 150/150 loss: -2.0102925300598145
[92mRank 0 - Testing RMSE: 0.0098[0m
[92mRank: 0, Lengthscale: [[0.5158819  0.22009219]] [0m
[92mRank: 0, Outputscale: 2.033679723739624 [0m
[92mRank: 0, Noise: 0.0001315180561505258 [0m
Run 2 completed successfully
Running gapxGP 3 with agents: 100
decpxADMM initialized with rho: 0.75, lip: 1.0, tol_abs: 1e-05, tol_rel: 0.001, rank: 0, world_size: 100
Rank 0 - Epoch 2/150 loss: 1.0292812585830688
Rank 0 - Epoch 10/150 loss: 0.7999569773674011
Rank 0 - Epoch 20/150 loss: 0.4896010160446167
Rank 0 - Epoch 30/150 loss: 0.13647009432315826
Rank 0 - Epoch 40/150 loss: -0.2761082053184509
Rank 0 - Epoch 50/150 loss: -0.6799166798591614
Rank 0 - Epoch 60/150 loss: -1.063664197921753
Rank 0 - Epoch 70/150 loss: -1.4163888692855835
Rank 0 - Epoch 80/150 loss: -1.727431297302246
Rank 0 - Epoch 90/150 loss: -1.9779341220855713
Rank 0 - Epoch 100/150 loss: -2.1593081951141357
Rank 0 - Epoch 110/150 loss: -2.27936053276062
Rank 0 - Epoch 120/150 loss: -2.342480182647705
Rank 0 - Epoch 130/150 loss: -2.214956521987915
Rank 0 - Epoch 140/150 loss: -2.3790221214294434
Rank 0 - Epoch 150/150 loss: -2.304333209991455
[92mRank 0 - Testing RMSE: 0.0088[0m
[92mRank: 0, Lengthscale: [[0.5731383  0.28971097]] [0m
[92mRank: 0, Outputscale: 2.0247771739959717 [0m
[92mRank: 0, Noise: 0.00013161773676984012 [0m
Run 3 completed successfully
Running gapxGP 4 with agents: 100
decpxADMM initialized with rho: 0.75, lip: 1.0, tol_abs: 1e-05, tol_rel: 0.001, rank: 0, world_size: 100
Rank 0 - Epoch 2/150 loss: 1.032748818397522
Rank 0 - Epoch 10/150 loss: 0.8069227933883667
Rank 0 - Epoch 20/150 loss: 0.4956936836242676
Rank 0 - Epoch 30/150 loss: 0.14365999400615692
Rank 0 - Epoch 40/150 loss: -0.26297423243522644
Rank 0 - Epoch 50/150 loss: -0.6645351648330688
Rank 0 - Epoch 60/150 loss: -1.0455677509307861
Rank 0 - Epoch 70/150 loss: -1.396130084991455
Rank 0 - Epoch 80/150 loss: -1.706682562828064
Rank 0 - Epoch 90/150 loss: -1.9579426050186157
Rank 0 - Epoch 100/150 loss: -2.140861749649048
Rank 0 - Epoch 110/150 loss: -2.2622101306915283
Rank 0 - Epoch 120/150 loss: -2.321678638458252
Rank 0 - Epoch 130/150 loss: -2.3356831073760986
Rank 0 - Epoch 140/150 loss: -2.382800340652466
Rank 0 - Epoch 150/150 loss: -2.3589351177215576
[92mRank 0 - Testing RMSE: 0.0079[0m
[92mRank: 0, Lengthscale: [[0.6462947  0.30225363]] [0m
[92mRank: 0, Outputscale: 2.018587112426758 [0m
[92mRank: 0, Noise: 0.00013233718345873058 [0m
Run 4 completed successfully
Running gapxGP 5 with agents: 100
decpxADMM initialized with rho: 0.75, lip: 1.0, tol_abs: 1e-05, tol_rel: 0.001, rank: 0, world_size: 100
Rank 0 - Epoch 2/150 loss: 1.0499087572097778
Rank 0 - Epoch 10/150 loss: 0.8296645283699036
Rank 0 - Epoch 20/150 loss: 0.510851263999939
Rank 0 - Epoch 30/150 loss: 0.13858002424240112
Rank 0 - Epoch 40/150 loss: -0.2670605480670929
Rank 0 - Epoch 50/150 loss: -0.6675021648406982
Rank 0 - Epoch 60/150 loss: -1.0470877885818481
Rank 0 - Epoch 70/150 loss: -1.3969179391860962
Rank 0 - Epoch 80/150 loss: -1.7057181596755981
Rank 0 - Epoch 90/150 loss: -1.9540457725524902
Rank 0 - Epoch 100/150 loss: -2.134458303451538
Rank 0 - Epoch 110/150 loss: -2.253788709640503
Rank 0 - Epoch 120/150 loss: -2.2760746479034424
Rank 0 - Epoch 130/150 loss: -2.3552069664001465
Rank 0 - Epoch 140/150 loss: -2.323275327682495
Rank 0 - Epoch 150/150 loss: -2.376446008682251
[92mRank 0 - Testing RMSE: 0.0098[0m
[92mRank: 0, Lengthscale: [[0.6823773  0.39762098]] [0m
[92mRank: 0, Outputscale: 2.0028765201568604 [0m
[92mRank: 0, Noise: 0.00013242359273135662 [0m
Run 5 failed, retrying...
Running gapxGP 6 with agents: 100
decpxADMM initialized with rho: 0.75, lip: 1.0, tol_abs: 1e-05, tol_rel: 0.001, rank: 0, world_size: 100
Rank 0 - Epoch 2/150 loss: 1.039818525314331
Rank 0 - Epoch 10/150 loss: 0.8116881847381592
Rank 0 - Epoch 20/150 loss: 0.48762303590774536
Rank 0 - Epoch 30/150 loss: 0.11449483036994934
Rank 0 - Epoch 40/150 loss: -0.2969669997692108
Rank 0 - Epoch 50/150 loss: -0.6963812708854675
Rank 0 - Epoch 60/150 loss: -1.0756032466888428
Rank 0 - Epoch 70/150 loss: -1.4244085550308228
Rank 0 - Epoch 80/150 loss: -1.7332258224487305
Rank 0 - Epoch 90/150 loss: -1.9815561771392822
Rank 0 - Epoch 100/150 loss: -2.1608293056488037
Rank 0 - Epoch 110/150 loss: -2.278963565826416
Rank 0 - Epoch 120/150 loss: -2.304286003112793
Rank 0 - Epoch 130/150 loss: -2.3509538173675537
Rank 0 - Epoch 140/150 loss: -2.2746665477752686
Rank 0 - Epoch 150/150 loss: -2.360153913497925
[92mRank 0 - Testing RMSE: 0.0123[0m
[92mRank: 0, Lengthscale: [[0.6922139 0.406888 ]] [0m
[92mRank: 0, Outputscale: 2.0052428245544434 [0m
[92mRank: 0, Noise: 0.0001316750713158399 [0m
Run 6 completed successfully
Running gapxGP 7 with agents: 100
decpxADMM initialized with rho: 0.75, lip: 1.0, tol_abs: 1e-05, tol_rel: 0.001, rank: 0, world_size: 100
Rank 0 - Epoch 2/150 loss: 1.0408202409744263
Rank 0 - Epoch 10/150 loss: 0.8126434087753296
Rank 0 - Epoch 20/150 loss: 0.4943925440311432
Rank 0 - Epoch 30/150 loss: 0.12980201840400696
Rank 0 - Epoch 40/150 loss: -0.2790481150150299
Rank 0 - Epoch 50/150 loss: -0.6811228394508362
Rank 0 - Epoch 60/150 loss: -1.0625807046890259
Rank 0 - Epoch 70/150 loss: -1.412780523300171
Rank 0 - Epoch 80/150 loss: -1.7208918333053589
Rank 0 - Epoch 90/150 loss: -1.9684637784957886
Rank 0 - Epoch 100/150 loss: -2.147880792617798
Rank 0 - Epoch 110/150 loss: -2.266632556915283
Rank 0 - Epoch 120/150 loss: -2.2867369651794434
Rank 0 - Epoch 130/150 loss: -2.2900729179382324
Rank 0 - Epoch 140/150 loss: -2.3147358894348145
Rank 0 - Epoch 150/150 loss: -1.8195549249649048
[92mRank 0 - Testing RMSE: 0.0151[0m
[92mRank: 0, Lengthscale: [[0.49916154 0.1834314 ]] [0m
[92mRank: 0, Outputscale: 2.040454387664795 [0m
[92mRank: 0, Noise: 0.00013224928989075124 [0m
Run 7 completed successfully
Running gapxGP 8 with agents: 100
decpxADMM initialized with rho: 0.75, lip: 1.0, tol_abs: 1e-05, tol_rel: 0.001, rank: 0, world_size: 100
Rank 0 - Epoch 2/150 loss: 1.0374103784561157
Rank 0 - Epoch 10/150 loss: 0.8116580843925476
Rank 0 - Epoch 20/150 loss: 0.5000551342964172
Rank 0 - Epoch 30/150 loss: 0.13462094962596893
Rank 0 - Epoch 40/150 loss: -0.2851254940032959
Rank 0 - Epoch 50/150 loss: -0.6915911436080933
Rank 0 - Epoch 60/150 loss: -1.0765914916992188
Rank 0 - Epoch 70/150 loss: -1.42892587184906
Rank 0 - Epoch 80/150 loss: -1.7383193969726562
Rank 0 - Epoch 90/150 loss: -1.9871529340744019
Rank 0 - Epoch 100/150 loss: -2.166862726211548
Rank 0 - Epoch 110/150 loss: -2.2856106758117676
Rank 0 - Epoch 120/150 loss: -2.3033220767974854
Rank 0 - Epoch 130/150 loss: -2.1600234508514404
Rank 0 - Epoch 140/150 loss: -2.387338638305664
Rank 0 - Epoch 150/150 loss: -2.3427226543426514
[92mRank 0 - Testing RMSE: 0.0112[0m
[92mRank: 0, Lengthscale: [[0.56640184 0.30478802]] [0m
[92mRank: 0, Outputscale: 2.020657539367676 [0m
[92mRank: 0, Noise: 0.00013144072727300227 [0m
Run 8 completed successfully
Running gapxGP 9 with agents: 100
decpxADMM initialized with rho: 0.75, lip: 1.0, tol_abs: 1e-05, tol_rel: 0.001, rank: 0, world_size: 100
Rank 0 - Epoch 2/150 loss: 1.03341805934906
Rank 0 - Epoch 10/150 loss: 0.8056266903877258
Rank 0 - Epoch 20/150 loss: 0.48812153935432434
Rank 0 - Epoch 30/150 loss: 0.12580712139606476
Rank 0 - Epoch 40/150 loss: -0.2850376069545746
Rank 0 - Epoch 50/150 loss: -0.6846310496330261
Rank 0 - Epoch 60/150 loss: -1.0635442733764648
Rank 0 - Epoch 70/150 loss: -1.4102544784545898
Rank 0 - Epoch 80/150 loss: -1.7164658308029175
Rank 0 - Epoch 90/150 loss: -1.9640570878982544
Rank 0 - Epoch 100/150 loss: -2.1446421146392822
Rank 0 - Epoch 110/150 loss: -2.264927864074707
Rank 0 - Epoch 120/150 loss: -2.2805964946746826
Rank 0 - Epoch 130/150 loss: -2.134273052215576
Rank 0 - Epoch 140/150 loss: -2.268495798110962
Run 9 failed, retrying...
Running gapxGP 10 with agents: 100
decpxADMM initialized with rho: 0.75, lip: 1.0, tol_abs: 1e-05, tol_rel: 0.001, rank: 0, world_size: 100
Rank 0 - Epoch 2/150 loss: 1.0323545932769775
Rank 0 - Epoch 10/150 loss: 0.8037863969802856
Rank 0 - Epoch 20/150 loss: 0.4882356524467468
Rank 0 - Epoch 30/150 loss: 0.13747230172157288
Rank 0 - Epoch 40/150 loss: -0.27300572395324707
Rank 0 - Epoch 50/150 loss: -0.6770612001419067
Rank 0 - Epoch 60/150 loss: -1.0567317008972168
Rank 0 - Epoch 70/150 loss: -1.4052653312683105
Rank 0 - Epoch 80/150 loss: -1.7133753299713135
Rank 0 - Epoch 90/150 loss: -1.9623162746429443
Rank 0 - Epoch 100/150 loss: -2.143561840057373
Rank 0 - Epoch 110/150 loss: -2.264225482940674
Rank 0 - Epoch 120/150 loss: -2.201672315597534
Rank 0 - Epoch 130/150 loss: -2.1725027561187744
Rank 0 - Epoch 140/150 loss: -2.34395170211792
Run 10 failed, retrying...
Running apxGP 1 with agents: 100
decpxADMM initialized with rho: 0.85, lip: 1.0, tol_abs: 1e-05, tol_rel: 0.001, rank: 0, world_size: 100
Rank 0 - Epoch 2/200 loss: 0.7938461303710938
Rank 0 - Epoch 10/200 loss: 0.5273297429084778
Rank 0 - Epoch 20/200 loss: 0.11495519429445267
Rank 0 - Epoch 30/200 loss: -0.36741846799850464
Rank 0 - Epoch 40/200 loss: -0.8911980390548706
Rank 0 - Epoch 50/200 loss: -1.4145517349243164
Rank 0 - Epoch 60/200 loss: -1.9220753908157349
Rank 0 - Epoch 70/200 loss: -2.383523941040039
Rank 0 - Epoch 80/200 loss: -2.75624942779541
Rank 0 - Epoch 90/200 loss: -3.014780282974243
Rank 0 - Epoch 100/200 loss: -3.1721131801605225
Rank 0 - Epoch 110/200 loss: -3.265511989593506
Rank 0 - Epoch 120/200 loss: -3.3222427368164062
Rank 0 - Epoch 130/200 loss: -3.358527660369873
Rank 0 - Epoch 140/200 loss: -3.3833229541778564
Rank 0 - Epoch 150/200 loss: -3.4014134407043457
Rank 0 - Epoch 160/200 loss: -3.415029287338257
Rank 0 - Epoch 170/200 loss: -3.4258735179901123
Rank 0 - Epoch 180/200 loss: -3.433915138244629
Rank 0 - Epoch 190/200 loss: -3.4409284591674805
Rank 0 - Epoch 200/200 loss: -3.446322202682495
Training complete.
[92mRank 0 - Testing RMSE: 2.8843[0m
[92mRank: 0, Lengthscale: [[0.5917924  0.36337626]] [0m
[92mRank: 0, Outputscale: 1.4329828023910522 [0m
[92mRank: 0, Noise: 0.00011016800272045657 [0m
Run 1 completed successfully
Running apxGP 2 with agents: 100
decpxADMM initialized with rho: 0.85, lip: 1.0, tol_abs: 1e-05, tol_rel: 0.001, rank: 0, world_size: 100
Rank 0 - Epoch 2/200 loss: 0.7938461303710938
Rank 0 - Epoch 10/200 loss: 0.5273297429084778
Rank 0 - Epoch 20/200 loss: 0.11495519429445267
Rank 0 - Epoch 30/200 loss: -0.36741846799850464
Rank 0 - Epoch 40/200 loss: -0.8911980390548706
Rank 0 - Epoch 50/200 loss: -1.4145517349243164
Rank 0 - Epoch 60/200 loss: -1.9220753908157349
Rank 0 - Epoch 70/200 loss: -2.383523941040039
Rank 0 - Epoch 80/200 loss: -2.75624942779541
Rank 0 - Epoch 90/200 loss: -3.014780282974243
Rank 0 - Epoch 100/200 loss: -3.1721131801605225
Rank 0 - Epoch 110/200 loss: -3.265511989593506
Rank 0 - Epoch 120/200 loss: -3.3222427368164062
Rank 0 - Epoch 130/200 loss: -3.358527660369873
Rank 0 - Epoch 140/200 loss: -3.3833229541778564
Rank 0 - Epoch 150/200 loss: -3.4014134407043457
Rank 0 - Epoch 160/200 loss: -3.415029287338257
Rank 0 - Epoch 170/200 loss: -3.4258735179901123
Rank 0 - Epoch 180/200 loss: -3.433915138244629
Rank 0 - Epoch 190/200 loss: -3.4409284591674805
Rank 0 - Epoch 200/200 loss: -3.446322202682495
Training complete.
[92mRank 0 - Testing RMSE: 2.8843[0m
[92mRank: 0, Lengthscale: [[0.5917924  0.36337626]] [0m
[92mRank: 0, Outputscale: 1.4329828023910522 [0m
[92mRank: 0, Noise: 0.00011016800272045657 [0m
Run 2 completed successfully
Running apxGP 3 with agents: 100
decpxADMM initialized with rho: 0.85, lip: 1.0, tol_abs: 1e-05, tol_rel: 0.001, rank: 0, world_size: 100
Rank 0 - Epoch 2/200 loss: 0.7938461303710938
Rank 0 - Epoch 10/200 loss: 0.5273297429084778
Rank 0 - Epoch 20/200 loss: 0.11495519429445267
Rank 0 - Epoch 30/200 loss: -0.36741846799850464
Rank 0 - Epoch 40/200 loss: -0.8911980390548706
Rank 0 - Epoch 50/200 loss: -1.4145517349243164
Rank 0 - Epoch 60/200 loss: -1.9220753908157349
Rank 0 - Epoch 70/200 loss: -2.383523941040039
Rank 0 - Epoch 80/200 loss: -2.75624942779541
Rank 0 - Epoch 90/200 loss: -3.014780282974243
Rank 0 - Epoch 100/200 loss: -3.1721131801605225
Rank 0 - Epoch 110/200 loss: -3.265511989593506
Rank 0 - Epoch 120/200 loss: -3.3222427368164062
Rank 0 - Epoch 130/200 loss: -3.358527660369873
Rank 0 - Epoch 140/200 loss: -3.3833229541778564
Rank 0 - Epoch 150/200 loss: -3.4014134407043457
Rank 0 - Epoch 160/200 loss: -3.415029287338257
Rank 0 - Epoch 170/200 loss: -3.4258735179901123
Rank 0 - Epoch 180/200 loss: -3.433915138244629
Rank 0 - Epoch 190/200 loss: -3.4409284591674805
Rank 0 - Epoch 200/200 loss: -3.446322202682495
Training complete.
[92mRank 0 - Testing RMSE: 2.8843[0m
[92mRank: 0, Lengthscale: [[0.5917924  0.36337626]] [0m
[92mRank: 0, Outputscale: 1.4329828023910522 [0m
[92mRank: 0, Noise: 0.00011016800272045657 [0m
Run 3 completed successfully
Running apxGP 4 with agents: 100
decpxADMM initialized with rho: 0.85, lip: 1.0, tol_abs: 1e-05, tol_rel: 0.001, rank: 0, world_size: 100
Rank 0 - Epoch 2/200 loss: 0.7938461303710938
Rank 0 - Epoch 10/200 loss: 0.5273297429084778
Rank 0 - Epoch 20/200 loss: 0.11495519429445267
Rank 0 - Epoch 30/200 loss: -0.36741846799850464
Rank 0 - Epoch 40/200 loss: -0.8911980390548706
Rank 0 - Epoch 50/200 loss: -1.4145517349243164
Rank 0 - Epoch 60/200 loss: -1.9220753908157349
Rank 0 - Epoch 70/200 loss: -2.383523941040039
Rank 0 - Epoch 80/200 loss: -2.75624942779541
Rank 0 - Epoch 90/200 loss: -3.014780282974243
Rank 0 - Epoch 100/200 loss: -3.1721131801605225
Rank 0 - Epoch 110/200 loss: -3.265511989593506
Rank 0 - Epoch 120/200 loss: -3.3222427368164062
Rank 0 - Epoch 130/200 loss: -3.358527660369873
Rank 0 - Epoch 140/200 loss: -3.3833229541778564
Rank 0 - Epoch 150/200 loss: -3.4014134407043457
Rank 0 - Epoch 160/200 loss: -3.415029287338257
Rank 0 - Epoch 170/200 loss: -3.4258735179901123
Rank 0 - Epoch 180/200 loss: -3.433915138244629
Rank 0 - Epoch 190/200 loss: -3.4409284591674805
Rank 0 - Epoch 200/200 loss: -3.446322202682495
Training complete.
[92mRank 0 - Testing RMSE: 2.8843[0m
[92mRank: 0, Lengthscale: [[0.5917924  0.36337626]] [0m
[92mRank: 0, Outputscale: 1.4329828023910522 [0m
[92mRank: 0, Noise: 0.00011016800272045657 [0m
Run 4 completed successfully
Running apxGP 5 with agents: 100
decpxADMM initialized with rho: 0.85, lip: 1.0, tol_abs: 1e-05, tol_rel: 0.001, rank: 0, world_size: 100
Rank 0 - Epoch 2/200 loss: 0.7938461303710938
Rank 0 - Epoch 10/200 loss: 0.5273297429084778
Rank 0 - Epoch 20/200 loss: 0.11495519429445267
Rank 0 - Epoch 30/200 loss: -0.36741846799850464
Rank 0 - Epoch 40/200 loss: -0.8911980390548706
Rank 0 - Epoch 50/200 loss: -1.4145517349243164
Rank 0 - Epoch 60/200 loss: -1.9220753908157349
Rank 0 - Epoch 70/200 loss: -2.383523941040039
Rank 0 - Epoch 80/200 loss: -2.75624942779541
Rank 0 - Epoch 90/200 loss: -3.014780282974243
Rank 0 - Epoch 100/200 loss: -3.1721131801605225
Rank 0 - Epoch 110/200 loss: -3.265511989593506
Rank 0 - Epoch 120/200 loss: -3.3222427368164062
Rank 0 - Epoch 130/200 loss: -3.358527660369873
Rank 0 - Epoch 140/200 loss: -3.3833229541778564
Rank 0 - Epoch 150/200 loss: -3.4014134407043457
Rank 0 - Epoch 160/200 loss: -3.415029287338257
Rank 0 - Epoch 170/200 loss: -3.4258735179901123
Rank 0 - Epoch 180/200 loss: -3.433915138244629
Rank 0 - Epoch 190/200 loss: -3.4409284591674805
Rank 0 - Epoch 200/200 loss: -3.446322202682495
Training complete.
[92mRank 0 - Testing RMSE: 2.8843[0m
[92mRank: 0, Lengthscale: [[0.5917924  0.36337626]] [0m
[92mRank: 0, Outputscale: 1.4329828023910522 [0m
[92mRank: 0, Noise: 0.00011016800272045657 [0m
Run 5 completed successfully
Running apxGP 6 with agents: 100
decpxADMM initialized with rho: 0.85, lip: 1.0, tol_abs: 1e-05, tol_rel: 0.001, rank: 0, world_size: 100
Rank 0 - Epoch 2/200 loss: 0.7938461303710938
Rank 0 - Epoch 10/200 loss: 0.5273297429084778
Rank 0 - Epoch 20/200 loss: 0.11495519429445267
Rank 0 - Epoch 30/200 loss: -0.36741846799850464
Rank 0 - Epoch 40/200 loss: -0.8911980390548706
Rank 0 - Epoch 50/200 loss: -1.4145517349243164
Rank 0 - Epoch 60/200 loss: -1.9220753908157349
Rank 0 - Epoch 70/200 loss: -2.383523941040039
Rank 0 - Epoch 80/200 loss: -2.75624942779541
Rank 0 - Epoch 90/200 loss: -3.014780282974243
Rank 0 - Epoch 100/200 loss: -3.1721131801605225
Rank 0 - Epoch 110/200 loss: -3.265511989593506
Rank 0 - Epoch 120/200 loss: -3.3222427368164062
Rank 0 - Epoch 130/200 loss: -3.358527660369873
Rank 0 - Epoch 140/200 loss: -3.3833229541778564
Rank 0 - Epoch 150/200 loss: -3.4014134407043457
Rank 0 - Epoch 160/200 loss: -3.415029287338257
Rank 0 - Epoch 170/200 loss: -3.4258735179901123
Rank 0 - Epoch 180/200 loss: -3.433915138244629
Rank 0 - Epoch 190/200 loss: -3.4409284591674805
Rank 0 - Epoch 200/200 loss: -3.446322202682495
Training complete.
[92mRank 0 - Testing RMSE: 2.8843[0m
[92mRank: 0, Lengthscale: [[0.5917924  0.36337626]] [0m
[92mRank: 0, Outputscale: 1.4329828023910522 [0m
[92mRank: 0, Noise: 0.00011016800272045657 [0m
Run 6 completed successfully
Running apxGP 7 with agents: 100
decpxADMM initialized with rho: 0.85, lip: 1.0, tol_abs: 1e-05, tol_rel: 0.001, rank: 0, world_size: 100
Rank 0 - Epoch 2/200 loss: 0.7938461303710938
Rank 0 - Epoch 10/200 loss: 0.5273297429084778
Rank 0 - Epoch 20/200 loss: 0.11495519429445267
Rank 0 - Epoch 30/200 loss: -0.36741846799850464
Rank 0 - Epoch 40/200 loss: -0.8911980390548706
Rank 0 - Epoch 50/200 loss: -1.4145517349243164
Rank 0 - Epoch 60/200 loss: -1.9220753908157349
Rank 0 - Epoch 70/200 loss: -2.383523941040039
Rank 0 - Epoch 80/200 loss: -2.75624942779541
Rank 0 - Epoch 90/200 loss: -3.014780282974243
Rank 0 - Epoch 100/200 loss: -3.1721131801605225
Rank 0 - Epoch 110/200 loss: -3.265511989593506
Rank 0 - Epoch 120/200 loss: -3.3222427368164062
Rank 0 - Epoch 130/200 loss: -3.358527660369873
Rank 0 - Epoch 140/200 loss: -3.3833229541778564
Rank 0 - Epoch 150/200 loss: -3.4014134407043457
Rank 0 - Epoch 160/200 loss: -3.415029287338257
Rank 0 - Epoch 170/200 loss: -3.4258735179901123
Rank 0 - Epoch 180/200 loss: -3.433915138244629
Rank 0 - Epoch 190/200 loss: -3.4409284591674805
Rank 0 - Epoch 200/200 loss: -3.446322202682495
Training complete.
[92mRank 0 - Testing RMSE: 2.8843[0m
[92mRank: 0, Lengthscale: [[0.5917924  0.36337626]] [0m
[92mRank: 0, Outputscale: 1.4329828023910522 [0m
[92mRank: 0, Noise: 0.00011016800272045657 [0m
Run 7 completed successfully
Running apxGP 8 with agents: 100
decpxADMM initialized with rho: 0.85, lip: 1.0, tol_abs: 1e-05, tol_rel: 0.001, rank: 0, world_size: 100
Rank 0 - Epoch 2/200 loss: 0.7938461303710938
Rank 0 - Epoch 10/200 loss: 0.5273297429084778
Rank 0 - Epoch 20/200 loss: 0.11495519429445267
Rank 0 - Epoch 30/200 loss: -0.36741846799850464
Rank 0 - Epoch 40/200 loss: -0.8911980390548706
Rank 0 - Epoch 50/200 loss: -1.4145517349243164
Rank 0 - Epoch 60/200 loss: -1.9220753908157349
Rank 0 - Epoch 70/200 loss: -2.383523941040039
Rank 0 - Epoch 80/200 loss: -2.75624942779541
Rank 0 - Epoch 90/200 loss: -3.014780282974243
Rank 0 - Epoch 100/200 loss: -3.1721131801605225
Rank 0 - Epoch 110/200 loss: -3.265511989593506
Rank 0 - Epoch 120/200 loss: -3.3222427368164062
Rank 0 - Epoch 130/200 loss: -3.358527660369873
Rank 0 - Epoch 140/200 loss: -3.3833229541778564
Rank 0 - Epoch 150/200 loss: -3.4014134407043457
Rank 0 - Epoch 160/200 loss: -3.415029287338257
Rank 0 - Epoch 170/200 loss: -3.4258735179901123
Rank 0 - Epoch 180/200 loss: -3.433915138244629
Rank 0 - Epoch 190/200 loss: -3.4409284591674805
Rank 0 - Epoch 200/200 loss: -3.446322202682495
Training complete.
[92mRank 0 - Testing RMSE: 2.8843[0m
[92mRank: 0, Lengthscale: [[0.5917924  0.36337626]] [0m
[92mRank: 0, Outputscale: 1.4329828023910522 [0m
[92mRank: 0, Noise: 0.00011016800272045657 [0m
Run 8 completed successfully
Running apxGP 9 with agents: 100
decpxADMM initialized with rho: 0.85, lip: 1.0, tol_abs: 1e-05, tol_rel: 0.001, rank: 0, world_size: 100
Rank 0 - Epoch 2/200 loss: 0.7938461303710938
Rank 0 - Epoch 10/200 loss: 0.5273297429084778
Rank 0 - Epoch 20/200 loss: 0.11495519429445267
Rank 0 - Epoch 30/200 loss: -0.36741846799850464
Rank 0 - Epoch 40/200 loss: -0.8911980390548706
Rank 0 - Epoch 50/200 loss: -1.4145517349243164
Rank 0 - Epoch 60/200 loss: -1.9220753908157349
Rank 0 - Epoch 70/200 loss: -2.383523941040039
Rank 0 - Epoch 80/200 loss: -2.75624942779541
Rank 0 - Epoch 90/200 loss: -3.014780282974243
Rank 0 - Epoch 100/200 loss: -3.1721131801605225
Rank 0 - Epoch 110/200 loss: -3.265511989593506
Rank 0 - Epoch 120/200 loss: -3.3222427368164062
Rank 0 - Epoch 130/200 loss: -3.358527660369873
Rank 0 - Epoch 140/200 loss: -3.3833229541778564
Rank 0 - Epoch 150/200 loss: -3.4014134407043457
Rank 0 - Epoch 160/200 loss: -3.415029287338257
Rank 0 - Epoch 170/200 loss: -3.4258735179901123
Rank 0 - Epoch 180/200 loss: -3.433915138244629
Rank 0 - Epoch 190/200 loss: -3.4409284591674805
Rank 0 - Epoch 200/200 loss: -3.446322202682495
Training complete.
[92mRank 0 - Testing RMSE: 2.8843[0m
[92mRank: 0, Lengthscale: [[0.5917924  0.36337626]] [0m
[92mRank: 0, Outputscale: 1.4329828023910522 [0m
[92mRank: 0, Noise: 0.00011016800272045657 [0m
Run 9 completed successfully
Running apxGP 10 with agents: 100
decpxADMM initialized with rho: 0.85, lip: 1.0, tol_abs: 1e-05, tol_rel: 0.001, rank: 0, world_size: 100
Rank 0 - Epoch 2/200 loss: 0.7938461303710938
Rank 0 - Epoch 10/200 loss: 0.5273297429084778
Rank 0 - Epoch 20/200 loss: 0.11495519429445267
Rank 0 - Epoch 30/200 loss: -0.36741846799850464
Rank 0 - Epoch 40/200 loss: -0.8911980390548706
Rank 0 - Epoch 50/200 loss: -1.4145517349243164
Rank 0 - Epoch 60/200 loss: -1.9220753908157349
Rank 0 - Epoch 70/200 loss: -2.383523941040039
Rank 0 - Epoch 80/200 loss: -2.75624942779541
Rank 0 - Epoch 90/200 loss: -3.014780282974243
Rank 0 - Epoch 100/200 loss: -3.1721131801605225
Rank 0 - Epoch 110/200 loss: -3.265511989593506
Rank 0 - Epoch 120/200 loss: -3.3222427368164062
Rank 0 - Epoch 130/200 loss: -3.358527660369873
Rank 0 - Epoch 140/200 loss: -3.3833229541778564
Rank 0 - Epoch 150/200 loss: -3.4014134407043457
Rank 0 - Epoch 160/200 loss: -3.415029287338257
Rank 0 - Epoch 170/200 loss: -3.4258735179901123
Rank 0 - Epoch 180/200 loss: -3.433915138244629
Rank 0 - Epoch 190/200 loss: -3.4409284591674805
Rank 0 - Epoch 200/200 loss: -3.446322202682495
Training complete.
[92mRank 0 - Testing RMSE: 2.8843[0m
[92mRank: 0, Lengthscale: [[0.5917924  0.36337626]] [0m
[92mRank: 0, Outputscale: 1.4329828023910522 [0m
[92mRank: 0, Noise: 0.00011016800272045657 [0m
Run 10 completed successfully
Running cGP 1 with agents: 100
decADMM initialized with rho: 0.85, max_iter: 5, lr: 0.0001, rank: 0, world_size: 100
Rank 0 - Epoch 2/200 loss: 0.8504831790924072
Rank 0 - Epoch 10/200 loss: 0.8459839820861816
Rank 0 - Epoch 20/200 loss: 0.8403559327125549
Rank 0 - Epoch 30/200 loss: 0.8347246050834656
Rank 0 - Epoch 40/200 loss: 0.8290915489196777
Rank 0 - Epoch 50/200 loss: 0.8234583735466003
Rank 0 - Epoch 60/200 loss: 0.8178269267082214
Rank 0 - Epoch 70/200 loss: 0.8121991753578186
Rank 0 - Epoch 80/200 loss: 0.8065771460533142
Rank 0 - Epoch 90/200 loss: 0.8009629249572754
Rank 0 - Epoch 100/200 loss: 0.7953593134880066
Rank 0 - Epoch 110/200 loss: 0.7897683382034302
Rank 0 - Epoch 120/200 loss: 0.7841931581497192
Rank 0 - Epoch 130/200 loss: 0.7786365747451782
Rank 0 - Epoch 140/200 loss: 0.7731016278266907
Rank 0 - Epoch 150/200 loss: 0.7675917148590088
Rank 0 - Epoch 160/200 loss: 0.7621104121208191
Rank 0 - Epoch 170/200 loss: 0.7566614747047424
Rank 0 - Epoch 180/200 loss: 0.7512487173080444
Rank 0 - Epoch 190/200 loss: 0.745876669883728
Rank 0 - Epoch 200/200 loss: 0.7405494451522827
Training complete.
[92mRank 0 - Testing RMSE: 3.8976[0m
[92mRank: 0, Lengthscale: [[0.53739333 0.5366974 ]] [0m
[92mRank: 0, Outputscale: 0.5405246019363403 [0m
[92mRank: 0, Noise: 0.5226854085922241 [0m
Run 1 completed successfully
Running cGP 2 with agents: 100
decADMM initialized with rho: 0.85, max_iter: 5, lr: 0.0001, rank: 0, world_size: 100
Rank 0 - Epoch 2/200 loss: 0.8504831790924072
Rank 0 - Epoch 10/200 loss: 0.8459839820861816
Rank 0 - Epoch 20/200 loss: 0.8403559327125549
Rank 0 - Epoch 30/200 loss: 0.8347246050834656
Rank 0 - Epoch 40/200 loss: 0.8290915489196777
Rank 0 - Epoch 50/200 loss: 0.8234583735466003
Rank 0 - Epoch 60/200 loss: 0.8178269267082214
Rank 0 - Epoch 70/200 loss: 0.8121991753578186
Rank 0 - Epoch 80/200 loss: 0.8065771460533142
Rank 0 - Epoch 90/200 loss: 0.8009629249572754
Rank 0 - Epoch 100/200 loss: 0.7953593134880066
Rank 0 - Epoch 110/200 loss: 0.7897683382034302
Rank 0 - Epoch 120/200 loss: 0.7841931581497192
Rank 0 - Epoch 130/200 loss: 0.7786365747451782
Rank 0 - Epoch 140/200 loss: 0.7731016278266907
Rank 0 - Epoch 150/200 loss: 0.7675917148590088
Rank 0 - Epoch 160/200 loss: 0.7621104121208191
Rank 0 - Epoch 170/200 loss: 0.7566614747047424
Rank 0 - Epoch 180/200 loss: 0.7512487173080444
Rank 0 - Epoch 190/200 loss: 0.745876669883728
Rank 0 - Epoch 200/200 loss: 0.7405494451522827
Training complete.
[92mRank 0 - Testing RMSE: 3.8976[0m
[92mRank: 0, Lengthscale: [[0.53739333 0.5366974 ]] [0m
[92mRank: 0, Outputscale: 0.5405246019363403 [0m
[92mRank: 0, Noise: 0.5226854085922241 [0m
Run 2 completed successfully
Running cGP 3 with agents: 100
decADMM initialized with rho: 0.85, max_iter: 5, lr: 0.0001, rank: 0, world_size: 100
Rank 0 - Epoch 2/200 loss: 0.8504831790924072
Rank 0 - Epoch 10/200 loss: 0.8459839820861816
Rank 0 - Epoch 20/200 loss: 0.8403559327125549
Rank 0 - Epoch 30/200 loss: 0.8347246050834656
Rank 0 - Epoch 40/200 loss: 0.8290915489196777
Rank 0 - Epoch 50/200 loss: 0.8234583735466003
Rank 0 - Epoch 60/200 loss: 0.8178269267082214
Rank 0 - Epoch 70/200 loss: 0.8121991753578186
Rank 0 - Epoch 80/200 loss: 0.8065771460533142
Rank 0 - Epoch 90/200 loss: 0.8009629249572754
Rank 0 - Epoch 100/200 loss: 0.7953593134880066
Rank 0 - Epoch 110/200 loss: 0.7897683382034302
Rank 0 - Epoch 120/200 loss: 0.7841931581497192
Rank 0 - Epoch 130/200 loss: 0.7786365747451782
Rank 0 - Epoch 140/200 loss: 0.7731016278266907
Rank 0 - Epoch 150/200 loss: 0.7675917148590088
Rank 0 - Epoch 160/200 loss: 0.7621104121208191
Rank 0 - Epoch 170/200 loss: 0.7566614747047424
Rank 0 - Epoch 180/200 loss: 0.7512487173080444
Rank 0 - Epoch 190/200 loss: 0.745876669883728
Rank 0 - Epoch 200/200 loss: 0.7405494451522827
Training complete.
[92mRank 0 - Testing RMSE: 3.8976[0m
[92mRank: 0, Lengthscale: [[0.53739333 0.5366974 ]] [0m
[92mRank: 0, Outputscale: 0.5405246019363403 [0m
[92mRank: 0, Noise: 0.5226854085922241 [0m
Run 3 completed successfully
Running cGP 4 with agents: 100
decADMM initialized with rho: 0.85, max_iter: 5, lr: 0.0001, rank: 0, world_size: 100
Rank 0 - Epoch 2/200 loss: 0.8504831790924072
Rank 0 - Epoch 10/200 loss: 0.8459839820861816
Rank 0 - Epoch 20/200 loss: 0.8403559327125549
Rank 0 - Epoch 30/200 loss: 0.8347246050834656
Rank 0 - Epoch 40/200 loss: 0.8290915489196777
Rank 0 - Epoch 50/200 loss: 0.8234583735466003
Rank 0 - Epoch 60/200 loss: 0.8178269267082214
Rank 0 - Epoch 70/200 loss: 0.8121991753578186
Rank 0 - Epoch 80/200 loss: 0.8065771460533142
Rank 0 - Epoch 90/200 loss: 0.8009629249572754
Rank 0 - Epoch 100/200 loss: 0.7953593134880066
Rank 0 - Epoch 110/200 loss: 0.7897683382034302
