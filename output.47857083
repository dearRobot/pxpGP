Job started on: g005
SLURM_JOB_ID: 47857083
Running pxpGP 1 with agents: 64
[92mRank 0 - sparse dataset size is: 8, local dataset: torch.Size([529, 2]), [0m
[92mRank 0 - Training local sparse GP model with 529 samples[0m
Epoch 1/200 - Loss: 5.181
Epoch 11/200 - Loss: 1.109
Epoch 21/200 - Loss: 0.764
Epoch 31/200 - Loss: 0.447
Epoch 41/200 - Loss: -0.085
Converged at epoch 41 with loss -0.085
[92mRank 0 - Lengthscale: [[0.49968407 0.3447856 ]] [0m
[92mRank 0 - Outputscale: 1.8453121185302734 [0m
[92mRank 0 - Noise: 0.1029304563999176 [0m
Rank 0 - Augmented dataset size: 1041
Rank 0: After warm start model parameters:
Rank: 0, Lengthscale: [[0.49968407 0.3447856 ]]
Rank: 0, Outputscale: 1.8453121185302734
Rank: 0, Noise: 0.1029304563999176
decpxADMM initialized with rho: 0.85, lip: 1.0, tol_abs: 1e-05, tol_rel: 0.001, rank: 0, world_size: 64
[92mRank 0 - Training global model with dec-pxADMM optimizer[0m
rank 0, epoch 9, loss: 0.6204095482826233, rho: 0.4250, lip: 1.0000
rank 0, epoch 19, loss: 0.5725905299186707, rho: 0.1062, lip: 1.0000
rank 0, epoch 29, loss: 0.5682912468910217, rho: 0.0531, lip: 1.0000
rank 0, epoch 39, loss: 0.5677751302719116, rho: 0.0531, lip: 1.0000
rank 0, epoch 49, loss: 0.552879273891449, rho: 0.0531, lip: 1.0000
rank 0, epoch 59, loss: 0.5617115497589111, rho: 0.0133, lip: 1.0000
rank 0, epoch 69, loss: 0.5616511702537537, rho: 0.0133, lip: 1.0000
rank 0, epoch 79, loss: 0.5653947591781616, rho: 0.0133, lip: 1.0000
rank 0, epoch 89, loss: 0.5515638589859009, rho: 0.0133, lip: 1.0000
Rank 0 - Training time: 79.20 seconds
[92mRank 0 - Testing RMSE: 0.3484[0m
[92mRank: 0, Lengthscale: [[0.5697557  0.45776463]] [0m
[92mRank: 0, Outputscale: 1.382602572441101 [0m
[92mRank: 0, Noise: 0.12996713817119598 [0m
Run 1 completed successfully
Running pxpGP 2 with agents: 64
[92mRank 0 - sparse dataset size is: 8, local dataset: torch.Size([529, 2]), [0m
[92mRank 0 - Training local sparse GP model with 529 samples[0m
Epoch 1/200 - Loss: 5.166
Epoch 11/200 - Loss: 1.001
Epoch 21/200 - Loss: 0.787
Epoch 31/200 - Loss: 0.471
Epoch 41/200 - Loss: 0.082
Converged at epoch 42 with loss -0.113
[92mRank 0 - Lengthscale: [[0.5285049  0.35011947]] [0m
[92mRank 0 - Outputscale: 1.915727972984314 [0m
[92mRank 0 - Noise: 0.09152913838624954 [0m
Rank 0 - Augmented dataset size: 1041
Rank 0: After warm start model parameters:
Rank: 0, Lengthscale: [[0.5285049  0.35011947]]
Rank: 0, Outputscale: 1.915727972984314
Rank: 0, Noise: 0.09152916073799133
decpxADMM initialized with rho: 0.85, lip: 1.0, tol_abs: 1e-05, tol_rel: 0.001, rank: 0, world_size: 64
[92mRank 0 - Training global model with dec-pxADMM optimizer[0m
rank 0, epoch 9, loss: 0.6721768975257874, rho: 0.4250, lip: 1.0000
rank 0, epoch 19, loss: 0.5955551862716675, rho: 0.2125, lip: 1.0000
rank 0, epoch 29, loss: 0.6057921648025513, rho: 0.1062, lip: 1.0000
rank 0, epoch 39, loss: 0.6049896478652954, rho: 0.1062, lip: 1.0000
rank 0, epoch 49, loss: 0.5935062766075134, rho: 0.1062, lip: 1.0000
rank 0, epoch 59, loss: 0.6044273376464844, rho: 0.0266, lip: 1.0000
rank 0, epoch 69, loss: 0.5990918278694153, rho: 0.0266, lip: 1.0000
rank 0, epoch 79, loss: 0.5902326107025146, rho: 0.0266, lip: 1.0000
rank 0, epoch 89, loss: 0.5906662940979004, rho: 0.0266, lip: 1.0000
Rank 0 - Training time: 80.01 seconds
[92mRank 0 - Testing RMSE: 0.3221[0m
[92mRank: 0, Lengthscale: [[0.5288527  0.41721827]] [0m
[92mRank: 0, Outputscale: 2.1635966300964355 [0m
[92mRank: 0, Noise: 0.138292133808136 [0m
Run 2 completed successfully
Running pxpGP 3 with agents: 64
[92mRank 0 - sparse dataset size is: 8, local dataset: torch.Size([529, 2]), [0m
[92mRank 0 - Training local sparse GP model with 529 samples[0m
Epoch 1/200 - Loss: 5.302
Epoch 11/200 - Loss: 0.972
Epoch 21/200 - Loss: 0.788
Epoch 31/200 - Loss: 0.445
Converged at epoch 40 with loss -0.062
[92mRank 0 - Lengthscale: [[0.88687724 0.21612592]] [0m
[92mRank 0 - Outputscale: 1.655670166015625 [0m
[92mRank 0 - Noise: 0.10482767969369888 [0m
Rank 0 - Augmented dataset size: 1041
Rank 0: After warm start model parameters:
Rank: 0, Lengthscale: [[0.8868772  0.21612594]]
Rank: 0, Outputscale: 1.655670166015625
Rank: 0, Noise: 0.10482767969369888
decpxADMM initialized with rho: 0.85, lip: 1.0, tol_abs: 1e-05, tol_rel: 0.001, rank: 0, world_size: 64
[92mRank 0 - Training global model with dec-pxADMM optimizer[0m
rank 0, epoch 9, loss: 0.6525436043739319, rho: 0.4250, lip: 1.0000
rank 0, epoch 19, loss: 0.5938944816589355, rho: 0.2125, lip: 1.0000
rank 0, epoch 29, loss: 0.5859728455543518, rho: 0.1062, lip: 1.0000
rank 0, epoch 39, loss: 0.5620044469833374, rho: 0.1062, lip: 1.0000
rank 0, epoch 49, loss: 0.5660001635551453, rho: 0.0531, lip: 1.0000
rank 0, epoch 59, loss: 0.5663959383964539, rho: 0.0531, lip: 1.0000
rank 0, epoch 69, loss: 0.5789886713027954, rho: 0.0531, lip: 1.0000
rank 0, epoch 79, loss: 0.5728524327278137, rho: 0.0266, lip: 1.0000
rank 0, epoch 89, loss: 0.5736412405967712, rho: 0.0266, lip: 1.0000
Rank 0 - Training time: 87.02 seconds
[92mRank 0 - Testing RMSE: 0.3945[0m
[92mRank: 0, Lengthscale: [[0.48967427 0.3364076 ]] [0m
[92mRank: 0, Outputscale: 1.046283483505249 [0m
[92mRank: 0, Noise: 0.13579457998275757 [0m
Run 3 completed successfully
Running pxpGP 4 with agents: 64
[92mRank 0 - sparse dataset size is: 8, local dataset: torch.Size([529, 2]), [0m
[92mRank 0 - Training local sparse GP model with 529 samples[0m
Epoch 1/200 - Loss: 4.107
Epoch 11/200 - Loss: 1.026
Epoch 21/200 - Loss: 0.795
Epoch 31/200 - Loss: 0.444
Epoch 41/200 - Loss: -0.054
Converged at epoch 41 with loss -0.054
[92mRank 0 - Lengthscale: [[0.5023954 0.3363846]] [0m
[92mRank 0 - Outputscale: 1.861487627029419 [0m
[92mRank 0 - Noise: 0.10295350104570389 [0m
Rank 0 - Augmented dataset size: 1041
Rank 0: After warm start model parameters:
Rank: 0, Lengthscale: [[0.5023954 0.3363846]]
Rank: 0, Outputscale: 1.861487627029419
Rank: 0, Noise: 0.10295350104570389
decpxADMM initialized with rho: 0.85, lip: 1.0, tol_abs: 1e-05, tol_rel: 0.001, rank: 0, world_size: 64
[92mRank 0 - Training global model with dec-pxADMM optimizer[0m
rank 0, epoch 9, loss: 0.7068003416061401, rho: 0.4250, lip: 1.0000
rank 0, epoch 19, loss: 0.6567346453666687, rho: 0.1062, lip: 1.0000
rank 0, epoch 29, loss: 0.6602181792259216, rho: 0.1062, lip: 1.0000
rank 0, epoch 39, loss: 0.6536280512809753, rho: 0.1062, lip: 1.0000
rank 0, epoch 49, loss: 0.6630063652992249, rho: 0.0531, lip: 1.0000
rank 0, epoch 59, loss: 0.6657774448394775, rho: 0.0531, lip: 1.0000
rank 0, epoch 69, loss: 0.6900181770324707, rho: 0.0531, lip: 1.0000
rank 0, epoch 79, loss: 0.6822190880775452, rho: 0.0266, lip: 1.0000
rank 0, epoch 89, loss: 0.6800150871276855, rho: 0.0266, lip: 1.0000
Rank 0 - Training time: 71.52 seconds
[92mRank 0 - Testing RMSE: 0.3622[0m
[92mRank: 0, Lengthscale: [[0.5180132  0.41572177]] [0m
[92mRank: 0, Outputscale: 0.640903651714325 [0m
[92mRank: 0, Noise: 0.17065057158470154 [0m
Run 4 completed successfully
Running pxpGP 5 with agents: 64
[92mRank 0 - sparse dataset size is: 8, local dataset: torch.Size([529, 2]), [0m
[92mRank 0 - Training local sparse GP model with 529 samples[0m
Epoch 1/200 - Loss: 4.355
Epoch 11/200 - Loss: 1.120
Epoch 21/200 - Loss: 0.775
Epoch 31/200 - Loss: 0.590
Converged at epoch 40 with loss -0.052
[92mRank 0 - Lengthscale: [[0.5013572  0.32979205]] [0m
[92mRank 0 - Outputscale: 1.8254635334014893 [0m
[92mRank 0 - Noise: 0.11216437816619873 [0m
Rank 0 - Augmented dataset size: 1041
Rank 0: After warm start model parameters:
Rank: 0, Lengthscale: [[0.5013572  0.32979205]]
Rank: 0, Outputscale: 1.8254635334014893
Rank: 0, Noise: 0.11216437816619873
decpxADMM initialized with rho: 0.85, lip: 1.0, tol_abs: 1e-05, tol_rel: 0.001, rank: 0, world_size: 64
[92mRank 0 - Training global model with dec-pxADMM optimizer[0m
rank 0, epoch 9, loss: 0.7313039898872375, rho: 0.4250, lip: 1.0000
rank 0, epoch 19, loss: 0.6414942145347595, rho: 0.2125, lip: 1.0000
rank 0, epoch 29, loss: 0.6095483899116516, rho: 0.0531, lip: 1.0000
rank 0, epoch 39, loss: 0.595848798751831, rho: 0.0531, lip: 1.0000
rank 0, epoch 49, loss: 0.6079232096672058, rho: 0.0531, lip: 1.0000
rank 0, epoch 59, loss: 0.607215404510498, rho: 0.0531, lip: 1.0000
rank 0, epoch 69, loss: 0.5974233150482178, rho: 0.0531, lip: 1.0000
rank 0, epoch 79, loss: 0.6026792526245117, rho: 0.0266, lip: 1.0000
rank 0, epoch 89, loss: 0.6004788279533386, rho: 0.0266, lip: 1.0000
Rank 0 - Training time: 92.91 seconds
[92mRank 0 - Testing RMSE: 0.3445[0m
[92mRank: 0, Lengthscale: [[0.40428662 0.50322974]] [0m
[92mRank: 0, Outputscale: 2.178133249282837 [0m
[92mRank: 0, Noise: 0.13546490669250488 [0m
Run 5 completed successfully
Running pxpGP 6 with agents: 64
[92mRank 0 - sparse dataset size is: 8, local dataset: torch.Size([529, 2]), [0m
[92mRank 0 - Training local sparse GP model with 529 samples[0m
Epoch 1/200 - Loss: 4.617
Epoch 11/200 - Loss: 1.005
Epoch 21/200 - Loss: 0.819
Epoch 31/200 - Loss: 0.440
Converged at epoch 39 with loss -0.001
[92mRank 0 - Lengthscale: [[0.8198661  0.21582219]] [0m
[92mRank 0 - Outputscale: 1.6521440744400024 [0m
[92mRank 0 - Noise: 0.1082647293806076 [0m
Rank 0 - Augmented dataset size: 1041
Rank 0: After warm start model parameters:
Rank: 0, Lengthscale: [[0.8198662 0.2158222]]
Rank: 0, Outputscale: 1.6521440744400024
Rank: 0, Noise: 0.1082647293806076
decpxADMM initialized with rho: 0.85, lip: 1.0, tol_abs: 1e-05, tol_rel: 0.001, rank: 0, world_size: 64
[92mRank 0 - Training global model with dec-pxADMM optimizer[0m
rank 0, epoch 9, loss: 0.625795304775238, rho: 0.4250, lip: 1.0000
rank 0, epoch 19, loss: 0.5675214529037476, rho: 0.1062, lip: 1.0000
rank 0, epoch 29, loss: 0.5774268507957458, rho: 0.0531, lip: 1.0000
rank 0, epoch 39, loss: 0.5722970962524414, rho: 0.0531, lip: 1.0000
rank 0, epoch 49, loss: 0.5570133328437805, rho: 0.0531, lip: 1.0000
rank 0, epoch 59, loss: 0.5616790652275085, rho: 0.0266, lip: 1.0000
rank 0, epoch 69, loss: 0.5732569098472595, rho: 0.0266, lip: 1.0000
rank 0, epoch 79, loss: 0.5692060589790344, rho: 0.0266, lip: 1.0000
rank 0, epoch 89, loss: 0.5656234622001648, rho: 0.0266, lip: 1.0000
Rank 0 - Training time: 79.23 seconds
[92mRank 0 - Testing RMSE: 0.3193[0m
[92mRank: 0, Lengthscale: [[0.6303427 0.3822935]] [0m
[92mRank: 0, Outputscale: 1.4455925226211548 [0m
[92mRank: 0, Noise: 0.13451910018920898 [0m
Run 6 completed successfully
Running pxpGP 7 with agents: 64
[92mRank 0 - sparse dataset size is: 8, local dataset: torch.Size([529, 2]), [0m
[92mRank 0 - Training local sparse GP model with 529 samples[0m
Epoch 1/200 - Loss: 4.906
Epoch 11/200 - Loss: 1.109
Epoch 21/200 - Loss: 0.798
Epoch 31/200 - Loss: 0.522
Epoch 41/200 - Loss: 0.024
Converged at epoch 42 with loss -0.086
[92mRank 0 - Lengthscale: [[0.52183753 0.34164724]] [0m
[92mRank 0 - Outputscale: 1.8640708923339844 [0m
[92mRank 0 - Noise: 0.09064225852489471 [0m
Rank 0 - Augmented dataset size: 1041
Rank 0: After warm start model parameters:
Rank: 0, Lengthscale: [[0.52183753 0.34164727]]
Rank: 0, Outputscale: 1.8640708923339844
Rank: 0, Noise: 0.09064225852489471
decpxADMM initialized with rho: 0.85, lip: 1.0, tol_abs: 1e-05, tol_rel: 0.001, rank: 0, world_size: 64
[92mRank 0 - Training global model with dec-pxADMM optimizer[0m
rank 0, epoch 9, loss: 0.6559736132621765, rho: 0.4250, lip: 1.0000
rank 0, epoch 19, loss: 0.599204957485199, rho: 0.1062, lip: 1.0000
rank 0, epoch 29, loss: 0.6068992018699646, rho: 0.0531, lip: 1.0000
rank 0, epoch 39, loss: 0.6214080452919006, rho: 0.0531, lip: 1.0000
rank 0, epoch 49, loss: 0.6048822402954102, rho: 0.0266, lip: 1.0000
rank 0, epoch 59, loss: 0.597621738910675, rho: 0.0266, lip: 1.0000
rank 0, epoch 69, loss: 0.6165065169334412, rho: 0.0266, lip: 1.0000
rank 0, epoch 79, loss: 0.599803626537323, rho: 0.0266, lip: 1.0000
rank 0, epoch 89, loss: 0.5937767624855042, rho: 0.0266, lip: 1.0000
Rank 0 - Training time: 83.17 seconds
[92mRank 0 - Testing RMSE: 0.3727[0m
[92mRank: 0, Lengthscale: [[0.42546082 0.35519934]] [0m
[92mRank: 0, Outputscale: 1.2251877784729004 [0m
[92mRank: 0, Noise: 0.14191097021102905 [0m
Run 7 completed successfully
Running pxpGP 8 with agents: 64
[92mRank 0 - sparse dataset size is: 8, local dataset: torch.Size([529, 2]), [0m
[92mRank 0 - Training local sparse GP model with 529 samples[0m
Epoch 1/200 - Loss: 5.603
Epoch 11/200 - Loss: 0.980
Epoch 21/200 - Loss: 0.817
Epoch 31/200 - Loss: 0.432
Epoch 41/200 - Loss: -0.002
Converged at epoch 41 with loss -0.002
[92mRank 0 - Lengthscale: [[0.4867418  0.33972785]] [0m
[92mRank 0 - Outputscale: 1.8546597957611084 [0m
[92mRank 0 - Noise: 0.10497410595417023 [0m
Rank 0 - Augmented dataset size: 1041
Rank 0: After warm start model parameters:
Rank: 0, Lengthscale: [[0.4867418  0.33972785]]
Rank: 0, Outputscale: 1.8546597957611084
Rank: 0, Noise: 0.10497410595417023
decpxADMM initialized with rho: 0.85, lip: 1.0, tol_abs: 1e-05, tol_rel: 0.001, rank: 0, world_size: 64
[92mRank 0 - Training global model with dec-pxADMM optimizer[0m
rank 0, epoch 9, loss: 0.6421146988868713, rho: 0.4250, lip: 1.0000
rank 0, epoch 19, loss: 0.5872642993927002, rho: 0.2125, lip: 1.0000
rank 0, epoch 29, loss: 0.5945727229118347, rho: 0.1062, lip: 1.0000
rank 0, epoch 39, loss: 0.5954368114471436, rho: 0.0531, lip: 1.0000
rank 0, epoch 49, loss: 0.5855506658554077, rho: 0.0531, lip: 1.0000
rank 0, epoch 59, loss: 0.5850638747215271, rho: 0.0266, lip: 1.0000
rank 0, epoch 69, loss: 0.5936753153800964, rho: 0.0266, lip: 1.0000
rank 0, epoch 79, loss: 0.5989937782287598, rho: 0.0266, lip: 1.0000
rank 0, epoch 89, loss: 0.5818507671356201, rho: 0.0266, lip: 1.0000
Rank 0 - Training time: 91.54 seconds
[92mRank 0 - Testing RMSE: 0.3355[0m
[92mRank: 0, Lengthscale: [[0.45606315 0.40205842]] [0m
[92mRank: 0, Outputscale: 1.8256477117538452 [0m
[92mRank: 0, Noise: 0.15114101767539978 [0m
Run 8 completed successfully
Running pxpGP 9 with agents: 64
[92mRank 0 - sparse dataset size is: 8, local dataset: torch.Size([529, 2]), [0m
[92mRank 0 - Training local sparse GP model with 529 samples[0m
Epoch 1/200 - Loss: 4.350
Epoch 11/200 - Loss: 1.125
Epoch 21/200 - Loss: 0.862
Epoch 31/200 - Loss: 0.387
Converged at epoch 40 with loss -0.079
[92mRank 0 - Lengthscale: [[0.8175746  0.20427445]] [0m
[92mRank 0 - Outputscale: 1.697672963142395 [0m
[92mRank 0 - Noise: 0.09497424215078354 [0m
Rank 0 - Augmented dataset size: 1041
Rank 0: After warm start model parameters:
Rank: 0, Lengthscale: [[0.8175746  0.20427445]]
Rank: 0, Outputscale: 1.697672963142395
Rank: 0, Noise: 0.09497424215078354
decpxADMM initialized with rho: 0.85, lip: 1.0, tol_abs: 1e-05, tol_rel: 0.001, rank: 0, world_size: 64
[92mRank 0 - Training global model with dec-pxADMM optimizer[0m
rank 0, epoch 9, loss: 0.7203463912010193, rho: 0.4250, lip: 1.0000
rank 0, epoch 19, loss: 0.6663536429405212, rho: 0.1062, lip: 1.0000
rank 0, epoch 29, loss: 0.6449392437934875, rho: 0.1062, lip: 1.0000
rank 0, epoch 39, loss: 0.6530343294143677, rho: 0.1062, lip: 1.0000
rank 0, epoch 49, loss: 0.6483238339424133, rho: 0.0531, lip: 1.0000
rank 0, epoch 59, loss: 0.6467235088348389, rho: 0.0531, lip: 1.0000
rank 0, epoch 69, loss: 0.6493929028511047, rho: 0.0531, lip: 1.0000
rank 0, epoch 79, loss: 0.6409685015678406, rho: 0.0531, lip: 1.0000
rank 0, epoch 89, loss: 0.6320651769638062, rho: 0.0531, lip: 1.0000
Rank 0 - Training time: 79.66 seconds
[92mRank 0 - Testing RMSE: 0.3781[0m
[92mRank: 0, Lengthscale: [[0.5354257  0.44463947]] [0m
[92mRank: 0, Outputscale: 1.1386620998382568 [0m
[92mRank: 0, Noise: 0.16406191885471344 [0m
Run 9 completed successfully
Running pxpGP 10 with agents: 64
[92mRank 0 - sparse dataset size is: 8, local dataset: torch.Size([529, 2]), [0m
[92mRank 0 - Training local sparse GP model with 529 samples[0m
Epoch 1/200 - Loss: 4.345
Epoch 11/200 - Loss: 1.070
Epoch 21/200 - Loss: 0.751
Epoch 31/200 - Loss: 0.420
Converged at epoch 39 with loss -0.000
[92mRank 0 - Lengthscale: [[0.7724067  0.20648773]] [0m
[92mRank 0 - Outputscale: 1.7004327774047852 [0m
[92mRank 0 - Noise: 0.11349833756685257 [0m
Rank 0 - Augmented dataset size: 1041
Rank 0: After warm start model parameters:
Rank: 0, Lengthscale: [[0.7724067  0.20648773]]
Rank: 0, Outputscale: 1.7004326581954956
Rank: 0, Noise: 0.11349833756685257
decpxADMM initialized with rho: 0.85, lip: 1.0, tol_abs: 1e-05, tol_rel: 0.001, rank: 0, world_size: 64
[92mRank 0 - Training global model with dec-pxADMM optimizer[0m
rank 0, epoch 9, loss: 0.7271149158477783, rho: 0.4250, lip: 1.0000
rank 0, epoch 19, loss: 0.6358332633972168, rho: 0.1062, lip: 1.0000
rank 0, epoch 29, loss: 0.6227560043334961, rho: 0.0531, lip: 1.0000
rank 0, epoch 39, loss: 0.6309205889701843, rho: 0.0531, lip: 1.0000
rank 0, epoch 49, loss: 0.6136138439178467, rho: 0.0531, lip: 1.0000
rank 0, epoch 59, loss: 0.6127032041549683, rho: 0.0531, lip: 1.0000
rank 0, epoch 69, loss: 0.6286463737487793, rho: 0.0266, lip: 1.0000
rank 0, epoch 79, loss: 0.6214644908905029, rho: 0.0266, lip: 1.0000
rank 0, epoch 89, loss: 0.6221905946731567, rho: 0.0266, lip: 1.0000
Rank 0 - Training time: 80.27 seconds
[92mRank 0 - Testing RMSE: 0.3606[0m
[92mRank: 0, Lengthscale: [[0.61075616 0.43105996]] [0m
[92mRank: 0, Outputscale: 1.672989845275879 [0m
[92mRank: 0, Noise: 0.14705422520637512 [0m
Run 10 completed successfully
Running gapxGP 1 with agents: 64
decpxADMM initialized with rho: 0.75, lip: 1.0, tol_abs: 1e-05, tol_rel: 0.001, rank: 0, world_size: 64
Rank 0 - Epoch 2/128 loss: 0.9330876469612122
Rank 0 - Epoch 10/128 loss: 0.6937545537948608
Rank 0 - Epoch 20/128 loss: 0.3049124479293823
Rank 0 - Epoch 30/128 loss: -0.1421058624982834
Rank 0 - Epoch 40/128 loss: -0.6203374266624451
Rank 0 - Epoch 50/128 loss: -1.048182487487793
Rank 0 - Epoch 60/128 loss: -1.4201056957244873
Rank 0 - Epoch 70/128 loss: -1.6673781871795654
Rank 0 - Epoch 80/128 loss: -1.8374052047729492
Rank 0 - Epoch 90/128 loss: -1.8610012531280518
Rank 0 - Epoch 100/128 loss: -1.896644115447998
Rank 0 - Epoch 110/128 loss: -1.9363055229187012
Rank 0 - Epoch 120/128 loss: -1.8958781957626343
Run 1 failed, retrying...
Running gapxGP 2 with agents: 64
decpxADMM initialized with rho: 0.75, lip: 1.0, tol_abs: 1e-05, tol_rel: 0.001, rank: 0, world_size: 64
Rank 0 - Epoch 2/128 loss: 0.9305872321128845
Rank 0 - Epoch 10/128 loss: 0.6914225816726685
Rank 0 - Epoch 20/128 loss: 0.30584946274757385
Rank 0 - Epoch 30/128 loss: -0.13996128737926483
Rank 0 - Epoch 40/128 loss: -0.6103221774101257
Rank 0 - Epoch 50/128 loss: -1.0452109575271606
Rank 0 - Epoch 60/128 loss: -1.4545766115188599
Rank 0 - Epoch 70/128 loss: -1.6854889392852783
Rank 0 - Epoch 80/128 loss: -1.8189289569854736
Rank 0 - Epoch 90/128 loss: -1.8744937181472778
Rank 0 - Epoch 100/128 loss: -1.9000334739685059
Rank 0 - Epoch 110/128 loss: -1.9094204902648926
Rank 0 - Epoch 120/128 loss: -1.9124398231506348
[92mRank 0 - Testing RMSE: 0.0389[0m
[92mRank: 0, Lengthscale: [[0.59841114 0.18701968]] [0m
[92mRank: 0, Outputscale: 1.6624038219451904 [0m
[92mRank: 0, Noise: 0.00013709704217035323 [0m
Run 2 completed successfully
Running gapxGP 3 with agents: 64
decpxADMM initialized with rho: 0.75, lip: 1.0, tol_abs: 1e-05, tol_rel: 0.001, rank: 0, world_size: 64
Rank 0 - Epoch 2/128 loss: 0.9333421587944031
Rank 0 - Epoch 10/128 loss: 0.6937978267669678
Rank 0 - Epoch 20/128 loss: 0.3175293505191803
Rank 0 - Epoch 30/128 loss: -0.1248900443315506
Rank 0 - Epoch 40/128 loss: -0.5861634016036987
Rank 0 - Epoch 50/128 loss: -1.0400837659835815
Rank 0 - Epoch 60/128 loss: -1.4064373970031738
Rank 0 - Epoch 70/128 loss: -1.6376813650131226
Rank 0 - Epoch 80/128 loss: -1.8656387329101562
Rank 0 - Epoch 90/128 loss: -1.8742271661758423
Rank 0 - Epoch 100/128 loss: -1.86679208278656
Rank 0 - Epoch 110/128 loss: -1.920278787612915
Rank 0 - Epoch 120/128 loss: -1.8865464925765991
[92mRank 0 - Testing RMSE: 0.0311[0m
[92mRank: 0, Lengthscale: [[0.6056305 0.3489042]] [0m
[92mRank: 0, Outputscale: 1.6358954906463623 [0m
[92mRank: 0, Noise: 0.00013703429431188852 [0m
Run 3 completed successfully
Running gapxGP 4 with agents: 64
decpxADMM initialized with rho: 0.75, lip: 1.0, tol_abs: 1e-05, tol_rel: 0.001, rank: 0, world_size: 64
Rank 0 - Epoch 2/128 loss: 0.9353065490722656
Rank 0 - Epoch 10/128 loss: 0.700957179069519
Rank 0 - Epoch 20/128 loss: 0.31818997859954834
Rank 0 - Epoch 30/128 loss: -0.1307976245880127
Rank 0 - Epoch 40/128 loss: -0.5915102362632751
Rank 0 - Epoch 50/128 loss: -1.0535613298416138
Rank 0 - Epoch 60/128 loss: -1.4351606369018555
Rank 0 - Epoch 70/128 loss: -1.7108852863311768
Rank 0 - Epoch 80/128 loss: -1.7952258586883545
Rank 0 - Epoch 90/128 loss: -1.8935402631759644
Rank 0 - Epoch 100/128 loss: -1.9461305141448975
Rank 0 - Epoch 110/128 loss: -1.7514570951461792
Rank 0 - Epoch 120/128 loss: -1.4792941808700562
[92mRank 0 - Testing RMSE: 0.0330[0m
[92mRank: 0, Lengthscale: [[0.61376595 0.36014163]] [0m
[92mRank: 0, Outputscale: 1.635536551475525 [0m
[92mRank: 0, Noise: 0.0001369684759993106 [0m
Run 4 completed successfully
Running gapxGP 5 with agents: 64
decpxADMM initialized with rho: 0.75, lip: 1.0, tol_abs: 1e-05, tol_rel: 0.001, rank: 0, world_size: 64
Rank 0 - Epoch 2/128 loss: 0.9306415915489197
Rank 0 - Epoch 10/128 loss: 0.691396951675415
Rank 0 - Epoch 20/128 loss: 0.31748953461647034
Rank 0 - Epoch 30/128 loss: -0.13845887780189514
Rank 0 - Epoch 40/128 loss: -0.5938124656677246
Rank 0 - Epoch 50/128 loss: -1.0428617000579834
Rank 0 - Epoch 60/128 loss: -1.4027868509292603
Rank 0 - Epoch 70/128 loss: -1.6678403615951538
Rank 0 - Epoch 80/128 loss: -1.8127737045288086
Rank 0 - Epoch 90/128 loss: -1.8662813901901245
Rank 0 - Epoch 100/128 loss: -1.9829195737838745
Rank 0 - Epoch 110/128 loss: -1.9943358898162842
Rank 0 - Epoch 120/128 loss: -1.867107629776001
[92mRank 0 - Testing RMSE: 0.0368[0m
[92mRank: 0, Lengthscale: [[0.636851   0.36173844]] [0m
[92mRank: 0, Outputscale: 1.630379557609558 [0m
[92mRank: 0, Noise: 0.00013685763406101614 [0m
Run 5 completed successfully
Running gapxGP 6 with agents: 64
decpxADMM initialized with rho: 0.75, lip: 1.0, tol_abs: 1e-05, tol_rel: 0.001, rank: 0, world_size: 64
Rank 0 - Epoch 2/128 loss: 0.932131290435791
Rank 0 - Epoch 10/128 loss: 0.703924834728241
Rank 0 - Epoch 20/128 loss: 0.32393312454223633
Rank 0 - Epoch 30/128 loss: -0.11372728645801544
Rank 0 - Epoch 40/128 loss: -0.5765743255615234
Rank 0 - Epoch 50/128 loss: -1.0288960933685303
Rank 0 - Epoch 60/128 loss: -1.4201159477233887
Rank 0 - Epoch 70/128 loss: -1.6870838403701782
Rank 0 - Epoch 80/128 loss: -1.7693074941635132
Rank 0 - Epoch 90/128 loss: -1.8737456798553467
Rank 0 - Epoch 100/128 loss: -1.894944429397583
Rank 0 - Epoch 110/128 loss: -1.8898001909255981
Rank 0 - Epoch 120/128 loss: -1.8050189018249512
[92mRank 0 - Testing RMSE: 0.0352[0m
[92mRank: 0, Lengthscale: [[0.61731625 0.36915162]] [0m
[92mRank: 0, Outputscale: 1.6271319389343262 [0m
[92mRank: 0, Noise: 0.00013748934725299478 [0m
Run 6 completed successfully
Running gapxGP 7 with agents: 64
decpxADMM initialized with rho: 0.75, lip: 1.0, tol_abs: 1e-05, tol_rel: 0.001, rank: 0, world_size: 64
Rank 0 - Epoch 2/128 loss: 0.9307205677032471
Rank 0 - Epoch 10/128 loss: 0.6943091750144958
Rank 0 - Epoch 20/128 loss: 0.32059627771377563
Rank 0 - Epoch 30/128 loss: -0.1350461095571518
Rank 0 - Epoch 40/128 loss: -0.5816313028335571
Rank 0 - Epoch 50/128 loss: -1.0223777294158936
Rank 0 - Epoch 60/128 loss: -1.4196099042892456
Rank 0 - Epoch 70/128 loss: -1.6853022575378418
Rank 0 - Epoch 80/128 loss: -1.7834198474884033
Rank 0 - Epoch 90/128 loss: -1.8436353206634521
Rank 0 - Epoch 100/128 loss: -1.864936113357544
Rank 0 - Epoch 110/128 loss: -1.8160935640335083
Rank 0 - Epoch 120/128 loss: -1.8328485488891602
Run 7 failed, retrying...
Running gapxGP 8 with agents: 64
decpxADMM initialized with rho: 0.75, lip: 1.0, tol_abs: 1e-05, tol_rel: 0.001, rank: 0, world_size: 64
Rank 0 - Epoch 2/128 loss: 0.9309002161026001
Rank 0 - Epoch 10/128 loss: 0.696404755115509
Rank 0 - Epoch 20/128 loss: 0.30718669295310974
Rank 0 - Epoch 30/128 loss: -0.12420583516359329
Rank 0 - Epoch 40/128 loss: -0.6199939846992493
Rank 0 - Epoch 50/128 loss: -1.033745288848877
Rank 0 - Epoch 60/128 loss: -1.4370062351226807
Rank 0 - Epoch 70/128 loss: -1.6481614112854004
Rank 0 - Epoch 80/128 loss: -1.788474202156067
Rank 0 - Epoch 90/128 loss: -1.8230023384094238
Rank 0 - Epoch 100/128 loss: -1.797417402267456
Rank 0 - Epoch 110/128 loss: -1.8723291158676147
Rank 0 - Epoch 120/128 loss: -1.829147458076477
[92mRank 0 - Testing RMSE: 0.0290[0m
[92mRank: 0, Lengthscale: [[0.59060264 0.3787745 ]] [0m
[92mRank: 0, Outputscale: 1.6320480108261108 [0m
[92mRank: 0, Noise: 0.00013715290697291493 [0m
Run 8 completed successfully
Running gapxGP 9 with agents: 64
decpxADMM initialized with rho: 0.75, lip: 1.0, tol_abs: 1e-05, tol_rel: 0.001, rank: 0, world_size: 64
Rank 0 - Epoch 2/128 loss: 0.9296213984489441
Rank 0 - Epoch 10/128 loss: 0.6942200064659119
Rank 0 - Epoch 20/128 loss: 0.3164047598838806
Rank 0 - Epoch 30/128 loss: -0.13231493532657623
Rank 0 - Epoch 40/128 loss: -0.6052778363227844
Rank 0 - Epoch 50/128 loss: -1.0376510620117188
Rank 0 - Epoch 60/128 loss: -1.4369854927062988
Rank 0 - Epoch 70/128 loss: -1.675925850868225
Rank 0 - Epoch 80/128 loss: -1.8105672597885132
Rank 0 - Epoch 90/128 loss: -1.8520288467407227
Rank 0 - Epoch 100/128 loss: -1.9215006828308105
Rank 0 - Epoch 110/128 loss: -1.8512964248657227
Rank 0 - Epoch 120/128 loss: -1.8990205526351929
[92mRank 0 - Testing RMSE: 0.0325[0m
[92mRank: 0, Lengthscale: [[0.5740638  0.30624738]] [0m
[92mRank: 0, Outputscale: 1.6392288208007812 [0m
[92mRank: 0, Noise: 0.0001369177916785702 [0m
Run 9 completed successfully
Running gapxGP 10 with agents: 64
decpxADMM initialized with rho: 0.75, lip: 1.0, tol_abs: 1e-05, tol_rel: 0.001, rank: 0, world_size: 64
Rank 0 - Epoch 2/128 loss: 0.9244832396507263
Rank 0 - Epoch 10/128 loss: 0.6911364197731018
Rank 0 - Epoch 20/128 loss: 0.303325891494751
Rank 0 - Epoch 30/128 loss: -0.13613079488277435
Rank 0 - Epoch 40/128 loss: -0.6048821806907654
Rank 0 - Epoch 50/128 loss: -1.049912929534912
Rank 0 - Epoch 60/128 loss: -1.4131393432617188
Rank 0 - Epoch 70/128 loss: -1.682083249092102
Rank 0 - Epoch 80/128 loss: -1.7973296642303467
Rank 0 - Epoch 90/128 loss: -1.8695166110992432
Rank 0 - Epoch 100/128 loss: -1.9062336683273315
Rank 0 - Epoch 110/128 loss: -1.844525694847107
Rank 0 - Epoch 120/128 loss: -1.5181316137313843
[92mRank 0 - Testing RMSE: 0.0349[0m
[92mRank: 0, Lengthscale: [[0.61214334 0.32015002]] [0m
[92mRank: 0, Outputscale: 1.6362884044647217 [0m
[92mRank: 0, Noise: 0.00013696700625587255 [0m
Run 10 completed successfully
Running apxGP 1 with agents: 64
decpxADMM initialized with rho: 0.85, lip: 1.0, tol_abs: 1e-05, tol_rel: 0.001, rank: 0, world_size: 64
Rank 0 - Epoch 2/128 loss: 0.7486082911491394
Rank 0 - Epoch 10/128 loss: 0.4769880175590515
Rank 0 - Epoch 20/128 loss: 0.05008886381983757
Rank 0 - Epoch 30/128 loss: -0.43038737773895264
Rank 0 - Epoch 40/128 loss: -0.9396020770072937
Rank 0 - Epoch 50/128 loss: -1.4781283140182495
Rank 0 - Epoch 60/128 loss: -1.9941364526748657
Rank 0 - Epoch 70/128 loss: -2.4621753692626953
Rank 0 - Epoch 80/128 loss: -2.836430311203003
Rank 0 - Epoch 90/128 loss: -3.091383457183838
Rank 0 - Epoch 100/128 loss: -3.2443976402282715
Rank 0 - Epoch 110/128 loss: -3.3339345455169678
Rank 0 - Epoch 120/128 loss: -3.388035535812378
Training complete.
[92mRank 0 - Testing RMSE: 3.0610[0m
[92mRank: 0, Lengthscale: [[0.58779395 0.36023992]] [0m
[92mRank: 0, Outputscale: 1.1191338300704956 [0m
[92mRank: 0, Noise: 0.00013098855561111122 [0m
Run 1 completed successfully
Running apxGP 2 with agents: 64
decpxADMM initialized with rho: 0.85, lip: 1.0, tol_abs: 1e-05, tol_rel: 0.001, rank: 0, world_size: 64
Rank 0 - Epoch 2/128 loss: 0.7486082911491394
Rank 0 - Epoch 10/128 loss: 0.4769880175590515
Rank 0 - Epoch 20/128 loss: 0.05008886381983757
Rank 0 - Epoch 30/128 loss: -0.43038737773895264
Rank 0 - Epoch 40/128 loss: -0.9396020770072937
Rank 0 - Epoch 50/128 loss: -1.4781283140182495
Rank 0 - Epoch 60/128 loss: -1.9941364526748657
Rank 0 - Epoch 70/128 loss: -2.4621753692626953
Rank 0 - Epoch 80/128 loss: -2.836430311203003
Rank 0 - Epoch 90/128 loss: -3.091383457183838
Rank 0 - Epoch 100/128 loss: -3.2443976402282715
Rank 0 - Epoch 110/128 loss: -3.3339345455169678
Rank 0 - Epoch 120/128 loss: -3.388035535812378
Training complete.
[92mRank 0 - Testing RMSE: 3.0610[0m
[92mRank: 0, Lengthscale: [[0.58779395 0.36023992]] [0m
[92mRank: 0, Outputscale: 1.1191338300704956 [0m
[92mRank: 0, Noise: 0.00013098855561111122 [0m
Run 2 completed successfully
Running apxGP 3 with agents: 64
decpxADMM initialized with rho: 0.85, lip: 1.0, tol_abs: 1e-05, tol_rel: 0.001, rank: 0, world_size: 64
Rank 0 - Epoch 2/128 loss: 0.7486082911491394
Rank 0 - Epoch 10/128 loss: 0.4769880175590515
Rank 0 - Epoch 20/128 loss: 0.05008886381983757
Rank 0 - Epoch 30/128 loss: -0.43038737773895264
Rank 0 - Epoch 40/128 loss: -0.9396020770072937
Rank 0 - Epoch 50/128 loss: -1.4781283140182495
Rank 0 - Epoch 60/128 loss: -1.9941364526748657
Rank 0 - Epoch 70/128 loss: -2.4621753692626953
Rank 0 - Epoch 80/128 loss: -2.836430311203003
Rank 0 - Epoch 90/128 loss: -3.091383457183838
Rank 0 - Epoch 100/128 loss: -3.2443976402282715
Rank 0 - Epoch 110/128 loss: -3.3339345455169678
Rank 0 - Epoch 120/128 loss: -3.388035535812378
Training complete.
[92mRank 0 - Testing RMSE: 3.0610[0m
[92mRank: 0, Lengthscale: [[0.58779395 0.36023992]] [0m
[92mRank: 0, Outputscale: 1.1191338300704956 [0m
[92mRank: 0, Noise: 0.00013098855561111122 [0m
Run 3 completed successfully
Running apxGP 4 with agents: 64
decpxADMM initialized with rho: 0.85, lip: 1.0, tol_abs: 1e-05, tol_rel: 0.001, rank: 0, world_size: 64
Rank 0 - Epoch 2/128 loss: 0.7486082911491394
Rank 0 - Epoch 10/128 loss: 0.4769880175590515
Rank 0 - Epoch 20/128 loss: 0.05008886381983757
Rank 0 - Epoch 30/128 loss: -0.43038737773895264
Rank 0 - Epoch 40/128 loss: -0.9396020770072937
Rank 0 - Epoch 50/128 loss: -1.4781283140182495
Rank 0 - Epoch 60/128 loss: -1.9941364526748657
Rank 0 - Epoch 70/128 loss: -2.4621753692626953
Rank 0 - Epoch 80/128 loss: -2.836430311203003
Rank 0 - Epoch 90/128 loss: -3.091383457183838
Rank 0 - Epoch 100/128 loss: -3.2443976402282715
Rank 0 - Epoch 110/128 loss: -3.3339345455169678
Rank 0 - Epoch 120/128 loss: -3.388035535812378
Training complete.
[92mRank 0 - Testing RMSE: 3.0610[0m
[92mRank: 0, Lengthscale: [[0.58779395 0.36023992]] [0m
[92mRank: 0, Outputscale: 1.1191338300704956 [0m
[92mRank: 0, Noise: 0.00013098855561111122 [0m
Run 4 completed successfully
Running apxGP 5 with agents: 64
decpxADMM initialized with rho: 0.85, lip: 1.0, tol_abs: 1e-05, tol_rel: 0.001, rank: 0, world_size: 64
Rank 0 - Epoch 2/128 loss: 0.7486082911491394
Rank 0 - Epoch 10/128 loss: 0.4769880175590515
Rank 0 - Epoch 20/128 loss: 0.05008886381983757
Rank 0 - Epoch 30/128 loss: -0.43038737773895264
Rank 0 - Epoch 40/128 loss: -0.9396020770072937
Rank 0 - Epoch 50/128 loss: -1.4781283140182495
Rank 0 - Epoch 60/128 loss: -1.9941364526748657
Rank 0 - Epoch 70/128 loss: -2.4621753692626953
Rank 0 - Epoch 80/128 loss: -2.836430311203003
Rank 0 - Epoch 90/128 loss: -3.091383457183838
Rank 0 - Epoch 100/128 loss: -3.2443976402282715
Rank 0 - Epoch 110/128 loss: -3.3339345455169678
Rank 0 - Epoch 120/128 loss: -3.388035535812378
Training complete.
[92mRank 0 - Testing RMSE: 3.0610[0m
[92mRank: 0, Lengthscale: [[0.58779395 0.36023992]] [0m
[92mRank: 0, Outputscale: 1.1191338300704956 [0m
[92mRank: 0, Noise: 0.00013098855561111122 [0m
Run 5 completed successfully
Running apxGP 6 with agents: 64
decpxADMM initialized with rho: 0.85, lip: 1.0, tol_abs: 1e-05, tol_rel: 0.001, rank: 0, world_size: 64
Rank 0 - Epoch 2/128 loss: 0.7486082911491394
Rank 0 - Epoch 10/128 loss: 0.4769880175590515
Rank 0 - Epoch 20/128 loss: 0.05008886381983757
Rank 0 - Epoch 30/128 loss: -0.43038737773895264
Rank 0 - Epoch 40/128 loss: -0.9396020770072937
Rank 0 - Epoch 50/128 loss: -1.4781283140182495
Rank 0 - Epoch 60/128 loss: -1.9941364526748657
Rank 0 - Epoch 70/128 loss: -2.4621753692626953
Rank 0 - Epoch 80/128 loss: -2.836430311203003
Rank 0 - Epoch 90/128 loss: -3.091383457183838
Rank 0 - Epoch 100/128 loss: -3.2443976402282715
Rank 0 - Epoch 110/128 loss: -3.3339345455169678
Rank 0 - Epoch 120/128 loss: -3.388035535812378
Training complete.
[92mRank 0 - Testing RMSE: 3.0610[0m
[92mRank: 0, Lengthscale: [[0.58779395 0.36023992]] [0m
[92mRank: 0, Outputscale: 1.1191338300704956 [0m
[92mRank: 0, Noise: 0.00013098855561111122 [0m
Run 6 completed successfully
Running apxGP 7 with agents: 64
decpxADMM initialized with rho: 0.85, lip: 1.0, tol_abs: 1e-05, tol_rel: 0.001, rank: 0, world_size: 64
Rank 0 - Epoch 2/128 loss: 0.7486082911491394
Rank 0 - Epoch 10/128 loss: 0.4769880175590515
Rank 0 - Epoch 20/128 loss: 0.05008886381983757
Rank 0 - Epoch 30/128 loss: -0.43038737773895264
Rank 0 - Epoch 40/128 loss: -0.9396020770072937
Rank 0 - Epoch 50/128 loss: -1.4781283140182495
Rank 0 - Epoch 60/128 loss: -1.9941364526748657
Rank 0 - Epoch 70/128 loss: -2.4621753692626953
Rank 0 - Epoch 80/128 loss: -2.836430311203003
Rank 0 - Epoch 90/128 loss: -3.091383457183838
Rank 0 - Epoch 100/128 loss: -3.2443976402282715
Rank 0 - Epoch 110/128 loss: -3.3339345455169678
Rank 0 - Epoch 120/128 loss: -3.388035535812378
Training complete.
[92mRank 0 - Testing RMSE: 3.0610[0m
[92mRank: 0, Lengthscale: [[0.58779395 0.36023992]] [0m
[92mRank: 0, Outputscale: 1.1191338300704956 [0m
[92mRank: 0, Noise: 0.00013098855561111122 [0m
Run 7 completed successfully
Running apxGP 8 with agents: 64
decpxADMM initialized with rho: 0.85, lip: 1.0, tol_abs: 1e-05, tol_rel: 0.001, rank: 0, world_size: 64
Rank 0 - Epoch 2/128 loss: 0.7486082911491394
Rank 0 - Epoch 10/128 loss: 0.4769880175590515
Rank 0 - Epoch 20/128 loss: 0.05008886381983757
Rank 0 - Epoch 30/128 loss: -0.43038737773895264
Rank 0 - Epoch 40/128 loss: -0.9396020770072937
Rank 0 - Epoch 50/128 loss: -1.4781283140182495
Rank 0 - Epoch 60/128 loss: -1.9941364526748657
Rank 0 - Epoch 70/128 loss: -2.4621753692626953
Rank 0 - Epoch 80/128 loss: -2.836430311203003
Rank 0 - Epoch 90/128 loss: -3.091383457183838
Rank 0 - Epoch 100/128 loss: -3.2443976402282715
Rank 0 - Epoch 110/128 loss: -3.3339345455169678
Rank 0 - Epoch 120/128 loss: -3.388035535812378
Training complete.
[92mRank 0 - Testing RMSE: 3.0610[0m
[92mRank: 0, Lengthscale: [[0.58779395 0.36023992]] [0m
[92mRank: 0, Outputscale: 1.1191338300704956 [0m
[92mRank: 0, Noise: 0.00013098855561111122 [0m
Run 8 completed successfully
Running apxGP 9 with agents: 64
decpxADMM initialized with rho: 0.85, lip: 1.0, tol_abs: 1e-05, tol_rel: 0.001, rank: 0, world_size: 64
Rank 0 - Epoch 2/128 loss: 0.7486082911491394
Rank 0 - Epoch 10/128 loss: 0.4769880175590515
Rank 0 - Epoch 20/128 loss: 0.05008886381983757
Rank 0 - Epoch 30/128 loss: -0.43038737773895264
Rank 0 - Epoch 40/128 loss: -0.9396020770072937
Rank 0 - Epoch 50/128 loss: -1.4781283140182495
Rank 0 - Epoch 60/128 loss: -1.9941364526748657
Rank 0 - Epoch 70/128 loss: -2.4621753692626953
Rank 0 - Epoch 80/128 loss: -2.836430311203003
Rank 0 - Epoch 90/128 loss: -3.091383457183838
Rank 0 - Epoch 100/128 loss: -3.2443976402282715
Rank 0 - Epoch 110/128 loss: -3.3339345455169678
Rank 0 - Epoch 120/128 loss: -3.388035535812378
Training complete.
[92mRank 0 - Testing RMSE: 3.0610[0m
[92mRank: 0, Lengthscale: [[0.58779395 0.36023992]] [0m
[92mRank: 0, Outputscale: 1.1191338300704956 [0m
[92mRank: 0, Noise: 0.00013098855561111122 [0m
Run 9 completed successfully
Running apxGP 10 with agents: 64
decpxADMM initialized with rho: 0.85, lip: 1.0, tol_abs: 1e-05, tol_rel: 0.001, rank: 0, world_size: 64
Rank 0 - Epoch 2/128 loss: 0.7486082911491394
Rank 0 - Epoch 10/128 loss: 0.4769880175590515
Rank 0 - Epoch 20/128 loss: 0.05008886381983757
Rank 0 - Epoch 30/128 loss: -0.43038737773895264
Rank 0 - Epoch 40/128 loss: -0.9396020770072937
Rank 0 - Epoch 50/128 loss: -1.4781283140182495
Rank 0 - Epoch 60/128 loss: -1.9941364526748657
Rank 0 - Epoch 70/128 loss: -2.4621753692626953
Rank 0 - Epoch 80/128 loss: -2.836430311203003
Rank 0 - Epoch 90/128 loss: -3.091383457183838
Rank 0 - Epoch 100/128 loss: -3.2443976402282715
Rank 0 - Epoch 110/128 loss: -3.3339345455169678
Rank 0 - Epoch 120/128 loss: -3.388035535812378
Training complete.
[92mRank 0 - Testing RMSE: 3.0610[0m
[92mRank: 0, Lengthscale: [[0.58779395 0.36023992]] [0m
[92mRank: 0, Outputscale: 1.1191338300704956 [0m
[92mRank: 0, Noise: 0.00013098855561111122 [0m
Run 10 completed successfully
Running cGP 1 with agents: 64
decADMM initialized with rho: 0.85, max_iter: 5, lr: 0.0001, rank: 0, world_size: 64
Rank 0 - Epoch 2/128 loss: 0.8057684898376465
Rank 0 - Epoch 10/128 loss: 0.8002686500549316
Rank 0 - Epoch 20/128 loss: 0.7933751344680786
Rank 0 - Epoch 30/128 loss: 0.7864617705345154
Rank 0 - Epoch 40/128 loss: 0.7795299291610718
Rank 0 - Epoch 50/128 loss: 0.7725805640220642
Rank 0 - Epoch 60/128 loss: 0.7656152248382568
Rank 0 - Epoch 70/128 loss: 0.7586351037025452
Rank 0 - Epoch 80/128 loss: 0.7516416907310486
Rank 0 - Epoch 90/128 loss: 0.7446364760398865
Rank 0 - Epoch 100/128 loss: 0.7376208901405334
Rank 0 - Epoch 110/128 loss: 0.7305964827537537
Rank 0 - Epoch 120/128 loss: 0.7235648036003113
Training complete.
[92mRank 0 - Testing RMSE: 3.5634[0m
[92mRank: 0, Lengthscale: [[0.59004223 0.5889989 ]] [0m
[92mRank: 0, Outputscale: 0.5912106037139893 [0m
[92mRank: 0, Noise: 0.5801180005073547 [0m
Run 1 completed successfully
Running cGP 2 with agents: 64
decADMM initialized with rho: 0.85, max_iter: 5, lr: 0.0001, rank: 0, world_size: 64
Rank 0 - Epoch 2/128 loss: 0.8057684898376465
Rank 0 - Epoch 10/128 loss: 0.8002686500549316
Rank 0 - Epoch 20/128 loss: 0.7933751344680786
Rank 0 - Epoch 30/128 loss: 0.7864617705345154
Rank 0 - Epoch 40/128 loss: 0.7795299291610718
Rank 0 - Epoch 50/128 loss: 0.7725805640220642
Rank 0 - Epoch 60/128 loss: 0.7656152248382568
Rank 0 - Epoch 70/128 loss: 0.7586351037025452
Rank 0 - Epoch 80/128 loss: 0.7516416907310486
Rank 0 - Epoch 90/128 loss: 0.7446364760398865
Rank 0 - Epoch 100/128 loss: 0.7376208901405334
Rank 0 - Epoch 110/128 loss: 0.7305964827537537
Rank 0 - Epoch 120/128 loss: 0.7235648036003113
Training complete.
[92mRank 0 - Testing RMSE: 3.5634[0m
[92mRank: 0, Lengthscale: [[0.59004223 0.5889989 ]] [0m
[92mRank: 0, Outputscale: 0.5912106037139893 [0m
[92mRank: 0, Noise: 0.5801180005073547 [0m
Run 2 completed successfully
Running cGP 3 with agents: 64
decADMM initialized with rho: 0.85, max_iter: 5, lr: 0.0001, rank: 0, world_size: 64
Rank 0 - Epoch 2/128 loss: 0.8057684898376465
Rank 0 - Epoch 10/128 loss: 0.8002686500549316
Rank 0 - Epoch 20/128 loss: 0.7933751344680786
Rank 0 - Epoch 30/128 loss: 0.7864617705345154
Rank 0 - Epoch 40/128 loss: 0.7795299291610718
Rank 0 - Epoch 50/128 loss: 0.7725805640220642
Rank 0 - Epoch 60/128 loss: 0.7656152248382568
Rank 0 - Epoch 70/128 loss: 0.7586351037025452
Rank 0 - Epoch 80/128 loss: 0.7516416907310486
Rank 0 - Epoch 90/128 loss: 0.7446364760398865
Rank 0 - Epoch 100/128 loss: 0.7376208901405334
Rank 0 - Epoch 110/128 loss: 0.7305964827537537
Rank 0 - Epoch 120/128 loss: 0.7235648036003113
Training complete.
[92mRank 0 - Testing RMSE: 3.5634[0m
[92mRank: 0, Lengthscale: [[0.59004223 0.5889989 ]] [0m
[92mRank: 0, Outputscale: 0.5912106037139893 [0m
[92mRank: 0, Noise: 0.5801180005073547 [0m
Run 3 completed successfully
Running cGP 4 with agents: 64
decADMM initialized with rho: 0.85, max_iter: 5, lr: 0.0001, rank: 0, world_size: 64
Rank 0 - Epoch 2/128 loss: 0.8057684898376465
Rank 0 - Epoch 10/128 loss: 0.8002686500549316
Rank 0 - Epoch 20/128 loss: 0.7933751344680786
Rank 0 - Epoch 30/128 loss: 0.7864617705345154
Rank 0 - Epoch 40/128 loss: 0.7795299291610718
Rank 0 - Epoch 50/128 loss: 0.7725805640220642
Rank 0 - Epoch 60/128 loss: 0.7656152248382568
Rank 0 - Epoch 70/128 loss: 0.7586351037025452
Rank 0 - Epoch 80/128 loss: 0.7516416907310486
Rank 0 - Epoch 90/128 loss: 0.7446364760398865
Rank 0 - Epoch 100/128 loss: 0.7376208901405334
Rank 0 - Epoch 110/128 loss: 0.7305964827537537
Rank 0 - Epoch 120/128 loss: 0.7235648036003113
Training complete.
[92mRank 0 - Testing RMSE: 3.5634[0m
[92mRank: 0, Lengthscale: [[0.59004223 0.5889989 ]] [0m
[92mRank: 0, Outputscale: 0.5912106037139893 [0m
[92mRank: 0, Noise: 0.5801180005073547 [0m
Run 4 completed successfully
Running cGP 5 with agents: 64
decADMM initialized with rho: 0.85, max_iter: 5, lr: 0.0001, rank: 0, world_size: 64
Rank 0 - Epoch 2/128 loss: 0.8057684898376465
Rank 0 - Epoch 10/128 loss: 0.8002686500549316
Rank 0 - Epoch 20/128 loss: 0.7933751344680786
Rank 0 - Epoch 30/128 loss: 0.7864617705345154
Rank 0 - Epoch 40/128 loss: 0.7795299291610718
Rank 0 - Epoch 50/128 loss: 0.7725805640220642
Rank 0 - Epoch 60/128 loss: 0.7656152248382568
Rank 0 - Epoch 70/128 loss: 0.7586351037025452
Rank 0 - Epoch 80/128 loss: 0.7516416907310486
Rank 0 - Epoch 90/128 loss: 0.7446364760398865
Rank 0 - Epoch 100/128 loss: 0.7376208901405334
Rank 0 - Epoch 110/128 loss: 0.7305964827537537
Rank 0 - Epoch 120/128 loss: 0.7235648036003113
Training complete.
[92mRank 0 - Testing RMSE: 3.5634[0m
[92mRank: 0, Lengthscale: [[0.59004223 0.5889989 ]] [0m
[92mRank: 0, Outputscale: 0.5912106037139893 [0m
[92mRank: 0, Noise: 0.5801180005073547 [0m
Run 5 completed successfully
Running cGP 6 with agents: 64
decADMM initialized with rho: 0.85, max_iter: 5, lr: 0.0001, rank: 0, world_size: 64
Rank 0 - Epoch 2/128 loss: 0.8057684898376465
Rank 0 - Epoch 10/128 loss: 0.8002686500549316
Rank 0 - Epoch 20/128 loss: 0.7933751344680786
Rank 0 - Epoch 30/128 loss: 0.7864617705345154
Rank 0 - Epoch 40/128 loss: 0.7795299291610718
Rank 0 - Epoch 50/128 loss: 0.7725805640220642
Rank 0 - Epoch 60/128 loss: 0.7656152248382568
Rank 0 - Epoch 70/128 loss: 0.7586351037025452
Rank 0 - Epoch 80/128 loss: 0.7516416907310486
Rank 0 - Epoch 90/128 loss: 0.7446364760398865
Rank 0 - Epoch 100/128 loss: 0.7376208901405334
Rank 0 - Epoch 110/128 loss: 0.7305964827537537
Rank 0 - Epoch 120/128 loss: 0.7235648036003113
Training complete.
[92mRank 0 - Testing RMSE: 3.5634[0m
[92mRank: 0, Lengthscale: [[0.59004223 0.5889989 ]] [0m
[92mRank: 0, Outputscale: 0.5912106037139893 [0m
[92mRank: 0, Noise: 0.5801180005073547 [0m
Run 6 completed successfully
Running cGP 7 with agents: 64
decADMM initialized with rho: 0.85, max_iter: 5, lr: 0.0001, rank: 0, world_size: 64
Rank 0 - Epoch 2/128 loss: 0.8057684898376465
Rank 0 - Epoch 10/128 loss: 0.8002686500549316
Rank 0 - Epoch 20/128 loss: 0.7933751344680786
Rank 0 - Epoch 30/128 loss: 0.7864617705345154
Rank 0 - Epoch 40/128 loss: 0.7795299291610718
Rank 0 - Epoch 50/128 loss: 0.7725805640220642
Rank 0 - Epoch 60/128 loss: 0.7656152248382568
Rank 0 - Epoch 70/128 loss: 0.7586351037025452
Rank 0 - Epoch 80/128 loss: 0.7516416907310486
Rank 0 - Epoch 90/128 loss: 0.7446364760398865
Rank 0 - Epoch 100/128 loss: 0.7376208901405334
Rank 0 - Epoch 110/128 loss: 0.7305964827537537
Rank 0 - Epoch 120/128 loss: 0.7235648036003113
Training complete.
[92mRank 0 - Testing RMSE: 3.5634[0m
[92mRank: 0, Lengthscale: [[0.59004223 0.5889989 ]] [0m
[92mRank: 0, Outputscale: 0.5912106037139893 [0m
[92mRank: 0, Noise: 0.5801180005073547 [0m
Run 7 completed successfully
Running cGP 8 with agents: 64
decADMM initialized with rho: 0.85, max_iter: 5, lr: 0.0001, rank: 0, world_size: 64
Rank 0 - Epoch 2/128 loss: 0.8057684898376465
Rank 0 - Epoch 10/128 loss: 0.8002686500549316
Rank 0 - Epoch 20/128 loss: 0.7933751344680786
Rank 0 - Epoch 30/128 loss: 0.7864617705345154
Rank 0 - Epoch 40/128 loss: 0.7795299291610718
Rank 0 - Epoch 50/128 loss: 0.7725805640220642
Rank 0 - Epoch 60/128 loss: 0.7656152248382568
Rank 0 - Epoch 70/128 loss: 0.7586351037025452
Rank 0 - Epoch 80/128 loss: 0.7516416907310486
Rank 0 - Epoch 90/128 loss: 0.7446364760398865
Rank 0 - Epoch 100/128 loss: 0.7376208901405334
Rank 0 - Epoch 110/128 loss: 0.7305964827537537
Rank 0 - Epoch 120/128 loss: 0.7235648036003113
Training complete.
[92mRank 0 - Testing RMSE: 3.5634[0m
[92mRank: 0, Lengthscale: [[0.59004223 0.5889989 ]] [0m
[92mRank: 0, Outputscale: 0.5912106037139893 [0m
[92mRank: 0, Noise: 0.5801180005073547 [0m
Run 8 completed successfully
Running cGP 9 with agents: 64
decADMM initialized with rho: 0.85, max_iter: 5, lr: 0.0001, rank: 0, world_size: 64
Rank 0 - Epoch 2/128 loss: 0.8057684898376465
Rank 0 - Epoch 10/128 loss: 0.8002686500549316
Rank 0 - Epoch 20/128 loss: 0.7933751344680786
Rank 0 - Epoch 30/128 loss: 0.7864617705345154
Rank 0 - Epoch 40/128 loss: 0.7795299291610718
Rank 0 - Epoch 50/128 loss: 0.7725805640220642
Rank 0 - Epoch 60/128 loss: 0.7656152248382568
Rank 0 - Epoch 70/128 loss: 0.7586351037025452
Rank 0 - Epoch 80/128 loss: 0.7516416907310486
Rank 0 - Epoch 90/128 loss: 0.7446364760398865
Rank 0 - Epoch 100/128 loss: 0.7376208901405334
Rank 0 - Epoch 110/128 loss: 0.7305964827537537
Rank 0 - Epoch 120/128 loss: 0.7235648036003113
Training complete.
[92mRank 0 - Testing RMSE: 3.5634[0m
[92mRank: 0, Lengthscale: [[0.59004223 0.5889989 ]] [0m
[92mRank: 0, Outputscale: 0.5912106037139893 [0m
[92mRank: 0, Noise: 0.5801180005073547 [0m
Run 9 completed successfully
Running cGP 10 with agents: 64
decADMM initialized with rho: 0.85, max_iter: 5, lr: 0.0001, rank: 0, world_size: 64
Rank 0 - Epoch 2/128 loss: 0.8057684898376465
Rank 0 - Epoch 10/128 loss: 0.8002686500549316
Rank 0 - Epoch 20/128 loss: 0.7933751344680786
Rank 0 - Epoch 30/128 loss: 0.7864617705345154
Rank 0 - Epoch 40/128 loss: 0.7795299291610718
Rank 0 - Epoch 50/128 loss: 0.7725805640220642
Rank 0 - Epoch 60/128 loss: 0.7656152248382568
Rank 0 - Epoch 70/128 loss: 0.7586351037025452
Rank 0 - Epoch 80/128 loss: 0.7516416907310486
Rank 0 - Epoch 90/128 loss: 0.7446364760398865
Rank 0 - Epoch 100/128 loss: 0.7376208901405334
Rank 0 - Epoch 110/128 loss: 0.7305964827537537
Rank 0 - Epoch 120/128 loss: 0.7235648036003113
Training complete.
[92mRank 0 - Testing RMSE: 3.5634[0m
[92mRank: 0, Lengthscale: [[0.59004223 0.5889989 ]] [0m
[92mRank: 0, Outputscale: 0.5912106037139893 [0m
[92mRank: 0, Noise: 0.5801180005073547 [0m
Run 10 completed successfully
Running pxpGP 1 with agents: 100
[92mRank 0 - sparse dataset size is: 4, local dataset: torch.Size([324, 2]), [0m
[92mRank 0 - Training local sparse GP model with 324 samples[0m
Epoch 1/200 - Loss: 2.948
Epoch 11/200 - Loss: 0.942
Epoch 21/200 - Loss: 0.549
Converged at epoch 30 with loss -0.075
[92mRank 0 - Lengthscale: [[0.4648825  0.52025676]] [0m
[92mRank 0 - Outputscale: 1.7629090547561646 [0m
[92mRank 0 - Noise: 0.10166043043136597 [0m
Rank 0 - Augmented dataset size: 724
Rank 0: After warm start model parameters:
Rank: 0, Lengthscale: [[0.4648825  0.52025676]]
Rank: 0, Outputscale: 1.762909173965454
Rank: 0, Noise: 0.10166043043136597
decpxADMM initialized with rho: 0.85, lip: 1.0, tol_abs: 1e-05, tol_rel: 0.001, rank: 0, world_size: 100
[92mRank 0 - Training global model with dec-pxADMM optimizer[0m
rank 0, epoch 9, loss: 0.8015590906143188, rho: 0.4250, lip: 1.0000
rank 0, epoch 19, loss: 0.7246701717376709, rho: 0.1062, lip: 1.0000
rank 0, epoch 29, loss: 0.7171667814254761, rho: 0.0531, lip: 1.0000
rank 0, epoch 39, loss: 0.7191386222839355, rho: 0.0531, lip: 1.0000
rank 0, epoch 49, loss: 0.7174974083900452, rho: 0.0266, lip: 1.0000
rank 0, epoch 59, loss: 0.7151403427124023, rho: 0.0266, lip: 1.0000
rank 0, epoch 69, loss: 0.7132706642150879, rho: 0.0266, lip: 1.0000
rank 0, epoch 79, loss: 0.7122492790222168, rho: 0.0266, lip: 1.0000
rank 0, epoch 89, loss: 0.7121102213859558, rho: 0.0266, lip: 1.0000
rank 0, epoch 99, loss: 0.7123162150382996, rho: 0.0266, lip: 1.0000
rank 0, epoch 109, loss: 0.7106398940086365, rho: 0.0266, lip: 1.0000
rank 0, epoch 119, loss: 0.7082625031471252, rho: 0.0266, lip: 1.0000
rank 0, epoch 129, loss: 0.7069787383079529, rho: 0.0266, lip: 1.0000
rank 0, epoch 139, loss: 0.7064028978347778, rho: 0.0133, lip: 1.0000
rank 0, epoch 149, loss: 0.7062810659408569, rho: 0.0133, lip: 1.0000
Rank 0 - Training time: 186.95 seconds
[92mRank 0 - Testing RMSE: 0.3245[0m
[92mRank: 0, Lengthscale: [[0.488567   0.35208562]] [0m
[92mRank: 0, Outputscale: 1.50018310546875 [0m
[92mRank: 0, Noise: 0.16564451158046722 [0m
Run 1 completed successfully
Running pxpGP 2 with agents: 100
[92mRank 0 - sparse dataset size is: 4, local dataset: torch.Size([324, 2]), [0m
[92mRank 0 - Training local sparse GP model with 324 samples[0m
Epoch 1/200 - Loss: 3.657
Epoch 11/200 - Loss: 0.864
Epoch 21/200 - Loss: 0.404
Converged at epoch 28 with loss -0.064
[92mRank 0 - Lengthscale: [[0.57517505 0.3981703 ]] [0m
[92mRank 0 - Outputscale: 1.561975359916687 [0m
[92mRank 0 - Noise: 0.11674429476261139 [0m
Rank 0 - Augmented dataset size: 724
Rank 0: After warm start model parameters:
Rank: 0, Lengthscale: [[0.57517505 0.3981703 ]]
Rank: 0, Outputscale: 1.561975359916687
Rank: 0, Noise: 0.11674429476261139
decpxADMM initialized with rho: 0.85, lip: 1.0, tol_abs: 1e-05, tol_rel: 0.001, rank: 0, world_size: 100
[92mRank 0 - Training global model with dec-pxADMM optimizer[0m
rank 0, epoch 9, loss: 0.6626364588737488, rho: 0.2125, lip: 1.0000
rank 0, epoch 19, loss: 0.6401373744010925, rho: 0.1062, lip: 1.0000
rank 0, epoch 29, loss: 0.6503735780715942, rho: 0.0531, lip: 1.0000
rank 0, epoch 39, loss: 0.6533013582229614, rho: 0.0531, lip: 1.0000
rank 0, epoch 49, loss: 0.6363269090652466, rho: 0.0531, lip: 1.0000
rank 0, epoch 59, loss: 0.6334741711616516, rho: 0.0266, lip: 1.0000
rank 0, epoch 69, loss: 0.6371796131134033, rho: 0.0266, lip: 1.0000
rank 0, epoch 79, loss: 0.6394444704055786, rho: 0.0266, lip: 1.0000
rank 0, epoch 89, loss: 0.6381081342697144, rho: 0.0266, lip: 1.0000
rank 0, epoch 99, loss: 0.635564386844635, rho: 0.0266, lip: 1.0000
rank 0, epoch 109, loss: 0.6332511901855469, rho: 0.0133, lip: 1.0000
rank 0, epoch 119, loss: 0.632129430770874, rho: 0.0066, lip: 1.0000
rank 0, epoch 129, loss: 0.6315327882766724, rho: 0.0066, lip: 1.0000
rank 0, epoch 139, loss: 0.6312469840049744, rho: 0.0066, lip: 1.0000
rank 0, epoch 149, loss: 0.6312382817268372, rho: 0.0066, lip: 1.0000
Rank 0 - Training time: 218.76 seconds
[92mRank 0 - Testing RMSE: 0.2812[0m
[92mRank: 0, Lengthscale: [[0.546643   0.19070391]] [0m
[92mRank: 0, Outputscale: 1.0112930536270142 [0m
[92mRank: 0, Noise: 0.1227794885635376 [0m
Run 2 completed successfully
Running pxpGP 3 with agents: 100
[92mRank 0 - sparse dataset size is: 4, local dataset: torch.Size([324, 2]), [0m
[92mRank 0 - Training local sparse GP model with 324 samples[0m
Epoch 1/200 - Loss: 3.271
Epoch 11/200 - Loss: 0.856
Epoch 21/200 - Loss: 0.480
Converged at epoch 28 with loss -0.051
[92mRank 0 - Lengthscale: [[0.5893719 0.3932796]] [0m
[92mRank 0 - Outputscale: 1.5305442810058594 [0m
[92mRank 0 - Noise: 0.11734937876462936 [0m
Rank 0 - Augmented dataset size: 724
Rank 0: After warm start model parameters:
Rank: 0, Lengthscale: [[0.5893719 0.3932796]]
Rank: 0, Outputscale: 1.5305442810058594
Rank: 0, Noise: 0.11734937876462936
decpxADMM initialized with rho: 0.85, lip: 1.0, tol_abs: 1e-05, tol_rel: 0.001, rank: 0, world_size: 100
[92mRank 0 - Training global model with dec-pxADMM optimizer[0m
rank 0, epoch 9, loss: 0.7198707461357117, rho: 0.2125, lip: 1.0000
rank 0, epoch 19, loss: 0.6593096256256104, rho: 0.1062, lip: 1.0000
rank 0, epoch 29, loss: 0.6534335613250732, rho: 0.0531, lip: 1.0000
rank 0, epoch 39, loss: 0.6570366024971008, rho: 0.0531, lip: 1.0000
rank 0, epoch 49, loss: 0.6503356099128723, rho: 0.0266, lip: 1.0000
rank 0, epoch 59, loss: 0.6436261534690857, rho: 0.0266, lip: 1.0000
rank 0, epoch 69, loss: 0.6407520771026611, rho: 0.0266, lip: 1.0000
rank 0, epoch 79, loss: 0.6402272582054138, rho: 0.0266, lip: 1.0000
rank 0, epoch 89, loss: 0.6400707364082336, rho: 0.0266, lip: 1.0000
rank 0, epoch 99, loss: 0.6386328935623169, rho: 0.0266, lip: 1.0000
rank 0, epoch 109, loss: 0.6367291212081909, rho: 0.0266, lip: 1.0000
rank 0, epoch 119, loss: 0.6353532671928406, rho: 0.0133, lip: 1.0000
rank 0, epoch 129, loss: 0.6348134279251099, rho: 0.0133, lip: 1.0000
rank 0, epoch 139, loss: 0.6350439786911011, rho: 0.0133, lip: 1.0000
rank 0, epoch 149, loss: 0.6357808709144592, rho: 0.0133, lip: 1.0000
Rank 0 - Training time: 157.13 seconds
[92mRank 0 - Testing RMSE: 0.2832[0m
[92mRank: 0, Lengthscale: [[0.4958979  0.33026296]] [0m
[92mRank: 0, Outputscale: 1.020754098892212 [0m
[92mRank: 0, Noise: 0.14365807175636292 [0m
Run 3 completed successfully
Running pxpGP 4 with agents: 100
[92mRank 0 - sparse dataset size is: 4, local dataset: torch.Size([324, 2]), [0m
[92mRank 0 - Training local sparse GP model with 324 samples[0m
Epoch 1/200 - Loss: 4.859
Epoch 11/200 - Loss: 0.929
Epoch 21/200 - Loss: 0.487
Converged at epoch 28 with loss -0.003
[92mRank 0 - Lengthscale: [[0.5865635  0.33999038]] [0m
[92mRank 0 - Outputscale: 1.4621901512145996 [0m
[92mRank 0 - Noise: 0.13913680613040924 [0m
Rank 0 - Augmented dataset size: 724
Rank 0: After warm start model parameters:
Rank: 0, Lengthscale: [[0.5865635  0.33999038]]
Rank: 0, Outputscale: 1.4621901512145996
Rank: 0, Noise: 0.13913680613040924
decpxADMM initialized with rho: 0.85, lip: 1.0, tol_abs: 1e-05, tol_rel: 0.001, rank: 0, world_size: 100
[92mRank 0 - Training global model with dec-pxADMM optimizer[0m
rank 0, epoch 9, loss: 0.7023342251777649, rho: 0.2125, lip: 1.0000
rank 0, epoch 19, loss: 0.6209026575088501, rho: 0.1062, lip: 1.0000
rank 0, epoch 29, loss: 0.6161826252937317, rho: 0.0266, lip: 1.0000
rank 0, epoch 39, loss: 0.6228413581848145, rho: 0.0266, lip: 1.0000
rank 0, epoch 49, loss: 0.6196503639221191, rho: 0.0266, lip: 1.0000
rank 0, epoch 59, loss: 0.6144176721572876, rho: 0.0133, lip: 1.0000
rank 0, epoch 69, loss: 0.6117823123931885, rho: 0.0133, lip: 1.0000
rank 0, epoch 79, loss: 0.6105638146400452, rho: 0.0133, lip: 1.0000
rank 0, epoch 89, loss: 0.6106222867965698, rho: 0.0133, lip: 1.0000
rank 0, epoch 99, loss: 0.6111140847206116, rho: 0.0133, lip: 1.0000
rank 0, epoch 109, loss: 0.6104366779327393, rho: 0.0133, lip: 1.0000
rank 0, epoch 119, loss: 0.6086825132369995, rho: 0.0133, lip: 1.0000
rank 0, epoch 129, loss: 0.6071284413337708, rho: 0.0066, lip: 1.0000
rank 0, epoch 139, loss: 0.6062136292457581, rho: 0.0066, lip: 1.0000
rank 0, epoch 149, loss: 0.6056823134422302, rho: 0.0066, lip: 1.0000
Rank 0 - Training time: 154.31 seconds
[92mRank 0 - Testing RMSE: 0.2722[0m
[92mRank: 0, Lengthscale: [[0.6285477  0.34642202]] [0m
[92mRank: 0, Outputscale: 1.8488883972167969 [0m
[92mRank: 0, Noise: 0.13430695235729218 [0m
Run 4 completed successfully
Running pxpGP 5 with agents: 100
[92mRank 0 - sparse dataset size is: 4, local dataset: torch.Size([324, 2]), [0m
[92mRank 0 - Training local sparse GP model with 324 samples[0m
Epoch 1/200 - Loss: 1.731
Epoch 11/200 - Loss: 0.932
Epoch 21/200 - Loss: 0.447
Converged at epoch 27 with loss -0.011
[92mRank 0 - Lengthscale: [[0.56962645 0.38080072]] [0m
[92mRank 0 - Outputscale: 1.5387382507324219 [0m
[92mRank 0 - Noise: 0.13499096035957336 [0m
Rank 0 - Augmented dataset size: 724
Rank 0: After warm start model parameters:
Rank: 0, Lengthscale: [[0.56962645 0.3808007 ]]
Rank: 0, Outputscale: 1.5387382507324219
Rank: 0, Noise: 0.13499096035957336
decpxADMM initialized with rho: 0.85, lip: 1.0, tol_abs: 1e-05, tol_rel: 0.001, rank: 0, world_size: 100
[92mRank 0 - Training global model with dec-pxADMM optimizer[0m
rank 0, epoch 9, loss: 0.6519944667816162, rho: 0.2125, lip: 1.0000
rank 0, epoch 19, loss: 0.6373945474624634, rho: 0.1062, lip: 1.0000
rank 0, epoch 29, loss: 0.6289942264556885, rho: 0.1062, lip: 1.0000
rank 0, epoch 39, loss: 0.617902934551239, rho: 0.1062, lip: 1.0000
rank 0, epoch 49, loss: 0.6116576790809631, rho: 0.0266, lip: 1.0000
rank 0, epoch 59, loss: 0.6096904873847961, rho: 0.0266, lip: 1.0000
rank 0, epoch 69, loss: 0.6087088584899902, rho: 0.0266, lip: 1.0000
rank 0, epoch 79, loss: 0.6081557869911194, rho: 0.0133, lip: 1.0000
rank 0, epoch 89, loss: 0.6077123284339905, rho: 0.0133, lip: 1.0000
rank 0, epoch 99, loss: 0.607005774974823, rho: 0.0133, lip: 1.0000
rank 0, epoch 109, loss: 0.6058788299560547, rho: 0.0133, lip: 1.0000
rank 0, epoch 119, loss: 0.6044593453407288, rho: 0.0133, lip: 1.0000
rank 0, epoch 129, loss: 0.6029548048973083, rho: 0.0066, lip: 1.0000
rank 0, epoch 139, loss: 0.601842999458313, rho: 0.0033, lip: 1.0000
rank 0, epoch 149, loss: 0.6011903882026672, rho: 0.0033, lip: 1.0000
Rank 0 - Training time: 158.45 seconds
[92mRank 0 - Testing RMSE: 0.2893[0m
[92mRank: 0, Lengthscale: [[0.59601855 0.32041422]] [0m
[92mRank: 0, Outputscale: 1.004084587097168 [0m
[92mRank: 0, Noise: 0.13150443136692047 [0m
Run 5 completed successfully
Running pxpGP 6 with agents: 100
[92mRank 0 - sparse dataset size is: 4, local dataset: torch.Size([324, 2]), [0m
[92mRank 0 - Training local sparse GP model with 324 samples[0m
Epoch 1/200 - Loss: 4.087
Epoch 11/200 - Loss: 0.894
Epoch 21/200 - Loss: 0.433
Converged at epoch 28 with loss -0.030
[92mRank 0 - Lengthscale: [[0.5726059  0.37518233]] [0m
[92mRank 0 - Outputscale: 1.5432407855987549 [0m
[92mRank 0 - Noise: 0.12329244613647461 [0m
Rank 0 - Augmented dataset size: 724
Rank 0: After warm start model parameters:
Rank: 0, Lengthscale: [[0.5726059  0.37518233]]
Rank: 0, Outputscale: 1.5432407855987549
Rank: 0, Noise: 0.12329244613647461
decpxADMM initialized with rho: 0.85, lip: 1.0, tol_abs: 1e-05, tol_rel: 0.001, rank: 0, world_size: 100
[92mRank 0 - Training global model with dec-pxADMM optimizer[0m
rank 0, epoch 9, loss: 0.8042486906051636, rho: 0.4250, lip: 1.0000
rank 0, epoch 19, loss: 0.6819775700569153, rho: 0.2125, lip: 1.0000
rank 0, epoch 29, loss: 0.7016564607620239, rho: 0.1062, lip: 1.0000
rank 0, epoch 39, loss: 0.703853189945221, rho: 0.1062, lip: 1.0000
rank 0, epoch 49, loss: 0.6927390098571777, rho: 0.0531, lip: 1.0000
rank 0, epoch 59, loss: 0.6861167550086975, rho: 0.0531, lip: 1.0000
rank 0, epoch 69, loss: 0.6826903223991394, rho: 0.0266, lip: 1.0000
rank 0, epoch 79, loss: 0.6812776327133179, rho: 0.0266, lip: 1.0000
rank 0, epoch 89, loss: 0.68047034740448, rho: 0.0266, lip: 1.0000
rank 0, epoch 99, loss: 0.6793529987335205, rho: 0.0266, lip: 1.0000
rank 0, epoch 109, loss: 0.6776247620582581, rho: 0.0266, lip: 1.0000
rank 0, epoch 119, loss: 0.6756452918052673, rho: 0.0133, lip: 1.0000
rank 0, epoch 129, loss: 0.6737594604492188, rho: 0.0066, lip: 1.0000
rank 0, epoch 139, loss: 0.672265887260437, rho: 0.0066, lip: 1.0000
rank 0, epoch 149, loss: 0.6712871193885803, rho: 0.0066, lip: 1.0000
Rank 0 - Training time: 143.55 seconds
[92mRank 0 - Testing RMSE: 0.3018[0m
[92mRank: 0, Lengthscale: [[0.6727854  0.35845754]] [0m
[92mRank: 0, Outputscale: 1.1281416416168213 [0m
[92mRank: 0, Noise: 0.1488858163356781 [0m
Run 6 completed successfully
Running pxpGP 7 with agents: 100
[92mRank 0 - sparse dataset size is: 4, local dataset: torch.Size([324, 2]), [0m
[92mRank 0 - Training local sparse GP model with 324 samples[0m
Epoch 1/200 - Loss: 4.585
Epoch 11/200 - Loss: 0.925
Epoch 21/200 - Loss: 0.501
Converged at epoch 30 with loss -0.107
[92mRank 0 - Lengthscale: [[0.5951232  0.42828894]] [0m
[92mRank 0 - Outputscale: 1.602803111076355 [0m
[92mRank 0 - Noise: 0.10027660429477692 [0m
Rank 0 - Augmented dataset size: 724
Rank 0: After warm start model parameters:
Rank: 0, Lengthscale: [[0.5951232  0.42828897]]
Rank: 0, Outputscale: 1.602803111076355
Rank: 0, Noise: 0.10027660429477692
decpxADMM initialized with rho: 0.85, lip: 1.0, tol_abs: 1e-05, tol_rel: 0.001, rank: 0, world_size: 100
[92mRank 0 - Training global model with dec-pxADMM optimizer[0m
rank 0, epoch 9, loss: 0.7755784392356873, rho: 0.2125, lip: 1.0000
rank 0, epoch 19, loss: 0.7191453576087952, rho: 0.2125, lip: 1.0000
rank 0, epoch 29, loss: 0.7143411636352539, rho: 0.1062, lip: 1.0000
rank 0, epoch 39, loss: 0.7169122099876404, rho: 0.1062, lip: 1.0000
rank 0, epoch 49, loss: 0.7051243185997009, rho: 0.0266, lip: 1.0000
rank 0, epoch 59, loss: 0.6970130801200867, rho: 0.0266, lip: 1.0000
rank 0, epoch 69, loss: 0.6931676864624023, rho: 0.0266, lip: 1.0000
rank 0, epoch 79, loss: 0.6924888491630554, rho: 0.0266, lip: 1.0000
rank 0, epoch 89, loss: 0.6928268074989319, rho: 0.0266, lip: 1.0000
rank 0, epoch 99, loss: 0.6915827989578247, rho: 0.0266, lip: 1.0000
rank 0, epoch 109, loss: 0.6893435716629028, rho: 0.0133, lip: 1.0000
rank 0, epoch 119, loss: 0.6876670718193054, rho: 0.0133, lip: 1.0000
rank 0, epoch 129, loss: 0.6868672370910645, rho: 0.0133, lip: 1.0000
rank 0, epoch 139, loss: 0.686919629573822, rho: 0.0133, lip: 1.0000
rank 0, epoch 149, loss: 0.6871955394744873, rho: 0.0133, lip: 1.0000
Rank 0 - Training time: 144.53 seconds
[92mRank 0 - Testing RMSE: 0.3260[0m
[92mRank: 0, Lengthscale: [[0.586758 0.374366]] [0m
[92mRank: 0, Outputscale: 1.202174425125122 [0m
[92mRank: 0, Noise: 0.17800593376159668 [0m
Run 7 completed successfully
Running pxpGP 8 with agents: 100
[92mRank 0 - sparse dataset size is: 4, local dataset: torch.Size([324, 2]), [0m
[92mRank 0 - Training local sparse GP model with 324 samples[0m
Epoch 1/200 - Loss: 2.162
Epoch 11/200 - Loss: 0.859
Epoch 21/200 - Loss: 0.390
Converged at epoch 27 with loss -0.034
[92mRank 0 - Lengthscale: [[0.57005364 0.39406225]] [0m
[92mRank 0 - Outputscale: 1.5496286153793335 [0m
[92mRank 0 - Noise: 0.1294969767332077 [0m
Rank 0 - Augmented dataset size: 724
Rank 0: After warm start model parameters:
Rank: 0, Lengthscale: [[0.57005364 0.39406225]]
Rank: 0, Outputscale: 1.5496286153793335
Rank: 0, Noise: 0.1294969767332077
decpxADMM initialized with rho: 0.85, lip: 1.0, tol_abs: 1e-05, tol_rel: 0.001, rank: 0, world_size: 100
[92mRank 0 - Training global model with dec-pxADMM optimizer[0m
rank 0, epoch 9, loss: 0.6800150871276855, rho: 0.2125, lip: 1.0000
rank 0, epoch 19, loss: 0.6406223773956299, rho: 0.1062, lip: 1.0000
rank 0, epoch 29, loss: 0.665372908115387, rho: 0.1062, lip: 1.0000
rank 0, epoch 39, loss: 0.6639873385429382, rho: 0.1062, lip: 1.0000
rank 0, epoch 49, loss: 0.6527162194252014, rho: 0.0531, lip: 1.0000
rank 0, epoch 59, loss: 0.6517638564109802, rho: 0.0531, lip: 1.0000
rank 0, epoch 69, loss: 0.6575098037719727, rho: 0.0531, lip: 1.0000
rank 0, epoch 79, loss: 0.6602111458778381, rho: 0.0531, lip: 1.0000
rank 0, epoch 89, loss: 0.6594399809837341, rho: 0.0531, lip: 1.0000
rank 0, epoch 99, loss: 0.6598894000053406, rho: 0.0266, lip: 1.0000
rank 0, epoch 109, loss: 0.6606306433677673, rho: 0.0133, lip: 1.0000
rank 0, epoch 119, loss: 0.660897433757782, rho: 0.0133, lip: 1.0000
rank 0, epoch 129, loss: 0.6604190468788147, rho: 0.0133, lip: 1.0000
rank 0, epoch 139, loss: 0.6601598858833313, rho: 0.0133, lip: 1.0000
rank 0, epoch 149, loss: 0.6610144376754761, rho: 0.0133, lip: 1.0000
Rank 0 - Training time: 274.09 seconds
[92mRank 0 - Testing RMSE: 0.4372[0m
[92mRank: 0, Lengthscale: [[0.40997723 0.11801547]] [0m
[92mRank: 0, Outputscale: 1.8630397319793701 [0m
[92mRank: 0, Noise: 0.07715651392936707 [0m
Run 8 completed successfully
Running pxpGP 9 with agents: 100
[92mRank 0 - sparse dataset size is: 4, local dataset: torch.Size([324, 2]), [0m
[92mRank 0 - Training local sparse GP model with 324 samples[0m
Epoch 1/200 - Loss: 3.255
Epoch 11/200 - Loss: 0.873
Epoch 21/200 - Loss: 0.400
Converged at epoch 28 with loss -0.093
[92mRank 0 - Lengthscale: [[0.57814056 0.39473796]] [0m
[92mRank 0 - Outputscale: 1.5613211393356323 [0m
[92mRank 0 - Noise: 0.11462754756212234 [0m
Rank 0 - Augmented dataset size: 724
Rank 0: After warm start model parameters:
Rank: 0, Lengthscale: [[0.57814056 0.39473796]]
Rank: 0, Outputscale: 1.5613211393356323
Rank: 0, Noise: 0.11462754756212234
decpxADMM initialized with rho: 0.85, lip: 1.0, tol_abs: 1e-05, tol_rel: 0.001, rank: 0, world_size: 100
[92mRank 0 - Training global model with dec-pxADMM optimizer[0m
rank 0, epoch 9, loss: 0.7111309170722961, rho: 0.2125, lip: 1.0000
rank 0, epoch 19, loss: 0.6717925667762756, rho: 0.1062, lip: 1.0000
rank 0, epoch 29, loss: 0.664740264415741, rho: 0.0531, lip: 1.0000
rank 0, epoch 39, loss: 0.660314679145813, rho: 0.0531, lip: 1.0000
rank 0, epoch 49, loss: 0.6482502818107605, rho: 0.0266, lip: 1.0000
rank 0, epoch 59, loss: 0.638789713382721, rho: 0.0266, lip: 1.0000
rank 0, epoch 69, loss: 0.6346912980079651, rho: 0.0266, lip: 1.0000
rank 0, epoch 79, loss: 0.6353419423103333, rho: 0.0266, lip: 1.0000
rank 0, epoch 89, loss: 0.6384950280189514, rho: 0.0266, lip: 1.0000
rank 0, epoch 99, loss: 0.6404082179069519, rho: 0.0266, lip: 1.0000
rank 0, epoch 109, loss: 0.6395971775054932, rho: 0.0266, lip: 1.0000
rank 0, epoch 119, loss: 0.6377491354942322, rho: 0.0066, lip: 1.0000
rank 0, epoch 129, loss: 0.6365887522697449, rho: 0.0066, lip: 1.0000
rank 0, epoch 139, loss: 0.6359814405441284, rho: 0.0066, lip: 1.0000
rank 0, epoch 149, loss: 0.6357309818267822, rho: 0.0066, lip: 1.0000
Rank 0 - Training time: 169.19 seconds
[92mRank 0 - Testing RMSE: 0.2814[0m
[92mRank: 0, Lengthscale: [[0.49656367 0.3444665 ]] [0m
[92mRank: 0, Outputscale: 0.8900240659713745 [0m
[92mRank: 0, Noise: 0.13517676293849945 [0m
Run 9 completed successfully
Running pxpGP 10 with agents: 100
[92mRank 0 - sparse dataset size is: 4, local dataset: torch.Size([324, 2]), [0m
[92mRank 0 - Training local sparse GP model with 324 samples[0m
Epoch 1/200 - Loss: 2.328
Epoch 11/200 - Loss: 0.952
Epoch 21/200 - Loss: 0.637
Converged at epoch 30 with loss -0.082
[92mRank 0 - Lengthscale: [[0.8319403 0.3689077]] [0m
[92mRank 0 - Outputscale: 1.7512065172195435 [0m
[92mRank 0 - Noise: 0.10475984960794449 [0m
Rank 0 - Augmented dataset size: 724
Rank 0: After warm start model parameters:
Rank: 0, Lengthscale: [[0.8319403 0.3689077]]
Rank: 0, Outputscale: 1.7512065172195435
Rank: 0, Noise: 0.10475984960794449
decpxADMM initialized with rho: 0.85, lip: 1.0, tol_abs: 1e-05, tol_rel: 0.001, rank: 0, world_size: 100
[92mRank 0 - Training global model with dec-pxADMM optimizer[0m
rank 0, epoch 9, loss: 0.633384108543396, rho: 0.4250, lip: 1.0000
rank 0, epoch 19, loss: 0.6211690902709961, rho: 0.1062, lip: 1.0000
rank 0, epoch 29, loss: 0.5994759202003479, rho: 0.0531, lip: 1.0000
rank 0, epoch 39, loss: 0.5980198979377747, rho: 0.0531, lip: 1.0000
rank 0, epoch 49, loss: 0.5926614999771118, rho: 0.0266, lip: 1.0000
rank 0, epoch 59, loss: 0.589711606502533, rho: 0.0266, lip: 1.0000
rank 0, epoch 69, loss: 0.5883016586303711, rho: 0.0266, lip: 1.0000
rank 0, epoch 79, loss: 0.5871696472167969, rho: 0.0266, lip: 1.0000
rank 0, epoch 89, loss: 0.5864258408546448, rho: 0.0266, lip: 1.0000
rank 0, epoch 99, loss: 0.5859664678573608, rho: 0.0266, lip: 1.0000
rank 0, epoch 109, loss: 0.5855200886726379, rho: 0.0133, lip: 1.0000
rank 0, epoch 119, loss: 0.5852023959159851, rho: 0.0066, lip: 1.0000
rank 0, epoch 129, loss: 0.5850682258605957, rho: 0.0066, lip: 1.0000
rank 0, epoch 139, loss: 0.585083544254303, rho: 0.0066, lip: 1.0000
rank 0, epoch 149, loss: 0.5851548314094543, rho: 0.0066, lip: 1.0000
Rank 0 - Training time: 149.63 seconds
[92mRank 0 - Testing RMSE: 0.2918[0m
[92mRank: 0, Lengthscale: [[0.5954135 0.4179986]] [0m
[92mRank: 0, Outputscale: 2.400240421295166 [0m
[92mRank: 0, Noise: 0.1311100721359253 [0m
Run 10 completed successfully
Running gapxGP 1 with agents: 100
decpxADMM initialized with rho: 0.75, lip: 1.0, tol_abs: 1e-05, tol_rel: 0.001, rank: 0, world_size: 100
Rank 0 - Epoch 2/200 loss: 0.9982762932777405
Rank 0 - Epoch 10/200 loss: 0.7823501825332642
Rank 0 - Epoch 20/200 loss: 0.4387160539627075
Rank 0 - Epoch 30/200 loss: 0.03341623768210411
Rank 0 - Epoch 40/200 loss: -0.3999052345752716
Rank 0 - Epoch 50/200 loss: -0.8239133954048157
Rank 0 - Epoch 60/200 loss: -1.2231106758117676
Rank 0 - Epoch 70/200 loss: -1.5877288579940796
Rank 0 - Epoch 80/200 loss: -1.9002858400344849
Rank 0 - Epoch 90/200 loss: -2.1434695720672607
Rank 0 - Epoch 100/200 loss: -2.3107388019561768
Rank 0 - Epoch 110/200 loss: -2.4164934158325195
Rank 0 - Epoch 120/200 loss: -2.3289716243743896
Rank 0 - Epoch 130/200 loss: -2.390646457672119
Rank 0 - Epoch 140/200 loss: -2.277750015258789
Rank 0 - Epoch 150/200 loss: -2.5099503993988037
Run 1 failed, retrying...
Running gapxGP 2 with agents: 100
decpxADMM initialized with rho: 0.75, lip: 1.0, tol_abs: 1e-05, tol_rel: 0.001, rank: 0, world_size: 100
Rank 0 - Epoch 2/200 loss: 0.9900103807449341
Rank 0 - Epoch 10/200 loss: 0.7729758620262146
Rank 0 - Epoch 20/200 loss: 0.43820920586586
Rank 0 - Epoch 30/200 loss: 0.0384928397834301
Rank 0 - Epoch 40/200 loss: -0.38590919971466064
Rank 0 - Epoch 50/200 loss: -0.8057101964950562
Rank 0 - Epoch 60/200 loss: -1.2014050483703613
Rank 0 - Epoch 70/200 loss: -1.564157485961914
Rank 0 - Epoch 80/200 loss: -1.87747061252594
Rank 0 - Epoch 90/200 loss: -2.121440887451172
Rank 0 - Epoch 100/200 loss: -2.2904536724090576
Rank 0 - Epoch 110/200 loss: -2.3965532779693604
Rank 0 - Epoch 120/200 loss: -2.44244384765625
Rank 0 - Epoch 130/200 loss: -2.4588654041290283
Rank 0 - Epoch 140/200 loss: -2.5096096992492676
Rank 0 - Epoch 150/200 loss: -2.523435354232788
Run 2 failed, retrying...
Running gapxGP 3 with agents: 100
decpxADMM initialized with rho: 0.75, lip: 1.0, tol_abs: 1e-05, tol_rel: 0.001, rank: 0, world_size: 100
Rank 0 - Epoch 2/200 loss: 1.0034998655319214
Rank 0 - Epoch 10/200 loss: 0.7831113338470459
Rank 0 - Epoch 20/200 loss: 0.43217146396636963
Rank 0 - Epoch 30/200 loss: 0.027729542925953865
Rank 0 - Epoch 40/200 loss: -0.3992912173271179
Rank 0 - Epoch 50/200 loss: -0.8213878870010376
Rank 0 - Epoch 60/200 loss: -1.2184499502182007
Rank 0 - Epoch 70/200 loss: -1.5809533596038818
Rank 0 - Epoch 80/200 loss: -1.8926604986190796
Rank 0 - Epoch 90/200 loss: -2.1347737312316895
Rank 0 - Epoch 100/200 loss: -2.301718235015869
Rank 0 - Epoch 110/200 loss: -2.4064154624938965
Rank 0 - Epoch 120/200 loss: -2.316145420074463
Rank 0 - Epoch 130/200 loss: -2.358184814453125
Rank 0 - Epoch 140/200 loss: -2.2167673110961914
Run 3 failed, retrying...
Running gapxGP 4 with agents: 100
decpxADMM initialized with rho: 0.75, lip: 1.0, tol_abs: 1e-05, tol_rel: 0.001, rank: 0, world_size: 100
Rank 0 - Epoch 2/200 loss: 0.9993948936462402
Rank 0 - Epoch 10/200 loss: 0.7828435897827148
Rank 0 - Epoch 20/200 loss: 0.43888556957244873
Rank 0 - Epoch 30/200 loss: 0.03110622800886631
Rank 0 - Epoch 40/200 loss: -0.3985145688056946
Rank 0 - Epoch 50/200 loss: -0.8199291825294495
Rank 0 - Epoch 60/200 loss: -1.219675898551941
Rank 0 - Epoch 70/200 loss: -1.585925579071045
Rank 0 - Epoch 80/200 loss: -1.9004828929901123
Rank 0 - Epoch 90/200 loss: -2.1450369358062744
Rank 0 - Epoch 100/200 loss: -2.313026189804077
Rank 0 - Epoch 110/200 loss: -2.415928363800049
Rank 0 - Epoch 120/200 loss: -2.3724358081817627
Rank 0 - Epoch 130/200 loss: -2.3693110942840576
Rank 0 - Epoch 140/200 loss: -2.4094746112823486
Rank 0 - Epoch 150/200 loss: -2.2665343284606934
Run 4 failed, retrying...
Running gapxGP 5 with agents: 100
decpxADMM initialized with rho: 0.75, lip: 1.0, tol_abs: 1e-05, tol_rel: 0.001, rank: 0, world_size: 100
Rank 0 - Epoch 2/200 loss: 0.999500036239624
Rank 0 - Epoch 10/200 loss: 0.7819437384605408
Rank 0 - Epoch 20/200 loss: 0.4377101957798004
Rank 0 - Epoch 30/200 loss: 0.03358442336320877
Rank 0 - Epoch 40/200 loss: -0.39456260204315186
Rank 0 - Epoch 50/200 loss: -0.8143129348754883
Rank 0 - Epoch 60/200 loss: -1.2106387615203857
Rank 0 - Epoch 70/200 loss: -1.5723978281021118
Rank 0 - Epoch 80/200 loss: -1.8833215236663818
Rank 0 - Epoch 90/200 loss: -2.1256520748138428
Rank 0 - Epoch 100/200 loss: -2.292963981628418
Rank 0 - Epoch 110/200 loss: -2.4003939628601074
Rank 0 - Epoch 120/200 loss: -2.354104995727539
Rank 0 - Epoch 130/200 loss: -2.3300631046295166
Rank 0 - Epoch 140/200 loss: -2.4271318912506104
Rank 0 - Epoch 150/200 loss: -2.3903119564056396
Run 5 failed, retrying...
Running gapxGP 6 with agents: 100
decpxADMM initialized with rho: 0.75, lip: 1.0, tol_abs: 1e-05, tol_rel: 0.001, rank: 0, world_size: 100
Rank 0 - Epoch 2/200 loss: 1.0052688121795654
Rank 0 - Epoch 10/200 loss: 0.7927350401878357
Rank 0 - Epoch 20/200 loss: 0.44766685366630554
Rank 0 - Epoch 30/200 loss: 0.035817209631204605
Rank 0 - Epoch 40/200 loss: -0.3971497416496277
Rank 0 - Epoch 50/200 loss: -0.8197101354598999
Rank 0 - Epoch 60/200 loss: -1.2164262533187866
Rank 0 - Epoch 70/200 loss: -1.5796380043029785
Rank 0 - Epoch 80/200 loss: -1.891839623451233
Rank 0 - Epoch 90/200 loss: -2.1349031925201416
Rank 0 - Epoch 100/200 loss: -2.3028032779693604
Rank 0 - Epoch 110/200 loss: -2.409461498260498
Rank 0 - Epoch 120/200 loss: -2.4278435707092285
Rank 0 - Epoch 130/200 loss: -2.492213249206543
Rank 0 - Epoch 140/200 loss: -2.4862287044525146
Rank 0 - Epoch 150/200 loss: -2.5515804290771484
Run 6 failed, retrying...
Running gapxGP 7 with agents: 100
decpxADMM initialized with rho: 0.75, lip: 1.0, tol_abs: 1e-05, tol_rel: 0.001, rank: 0, world_size: 100
Rank 0 - Epoch 2/200 loss: 1.0000056028366089
Rank 0 - Epoch 10/200 loss: 0.783930778503418
Rank 0 - Epoch 20/200 loss: 0.44451814889907837
Rank 0 - Epoch 30/200 loss: 0.036620501428842545
Rank 0 - Epoch 40/200 loss: -0.3957725465297699
Rank 0 - Epoch 50/200 loss: -0.8210059404373169
Rank 0 - Epoch 60/200 loss: -1.2223212718963623
Rank 0 - Epoch 70/200 loss: -1.5889242887496948
Rank 0 - Epoch 80/200 loss: -1.9034874439239502
Rank 0 - Epoch 90/200 loss: -2.1474390029907227
Rank 0 - Epoch 100/200 loss: -2.315328359603882
Rank 0 - Epoch 110/200 loss: -2.4204790592193604
Rank 0 - Epoch 120/200 loss: -2.4654910564422607
Rank 0 - Epoch 130/200 loss: -2.4850008487701416
Rank 0 - Epoch 140/200 loss: -2.5421743392944336
Run 7 failed, retrying...
Running gapxGP 8 with agents: 100
decpxADMM initialized with rho: 0.75, lip: 1.0, tol_abs: 1e-05, tol_rel: 0.001, rank: 0, world_size: 100
Rank 0 - Epoch 2/200 loss: 0.9998888373374939
Rank 0 - Epoch 10/200 loss: 0.7819729447364807
Rank 0 - Epoch 20/200 loss: 0.436451256275177
Rank 0 - Epoch 30/200 loss: 0.028178829699754715
Rank 0 - Epoch 40/200 loss: -0.40379953384399414
Rank 0 - Epoch 50/200 loss: -0.827284574508667
Rank 0 - Epoch 60/200 loss: -1.2264180183410645
Rank 0 - Epoch 70/200 loss: -1.5912725925445557
Rank 0 - Epoch 80/200 loss: -1.9042150974273682
Rank 0 - Epoch 90/200 loss: -2.1465680599212646
Rank 0 - Epoch 100/200 loss: -2.313297748565674
Rank 0 - Epoch 110/200 loss: -2.4191856384277344
Rank 0 - Epoch 120/200 loss: -2.432760000228882
Rank 0 - Epoch 130/200 loss: -2.505582571029663
Rank 0 - Epoch 140/200 loss: -2.513930320739746
Rank 0 - Epoch 150/200 loss: -2.5244061946868896
Run 8 failed, retrying...
Running gapxGP 9 with agents: 100
decpxADMM initialized with rho: 0.75, lip: 1.0, tol_abs: 1e-05, tol_rel: 0.001, rank: 0, world_size: 100
Rank 0 - Epoch 2/200 loss: 1.0031228065490723
Rank 0 - Epoch 10/200 loss: 0.7885149717330933
Rank 0 - Epoch 20/200 loss: 0.4424346089363098
Rank 0 - Epoch 30/200 loss: 0.02894999273121357
Rank 0 - Epoch 40/200 loss: -0.3996221721172333
Rank 0 - Epoch 50/200 loss: -0.8187445998191833
Rank 0 - Epoch 60/200 loss: -1.2150806188583374
Rank 0 - Epoch 70/200 loss: -1.577509880065918
Rank 0 - Epoch 80/200 loss: -1.889244794845581
Rank 0 - Epoch 90/200 loss: -2.1320509910583496
Rank 0 - Epoch 100/200 loss: -2.2993531227111816
Rank 0 - Epoch 110/200 loss: -2.4056556224823
Rank 0 - Epoch 120/200 loss: -2.3173937797546387
Rank 0 - Epoch 130/200 loss: -2.3672680854797363
Rank 0 - Epoch 140/200 loss: -2.2331926822662354
Rank 0 - Epoch 150/200 loss: -2.3046765327453613
Run 9 failed, retrying...
Running gapxGP 10 with agents: 100
decpxADMM initialized with rho: 0.75, lip: 1.0, tol_abs: 1e-05, tol_rel: 0.001, rank: 0, world_size: 100
Rank 0 - Epoch 2/200 loss: 0.9982012510299683
Rank 0 - Epoch 10/200 loss: 0.7769972681999207
Rank 0 - Epoch 20/200 loss: 0.4340084493160248
Rank 0 - Epoch 30/200 loss: 0.03405524417757988
Rank 0 - Epoch 40/200 loss: -0.39706674218177795
Rank 0 - Epoch 50/200 loss: -0.8201619386672974
Rank 0 - Epoch 60/200 loss: -1.2196760177612305
Rank 0 - Epoch 70/200 loss: -1.5829942226409912
Rank 0 - Epoch 80/200 loss: -1.8954225778579712
Rank 0 - Epoch 90/200 loss: -2.1381757259368896
Rank 0 - Epoch 100/200 loss: -2.30540132522583
Rank 0 - Epoch 110/200 loss: -2.4111931324005127
Rank 0 - Epoch 120/200 loss: -2.459136962890625
Rank 0 - Epoch 130/200 loss: -2.469655752182007
Rank 0 - Epoch 140/200 loss: -2.527583122253418
Rank 0 - Epoch 150/200 loss: -2.538548469543457
Run 10 failed, retrying...
Running apxGP 1 with agents: 100
decpxADMM initialized with rho: 0.85, lip: 1.0, tol_abs: 1e-05, tol_rel: 0.001, rank: 0, world_size: 100
Rank 0 - Epoch 2/200 loss: 0.7676430344581604
Rank 0 - Epoch 10/200 loss: 0.500842273235321
Rank 0 - Epoch 20/200 loss: 0.08139979839324951
Rank 0 - Epoch 30/200 loss: -0.40261030197143555
Rank 0 - Epoch 40/200 loss: -0.9188417196273804
Rank 0 - Epoch 50/200 loss: -1.4427192211151123
Rank 0 - Epoch 60/200 loss: -1.9584128856658936
Rank 0 - Epoch 70/200 loss: -2.4205446243286133
Rank 0 - Epoch 80/200 loss: -2.7899391651153564
Rank 0 - Epoch 90/200 loss: -3.0436744689941406
Rank 0 - Epoch 100/200 loss: -3.1995201110839844
Rank 0 - Epoch 110/200 loss: -3.2914364337921143
Rank 0 - Epoch 120/200 loss: -3.3471758365631104
Rank 0 - Epoch 130/200 loss: -3.382741689682007
Rank 0 - Epoch 140/200 loss: -3.4073238372802734
Rank 0 - Epoch 150/200 loss: -3.4245736598968506
Rank 0 - Epoch 160/200 loss: -3.4377267360687256
Rank 0 - Epoch 170/200 loss: -3.4475598335266113
Rank 0 - Epoch 180/200 loss: -3.4555060863494873
Rank 0 - Epoch 190/200 loss: -3.461482286453247
Rank 0 - Epoch 200/200 loss: -3.4669008255004883
Training complete.
[92mRank 0 - Testing RMSE: 2.8110[0m
[92mRank: 0, Lengthscale: [[0.5881007 0.3692767]] [0m
[92mRank: 0, Outputscale: 1.394802451133728 [0m
[92mRank: 0, Noise: 0.00011015695054084063 [0m
Run 1 completed successfully
Running apxGP 2 with agents: 100
decpxADMM initialized with rho: 0.85, lip: 1.0, tol_abs: 1e-05, tol_rel: 0.001, rank: 0, world_size: 100
Rank 0 - Epoch 2/200 loss: 0.7676430344581604
Rank 0 - Epoch 10/200 loss: 0.500842273235321
Rank 0 - Epoch 20/200 loss: 0.08139979839324951
Rank 0 - Epoch 30/200 loss: -0.40261030197143555
Rank 0 - Epoch 40/200 loss: -0.9188417196273804
Rank 0 - Epoch 50/200 loss: -1.4427192211151123
Rank 0 - Epoch 60/200 loss: -1.9584128856658936
Rank 0 - Epoch 70/200 loss: -2.4205446243286133
Rank 0 - Epoch 80/200 loss: -2.7899391651153564
Rank 0 - Epoch 90/200 loss: -3.0436744689941406
Rank 0 - Epoch 100/200 loss: -3.1995201110839844
Rank 0 - Epoch 110/200 loss: -3.2914364337921143
Rank 0 - Epoch 120/200 loss: -3.3471758365631104
Rank 0 - Epoch 130/200 loss: -3.382741689682007
Rank 0 - Epoch 140/200 loss: -3.4073238372802734
Rank 0 - Epoch 150/200 loss: -3.4245736598968506
Rank 0 - Epoch 160/200 loss: -3.4377267360687256
Rank 0 - Epoch 170/200 loss: -3.4475598335266113
Rank 0 - Epoch 180/200 loss: -3.4555060863494873
Rank 0 - Epoch 190/200 loss: -3.461482286453247
Rank 0 - Epoch 200/200 loss: -3.4669008255004883
Training complete.
[92mRank 0 - Testing RMSE: 2.8110[0m
[92mRank: 0, Lengthscale: [[0.5881007 0.3692767]] [0m
[92mRank: 0, Outputscale: 1.394802451133728 [0m
[92mRank: 0, Noise: 0.00011015695054084063 [0m
Run 2 completed successfully
Running apxGP 3 with agents: 100
decpxADMM initialized with rho: 0.85, lip: 1.0, tol_abs: 1e-05, tol_rel: 0.001, rank: 0, world_size: 100
Rank 0 - Epoch 2/200 loss: 0.7676430344581604
Rank 0 - Epoch 10/200 loss: 0.500842273235321
Rank 0 - Epoch 20/200 loss: 0.08139979839324951
Rank 0 - Epoch 30/200 loss: -0.40261030197143555
Rank 0 - Epoch 40/200 loss: -0.9188417196273804
Rank 0 - Epoch 50/200 loss: -1.4427192211151123
Rank 0 - Epoch 60/200 loss: -1.9584128856658936
Rank 0 - Epoch 70/200 loss: -2.4205446243286133
Rank 0 - Epoch 80/200 loss: -2.7899391651153564
Rank 0 - Epoch 90/200 loss: -3.0436744689941406
Rank 0 - Epoch 100/200 loss: -3.1995201110839844
Rank 0 - Epoch 110/200 loss: -3.2914364337921143
Rank 0 - Epoch 120/200 loss: -3.3471758365631104
Rank 0 - Epoch 130/200 loss: -3.382741689682007
Rank 0 - Epoch 140/200 loss: -3.4073238372802734
Rank 0 - Epoch 150/200 loss: -3.4245736598968506
Rank 0 - Epoch 160/200 loss: -3.4377267360687256
Rank 0 - Epoch 170/200 loss: -3.4475598335266113
Rank 0 - Epoch 180/200 loss: -3.4555060863494873
Rank 0 - Epoch 190/200 loss: -3.461482286453247
Rank 0 - Epoch 200/200 loss: -3.4669008255004883
Training complete.
[92mRank 0 - Testing RMSE: 2.8110[0m
[92mRank: 0, Lengthscale: [[0.5881007 0.3692767]] [0m
[92mRank: 0, Outputscale: 1.394802451133728 [0m
[92mRank: 0, Noise: 0.00011015695054084063 [0m
Run 3 completed successfully
Running apxGP 4 with agents: 100
decpxADMM initialized with rho: 0.85, lip: 1.0, tol_abs: 1e-05, tol_rel: 0.001, rank: 0, world_size: 100
Rank 0 - Epoch 2/200 loss: 0.7676430344581604
Rank 0 - Epoch 10/200 loss: 0.500842273235321
Rank 0 - Epoch 20/200 loss: 0.08139979839324951
Rank 0 - Epoch 30/200 loss: -0.40261030197143555
Rank 0 - Epoch 40/200 loss: -0.9188417196273804
Rank 0 - Epoch 50/200 loss: -1.4427192211151123
Rank 0 - Epoch 60/200 loss: -1.9584128856658936
Rank 0 - Epoch 70/200 loss: -2.4205446243286133
Rank 0 - Epoch 80/200 loss: -2.7899391651153564
Rank 0 - Epoch 90/200 loss: -3.0436744689941406
Rank 0 - Epoch 100/200 loss: -3.1995201110839844
Rank 0 - Epoch 110/200 loss: -3.2914364337921143
Rank 0 - Epoch 120/200 loss: -3.3471758365631104
Rank 0 - Epoch 130/200 loss: -3.382741689682007
Rank 0 - Epoch 140/200 loss: -3.4073238372802734
Rank 0 - Epoch 150/200 loss: -3.4245736598968506
Rank 0 - Epoch 160/200 loss: -3.4377267360687256
Rank 0 - Epoch 170/200 loss: -3.4475598335266113
Rank 0 - Epoch 180/200 loss: -3.4555060863494873
Rank 0 - Epoch 190/200 loss: -3.461482286453247
Rank 0 - Epoch 200/200 loss: -3.4669008255004883
Training complete.
[92mRank 0 - Testing RMSE: 2.8110[0m
[92mRank: 0, Lengthscale: [[0.5881007 0.3692767]] [0m
[92mRank: 0, Outputscale: 1.394802451133728 [0m
[92mRank: 0, Noise: 0.00011015695054084063 [0m
Run 4 completed successfully
Running apxGP 5 with agents: 100
decpxADMM initialized with rho: 0.85, lip: 1.0, tol_abs: 1e-05, tol_rel: 0.001, rank: 0, world_size: 100
Rank 0 - Epoch 2/200 loss: 0.7676430344581604
Rank 0 - Epoch 10/200 loss: 0.500842273235321
Rank 0 - Epoch 20/200 loss: 0.08139979839324951
Rank 0 - Epoch 30/200 loss: -0.40261030197143555
Rank 0 - Epoch 40/200 loss: -0.9188417196273804
Rank 0 - Epoch 50/200 loss: -1.4427192211151123
Rank 0 - Epoch 60/200 loss: -1.9584128856658936
Rank 0 - Epoch 70/200 loss: -2.4205446243286133
Rank 0 - Epoch 80/200 loss: -2.7899391651153564
Rank 0 - Epoch 90/200 loss: -3.0436744689941406
Rank 0 - Epoch 100/200 loss: -3.1995201110839844
Rank 0 - Epoch 110/200 loss: -3.2914364337921143
Rank 0 - Epoch 120/200 loss: -3.3471758365631104
Rank 0 - Epoch 130/200 loss: -3.382741689682007
Rank 0 - Epoch 140/200 loss: -3.4073238372802734
Rank 0 - Epoch 150/200 loss: -3.4245736598968506
Rank 0 - Epoch 160/200 loss: -3.4377267360687256
Rank 0 - Epoch 170/200 loss: -3.4475598335266113
Rank 0 - Epoch 180/200 loss: -3.4555060863494873
Rank 0 - Epoch 190/200 loss: -3.461482286453247
Rank 0 - Epoch 200/200 loss: -3.4669008255004883
Training complete.
[92mRank 0 - Testing RMSE: 2.8110[0m
[92mRank: 0, Lengthscale: [[0.5881007 0.3692767]] [0m
[92mRank: 0, Outputscale: 1.394802451133728 [0m
[92mRank: 0, Noise: 0.00011015695054084063 [0m
Run 5 completed successfully
Running apxGP 6 with agents: 100
decpxADMM initialized with rho: 0.85, lip: 1.0, tol_abs: 1e-05, tol_rel: 0.001, rank: 0, world_size: 100
Rank 0 - Epoch 2/200 loss: 0.7676430344581604
Rank 0 - Epoch 10/200 loss: 0.500842273235321
Rank 0 - Epoch 20/200 loss: 0.08139979839324951
Rank 0 - Epoch 30/200 loss: -0.40261030197143555
Rank 0 - Epoch 40/200 loss: -0.9188417196273804
Rank 0 - Epoch 50/200 loss: -1.4427192211151123
Rank 0 - Epoch 60/200 loss: -1.9584128856658936
Rank 0 - Epoch 70/200 loss: -2.4205446243286133
Rank 0 - Epoch 80/200 loss: -2.7899391651153564
Rank 0 - Epoch 90/200 loss: -3.0436744689941406
Rank 0 - Epoch 100/200 loss: -3.1995201110839844
Rank 0 - Epoch 110/200 loss: -3.2914364337921143
Rank 0 - Epoch 120/200 loss: -3.3471758365631104
Rank 0 - Epoch 130/200 loss: -3.382741689682007
Rank 0 - Epoch 140/200 loss: -3.4073238372802734
Rank 0 - Epoch 150/200 loss: -3.4245736598968506
Rank 0 - Epoch 160/200 loss: -3.4377267360687256
Rank 0 - Epoch 170/200 loss: -3.4475598335266113
Rank 0 - Epoch 180/200 loss: -3.4555060863494873
Rank 0 - Epoch 190/200 loss: -3.461482286453247
Rank 0 - Epoch 200/200 loss: -3.4669008255004883
Training complete.
[92mRank 0 - Testing RMSE: 2.8110[0m
[92mRank: 0, Lengthscale: [[0.5881007 0.3692767]] [0m
[92mRank: 0, Outputscale: 1.394802451133728 [0m
[92mRank: 0, Noise: 0.00011015695054084063 [0m
Run 6 completed successfully
Running apxGP 7 with agents: 100
decpxADMM initialized with rho: 0.85, lip: 1.0, tol_abs: 1e-05, tol_rel: 0.001, rank: 0, world_size: 100
Rank 0 - Epoch 2/200 loss: 0.7676430344581604
Rank 0 - Epoch 10/200 loss: 0.500842273235321
Rank 0 - Epoch 20/200 loss: 0.08139979839324951
Rank 0 - Epoch 30/200 loss: -0.40261030197143555
Rank 0 - Epoch 40/200 loss: -0.9188417196273804
Rank 0 - Epoch 50/200 loss: -1.4427192211151123
Rank 0 - Epoch 60/200 loss: -1.9584128856658936
Rank 0 - Epoch 70/200 loss: -2.4205446243286133
Rank 0 - Epoch 80/200 loss: -2.7899391651153564
Rank 0 - Epoch 90/200 loss: -3.0436744689941406
Rank 0 - Epoch 100/200 loss: -3.1995201110839844
Rank 0 - Epoch 110/200 loss: -3.2914364337921143
Rank 0 - Epoch 120/200 loss: -3.3471758365631104
Rank 0 - Epoch 130/200 loss: -3.382741689682007
Rank 0 - Epoch 140/200 loss: -3.4073238372802734
Rank 0 - Epoch 150/200 loss: -3.4245736598968506
Rank 0 - Epoch 160/200 loss: -3.4377267360687256
Rank 0 - Epoch 170/200 loss: -3.4475598335266113
Rank 0 - Epoch 180/200 loss: -3.4555060863494873
Rank 0 - Epoch 190/200 loss: -3.461482286453247
Rank 0 - Epoch 200/200 loss: -3.4669008255004883
Training complete.
[92mRank 0 - Testing RMSE: 2.8110[0m
[92mRank: 0, Lengthscale: [[0.5881007 0.3692767]] [0m
[92mRank: 0, Outputscale: 1.394802451133728 [0m
[92mRank: 0, Noise: 0.00011015695054084063 [0m
Run 7 completed successfully
Running apxGP 8 with agents: 100
decpxADMM initialized with rho: 0.85, lip: 1.0, tol_abs: 1e-05, tol_rel: 0.001, rank: 0, world_size: 100
Rank 0 - Epoch 2/200 loss: 0.7676430344581604
Rank 0 - Epoch 10/200 loss: 0.500842273235321
Rank 0 - Epoch 20/200 loss: 0.08139979839324951
Rank 0 - Epoch 30/200 loss: -0.40261030197143555
Rank 0 - Epoch 40/200 loss: -0.9188417196273804
Rank 0 - Epoch 50/200 loss: -1.4427192211151123
Rank 0 - Epoch 60/200 loss: -1.9584128856658936
Rank 0 - Epoch 70/200 loss: -2.4205446243286133
Rank 0 - Epoch 80/200 loss: -2.7899391651153564
Rank 0 - Epoch 90/200 loss: -3.0436744689941406
Rank 0 - Epoch 100/200 loss: -3.1995201110839844
Rank 0 - Epoch 110/200 loss: -3.2914364337921143
Rank 0 - Epoch 120/200 loss: -3.3471758365631104
Rank 0 - Epoch 130/200 loss: -3.382741689682007
Rank 0 - Epoch 140/200 loss: -3.4073238372802734
Rank 0 - Epoch 150/200 loss: -3.4245736598968506
Rank 0 - Epoch 160/200 loss: -3.4377267360687256
Rank 0 - Epoch 170/200 loss: -3.4475598335266113
Rank 0 - Epoch 180/200 loss: -3.4555060863494873
Rank 0 - Epoch 190/200 loss: -3.461482286453247
Rank 0 - Epoch 200/200 loss: -3.4669008255004883
Training complete.
[92mRank 0 - Testing RMSE: 2.8110[0m
[92mRank: 0, Lengthscale: [[0.5881007 0.3692767]] [0m
[92mRank: 0, Outputscale: 1.394802451133728 [0m
[92mRank: 0, Noise: 0.00011015695054084063 [0m
Run 8 completed successfully
Running apxGP 9 with agents: 100
decpxADMM initialized with rho: 0.85, lip: 1.0, tol_abs: 1e-05, tol_rel: 0.001, rank: 0, world_size: 100
Rank 0 - Epoch 2/200 loss: 0.7676430344581604
Rank 0 - Epoch 10/200 loss: 0.500842273235321
Rank 0 - Epoch 20/200 loss: 0.08139979839324951
Rank 0 - Epoch 30/200 loss: -0.40261030197143555
Rank 0 - Epoch 40/200 loss: -0.9188417196273804
Rank 0 - Epoch 50/200 loss: -1.4427192211151123
Rank 0 - Epoch 60/200 loss: -1.9584128856658936
Rank 0 - Epoch 70/200 loss: -2.4205446243286133
Rank 0 - Epoch 80/200 loss: -2.7899391651153564
Rank 0 - Epoch 90/200 loss: -3.0436744689941406
Rank 0 - Epoch 100/200 loss: -3.1995201110839844
Rank 0 - Epoch 110/200 loss: -3.2914364337921143
Rank 0 - Epoch 120/200 loss: -3.3471758365631104
Rank 0 - Epoch 130/200 loss: -3.382741689682007
Rank 0 - Epoch 140/200 loss: -3.4073238372802734
Rank 0 - Epoch 150/200 loss: -3.4245736598968506
Rank 0 - Epoch 160/200 loss: -3.4377267360687256
Rank 0 - Epoch 170/200 loss: -3.4475598335266113
Rank 0 - Epoch 180/200 loss: -3.4555060863494873
Rank 0 - Epoch 190/200 loss: -3.461482286453247
Rank 0 - Epoch 200/200 loss: -3.4669008255004883
Training complete.
[92mRank 0 - Testing RMSE: 2.8110[0m
[92mRank: 0, Lengthscale: [[0.5881007 0.3692767]] [0m
[92mRank: 0, Outputscale: 1.394802451133728 [0m
[92mRank: 0, Noise: 0.00011015695054084063 [0m
Run 9 completed successfully
Running apxGP 10 with agents: 100
decpxADMM initialized with rho: 0.85, lip: 1.0, tol_abs: 1e-05, tol_rel: 0.001, rank: 0, world_size: 100
Rank 0 - Epoch 2/200 loss: 0.7676430344581604
Rank 0 - Epoch 10/200 loss: 0.500842273235321
Rank 0 - Epoch 20/200 loss: 0.08139979839324951
Rank 0 - Epoch 30/200 loss: -0.40261030197143555
Rank 0 - Epoch 40/200 loss: -0.9188417196273804
Rank 0 - Epoch 50/200 loss: -1.4427192211151123
Rank 0 - Epoch 60/200 loss: -1.9584128856658936
Rank 0 - Epoch 70/200 loss: -2.4205446243286133
Rank 0 - Epoch 80/200 loss: -2.7899391651153564
Rank 0 - Epoch 90/200 loss: -3.0436744689941406
Rank 0 - Epoch 100/200 loss: -3.1995201110839844
Rank 0 - Epoch 110/200 loss: -3.2914364337921143
Rank 0 - Epoch 120/200 loss: -3.3471758365631104
Rank 0 - Epoch 130/200 loss: -3.382741689682007
Rank 0 - Epoch 140/200 loss: -3.4073238372802734
Rank 0 - Epoch 150/200 loss: -3.4245736598968506
Rank 0 - Epoch 160/200 loss: -3.4377267360687256
Rank 0 - Epoch 170/200 loss: -3.4475598335266113
Rank 0 - Epoch 180/200 loss: -3.4555060863494873
Rank 0 - Epoch 190/200 loss: -3.461482286453247
Rank 0 - Epoch 200/200 loss: -3.4669008255004883
Training complete.
[92mRank 0 - Testing RMSE: 2.8110[0m
[92mRank: 0, Lengthscale: [[0.5881007 0.3692767]] [0m
[92mRank: 0, Outputscale: 1.394802451133728 [0m
[92mRank: 0, Noise: 0.00011015695054084063 [0m
Run 10 completed successfully
Running cGP 1 with agents: 100
decADMM initialized with rho: 0.85, max_iter: 5, lr: 0.0001, rank: 0, world_size: 100
Rank 0 - Epoch 2/200 loss: 0.8246126770973206
Rank 0 - Epoch 10/200 loss: 0.8192302584648132
Rank 0 - Epoch 20/200 loss: 0.8124861717224121
Rank 0 - Epoch 30/200 loss: 0.8057249188423157
Rank 0 - Epoch 40/200 loss: 0.7989470958709717
Rank 0 - Epoch 50/200 loss: 0.7921537160873413
Rank 0 - Epoch 60/200 loss: 0.7853453755378723
Rank 0 - Epoch 70/200 loss: 0.7785232067108154
Rank 0 - Epoch 80/200 loss: 0.7716879844665527
Rank 0 - Epoch 90/200 loss: 0.7648407816886902
Rank 0 - Epoch 100/200 loss: 0.7579826712608337
Rank 0 - Epoch 110/200 loss: 0.7511146068572998
Rank 0 - Epoch 120/200 loss: 0.7442378401756287
Rank 0 - Epoch 130/200 loss: 0.7373536229133606
Rank 0 - Epoch 140/200 loss: 0.7304630279541016
Rank 0 - Epoch 150/200 loss: 0.7235676050186157
Rank 0 - Epoch 160/200 loss: 0.7166687846183777
Rank 0 - Epoch 170/200 loss: 0.7097679376602173
Rank 0 - Epoch 180/200 loss: 0.7028667330741882
Rank 0 - Epoch 190/200 loss: 0.6959666609764099
Rank 0 - Epoch 200/200 loss: 0.6890692710876465
Training complete.
[92mRank 0 - Testing RMSE: 3.7387[0m
[92mRank: 0, Lengthscale: [[0.537307  0.5353914]] [0m
[92mRank: 0, Outputscale: 0.5393332839012146 [0m
[92mRank: 0, Noise: 0.5226958990097046 [0m
Run 1 completed successfully
Running cGP 2 with agents: 100
decADMM initialized with rho: 0.85, max_iter: 5, lr: 0.0001, rank: 0, world_size: 100
Rank 0 - Epoch 2/200 loss: 0.8246126770973206
Rank 0 - Epoch 10/200 loss: 0.8192302584648132
Rank 0 - Epoch 20/200 loss: 0.8124861717224121
Rank 0 - Epoch 30/200 loss: 0.8057249188423157
Rank 0 - Epoch 40/200 loss: 0.7989470958709717
Rank 0 - Epoch 50/200 loss: 0.7921537160873413
Rank 0 - Epoch 60/200 loss: 0.7853453755378723
Rank 0 - Epoch 70/200 loss: 0.7785232067108154
Rank 0 - Epoch 80/200 loss: 0.7716879844665527
Rank 0 - Epoch 90/200 loss: 0.7648407816886902
Rank 0 - Epoch 100/200 loss: 0.7579826712608337
Rank 0 - Epoch 110/200 loss: 0.7511146068572998
Rank 0 - Epoch 120/200 loss: 0.7442378401756287
Rank 0 - Epoch 130/200 loss: 0.7373536229133606
Rank 0 - Epoch 140/200 loss: 0.7304630279541016
Rank 0 - Epoch 150/200 loss: 0.7235676050186157
Rank 0 - Epoch 160/200 loss: 0.7166687846183777
Rank 0 - Epoch 170/200 loss: 0.7097679376602173
Rank 0 - Epoch 180/200 loss: 0.7028667330741882
Rank 0 - Epoch 190/200 loss: 0.6959666609764099
Rank 0 - Epoch 200/200 loss: 0.6890692710876465
Training complete.
[92mRank 0 - Testing RMSE: 3.7387[0m
[92mRank: 0, Lengthscale: [[0.537307  0.5353914]] [0m
[92mRank: 0, Outputscale: 0.5393332839012146 [0m
[92mRank: 0, Noise: 0.5226958990097046 [0m
Run 2 completed successfully
Running cGP 3 with agents: 100
decADMM initialized with rho: 0.85, max_iter: 5, lr: 0.0001, rank: 0, world_size: 100
Rank 0 - Epoch 2/200 loss: 0.8246126770973206
Rank 0 - Epoch 10/200 loss: 0.8192302584648132
Rank 0 - Epoch 20/200 loss: 0.8124861717224121
Rank 0 - Epoch 30/200 loss: 0.8057249188423157
Rank 0 - Epoch 40/200 loss: 0.7989470958709717
Rank 0 - Epoch 50/200 loss: 0.7921537160873413
Rank 0 - Epoch 60/200 loss: 0.7853453755378723
Rank 0 - Epoch 70/200 loss: 0.7785232067108154
Rank 0 - Epoch 80/200 loss: 0.7716879844665527
Rank 0 - Epoch 90/200 loss: 0.7648407816886902
Rank 0 - Epoch 100/200 loss: 0.7579826712608337
Rank 0 - Epoch 110/200 loss: 0.7511146068572998
Rank 0 - Epoch 120/200 loss: 0.7442378401756287
Rank 0 - Epoch 130/200 loss: 0.7373536229133606
Rank 0 - Epoch 140/200 loss: 0.7304630279541016
Rank 0 - Epoch 150/200 loss: 0.7235676050186157
Rank 0 - Epoch 160/200 loss: 0.7166687846183777
Rank 0 - Epoch 170/200 loss: 0.7097679376602173
Rank 0 - Epoch 180/200 loss: 0.7028667330741882
Rank 0 - Epoch 190/200 loss: 0.6959666609764099
Rank 0 - Epoch 200/200 loss: 0.6890692710876465
Training complete.
[92mRank 0 - Testing RMSE: 3.7387[0m
[92mRank: 0, Lengthscale: [[0.537307  0.5353914]] [0m
[92mRank: 0, Outputscale: 0.5393332839012146 [0m
[92mRank: 0, Noise: 0.5226958990097046 [0m
Run 3 completed successfully
Running cGP 4 with agents: 100
decADMM initialized with rho: 0.85, max_iter: 5, lr: 0.0001, rank: 0, world_size: 100
Rank 0 - Epoch 2/200 loss: 0.8246126770973206
Rank 0 - Epoch 10/200 loss: 0.8192302584648132
Rank 0 - Epoch 20/200 loss: 0.8124861717224121
Rank 0 - Epoch 30/200 loss: 0.8057249188423157
Rank 0 - Epoch 40/200 loss: 0.7989470958709717
Rank 0 - Epoch 50/200 loss: 0.7921537160873413
Rank 0 - Epoch 60/200 loss: 0.7853453755378723
Rank 0 - Epoch 70/200 loss: 0.7785232067108154
Rank 0 - Epoch 80/200 loss: 0.7716879844665527
Rank 0 - Epoch 90/200 loss: 0.7648407816886902
Rank 0 - Epoch 100/200 loss: 0.7579826712608337
Rank 0 - Epoch 110/200 loss: 0.7511146068572998
Rank 0 - Epoch 120/200 loss: 0.7442378401756287
Rank 0 - Epoch 130/200 loss: 0.7373536229133606
Rank 0 - Epoch 140/200 loss: 0.7304630279541016
Rank 0 - Epoch 150/200 loss: 0.7235676050186157
Rank 0 - Epoch 160/200 loss: 0.7166687846183777
Rank 0 - Epoch 170/200 loss: 0.7097679376602173
Rank 0 - Epoch 180/200 loss: 0.7028667330741882
Rank 0 - Epoch 190/200 loss: 0.6959666609764099
Rank 0 - Epoch 200/200 loss: 0.6890692710876465
Training complete.
[92mRank 0 - Testing RMSE: 3.7387[0m
[92mRank: 0, Lengthscale: [[0.537307  0.5353914]] [0m
[92mRank: 0, Outputscale: 0.5393332839012146 [0m
[92mRank: 0, Noise: 0.5226958990097046 [0m
Run 4 completed successfully
Running cGP 5 with agents: 100
decADMM initialized with rho: 0.85, max_iter: 5, lr: 0.0001, rank: 0, world_size: 100
Rank 0 - Epoch 2/200 loss: 0.8246126770973206
Rank 0 - Epoch 10/200 loss: 0.8192302584648132
Rank 0 - Epoch 20/200 loss: 0.8124861717224121
Rank 0 - Epoch 30/200 loss: 0.8057249188423157
Rank 0 - Epoch 40/200 loss: 0.7989470958709717
Rank 0 - Epoch 50/200 loss: 0.7921537160873413
Rank 0 - Epoch 60/200 loss: 0.7853453755378723
Rank 0 - Epoch 70/200 loss: 0.7785232067108154
Rank 0 - Epoch 80/200 loss: 0.7716879844665527
Rank 0 - Epoch 90/200 loss: 0.7648407816886902
Rank 0 - Epoch 100/200 loss: 0.7579826712608337
Rank 0 - Epoch 110/200 loss: 0.7511146068572998
Rank 0 - Epoch 120/200 loss: 0.7442378401756287
Rank 0 - Epoch 130/200 loss: 0.7373536229133606
Rank 0 - Epoch 140/200 loss: 0.7304630279541016
Rank 0 - Epoch 150/200 loss: 0.7235676050186157
Rank 0 - Epoch 160/200 loss: 0.7166687846183777
Rank 0 - Epoch 170/200 loss: 0.7097679376602173
Rank 0 - Epoch 180/200 loss: 0.7028667330741882
Rank 0 - Epoch 190/200 loss: 0.6959666609764099
Rank 0 - Epoch 200/200 loss: 0.6890692710876465
Training complete.
[92mRank 0 - Testing RMSE: 3.7387[0m
[92mRank: 0, Lengthscale: [[0.537307  0.5353914]] [0m
[92mRank: 0, Outputscale: 0.5393332839012146 [0m
[92mRank: 0, Noise: 0.5226958990097046 [0m
Run 5 completed successfully
Running cGP 6 with agents: 100
decADMM initialized with rho: 0.85, max_iter: 5, lr: 0.0001, rank: 0, world_size: 100
Rank 0 - Epoch 2/200 loss: 0.8246126770973206
Rank 0 - Epoch 10/200 loss: 0.8192302584648132
Rank 0 - Epoch 20/200 loss: 0.8124861717224121
Rank 0 - Epoch 30/200 loss: 0.8057249188423157
Rank 0 - Epoch 40/200 loss: 0.7989470958709717
Rank 0 - Epoch 50/200 loss: 0.7921537160873413
Rank 0 - Epoch 60/200 loss: 0.7853453755378723
Rank 0 - Epoch 70/200 loss: 0.7785232067108154
Rank 0 - Epoch 80/200 loss: 0.7716879844665527
Rank 0 - Epoch 90/200 loss: 0.7648407816886902
Rank 0 - Epoch 100/200 loss: 0.7579826712608337
Rank 0 - Epoch 110/200 loss: 0.7511146068572998
Rank 0 - Epoch 120/200 loss: 0.7442378401756287
Rank 0 - Epoch 130/200 loss: 0.7373536229133606
Rank 0 - Epoch 140/200 loss: 0.7304630279541016
Rank 0 - Epoch 150/200 loss: 0.7235676050186157
Rank 0 - Epoch 160/200 loss: 0.7166687846183777
Rank 0 - Epoch 170/200 loss: 0.7097679376602173
Rank 0 - Epoch 180/200 loss: 0.7028667330741882
Rank 0 - Epoch 190/200 loss: 0.6959666609764099
Rank 0 - Epoch 200/200 loss: 0.6890692710876465
Training complete.
[92mRank 0 - Testing RMSE: 3.7387[0m
[92mRank: 0, Lengthscale: [[0.537307  0.5353914]] [0m
[92mRank: 0, Outputscale: 0.5393332839012146 [0m
[92mRank: 0, Noise: 0.5226958990097046 [0m
Run 6 completed successfully
Running cGP 7 with agents: 100
decADMM initialized with rho: 0.85, max_iter: 5, lr: 0.0001, rank: 0, world_size: 100
Rank 0 - Epoch 2/200 loss: 0.8246126770973206
Rank 0 - Epoch 10/200 loss: 0.8192302584648132
Rank 0 - Epoch 20/200 loss: 0.8124861717224121
Rank 0 - Epoch 30/200 loss: 0.8057249188423157
Rank 0 - Epoch 40/200 loss: 0.7989470958709717
Rank 0 - Epoch 50/200 loss: 0.7921537160873413
Rank 0 - Epoch 60/200 loss: 0.7853453755378723
Rank 0 - Epoch 70/200 loss: 0.7785232067108154
Rank 0 - Epoch 80/200 loss: 0.7716879844665527
Rank 0 - Epoch 90/200 loss: 0.7648407816886902
Rank 0 - Epoch 100/200 loss: 0.7579826712608337
Rank 0 - Epoch 110/200 loss: 0.7511146068572998
Rank 0 - Epoch 120/200 loss: 0.7442378401756287
Rank 0 - Epoch 130/200 loss: 0.7373536229133606
Rank 0 - Epoch 140/200 loss: 0.7304630279541016
Rank 0 - Epoch 150/200 loss: 0.7235676050186157
Rank 0 - Epoch 160/200 loss: 0.7166687846183777
Rank 0 - Epoch 170/200 loss: 0.7097679376602173
Rank 0 - Epoch 180/200 loss: 0.7028667330741882
Rank 0 - Epoch 190/200 loss: 0.6959666609764099
Rank 0 - Epoch 200/200 loss: 0.6890692710876465
Training complete.
[92mRank 0 - Testing RMSE: 3.7387[0m
[92mRank: 0, Lengthscale: [[0.537307  0.5353914]] [0m
[92mRank: 0, Outputscale: 0.5393332839012146 [0m
[92mRank: 0, Noise: 0.5226958990097046 [0m
Run 7 completed successfully
Running cGP 8 with agents: 100
decADMM initialized with rho: 0.85, max_iter: 5, lr: 0.0001, rank: 0, world_size: 100
Rank 0 - Epoch 2/200 loss: 0.8246126770973206
Rank 0 - Epoch 10/200 loss: 0.8192302584648132
Rank 0 - Epoch 20/200 loss: 0.8124861717224121
Rank 0 - Epoch 30/200 loss: 0.8057249188423157
Rank 0 - Epoch 40/200 loss: 0.7989470958709717
Rank 0 - Epoch 50/200 loss: 0.7921537160873413
Rank 0 - Epoch 60/200 loss: 0.7853453755378723
Rank 0 - Epoch 70/200 loss: 0.7785232067108154
Rank 0 - Epoch 80/200 loss: 0.7716879844665527
Rank 0 - Epoch 90/200 loss: 0.7648407816886902
Rank 0 - Epoch 100/200 loss: 0.7579826712608337
Rank 0 - Epoch 110/200 loss: 0.7511146068572998
Rank 0 - Epoch 120/200 loss: 0.7442378401756287
Rank 0 - Epoch 130/200 loss: 0.7373536229133606
Rank 0 - Epoch 140/200 loss: 0.7304630279541016
Rank 0 - Epoch 150/200 loss: 0.7235676050186157
Rank 0 - Epoch 160/200 loss: 0.7166687846183777
Rank 0 - Epoch 170/200 loss: 0.7097679376602173
Rank 0 - Epoch 180/200 loss: 0.7028667330741882
Rank 0 - Epoch 190/200 loss: 0.6959666609764099
Rank 0 - Epoch 200/200 loss: 0.6890692710876465
Training complete.
[92mRank 0 - Testing RMSE: 3.7387[0m
[92mRank: 0, Lengthscale: [[0.537307  0.5353914]] [0m
[92mRank: 0, Outputscale: 0.5393332839012146 [0m
[92mRank: 0, Noise: 0.5226958990097046 [0m
Run 8 completed successfully
Running cGP 9 with agents: 100
decADMM initialized with rho: 0.85, max_iter: 5, lr: 0.0001, rank: 0, world_size: 100
Rank 0 - Epoch 2/200 loss: 0.8246126770973206
Rank 0 - Epoch 10/200 loss: 0.8192302584648132
Rank 0 - Epoch 20/200 loss: 0.8124861717224121
Rank 0 - Epoch 30/200 loss: 0.8057249188423157
Rank 0 - Epoch 40/200 loss: 0.7989470958709717
Rank 0 - Epoch 50/200 loss: 0.7921537160873413
Rank 0 - Epoch 60/200 loss: 0.7853453755378723
Rank 0 - Epoch 70/200 loss: 0.7785232067108154
Rank 0 - Epoch 80/200 loss: 0.7716879844665527
Rank 0 - Epoch 90/200 loss: 0.7648407816886902
Rank 0 - Epoch 100/200 loss: 0.7579826712608337
Rank 0 - Epoch 110/200 loss: 0.7511146068572998
Rank 0 - Epoch 120/200 loss: 0.7442378401756287
Rank 0 - Epoch 130/200 loss: 0.7373536229133606
Rank 0 - Epoch 140/200 loss: 0.7304630279541016
Rank 0 - Epoch 150/200 loss: 0.7235676050186157
Rank 0 - Epoch 160/200 loss: 0.7166687846183777
Rank 0 - Epoch 170/200 loss: 0.7097679376602173
Rank 0 - Epoch 180/200 loss: 0.7028667330741882
Rank 0 - Epoch 190/200 loss: 0.6959666609764099
Rank 0 - Epoch 200/200 loss: 0.6890692710876465
Training complete.
[92mRank 0 - Testing RMSE: 3.7387[0m
[92mRank: 0, Lengthscale: [[0.537307  0.5353914]] [0m
[92mRank: 0, Outputscale: 0.5393332839012146 [0m
[92mRank: 0, Noise: 0.5226958990097046 [0m
Run 9 completed successfully
Running cGP 10 with agents: 100
decADMM initialized with rho: 0.85, max_iter: 5, lr: 0.0001, rank: 0, world_size: 100
Rank 0 - Epoch 2/200 loss: 0.8246126770973206
Rank 0 - Epoch 10/200 loss: 0.8192302584648132
Rank 0 - Epoch 20/200 loss: 0.8124861717224121
Rank 0 - Epoch 30/200 loss: 0.8057249188423157
Rank 0 - Epoch 40/200 loss: 0.7989470958709717
Rank 0 - Epoch 50/200 loss: 0.7921537160873413
Rank 0 - Epoch 60/200 loss: 0.7853453755378723
Rank 0 - Epoch 70/200 loss: 0.7785232067108154
Rank 0 - Epoch 80/200 loss: 0.7716879844665527
Rank 0 - Epoch 90/200 loss: 0.7648407816886902
Rank 0 - Epoch 100/200 loss: 0.7579826712608337
Rank 0 - Epoch 110/200 loss: 0.7511146068572998
Rank 0 - Epoch 120/200 loss: 0.7442378401756287
Rank 0 - Epoch 130/200 loss: 0.7373536229133606
Rank 0 - Epoch 140/200 loss: 0.7304630279541016
Rank 0 - Epoch 150/200 loss: 0.7235676050186157
Rank 0 - Epoch 160/200 loss: 0.7166687846183777
Rank 0 - Epoch 170/200 loss: 0.7097679376602173
Rank 0 - Epoch 180/200 loss: 0.7028667330741882
Rank 0 - Epoch 190/200 loss: 0.6959666609764099
Rank 0 - Epoch 200/200 loss: 0.6890692710876465
Training complete.
[92mRank 0 - Testing RMSE: 3.7387[0m
[92mRank: 0, Lengthscale: [[0.537307  0.5353914]] [0m
[92mRank: 0, Outputscale: 0.5393332839012146 [0m
[92mRank: 0, Noise: 0.5226958990097046 [0m
Run 10 completed successfully
Running pxpGP 1 with agents: 121
[92mRank 0 - sparse dataset size is: 4, local dataset: torch.Size([289, 2]), [0m
[92mRank 0 - Training local sparse GP model with 289 samples[0m
Epoch 1/200 - Loss: 3.547
Epoch 11/200 - Loss: 0.863
Epoch 21/200 - Loss: 0.353
Converged at epoch 27 with loss -0.034
[92mRank 0 - Lengthscale: [[0.5703585 0.3848182]] [0m
[92mRank 0 - Outputscale: 1.4903861284255981 [0m
[92mRank 0 - Noise: 0.10372146964073181 [0m
Rank 0 - Augmented dataset size: 773
Rank 0: After warm start model parameters:
Rank: 0, Lengthscale: [[0.5703585 0.3848182]]
Rank: 0, Outputscale: 1.4903862476348877
Rank: 0, Noise: 0.10372146964073181
decpxADMM initialized with rho: 0.85, lip: 1.0, tol_abs: 1e-05, tol_rel: 0.001, rank: 0, world_size: 121
[92mRank 0 - Training global model with dec-pxADMM optimizer[0m
rank 0, epoch 9, loss: 0.7342393398284912, rho: 0.2125, lip: 1.0000
rank 0, epoch 19, loss: 0.7085690498352051, rho: 0.1062, lip: 1.0000
rank 0, epoch 29, loss: 0.7086343765258789, rho: 0.0531, lip: 1.0000
rank 0, epoch 39, loss: 0.7136034369468689, rho: 0.0531, lip: 1.0000
rank 0, epoch 49, loss: 0.711109459400177, rho: 0.0531, lip: 1.0000
rank 0, epoch 59, loss: 0.7046774625778198, rho: 0.0133, lip: 1.0000
rank 0, epoch 69, loss: 0.7022311687469482, rho: 0.0133, lip: 1.0000
rank 0, epoch 79, loss: 0.7014605402946472, rho: 0.0133, lip: 1.0000
rank 0, epoch 89, loss: 0.7011423707008362, rho: 0.0133, lip: 1.0000
rank 0, epoch 99, loss: 0.7010554075241089, rho: 0.0133, lip: 1.0000
rank 0, epoch 109, loss: 0.7010560631752014, rho: 0.0133, lip: 1.0000
rank 0, epoch 119, loss: 0.7010079026222229, rho: 0.0133, lip: 1.0000
rank 0, epoch 129, loss: 0.7008171081542969, rho: 0.0133, lip: 1.0000
rank 0, epoch 139, loss: 0.7004331946372986, rho: 0.0133, lip: 1.0000
rank 0, epoch 149, loss: 0.7000442147254944, rho: 0.0066, lip: 1.0000
rank 0, epoch 159, loss: 0.6997991800308228, rho: 0.0066, lip: 1.0000
rank 0, epoch 169, loss: 0.6996833682060242, rho: 0.0066, lip: 1.0000
rank 0, epoch 179, loss: 0.6997047662734985, rho: 0.0033, lip: 1.0000
Rank 0 - Training time: 267.12 seconds
[92mRank 0 - Testing RMSE: 0.2787[0m
[92mRank: 0, Lengthscale: [[0.59778094 0.34843457]] [0m
[92mRank: 0, Outputscale: 2.472254514694214 [0m
[92mRank: 0, Noise: 0.18508456647396088 [0m
Run 1 completed successfully
Running pxpGP 2 with agents: 121
[92mRank 0 - sparse dataset size is: 4, local dataset: torch.Size([289, 2]), [0m
[92mRank 0 - Training local sparse GP model with 289 samples[0m
Epoch 1/200 - Loss: 3.055
Epoch 11/200 - Loss: 0.879
Epoch 21/200 - Loss: 0.401
Converged at epoch 27 with loss -0.053
[92mRank 0 - Lengthscale: [[0.79999244 0.31438288]] [0m
[92mRank 0 - Outputscale: 1.7236049175262451 [0m
[92mRank 0 - Noise: 0.11982265114784241 [0m
Rank 0 - Augmented dataset size: 773
Rank 0: After warm start model parameters:
Rank: 0, Lengthscale: [[0.79999244 0.31438285]]
Rank: 0, Outputscale: 1.7236049175262451
Rank: 0, Noise: 0.11982265114784241
decpxADMM initialized with rho: 0.85, lip: 1.0, tol_abs: 1e-05, tol_rel: 0.001, rank: 0, world_size: 121
[92mRank 0 - Training global model with dec-pxADMM optimizer[0m
rank 0, epoch 9, loss: 0.7518033981323242, rho: 0.4250, lip: 1.0000
rank 0, epoch 19, loss: 0.7280616164207458, rho: 0.2125, lip: 1.0000
rank 0, epoch 29, loss: 0.7174100875854492, rho: 0.1062, lip: 1.0000
rank 0, epoch 39, loss: 0.7226810455322266, rho: 0.0531, lip: 1.0000
rank 0, epoch 49, loss: 0.7216767072677612, rho: 0.0531, lip: 1.0000
rank 0, epoch 59, loss: 0.71909499168396, rho: 0.0266, lip: 1.0000
rank 0, epoch 69, loss: 0.7168253660202026, rho: 0.0266, lip: 1.0000
rank 0, epoch 79, loss: 0.7155243158340454, rho: 0.0266, lip: 1.0000
rank 0, epoch 89, loss: 0.7148676514625549, rho: 0.0133, lip: 1.0000
rank 0, epoch 99, loss: 0.7146329283714294, rho: 0.0133, lip: 1.0000
rank 0, epoch 109, loss: 0.7148026823997498, rho: 0.0066, lip: 1.0000
rank 0, epoch 119, loss: 0.7150347232818604, rho: 0.0066, lip: 1.0000
rank 0, epoch 129, loss: 0.7147827744483948, rho: 0.0066, lip: 1.0000
rank 0, epoch 139, loss: 0.7141945362091064, rho: 0.0066, lip: 1.0000
rank 0, epoch 149, loss: 0.7137566208839417, rho: 0.0066, lip: 1.0000
rank 0, epoch 159, loss: 0.7137079238891602, rho: 0.0066, lip: 1.0000
rank 0, epoch 169, loss: 0.7140709161758423, rho: 0.0066, lip: 1.0000
rank 0, epoch 179, loss: 0.7147295475006104, rho: 0.0066, lip: 1.0000
Rank 0 - Training time: 389.50 seconds
[92mRank 0 - Testing RMSE: 0.2844[0m
[92mRank: 0, Lengthscale: [[0.5382935  0.30140388]] [0m
[92mRank: 0, Outputscale: 1.2974218130111694 [0m
[92mRank: 0, Noise: 0.17566841840744019 [0m
Run 2 completed successfully
Running pxpGP 3 with agents: 121
[92mRank 0 - sparse dataset size is: 4, local dataset: torch.Size([289, 2]), [0m
[92mRank 0 - Training local sparse GP model with 289 samples[0m
Epoch 1/200 - Loss: 5.291
Epoch 11/200 - Loss: 0.838
Epoch 21/200 - Loss: 0.351
Converged at epoch 27 with loss -0.079
[92mRank 0 - Lengthscale: [[0.5689213 0.3809123]] [0m
[92mRank 0 - Outputscale: 1.52043879032135 [0m
[92mRank 0 - Noise: 0.10852237790822983 [0m
Rank 0 - Augmented dataset size: 773
Rank 0: After warm start model parameters:
Rank: 0, Lengthscale: [[0.5689213 0.3809123]]
Rank: 0, Outputscale: 1.52043879032135
Rank: 0, Noise: 0.10852237790822983
decpxADMM initialized with rho: 0.85, lip: 1.0, tol_abs: 1e-05, tol_rel: 0.001, rank: 0, world_size: 121
[92mRank 0 - Training global model with dec-pxADMM optimizer[0m
rank 0, epoch 9, loss: 0.6837289333343506, rho: 0.2125, lip: 1.0000
rank 0, epoch 19, loss: 0.6784448623657227, rho: 0.1062, lip: 1.0000
rank 0, epoch 29, loss: 0.6800969243049622, rho: 0.1062, lip: 1.0000
rank 0, epoch 39, loss: 0.6908634305000305, rho: 0.0266, lip: 1.0000
rank 0, epoch 49, loss: 0.6941444873809814, rho: 0.0266, lip: 1.0000
rank 0, epoch 59, loss: 0.6847308874130249, rho: 0.0266, lip: 1.0000
rank 0, epoch 69, loss: 0.6779745817184448, rho: 0.0266, lip: 1.0000
rank 0, epoch 79, loss: 0.6752598285675049, rho: 0.0266, lip: 1.0000
rank 0, epoch 89, loss: 0.6736360788345337, rho: 0.0266, lip: 1.0000
rank 0, epoch 99, loss: 0.6728821396827698, rho: 0.0266, lip: 1.0000
rank 0, epoch 109, loss: 0.6727566719055176, rho: 0.0133, lip: 1.0000
rank 0, epoch 119, loss: 0.6727471947669983, rho: 0.0133, lip: 1.0000
rank 0, epoch 129, loss: 0.6726282835006714, rho: 0.0133, lip: 1.0000
rank 0, epoch 139, loss: 0.6721898913383484, rho: 0.0133, lip: 1.0000
rank 0, epoch 149, loss: 0.671532928943634, rho: 0.0133, lip: 1.0000
rank 0, epoch 159, loss: 0.67100989818573, rho: 0.0066, lip: 1.0000
rank 0, epoch 169, loss: 0.6707948446273804, rho: 0.0066, lip: 1.0000
rank 0, epoch 179, loss: 0.6709234118461609, rho: 0.0066, lip: 1.0000
Rank 0 - Training time: 339.33 seconds
[92mRank 0 - Testing RMSE: 0.2634[0m
[92mRank: 0, Lengthscale: [[0.5676069 0.3062508]] [0m
[92mRank: 0, Outputscale: 1.1868565082550049 [0m
[92mRank: 0, Noise: 0.16404111683368683 [0m
Run 3 completed successfully
Running pxpGP 4 with agents: 121
[92mRank 0 - sparse dataset size is: 4, local dataset: torch.Size([289, 2]), [0m
[92mRank 0 - Training local sparse GP model with 289 samples[0m
Epoch 1/200 - Loss: 2.572
Epoch 11/200 - Loss: 0.848
Epoch 21/200 - Loss: 0.300
Converged at epoch 26 with loss -0.057
[92mRank 0 - Lengthscale: [[0.589056   0.37326986]] [0m
[92mRank 0 - Outputscale: 1.4807225465774536 [0m
[92mRank 0 - Noise: 0.11765439063310623 [0m
Rank 0 - Augmented dataset size: 773
Rank 0: After warm start model parameters:
Rank: 0, Lengthscale: [[0.589056   0.37326986]]
Rank: 0, Outputscale: 1.4807225465774536
Rank: 0, Noise: 0.11765439063310623
decpxADMM initialized with rho: 0.85, lip: 1.0, tol_abs: 1e-05, tol_rel: 0.001, rank: 0, world_size: 121
[92mRank 0 - Training global model with dec-pxADMM optimizer[0m
rank 0, epoch 9, loss: 0.6545513272285461, rho: 0.2125, lip: 1.0000
rank 0, epoch 19, loss: 0.6351542472839355, rho: 0.1062, lip: 1.0000
rank 0, epoch 29, loss: 0.6376902461051941, rho: 0.1062, lip: 1.0000
rank 0, epoch 39, loss: 0.6424704790115356, rho: 0.0531, lip: 1.0000
rank 0, epoch 49, loss: 0.6342384815216064, rho: 0.0531, lip: 1.0000
rank 0, epoch 59, loss: 0.6291692852973938, rho: 0.0133, lip: 1.0000
rank 0, epoch 69, loss: 0.6273489594459534, rho: 0.0133, lip: 1.0000
rank 0, epoch 79, loss: 0.6265228986740112, rho: 0.0133, lip: 1.0000
rank 0, epoch 89, loss: 0.6259757876396179, rho: 0.0133, lip: 1.0000
rank 0, epoch 99, loss: 0.6254264116287231, rho: 0.0133, lip: 1.0000
rank 0, epoch 109, loss: 0.6250215768814087, rho: 0.0133, lip: 1.0000
rank 0, epoch 119, loss: 0.6247693300247192, rho: 0.0133, lip: 1.0000
rank 0, epoch 129, loss: 0.6248829960823059, rho: 0.0133, lip: 1.0000
rank 0, epoch 139, loss: 0.6253026723861694, rho: 0.0133, lip: 1.0000
rank 0, epoch 149, loss: 0.6256464719772339, rho: 0.0133, lip: 1.0000
rank 0, epoch 159, loss: 0.6257371306419373, rho: 0.0133, lip: 1.0000
rank 0, epoch 169, loss: 0.6256799101829529, rho: 0.0133, lip: 1.0000
rank 0, epoch 179, loss: 0.625567615032196, rho: 0.0133, lip: 1.0000
Rank 0 - Training time: 271.29 seconds
[92mRank 0 - Testing RMSE: 0.2325[0m
[92mRank: 0, Lengthscale: [[0.56924504 0.3654248 ]] [0m
[92mRank: 0, Outputscale: 2.4700441360473633 [0m
[92mRank: 0, Noise: 0.1497289538383484 [0m
Run 4 completed successfully
Running pxpGP 5 with agents: 121
[92mRank 0 - sparse dataset size is: 4, local dataset: torch.Size([289, 2]), [0m
[92mRank 0 - Training local sparse GP model with 289 samples[0m
Epoch 1/200 - Loss: 2.561
Epoch 11/200 - Loss: 0.833
Epoch 21/200 - Loss: 0.303
Converged at epoch 26 with loss -0.037
[92mRank 0 - Lengthscale: [[0.55900997 0.36958706]] [0m
[92mRank 0 - Outputscale: 1.4782878160476685 [0m
[92mRank 0 - Noise: 0.11881467700004578 [0m
Rank 0 - Augmented dataset size: 773
Rank 0: After warm start model parameters:
Rank: 0, Lengthscale: [[0.55900997 0.36958706]]
Rank: 0, Outputscale: 1.4782878160476685
Rank: 0, Noise: 0.11881464719772339
decpxADMM initialized with rho: 0.85, lip: 1.0, tol_abs: 1e-05, tol_rel: 0.001, rank: 0, world_size: 121
[92mRank 0 - Training global model with dec-pxADMM optimizer[0m
rank 0, epoch 9, loss: 0.7593108415603638, rho: 0.2125, lip: 1.0000
rank 0, epoch 19, loss: 0.7169206738471985, rho: 0.1062, lip: 1.0000
rank 0, epoch 29, loss: 0.6804805397987366, rho: 0.1062, lip: 1.0000
rank 0, epoch 39, loss: 0.676489531993866, rho: 0.0531, lip: 1.0000
rank 0, epoch 49, loss: 0.67755126953125, rho: 0.0531, lip: 1.0000
rank 0, epoch 59, loss: 0.6744211316108704, rho: 0.0133, lip: 1.0000
rank 0, epoch 69, loss: 0.6723178029060364, rho: 0.0133, lip: 1.0000
rank 0, epoch 79, loss: 0.6714816093444824, rho: 0.0133, lip: 1.0000
rank 0, epoch 89, loss: 0.6711971163749695, rho: 0.0133, lip: 1.0000
rank 0, epoch 99, loss: 0.6709339022636414, rho: 0.0133, lip: 1.0000
rank 0, epoch 109, loss: 0.6705747246742249, rho: 0.0133, lip: 1.0000
rank 0, epoch 119, loss: 0.6703084707260132, rho: 0.0133, lip: 1.0000
rank 0, epoch 129, loss: 0.6701799035072327, rho: 0.0133, lip: 1.0000
rank 0, epoch 139, loss: 0.6701072454452515, rho: 0.0133, lip: 1.0000
rank 0, epoch 149, loss: 0.6701613664627075, rho: 0.0133, lip: 1.0000
rank 0, epoch 159, loss: 0.6704320907592773, rho: 0.0133, lip: 1.0000
rank 0, epoch 169, loss: 0.6708774566650391, rho: 0.0133, lip: 1.0000
rank 0, epoch 179, loss: 0.6714027523994446, rho: 0.0133, lip: 1.0000
Rank 0 - Training time: 390.96 seconds
[92mRank 0 - Testing RMSE: 0.2854[0m
[92mRank: 0, Lengthscale: [[0.4909804 0.3885457]] [0m
[92mRank: 0, Outputscale: 1.8886162042617798 [0m
[92mRank: 0, Noise: 0.1556994765996933 [0m
Run 5 completed successfully
Running pxpGP 6 with agents: 121
[92mRank 0 - sparse dataset size is: 4, local dataset: torch.Size([289, 2]), [0m
[92mRank 0 - Training local sparse GP model with 289 samples[0m
Epoch 1/200 - Loss: 2.987
Epoch 11/200 - Loss: 0.819
Epoch 21/200 - Loss: 0.309
Converged at epoch 26 with loss -0.062
[92mRank 0 - Lengthscale: [[0.5769461  0.35791272]] [0m
[92mRank 0 - Outputscale: 1.524702548980713 [0m
[92mRank 0 - Noise: 0.11785728484392166 [0m
Rank 0 - Augmented dataset size: 773
Rank 0: After warm start model parameters:
Rank: 0, Lengthscale: [[0.576946   0.35791272]]
Rank: 0, Outputscale: 1.524702548980713
Rank: 0, Noise: 0.11785728484392166
decpxADMM initialized with rho: 0.85, lip: 1.0, tol_abs: 1e-05, tol_rel: 0.001, rank: 0, world_size: 121
[92mRank 0 - Training global model with dec-pxADMM optimizer[0m
rank 0, epoch 9, loss: 0.7659459710121155, rho: 0.2125, lip: 1.0000
rank 0, epoch 19, loss: 0.7027429938316345, rho: 0.2125, lip: 1.0000
rank 0, epoch 29, loss: 0.6835159063339233, rho: 0.1062, lip: 1.0000
rank 0, epoch 39, loss: 0.6943504810333252, rho: 0.0531, lip: 1.0000
rank 0, epoch 49, loss: 0.6941576600074768, rho: 0.0531, lip: 1.0000
rank 0, epoch 59, loss: 0.6885781288146973, rho: 0.0266, lip: 1.0000
rank 0, epoch 69, loss: 0.6842247843742371, rho: 0.0133, lip: 1.0000
rank 0, epoch 79, loss: 0.6820958852767944, rho: 0.0133, lip: 1.0000
rank 0, epoch 89, loss: 0.6813310980796814, rho: 0.0133, lip: 1.0000
rank 0, epoch 99, loss: 0.6808634996414185, rho: 0.0133, lip: 1.0000
rank 0, epoch 109, loss: 0.6802879571914673, rho: 0.0133, lip: 1.0000
rank 0, epoch 119, loss: 0.6794992685317993, rho: 0.0133, lip: 1.0000
rank 0, epoch 129, loss: 0.6786539554595947, rho: 0.0066, lip: 1.0000
rank 0, epoch 139, loss: 0.6778723001480103, rho: 0.0066, lip: 1.0000
rank 0, epoch 149, loss: 0.6770443320274353, rho: 0.0066, lip: 1.0000
rank 0, epoch 159, loss: 0.6761104464530945, rho: 0.0066, lip: 1.0000
rank 0, epoch 169, loss: 0.6751668453216553, rho: 0.0066, lip: 1.0000
rank 0, epoch 179, loss: 0.6742826104164124, rho: 0.0066, lip: 1.0000
Rank 0 - Training time: 426.65 seconds
[92mRank 0 - Testing RMSE: 0.2796[0m
[92mRank: 0, Lengthscale: [[0.60236096 0.36383426]] [0m
[92mRank: 0, Outputscale: 1.3806235790252686 [0m
[92mRank: 0, Noise: 0.1587648242712021 [0m
Run 6 completed successfully
Running pxpGP 7 with agents: 121
[92mRank 0 - sparse dataset size is: 4, local dataset: torch.Size([289, 2]), [0m
[92mRank 0 - Training local sparse GP model with 289 samples[0m
Epoch 1/200 - Loss: 2.753
Epoch 11/200 - Loss: 0.824
Epoch 21/200 - Loss: 0.297
Converged at epoch 25 with loss -0.005
[92mRank 0 - Lengthscale: [[0.5606992  0.36219344]] [0m
[92mRank 0 - Outputscale: 1.4988641738891602 [0m
[92mRank 0 - Noise: 0.13721540570259094 [0m
Rank 0 - Augmented dataset size: 773
Rank 0: After warm start model parameters:
Rank: 0, Lengthscale: [[0.5606992  0.36219347]]
Rank: 0, Outputscale: 1.4988641738891602
Rank: 0, Noise: 0.13721540570259094
decpxADMM initialized with rho: 0.85, lip: 1.0, tol_abs: 1e-05, tol_rel: 0.001, rank: 0, world_size: 121
[92mRank 0 - Training global model with dec-pxADMM optimizer[0m
rank 0, epoch 9, loss: 0.7308853268623352, rho: 0.4250, lip: 1.0000
rank 0, epoch 19, loss: 0.7054613828659058, rho: 0.2125, lip: 1.0000
rank 0, epoch 29, loss: 0.7421247959136963, rho: 0.2125, lip: 1.0000
rank 0, epoch 39, loss: 0.7589439749717712, rho: 0.1062, lip: 1.0000
rank 0, epoch 49, loss: 0.7384417057037354, rho: 0.0531, lip: 1.0000
rank 0, epoch 59, loss: 0.7240208983421326, rho: 0.0531, lip: 1.0000
rank 0, epoch 69, loss: 0.7182899713516235, rho: 0.0266, lip: 1.0000
rank 0, epoch 79, loss: 0.7178685069084167, rho: 0.0266, lip: 1.0000
rank 0, epoch 89, loss: 0.7190904021263123, rho: 0.0266, lip: 1.0000
rank 0, epoch 99, loss: 0.7198753356933594, rho: 0.0266, lip: 1.0000
rank 0, epoch 109, loss: 0.719831645488739, rho: 0.0266, lip: 1.0000
rank 0, epoch 119, loss: 0.7182170152664185, rho: 0.0266, lip: 1.0000
rank 0, epoch 129, loss: 0.716122031211853, rho: 0.0133, lip: 1.0000
rank 0, epoch 139, loss: 0.7146629095077515, rho: 0.0066, lip: 1.0000
rank 0, epoch 149, loss: 0.7137062549591064, rho: 0.0066, lip: 1.0000
rank 0, epoch 159, loss: 0.7129300236701965, rho: 0.0066, lip: 1.0000
rank 0, epoch 169, loss: 0.712245523929596, rho: 0.0066, lip: 1.0000
rank 0, epoch 179, loss: 0.7116655111312866, rho: 0.0066, lip: 1.0000
Rank 0 - Training time: 416.53 seconds
[92mRank 0 - Testing RMSE: 0.2826[0m
[92mRank: 0, Lengthscale: [[0.586834   0.25321895]] [0m
[92mRank: 0, Outputscale: 1.2044668197631836 [0m
[92mRank: 0, Noise: 0.17226554453372955 [0m
Run 7 completed successfully
Running pxpGP 8 with agents: 121
[92mRank 0 - sparse dataset size is: 4, local dataset: torch.Size([289, 2]), [0m
[92mRank 0 - Training local sparse GP model with 289 samples[0m
Epoch 1/200 - Loss: 2.280
Epoch 11/200 - Loss: 0.846
Epoch 21/200 - Loss: 0.315
Converged at epoch 26 with loss -0.060
[92mRank 0 - Lengthscale: [[0.56462276 0.35937867]] [0m
[92mRank 0 - Outputscale: 1.480589747428894 [0m
[92mRank 0 - Noise: 0.11479441076517105 [0m
Rank 0 - Augmented dataset size: 773
Rank 0: After warm start model parameters:
Rank: 0, Lengthscale: [[0.56462276 0.35937867]]
Rank: 0, Outputscale: 1.480589747428894
Rank: 0, Noise: 0.11479441076517105
decpxADMM initialized with rho: 0.85, lip: 1.0, tol_abs: 1e-05, tol_rel: 0.001, rank: 0, world_size: 121
[92mRank 0 - Training global model with dec-pxADMM optimizer[0m
rank 0, epoch 9, loss: 0.6621423959732056, rho: 0.2125, lip: 1.0000
rank 0, epoch 19, loss: 0.6442770957946777, rho: 0.1062, lip: 1.0000
rank 0, epoch 29, loss: 0.7000734806060791, rho: 0.1062, lip: 1.0000
rank 0, epoch 39, loss: 0.7399224638938904, rho: 0.1062, lip: 1.0000
rank 0, epoch 49, loss: 0.732683539390564, rho: 0.0531, lip: 1.0000
rank 0, epoch 59, loss: 0.7215656638145447, rho: 0.0133, lip: 1.0000
rank 0, epoch 69, loss: 0.6930164694786072, rho: 0.0133, lip: 1.0000
rank 0, epoch 79, loss: 0.653573751449585, rho: 0.0133, lip: 1.0000
rank 0, epoch 89, loss: 0.6458740234375, rho: 0.0133, lip: 1.0000
rank 0, epoch 99, loss: 0.6455431580543518, rho: 0.0133, lip: 1.0000
rank 0, epoch 109, loss: 0.6457576751708984, rho: 0.0133, lip: 1.0000
rank 0, epoch 119, loss: 0.6469190716743469, rho: 0.0133, lip: 1.0000
rank 0, epoch 129, loss: 0.6471641063690186, rho: 0.0133, lip: 1.0000
rank 0, epoch 139, loss: 0.6468985676765442, rho: 0.0133, lip: 1.0000
rank 0, epoch 149, loss: 0.6465885043144226, rho: 0.0133, lip: 1.0000
rank 0, epoch 159, loss: 0.6463152766227722, rho: 0.0133, lip: 1.0000
rank 0, epoch 169, loss: 0.6461545825004578, rho: 0.0133, lip: 1.0000
rank 0, epoch 179, loss: 0.6461672186851501, rho: 0.0066, lip: 1.0000
Rank 0 - Training time: 434.30 seconds
[92mRank 0 - Testing RMSE: 0.2850[0m
[92mRank: 0, Lengthscale: [[0.5904493  0.30105653]] [0m
[92mRank: 0, Outputscale: 1.2524771690368652 [0m
[92mRank: 0, Noise: 0.1559898406267166 [0m
Run 8 completed successfully
Running pxpGP 9 with agents: 121
[92mRank 0 - sparse dataset size is: 4, local dataset: torch.Size([289, 2]), [0m
[92mRank 0 - Training local sparse GP model with 289 samples[0m
Epoch 1/200 - Loss: 3.174
Epoch 11/200 - Loss: 0.837
Epoch 21/200 - Loss: 0.371
Converged at epoch 27 with loss -0.049
[92mRank 0 - Lengthscale: [[0.7458536 0.4015557]] [0m
[92mRank 0 - Outputscale: 1.4441241025924683 [0m
[92mRank 0 - Noise: 0.110763318836689 [0m
Rank 0 - Augmented dataset size: 773
Rank 0: After warm start model parameters:
Rank: 0, Lengthscale: [[0.7458536 0.4015557]]
Rank: 0, Outputscale: 1.4441241025924683
Rank: 0, Noise: 0.110763318836689
decpxADMM initialized with rho: 0.85, lip: 1.0, tol_abs: 1e-05, tol_rel: 0.001, rank: 0, world_size: 121
[92mRank 0 - Training global model with dec-pxADMM optimizer[0m
rank 0, epoch 9, loss: 0.7803801894187927, rho: 0.2125, lip: 1.0000
rank 0, epoch 19, loss: 0.7533483505249023, rho: 0.1062, lip: 1.0000
rank 0, epoch 29, loss: 0.7495326995849609, rho: 0.1062, lip: 1.0000
rank 0, epoch 39, loss: 0.7618252038955688, rho: 0.1062, lip: 1.0000
rank 0, epoch 49, loss: 0.7543053030967712, rho: 0.0531, lip: 1.0000
rank 0, epoch 59, loss: 0.7477999925613403, rho: 0.0133, lip: 1.0000
rank 0, epoch 69, loss: 0.7447397112846375, rho: 0.0133, lip: 1.0000
rank 0, epoch 79, loss: 0.7437352538108826, rho: 0.0133, lip: 1.0000
rank 0, epoch 89, loss: 0.7444093823432922, rho: 0.0133, lip: 1.0000
rank 0, epoch 99, loss: 0.7457559108734131, rho: 0.0133, lip: 1.0000
rank 0, epoch 109, loss: 0.7461930513381958, rho: 0.0133, lip: 1.0000
rank 0, epoch 119, loss: 0.7456430792808533, rho: 0.0133, lip: 1.0000
rank 0, epoch 129, loss: 0.7448285222053528, rho: 0.0066, lip: 1.0000
rank 0, epoch 139, loss: 0.7442023158073425, rho: 0.0066, lip: 1.0000
rank 0, epoch 149, loss: 0.7438230514526367, rho: 0.0066, lip: 1.0000
rank 0, epoch 159, loss: 0.7435861825942993, rho: 0.0066, lip: 1.0000
rank 0, epoch 169, loss: 0.7433693408966064, rho: 0.0066, lip: 1.0000
rank 0, epoch 179, loss: 0.7431105375289917, rho: 0.0066, lip: 1.0000
Rank 0 - Training time: 369.26 seconds
[92mRank 0 - Testing RMSE: 0.2943[0m
[92mRank: 0, Lengthscale: [[0.56256515 0.32098427]] [0m
[92mRank: 0, Outputscale: 1.4703530073165894 [0m
[92mRank: 0, Noise: 0.19041752815246582 [0m
Run 9 completed successfully
Running pxpGP 10 with agents: 121
[92mRank 0 - sparse dataset size is: 4, local dataset: torch.Size([289, 2]), [0m
[92mRank 0 - Training local sparse GP model with 289 samples[0m
Epoch 1/200 - Loss: 3.420
Epoch 11/200 - Loss: 0.875
Epoch 21/200 - Loss: 0.321
Converged at epoch 26 with loss -0.034
[92mRank 0 - Lengthscale: [[0.5635818 0.3891644]] [0m
[92mRank 0 - Outputscale: 1.421115517616272 [0m
[92mRank 0 - Noise: 0.12372902780771255 [0m
Rank 0 - Augmented dataset size: 773
Rank 0: After warm start model parameters:
Rank: 0, Lengthscale: [[0.5635818  0.38916442]]
Rank: 0, Outputscale: 1.421115517616272
Rank: 0, Noise: 0.12372905015945435
decpxADMM initialized with rho: 0.85, lip: 1.0, tol_abs: 1e-05, tol_rel: 0.001, rank: 0, world_size: 121
[92mRank 0 - Training global model with dec-pxADMM optimizer[0m
rank 0, epoch 9, loss: 0.7941510081291199, rho: 0.2125, lip: 1.0000
rank 0, epoch 19, loss: 0.7448991537094116, rho: 0.1062, lip: 1.0000
rank 0, epoch 29, loss: 0.7441050410270691, rho: 0.1062, lip: 1.0000
rank 0, epoch 39, loss: 0.7565515041351318, rho: 0.1062, lip: 1.0000
rank 0, epoch 49, loss: 0.7536985874176025, rho: 0.0531, lip: 1.0000
rank 0, epoch 59, loss: 0.7472869753837585, rho: 0.0266, lip: 1.0000
rank 0, epoch 69, loss: 0.7416938543319702, rho: 0.0066, lip: 1.0000
rank 0, epoch 79, loss: 0.7383121252059937, rho: 0.0066, lip: 1.0000
rank 0, epoch 89, loss: 0.7364748120307922, rho: 0.0066, lip: 1.0000
rank 0, epoch 99, loss: 0.7358055710792542, rho: 0.0066, lip: 1.0000
rank 0, epoch 109, loss: 0.7357396483421326, rho: 0.0066, lip: 1.0000
rank 0, epoch 119, loss: 0.7357252240180969, rho: 0.0066, lip: 1.0000
rank 0, epoch 129, loss: 0.7354629635810852, rho: 0.0066, lip: 1.0000
rank 0, epoch 139, loss: 0.7349809408187866, rho: 0.0066, lip: 1.0000
rank 0, epoch 149, loss: 0.7345439791679382, rho: 0.0066, lip: 1.0000
rank 0, epoch 159, loss: 0.7343307733535767, rho: 0.0066, lip: 1.0000
rank 0, epoch 169, loss: 0.7343074083328247, rho: 0.0066, lip: 1.0000
rank 0, epoch 179, loss: 0.7343761324882507, rho: 0.0066, lip: 1.0000
Rank 0 - Training time: 322.23 seconds
[92mRank 0 - Testing RMSE: 0.2895[0m
[92mRank: 0, Lengthscale: [[0.524142   0.29354423]] [0m
[92mRank: 0, Outputscale: 1.0724095106124878 [0m
[92mRank: 0, Noise: 0.1653124988079071 [0m
Run 10 completed successfully
Running gapxGP 1 with agents: 121
decpxADMM initialized with rho: 0.75, lip: 1.0, tol_abs: 1e-05, tol_rel: 0.001, rank: 0, world_size: 121
Rank 0 - Epoch 2/242 loss: 0.9984113574028015
Rank 0 - Epoch 10/242 loss: 0.7800558805465698
Rank 0 - Epoch 20/242 loss: 0.43591180443763733
Rank 0 - Epoch 30/242 loss: 0.021123165264725685
Rank 0 - Epoch 40/242 loss: -0.4134431779384613
Rank 0 - Epoch 50/242 loss: -0.8405084609985352
Rank 0 - Epoch 60/242 loss: -1.2432279586791992
Rank 0 - Epoch 70/242 loss: -1.6102004051208496
Rank 0 - Epoch 80/242 loss: -1.9256787300109863
Rank 0 - Epoch 90/242 loss: -2.1703040599823
Rank 0 - Epoch 100/242 loss: -2.337697982788086
Rank 0 - Epoch 110/242 loss: -2.441279649734497
Rank 0 - Epoch 120/242 loss: -2.382801055908203
Rank 0 - Epoch 130/242 loss: -2.3319499492645264
Rank 0 - Epoch 140/242 loss: -2.481565237045288
Run 1 failed, retrying...
Running gapxGP 2 with agents: 121
decpxADMM initialized with rho: 0.75, lip: 1.0, tol_abs: 1e-05, tol_rel: 0.001, rank: 0, world_size: 121
Rank 0 - Epoch 2/242 loss: 0.9989215135574341
Rank 0 - Epoch 10/242 loss: 0.7813052535057068
Rank 0 - Epoch 20/242 loss: 0.43905338644981384
Rank 0 - Epoch 30/242 loss: 0.026032645255327225
Rank 0 - Epoch 40/242 loss: -0.40773001313209534
Rank 0 - Epoch 50/242 loss: -0.8353415131568909
Rank 0 - Epoch 60/242 loss: -1.2396808862686157
Rank 0 - Epoch 70/242 loss: -1.60874605178833
Rank 0 - Epoch 80/242 loss: -1.9254555702209473
Rank 0 - Epoch 90/242 loss: -2.1706390380859375
Rank 0 - Epoch 100/242 loss: -2.3386738300323486
Rank 0 - Epoch 110/242 loss: -2.442798614501953
Rank 0 - Epoch 120/242 loss: -2.4311227798461914
Rank 0 - Epoch 130/242 loss: -2.423689126968384
Rank 0 - Epoch 140/242 loss: -2.5389301776885986
Run 2 failed, retrying...
Running gapxGP 3 with agents: 121
decpxADMM initialized with rho: 0.75, lip: 1.0, tol_abs: 1e-05, tol_rel: 0.001, rank: 0, world_size: 121
Rank 0 - Epoch 2/242 loss: 0.9899898171424866
Rank 0 - Epoch 10/242 loss: 0.7726072669029236
Rank 0 - Epoch 20/242 loss: 0.42959776520729065
Rank 0 - Epoch 30/242 loss: 0.021148720756173134
Rank 0 - Epoch 40/242 loss: -0.4121968448162079
Rank 0 - Epoch 50/242 loss: -0.837011456489563
Rank 0 - Epoch 60/242 loss: -1.2384573221206665
Rank 0 - Epoch 70/242 loss: -1.605459213256836
Rank 0 - Epoch 80/242 loss: -1.9211769104003906
Rank 0 - Epoch 90/242 loss: -2.166541576385498
Rank 0 - Epoch 100/242 loss: -2.334962844848633
Rank 0 - Epoch 110/242 loss: -2.4408156871795654
Rank 0 - Epoch 120/242 loss: -2.4839324951171875
Rank 0 - Epoch 130/242 loss: -2.451943874359131
Rank 0 - Epoch 140/242 loss: -2.5508193969726562
Run 3 failed, retrying...
Running gapxGP 4 with agents: 121
decpxADMM initialized with rho: 0.75, lip: 1.0, tol_abs: 1e-05, tol_rel: 0.001, rank: 0, world_size: 121
Rank 0 - Epoch 2/242 loss: 0.9933514595031738
Rank 0 - Epoch 10/242 loss: 0.7766013145446777
Rank 0 - Epoch 20/242 loss: 0.43633055686950684
Rank 0 - Epoch 30/242 loss: 0.02404015325009823
Rank 0 - Epoch 40/242 loss: -0.41009521484375
Rank 0 - Epoch 50/242 loss: -0.8385533094406128
Rank 0 - Epoch 60/242 loss: -1.241976261138916
Rank 0 - Epoch 70/242 loss: -1.6108585596084595
Rank 0 - Epoch 80/242 loss: -1.927755355834961
Rank 0 - Epoch 90/242 loss: -2.1731646060943604
Rank 0 - Epoch 100/242 loss: -2.340792655944824
Rank 0 - Epoch 110/242 loss: -2.443938732147217
Rank 0 - Epoch 120/242 loss: -2.4918406009674072
Rank 0 - Epoch 130/242 loss: -2.502349853515625
Run 4 failed, retrying...
Running gapxGP 5 with agents: 121
decpxADMM initialized with rho: 0.75, lip: 1.0, tol_abs: 1e-05, tol_rel: 0.001, rank: 0, world_size: 121
Rank 0 - Epoch 2/242 loss: 1.000123143196106
Rank 0 - Epoch 10/242 loss: 0.7805197834968567
Rank 0 - Epoch 20/242 loss: 0.4298420250415802
Rank 0 - Epoch 30/242 loss: 0.011369682848453522
Rank 0 - Epoch 40/242 loss: -0.42108026146888733
Rank 0 - Epoch 50/242 loss: -0.8465310335159302
Rank 0 - Epoch 60/242 loss: -1.2478227615356445
Rank 0 - Epoch 70/242 loss: -1.6144918203353882
Rank 0 - Epoch 80/242 loss: -1.929713249206543
Rank 0 - Epoch 90/242 loss: -2.173358917236328
Rank 0 - Epoch 100/242 loss: -2.3398478031158447
Rank 0 - Epoch 110/242 loss: -2.4268321990966797
Rank 0 - Epoch 120/242 loss: -2.461108922958374
Rank 0 - Epoch 130/242 loss: -2.5371556282043457
Run 5 failed, retrying...
Running gapxGP 6 with agents: 121
decpxADMM initialized with rho: 0.75, lip: 1.0, tol_abs: 1e-05, tol_rel: 0.001, rank: 0, world_size: 121
Rank 0 - Epoch 2/242 loss: 0.9925504326820374
Rank 0 - Epoch 10/242 loss: 0.7755163311958313
Rank 0 - Epoch 20/242 loss: 0.43265095353126526
Rank 0 - Epoch 30/242 loss: 0.021267695352435112
Rank 0 - Epoch 40/242 loss: -0.4114218056201935
Rank 0 - Epoch 50/242 loss: -0.8380556106567383
Rank 0 - Epoch 60/242 loss: -1.2412443161010742
Rank 0 - Epoch 70/242 loss: -1.6099892854690552
Rank 0 - Epoch 80/242 loss: -1.9267677068710327
Rank 0 - Epoch 90/242 loss: -2.1724295616149902
Rank 0 - Epoch 100/242 loss: -2.340975284576416
Rank 0 - Epoch 110/242 loss: -2.446563720703125
Rank 0 - Epoch 120/242 loss: -2.399461030960083
Rank 0 - Epoch 130/242 loss: -2.4170191287994385
Rank 0 - Epoch 140/242 loss: -2.395037889480591
Run 6 failed, retrying...
Running gapxGP 7 with agents: 121
decpxADMM initialized with rho: 0.75, lip: 1.0, tol_abs: 1e-05, tol_rel: 0.001, rank: 0, world_size: 121
Rank 0 - Epoch 2/242 loss: 0.9948625564575195
Rank 0 - Epoch 10/242 loss: 0.7753220200538635
Rank 0 - Epoch 20/242 loss: 0.4305306375026703
Rank 0 - Epoch 30/242 loss: 0.019910398870706558
Rank 0 - Epoch 40/242 loss: -0.4101532995700836
Rank 0 - Epoch 50/242 loss: -0.83438640832901
Rank 0 - Epoch 60/242 loss: -1.2357405424118042
Rank 0 - Epoch 70/242 loss: -1.6027923822402954
Rank 0 - Epoch 80/242 loss: -1.918715476989746
Rank 0 - Epoch 90/242 loss: -2.1633551120758057
Rank 0 - Epoch 100/242 loss: -2.331198215484619
Rank 0 - Epoch 110/242 loss: -2.425933599472046
Rank 0 - Epoch 120/242 loss: -2.3509275913238525
Rank 0 - Epoch 130/242 loss: -2.32841420173645
Run 7 failed, retrying...
Running gapxGP 8 with agents: 121
decpxADMM initialized with rho: 0.75, lip: 1.0, tol_abs: 1e-05, tol_rel: 0.001, rank: 0, world_size: 121
Rank 0 - Epoch 2/242 loss: 0.9970589876174927
Rank 0 - Epoch 10/242 loss: 0.7792863249778748
Rank 0 - Epoch 20/242 loss: 0.43802565336227417
Rank 0 - Epoch 30/242 loss: 0.025241965427994728
Rank 0 - Epoch 40/242 loss: -0.40789803862571716
Rank 0 - Epoch 50/242 loss: -0.8348900675773621
Rank 0 - Epoch 60/242 loss: -1.2383408546447754
Rank 0 - Epoch 70/242 loss: -1.606513261795044
Rank 0 - Epoch 80/242 loss: -1.9229042530059814
Rank 0 - Epoch 90/242 loss: -2.167715072631836
Rank 0 - Epoch 100/242 loss: -2.3352603912353516
Rank 0 - Epoch 110/242 loss: -2.431344985961914
Rank 0 - Epoch 120/242 loss: -2.460669755935669
Rank 0 - Epoch 130/242 loss: -2.5252575874328613
Rank 0 - Epoch 140/242 loss: -2.5649876594543457
Run 8 failed, retrying...
Running gapxGP 9 with agents: 121
decpxADMM initialized with rho: 0.75, lip: 1.0, tol_abs: 1e-05, tol_rel: 0.001, rank: 0, world_size: 121
Rank 0 - Epoch 2/242 loss: 0.9943684339523315
Rank 0 - Epoch 10/242 loss: 0.7779723405838013
Rank 0 - Epoch 20/242 loss: 0.4320901334285736
Rank 0 - Epoch 30/242 loss: 0.02161327190697193
Rank 0 - Epoch 40/242 loss: -0.41026395559310913
Rank 0 - Epoch 50/242 loss: -0.8339314460754395
Rank 0 - Epoch 60/242 loss: -1.2352123260498047
Rank 0 - Epoch 70/242 loss: -1.6024329662322998
Rank 0 - Epoch 80/242 loss: -1.917624592781067
Rank 0 - Epoch 90/242 loss: -2.1625144481658936
Rank 0 - Epoch 100/242 loss: -2.3304061889648438
Rank 0 - Epoch 110/242 loss: -2.436338424682617
Rank 0 - Epoch 120/242 loss: -2.471034288406372
Rank 0 - Epoch 130/242 loss: -2.50783371925354
Rank 0 - Epoch 140/242 loss: -2.545583724975586
Run 9 failed, retrying...
Running gapxGP 10 with agents: 121
decpxADMM initialized with rho: 0.75, lip: 1.0, tol_abs: 1e-05, tol_rel: 0.001, rank: 0, world_size: 121
Rank 0 - Epoch 2/242 loss: 1.0040836334228516
Rank 0 - Epoch 10/242 loss: 0.7863790392875671
Rank 0 - Epoch 20/242 loss: 0.4392525553703308
Rank 0 - Epoch 30/242 loss: 0.02353893406689167
Rank 0 - Epoch 40/242 loss: -0.40827709436416626
Rank 0 - Epoch 50/242 loss: -0.8325880169868469
Rank 0 - Epoch 60/242 loss: -1.2339304685592651
Rank 0 - Epoch 70/242 loss: -1.6006052494049072
Rank 0 - Epoch 80/242 loss: -1.9157201051712036
Rank 0 - Epoch 90/242 loss: -2.160505771636963
Rank 0 - Epoch 100/242 loss: -2.3286218643188477
Rank 0 - Epoch 110/242 loss: -2.4164953231811523
Rank 0 - Epoch 120/242 loss: -2.338700771331787
Rank 0 - Epoch 130/242 loss: -2.267211675643921
Run 10 failed, retrying...
Running apxGP 1 with agents: 121
decpxADMM initialized with rho: 0.85, lip: 1.0, tol_abs: 1e-05, tol_rel: 0.001, rank: 0, world_size: 121
Rank 0 - Epoch 2/242 loss: 0.7721995711326599
Rank 0 - Epoch 10/242 loss: 0.5049041509628296
Rank 0 - Epoch 20/242 loss: 0.08690936118364334
Rank 0 - Epoch 30/242 loss: -0.3945114016532898
Rank 0 - Epoch 40/242 loss: -0.9098191857337952
Rank 0 - Epoch 50/242 loss: -1.4284933805465698
Rank 0 - Epoch 60/242 loss: -1.9361079931259155
Rank 0 - Epoch 70/242 loss: -2.3992910385131836
Rank 0 - Epoch 80/242 loss: -2.771091938018799
Rank 0 - Epoch 90/242 loss: -3.0304081439971924
Rank 0 - Epoch 100/242 loss: -3.1876745223999023
Rank 0 - Epoch 110/242 loss: -3.2793312072753906
Rank 0 - Epoch 120/242 loss: -3.3355565071105957
Rank 0 - Epoch 130/242 loss: -3.3710076808929443
Rank 0 - Epoch 140/242 loss: -3.39505934715271
Rank 0 - Epoch 150/242 loss: -3.413147211074829
Rank 0 - Epoch 160/242 loss: -3.426316022872925
Rank 0 - Epoch 170/242 loss: -3.43607497215271
Rank 0 - Epoch 180/242 loss: -3.444077491760254
Rank 0 - Epoch 190/242 loss: -3.4505198001861572
Rank 0 - Epoch 200/242 loss: -3.456190347671509
Rank 0 - Epoch 210/242 loss: -3.4605329036712646
Rank 0 - Epoch 220/242 loss: -3.4636762142181396
Rank 0 - Epoch 230/242 loss: -3.4672324657440186
Rank 0 - Epoch 240/242 loss: -3.4699056148529053
Training complete.
[92mRank 0 - Testing RMSE: 2.6560[0m
[92mRank: 0, Lengthscale: [[0.5930249 0.3754371]] [0m
[92mRank: 0, Outputscale: 1.5370829105377197 [0m
[92mRank: 0, Noise: 0.00010719443525886163 [0m
Run 1 completed successfully
Running apxGP 2 with agents: 121
decpxADMM initialized with rho: 0.85, lip: 1.0, tol_abs: 1e-05, tol_rel: 0.001, rank: 0, world_size: 121
Rank 0 - Epoch 2/242 loss: 0.7721995711326599
Rank 0 - Epoch 10/242 loss: 0.5049041509628296
Rank 0 - Epoch 20/242 loss: 0.08690936118364334
Rank 0 - Epoch 30/242 loss: -0.3945114016532898
Rank 0 - Epoch 40/242 loss: -0.9098191857337952
Rank 0 - Epoch 50/242 loss: -1.4284933805465698
Rank 0 - Epoch 60/242 loss: -1.9361079931259155
Rank 0 - Epoch 70/242 loss: -2.3992910385131836
Rank 0 - Epoch 80/242 loss: -2.771091938018799
Rank 0 - Epoch 90/242 loss: -3.0304081439971924
Rank 0 - Epoch 100/242 loss: -3.1876745223999023
Rank 0 - Epoch 110/242 loss: -3.2793312072753906
Rank 0 - Epoch 120/242 loss: -3.3355565071105957
Rank 0 - Epoch 130/242 loss: -3.3710076808929443
Rank 0 - Epoch 140/242 loss: -3.39505934715271
Rank 0 - Epoch 150/242 loss: -3.413147211074829
Rank 0 - Epoch 160/242 loss: -3.426316022872925
Rank 0 - Epoch 170/242 loss: -3.43607497215271
Rank 0 - Epoch 180/242 loss: -3.444077491760254
Rank 0 - Epoch 190/242 loss: -3.4505198001861572
Rank 0 - Epoch 200/242 loss: -3.456190347671509
Rank 0 - Epoch 210/242 loss: -3.4605329036712646
Rank 0 - Epoch 220/242 loss: -3.4636762142181396
Rank 0 - Epoch 230/242 loss: -3.4672324657440186
Rank 0 - Epoch 240/242 loss: -3.4699056148529053
Training complete.
[92mRank 0 - Testing RMSE: 2.6560[0m
[92mRank: 0, Lengthscale: [[0.5930249 0.3754371]] [0m
[92mRank: 0, Outputscale: 1.5370829105377197 [0m
[92mRank: 0, Noise: 0.00010719443525886163 [0m
Run 2 completed successfully
Running apxGP 3 with agents: 121
decpxADMM initialized with rho: 0.85, lip: 1.0, tol_abs: 1e-05, tol_rel: 0.001, rank: 0, world_size: 121
Rank 0 - Epoch 2/242 loss: 0.7721995711326599
Rank 0 - Epoch 10/242 loss: 0.5049041509628296
Rank 0 - Epoch 20/242 loss: 0.08690936118364334
Rank 0 - Epoch 30/242 loss: -0.3945114016532898
Rank 0 - Epoch 40/242 loss: -0.9098191857337952
Rank 0 - Epoch 50/242 loss: -1.4284933805465698
Rank 0 - Epoch 60/242 loss: -1.9361079931259155
Rank 0 - Epoch 70/242 loss: -2.3992910385131836
Rank 0 - Epoch 80/242 loss: -2.771091938018799
Rank 0 - Epoch 90/242 loss: -3.0304081439971924
Rank 0 - Epoch 100/242 loss: -3.1876745223999023
Rank 0 - Epoch 110/242 loss: -3.2793312072753906
Rank 0 - Epoch 120/242 loss: -3.3355565071105957
Rank 0 - Epoch 130/242 loss: -3.3710076808929443
Rank 0 - Epoch 140/242 loss: -3.39505934715271
Rank 0 - Epoch 150/242 loss: -3.413147211074829
Rank 0 - Epoch 160/242 loss: -3.426316022872925
Rank 0 - Epoch 170/242 loss: -3.43607497215271
Rank 0 - Epoch 180/242 loss: -3.444077491760254
Rank 0 - Epoch 190/242 loss: -3.4505198001861572
Rank 0 - Epoch 200/242 loss: -3.456190347671509
Rank 0 - Epoch 210/242 loss: -3.4605329036712646
Rank 0 - Epoch 220/242 loss: -3.4636762142181396
Rank 0 - Epoch 230/242 loss: -3.4672324657440186
Rank 0 - Epoch 240/242 loss: -3.4699056148529053
Training complete.
[92mRank 0 - Testing RMSE: 2.6560[0m
[92mRank: 0, Lengthscale: [[0.5930249 0.3754371]] [0m
[92mRank: 0, Outputscale: 1.5370829105377197 [0m
[92mRank: 0, Noise: 0.00010719443525886163 [0m
Run 3 completed successfully
Running apxGP 4 with agents: 121
decpxADMM initialized with rho: 0.85, lip: 1.0, tol_abs: 1e-05, tol_rel: 0.001, rank: 0, world_size: 121
Rank 0 - Epoch 2/242 loss: 0.7721995711326599
Rank 0 - Epoch 10/242 loss: 0.5049041509628296
Rank 0 - Epoch 20/242 loss: 0.08690936118364334
Rank 0 - Epoch 30/242 loss: -0.3945114016532898
Rank 0 - Epoch 40/242 loss: -0.9098191857337952
Rank 0 - Epoch 50/242 loss: -1.4284933805465698
Rank 0 - Epoch 60/242 loss: -1.9361079931259155
Rank 0 - Epoch 70/242 loss: -2.3992910385131836
Rank 0 - Epoch 80/242 loss: -2.771091938018799
Rank 0 - Epoch 90/242 loss: -3.0304081439971924
Rank 0 - Epoch 100/242 loss: -3.1876745223999023
Rank 0 - Epoch 110/242 loss: -3.2793312072753906
Rank 0 - Epoch 120/242 loss: -3.3355565071105957
Rank 0 - Epoch 130/242 loss: -3.3710076808929443
Rank 0 - Epoch 140/242 loss: -3.39505934715271
Rank 0 - Epoch 150/242 loss: -3.413147211074829
Rank 0 - Epoch 160/242 loss: -3.426316022872925
Rank 0 - Epoch 170/242 loss: -3.43607497215271
Rank 0 - Epoch 180/242 loss: -3.444077491760254
Rank 0 - Epoch 190/242 loss: -3.4505198001861572
Rank 0 - Epoch 200/242 loss: -3.456190347671509
Rank 0 - Epoch 210/242 loss: -3.4605329036712646
Rank 0 - Epoch 220/242 loss: -3.4636762142181396
Rank 0 - Epoch 230/242 loss: -3.4672324657440186
Rank 0 - Epoch 240/242 loss: -3.4699056148529053
Training complete.
[92mRank 0 - Testing RMSE: 2.6560[0m
[92mRank: 0, Lengthscale: [[0.5930249 0.3754371]] [0m
[92mRank: 0, Outputscale: 1.5370829105377197 [0m
[92mRank: 0, Noise: 0.00010719443525886163 [0m
Run 4 completed successfully
Running apxGP 5 with agents: 121
decpxADMM initialized with rho: 0.85, lip: 1.0, tol_abs: 1e-05, tol_rel: 0.001, rank: 0, world_size: 121
Rank 0 - Epoch 2/242 loss: 0.7721995711326599
Rank 0 - Epoch 10/242 loss: 0.5049041509628296
Rank 0 - Epoch 20/242 loss: 0.08690936118364334
Rank 0 - Epoch 30/242 loss: -0.3945114016532898
Rank 0 - Epoch 40/242 loss: -0.9098191857337952
Rank 0 - Epoch 50/242 loss: -1.4284933805465698
Rank 0 - Epoch 60/242 loss: -1.9361079931259155
Rank 0 - Epoch 70/242 loss: -2.3992910385131836
Rank 0 - Epoch 80/242 loss: -2.771091938018799
Rank 0 - Epoch 90/242 loss: -3.0304081439971924
Rank 0 - Epoch 100/242 loss: -3.1876745223999023
Rank 0 - Epoch 110/242 loss: -3.2793312072753906
Rank 0 - Epoch 120/242 loss: -3.3355565071105957
Rank 0 - Epoch 130/242 loss: -3.3710076808929443
Rank 0 - Epoch 140/242 loss: -3.39505934715271
Rank 0 - Epoch 150/242 loss: -3.413147211074829
Rank 0 - Epoch 160/242 loss: -3.426316022872925
Rank 0 - Epoch 170/242 loss: -3.43607497215271
Rank 0 - Epoch 180/242 loss: -3.444077491760254
Rank 0 - Epoch 190/242 loss: -3.4505198001861572
Rank 0 - Epoch 200/242 loss: -3.456190347671509
Rank 0 - Epoch 210/242 loss: -3.4605329036712646
Rank 0 - Epoch 220/242 loss: -3.4636762142181396
Rank 0 - Epoch 230/242 loss: -3.4672324657440186
Rank 0 - Epoch 240/242 loss: -3.4699056148529053
Training complete.
[92mRank 0 - Testing RMSE: 2.6560[0m
[92mRank: 0, Lengthscale: [[0.5930249 0.3754371]] [0m
[92mRank: 0, Outputscale: 1.5370829105377197 [0m
[92mRank: 0, Noise: 0.00010719443525886163 [0m
Run 5 completed successfully
Running apxGP 6 with agents: 121
decpxADMM initialized with rho: 0.85, lip: 1.0, tol_abs: 1e-05, tol_rel: 0.001, rank: 0, world_size: 121
Rank 0 - Epoch 2/242 loss: 0.7721995711326599
Rank 0 - Epoch 10/242 loss: 0.5049041509628296
Rank 0 - Epoch 20/242 loss: 0.08690936118364334
Rank 0 - Epoch 30/242 loss: -0.3945114016532898
Rank 0 - Epoch 40/242 loss: -0.9098191857337952
Rank 0 - Epoch 50/242 loss: -1.4284933805465698
Rank 0 - Epoch 60/242 loss: -1.9361079931259155
Rank 0 - Epoch 70/242 loss: -2.3992910385131836
Rank 0 - Epoch 80/242 loss: -2.771091938018799
Rank 0 - Epoch 90/242 loss: -3.0304081439971924
Rank 0 - Epoch 100/242 loss: -3.1876745223999023
Rank 0 - Epoch 110/242 loss: -3.2793312072753906
Rank 0 - Epoch 120/242 loss: -3.3355565071105957
Rank 0 - Epoch 130/242 loss: -3.3710076808929443
Rank 0 - Epoch 140/242 loss: -3.39505934715271
Rank 0 - Epoch 150/242 loss: -3.413147211074829
Rank 0 - Epoch 160/242 loss: -3.426316022872925
Rank 0 - Epoch 170/242 loss: -3.43607497215271
Rank 0 - Epoch 180/242 loss: -3.444077491760254
Rank 0 - Epoch 190/242 loss: -3.4505198001861572
Rank 0 - Epoch 200/242 loss: -3.456190347671509
Rank 0 - Epoch 210/242 loss: -3.4605329036712646
Rank 0 - Epoch 220/242 loss: -3.4636762142181396
Rank 0 - Epoch 230/242 loss: -3.4672324657440186
Rank 0 - Epoch 240/242 loss: -3.4699056148529053
Training complete.
[92mRank 0 - Testing RMSE: 2.6560[0m
[92mRank: 0, Lengthscale: [[0.5930249 0.3754371]] [0m
[92mRank: 0, Outputscale: 1.5370829105377197 [0m
[92mRank: 0, Noise: 0.00010719443525886163 [0m
Run 6 completed successfully
Running apxGP 7 with agents: 121
decpxADMM initialized with rho: 0.85, lip: 1.0, tol_abs: 1e-05, tol_rel: 0.001, rank: 0, world_size: 121
Rank 0 - Epoch 2/242 loss: 0.7721995711326599
Rank 0 - Epoch 10/242 loss: 0.5049041509628296
Rank 0 - Epoch 20/242 loss: 0.08690936118364334
Rank 0 - Epoch 30/242 loss: -0.3945114016532898
Rank 0 - Epoch 40/242 loss: -0.9098191857337952
Rank 0 - Epoch 50/242 loss: -1.4284933805465698
Rank 0 - Epoch 60/242 loss: -1.9361079931259155
Rank 0 - Epoch 70/242 loss: -2.3992910385131836
Rank 0 - Epoch 80/242 loss: -2.771091938018799
Rank 0 - Epoch 90/242 loss: -3.0304081439971924
Rank 0 - Epoch 100/242 loss: -3.1876745223999023
Rank 0 - Epoch 110/242 loss: -3.2793312072753906
Rank 0 - Epoch 120/242 loss: -3.3355565071105957
Rank 0 - Epoch 130/242 loss: -3.3710076808929443
Rank 0 - Epoch 140/242 loss: -3.39505934715271
Rank 0 - Epoch 150/242 loss: -3.413147211074829
Rank 0 - Epoch 160/242 loss: -3.426316022872925
Rank 0 - Epoch 170/242 loss: -3.43607497215271
Rank 0 - Epoch 180/242 loss: -3.444077491760254
Rank 0 - Epoch 190/242 loss: -3.4505198001861572
Rank 0 - Epoch 200/242 loss: -3.456190347671509
Rank 0 - Epoch 210/242 loss: -3.4605329036712646
Rank 0 - Epoch 220/242 loss: -3.4636762142181396
Rank 0 - Epoch 230/242 loss: -3.4672324657440186
Rank 0 - Epoch 240/242 loss: -3.4699056148529053
Training complete.
[92mRank 0 - Testing RMSE: 2.6560[0m
[92mRank: 0, Lengthscale: [[0.5930249 0.3754371]] [0m
[92mRank: 0, Outputscale: 1.5370829105377197 [0m
[92mRank: 0, Noise: 0.00010719443525886163 [0m
Run 7 completed successfully
Running apxGP 8 with agents: 121
decpxADMM initialized with rho: 0.85, lip: 1.0, tol_abs: 1e-05, tol_rel: 0.001, rank: 0, world_size: 121
Rank 0 - Epoch 2/242 loss: 0.7721995711326599
Rank 0 - Epoch 10/242 loss: 0.5049041509628296
Rank 0 - Epoch 20/242 loss: 0.08690936118364334
Rank 0 - Epoch 30/242 loss: -0.3945114016532898
Rank 0 - Epoch 40/242 loss: -0.9098191857337952
Rank 0 - Epoch 50/242 loss: -1.4284933805465698
Rank 0 - Epoch 60/242 loss: -1.9361079931259155
Rank 0 - Epoch 70/242 loss: -2.3992910385131836
Rank 0 - Epoch 80/242 loss: -2.771091938018799
Rank 0 - Epoch 90/242 loss: -3.0304081439971924
Rank 0 - Epoch 100/242 loss: -3.1876745223999023
Rank 0 - Epoch 110/242 loss: -3.2793312072753906
Rank 0 - Epoch 120/242 loss: -3.3355565071105957
Rank 0 - Epoch 130/242 loss: -3.3710076808929443
Rank 0 - Epoch 140/242 loss: -3.39505934715271
Rank 0 - Epoch 150/242 loss: -3.413147211074829
Rank 0 - Epoch 160/242 loss: -3.426316022872925
Rank 0 - Epoch 170/242 loss: -3.43607497215271
Rank 0 - Epoch 180/242 loss: -3.444077491760254
Rank 0 - Epoch 190/242 loss: -3.4505198001861572
Rank 0 - Epoch 200/242 loss: -3.456190347671509
Rank 0 - Epoch 210/242 loss: -3.4605329036712646
Rank 0 - Epoch 220/242 loss: -3.4636762142181396
Rank 0 - Epoch 230/242 loss: -3.4672324657440186
Rank 0 - Epoch 240/242 loss: -3.4699056148529053
Training complete.
[92mRank 0 - Testing RMSE: 2.6560[0m
[92mRank: 0, Lengthscale: [[0.5930249 0.3754371]] [0m
[92mRank: 0, Outputscale: 1.5370829105377197 [0m
[92mRank: 0, Noise: 0.00010719443525886163 [0m
Run 8 completed successfully
Running apxGP 9 with agents: 121
decpxADMM initialized with rho: 0.85, lip: 1.0, tol_abs: 1e-05, tol_rel: 0.001, rank: 0, world_size: 121
Rank 0 - Epoch 2/242 loss: 0.7721995711326599
Rank 0 - Epoch 10/242 loss: 0.5049041509628296
Rank 0 - Epoch 20/242 loss: 0.08690936118364334
Rank 0 - Epoch 30/242 loss: -0.3945114016532898
Rank 0 - Epoch 40/242 loss: -0.9098191857337952
Rank 0 - Epoch 50/242 loss: -1.4284933805465698
Rank 0 - Epoch 60/242 loss: -1.9361079931259155
Rank 0 - Epoch 70/242 loss: -2.3992910385131836
Rank 0 - Epoch 80/242 loss: -2.771091938018799
Rank 0 - Epoch 90/242 loss: -3.0304081439971924
Rank 0 - Epoch 100/242 loss: -3.1876745223999023
Rank 0 - Epoch 110/242 loss: -3.2793312072753906
Rank 0 - Epoch 120/242 loss: -3.3355565071105957
Rank 0 - Epoch 130/242 loss: -3.3710076808929443
Rank 0 - Epoch 140/242 loss: -3.39505934715271
Rank 0 - Epoch 150/242 loss: -3.413147211074829
Rank 0 - Epoch 160/242 loss: -3.426316022872925
Rank 0 - Epoch 170/242 loss: -3.43607497215271
Rank 0 - Epoch 180/242 loss: -3.444077491760254
Rank 0 - Epoch 190/242 loss: -3.4505198001861572
Rank 0 - Epoch 200/242 loss: -3.456190347671509
Rank 0 - Epoch 210/242 loss: -3.4605329036712646
Rank 0 - Epoch 220/242 loss: -3.4636762142181396
Rank 0 - Epoch 230/242 loss: -3.4672324657440186
Rank 0 - Epoch 240/242 loss: -3.4699056148529053
Training complete.
[92mRank 0 - Testing RMSE: 2.6560[0m
[92mRank: 0, Lengthscale: [[0.5930249 0.3754371]] [0m
[92mRank: 0, Outputscale: 1.5370829105377197 [0m
[92mRank: 0, Noise: 0.00010719443525886163 [0m
Run 9 completed successfully
Running apxGP 10 with agents: 121
decpxADMM initialized with rho: 0.85, lip: 1.0, tol_abs: 1e-05, tol_rel: 0.001, rank: 0, world_size: 121
Rank 0 - Epoch 2/242 loss: 0.7721995711326599
Rank 0 - Epoch 10/242 loss: 0.5049041509628296
Rank 0 - Epoch 20/242 loss: 0.08690936118364334
Rank 0 - Epoch 30/242 loss: -0.3945114016532898
Rank 0 - Epoch 40/242 loss: -0.9098191857337952
Rank 0 - Epoch 50/242 loss: -1.4284933805465698
Rank 0 - Epoch 60/242 loss: -1.9361079931259155
Rank 0 - Epoch 70/242 loss: -2.3992910385131836
Rank 0 - Epoch 80/242 loss: -2.771091938018799
Rank 0 - Epoch 90/242 loss: -3.0304081439971924
Rank 0 - Epoch 100/242 loss: -3.1876745223999023
Rank 0 - Epoch 110/242 loss: -3.2793312072753906
Rank 0 - Epoch 120/242 loss: -3.3355565071105957
Rank 0 - Epoch 130/242 loss: -3.3710076808929443
Rank 0 - Epoch 140/242 loss: -3.39505934715271
Rank 0 - Epoch 150/242 loss: -3.413147211074829
Rank 0 - Epoch 160/242 loss: -3.426316022872925
Rank 0 - Epoch 170/242 loss: -3.43607497215271
Rank 0 - Epoch 180/242 loss: -3.444077491760254
Rank 0 - Epoch 190/242 loss: -3.4505198001861572
Rank 0 - Epoch 200/242 loss: -3.456190347671509
Rank 0 - Epoch 210/242 loss: -3.4605329036712646
Rank 0 - Epoch 220/242 loss: -3.4636762142181396
Rank 0 - Epoch 230/242 loss: -3.4672324657440186
Rank 0 - Epoch 240/242 loss: -3.4699056148529053
Training complete.
[92mRank 0 - Testing RMSE: 2.6560[0m
[92mRank: 0, Lengthscale: [[0.5930249 0.3754371]] [0m
[92mRank: 0, Outputscale: 1.5370829105377197 [0m
[92mRank: 0, Noise: 0.00010719443525886163 [0m
Run 10 completed successfully
Running cGP 1 with agents: 121
decADMM initialized with rho: 0.85, max_iter: 5, lr: 0.0001, rank: 0, world_size: 121
Rank 0 - Epoch 2/242 loss: 0.8289426565170288
Rank 0 - Epoch 10/242 loss: 0.8235780000686646
Rank 0 - Epoch 20/242 loss: 0.8168559670448303
Rank 0 - Epoch 30/242 loss: 0.8101170659065247
Rank 0 - Epoch 40/242 loss: 0.8033618330955505
Rank 0 - Epoch 50/242 loss: 0.7965909242630005
Rank 0 - Epoch 60/242 loss: 0.7898054122924805
Rank 0 - Epoch 70/242 loss: 0.7830060124397278
Rank 0 - Epoch 80/242 loss: 0.7761937975883484
Rank 0 - Epoch 90/242 loss: 0.7693696022033691
Rank 0 - Epoch 100/242 loss: 0.7625346183776855
Rank 0 - Epoch 110/242 loss: 0.7556896805763245
Rank 0 - Epoch 120/242 loss: 0.7488359808921814
Rank 0 - Epoch 130/242 loss: 0.7419748306274414
Rank 0 - Epoch 140/242 loss: 0.7351073026657104
Rank 0 - Epoch 150/242 loss: 0.7282346487045288
Rank 0 - Epoch 160/242 loss: 0.7213583588600159
Rank 0 - Epoch 170/242 loss: 0.7144796252250671
Rank 0 - Epoch 180/242 loss: 0.7076002359390259
Rank 0 - Epoch 190/242 loss: 0.7007213830947876
Rank 0 - Epoch 200/242 loss: 0.6938450336456299
Rank 0 - Epoch 210/242 loss: 0.6869725584983826
Rank 0 - Epoch 220/242 loss: 0.6801058650016785
Rank 0 - Epoch 230/242 loss: 0.6732469797134399
Rank 0 - Epoch 240/242 loss: 0.6663975119590759
Training complete.
[92mRank 0 - Testing RMSE: 3.8261[0m
[92mRank: 0, Lengthscale: [[0.5082376 0.5058975]] [0m
[92mRank: 0, Outputscale: 0.5106613636016846 [0m
[92mRank: 0, Noise: 0.49119803309440613 [0m
Run 1 completed successfully
Running cGP 2 with agents: 121
decADMM initialized with rho: 0.85, max_iter: 5, lr: 0.0001, rank: 0, world_size: 121
Rank 0 - Epoch 2/242 loss: 0.8289426565170288
Rank 0 - Epoch 10/242 loss: 0.8235780000686646
Rank 0 - Epoch 20/242 loss: 0.8168559670448303
Rank 0 - Epoch 30/242 loss: 0.8101170659065247
Rank 0 - Epoch 40/242 loss: 0.8033618330955505
Rank 0 - Epoch 50/242 loss: 0.7965909242630005
Rank 0 - Epoch 60/242 loss: 0.7898054122924805
Rank 0 - Epoch 70/242 loss: 0.7830060124397278
Rank 0 - Epoch 80/242 loss: 0.7761937975883484
Rank 0 - Epoch 90/242 loss: 0.7693696022033691
Rank 0 - Epoch 100/242 loss: 0.7625346183776855
Rank 0 - Epoch 110/242 loss: 0.7556896805763245
Rank 0 - Epoch 120/242 loss: 0.7488359808921814
Rank 0 - Epoch 130/242 loss: 0.7419748306274414
Rank 0 - Epoch 140/242 loss: 0.7351073026657104
Rank 0 - Epoch 150/242 loss: 0.7282346487045288
Rank 0 - Epoch 160/242 loss: 0.7213583588600159
Rank 0 - Epoch 170/242 loss: 0.7144796252250671
Rank 0 - Epoch 180/242 loss: 0.7076002359390259
Rank 0 - Epoch 190/242 loss: 0.7007213830947876
Rank 0 - Epoch 200/242 loss: 0.6938450336456299
Rank 0 - Epoch 210/242 loss: 0.6869725584983826
Rank 0 - Epoch 220/242 loss: 0.6801058650016785
Rank 0 - Epoch 230/242 loss: 0.6732469797134399
Rank 0 - Epoch 240/242 loss: 0.6663975119590759
Training complete.
[92mRank 0 - Testing RMSE: 3.8261[0m
[92mRank: 0, Lengthscale: [[0.5082376 0.5058975]] [0m
[92mRank: 0, Outputscale: 0.5106613636016846 [0m
[92mRank: 0, Noise: 0.49119803309440613 [0m
Run 2 completed successfully
Running cGP 3 with agents: 121
decADMM initialized with rho: 0.85, max_iter: 5, lr: 0.0001, rank: 0, world_size: 121
Rank 0 - Epoch 2/242 loss: 0.8289426565170288
Rank 0 - Epoch 10/242 loss: 0.8235780000686646
Rank 0 - Epoch 20/242 loss: 0.8168559670448303
Rank 0 - Epoch 30/242 loss: 0.8101170659065247
Rank 0 - Epoch 40/242 loss: 0.8033618330955505
Rank 0 - Epoch 50/242 loss: 0.7965909242630005
Rank 0 - Epoch 60/242 loss: 0.7898054122924805
Rank 0 - Epoch 70/242 loss: 0.7830060124397278
Rank 0 - Epoch 80/242 loss: 0.7761937975883484
Rank 0 - Epoch 90/242 loss: 0.7693696022033691
Rank 0 - Epoch 100/242 loss: 0.7625346183776855
Rank 0 - Epoch 110/242 loss: 0.7556896805763245
Rank 0 - Epoch 120/242 loss: 0.7488359808921814
Rank 0 - Epoch 130/242 loss: 0.7419748306274414
Rank 0 - Epoch 140/242 loss: 0.7351073026657104
Rank 0 - Epoch 150/242 loss: 0.7282346487045288
Rank 0 - Epoch 160/242 loss: 0.7213583588600159
Rank 0 - Epoch 170/242 loss: 0.7144796252250671
Rank 0 - Epoch 180/242 loss: 0.7076002359390259
Rank 0 - Epoch 190/242 loss: 0.7007213830947876
Rank 0 - Epoch 200/242 loss: 0.6938450336456299
Rank 0 - Epoch 210/242 loss: 0.6869725584983826
Rank 0 - Epoch 220/242 loss: 0.6801058650016785
Rank 0 - Epoch 230/242 loss: 0.6732469797134399
Rank 0 - Epoch 240/242 loss: 0.6663975119590759
Training complete.
[92mRank 0 - Testing RMSE: 3.8261[0m
[92mRank: 0, Lengthscale: [[0.5082376 0.5058975]] [0m
[92mRank: 0, Outputscale: 0.5106613636016846 [0m
[92mRank: 0, Noise: 0.49119803309440613 [0m
Run 3 completed successfully
Running cGP 4 with agents: 121
decADMM initialized with rho: 0.85, max_iter: 5, lr: 0.0001, rank: 0, world_size: 121
Rank 0 - Epoch 2/242 loss: 0.8289426565170288
Rank 0 - Epoch 10/242 loss: 0.8235780000686646
Rank 0 - Epoch 20/242 loss: 0.8168559670448303
Rank 0 - Epoch 30/242 loss: 0.8101170659065247
Rank 0 - Epoch 40/242 loss: 0.8033618330955505
Rank 0 - Epoch 50/242 loss: 0.7965909242630005
Rank 0 - Epoch 60/242 loss: 0.7898054122924805
Rank 0 - Epoch 70/242 loss: 0.7830060124397278
Rank 0 - Epoch 80/242 loss: 0.7761937975883484
Rank 0 - Epoch 90/242 loss: 0.7693696022033691
Rank 0 - Epoch 100/242 loss: 0.7625346183776855
Rank 0 - Epoch 110/242 loss: 0.7556896805763245
Rank 0 - Epoch 120/242 loss: 0.7488359808921814
Rank 0 - Epoch 130/242 loss: 0.7419748306274414
Rank 0 - Epoch 140/242 loss: 0.7351073026657104
Rank 0 - Epoch 150/242 loss: 0.7282346487045288
Rank 0 - Epoch 160/242 loss: 0.7213583588600159
Rank 0 - Epoch 170/242 loss: 0.7144796252250671
Rank 0 - Epoch 180/242 loss: 0.7076002359390259
Rank 0 - Epoch 190/242 loss: 0.7007213830947876
Rank 0 - Epoch 200/242 loss: 0.6938450336456299
Rank 0 - Epoch 210/242 loss: 0.6869725584983826
Rank 0 - Epoch 220/242 loss: 0.6801058650016785
Rank 0 - Epoch 230/242 loss: 0.6732469797134399
Rank 0 - Epoch 240/242 loss: 0.6663975119590759
Training complete.
[92mRank 0 - Testing RMSE: 3.8261[0m
[92mRank: 0, Lengthscale: [[0.5082376 0.5058975]] [0m
[92mRank: 0, Outputscale: 0.5106613636016846 [0m
[92mRank: 0, Noise: 0.49119803309440613 [0m
Run 4 completed successfully
Running cGP 5 with agents: 121
decADMM initialized with rho: 0.85, max_iter: 5, lr: 0.0001, rank: 0, world_size: 121
Rank 0 - Epoch 2/242 loss: 0.8289426565170288
Rank 0 - Epoch 10/242 loss: 0.8235780000686646
Rank 0 - Epoch 20/242 loss: 0.8168559670448303
Rank 0 - Epoch 30/242 loss: 0.8101170659065247
Rank 0 - Epoch 40/242 loss: 0.8033618330955505
Rank 0 - Epoch 50/242 loss: 0.7965909242630005
Rank 0 - Epoch 60/242 loss: 0.7898054122924805
Rank 0 - Epoch 70/242 loss: 0.7830060124397278
Rank 0 - Epoch 80/242 loss: 0.7761937975883484
Rank 0 - Epoch 90/242 loss: 0.7693696022033691
Rank 0 - Epoch 100/242 loss: 0.7625346183776855
Rank 0 - Epoch 110/242 loss: 0.7556896805763245
Rank 0 - Epoch 120/242 loss: 0.7488359808921814
Rank 0 - Epoch 130/242 loss: 0.7419748306274414
Rank 0 - Epoch 140/242 loss: 0.7351073026657104
Rank 0 - Epoch 150/242 loss: 0.7282346487045288
Rank 0 - Epoch 160/242 loss: 0.7213583588600159
Rank 0 - Epoch 170/242 loss: 0.7144796252250671
Rank 0 - Epoch 180/242 loss: 0.7076002359390259
Rank 0 - Epoch 190/242 loss: 0.7007213830947876
Rank 0 - Epoch 200/242 loss: 0.6938450336456299
Rank 0 - Epoch 210/242 loss: 0.6869725584983826
Rank 0 - Epoch 220/242 loss: 0.6801058650016785
Rank 0 - Epoch 230/242 loss: 0.6732469797134399
Rank 0 - Epoch 240/242 loss: 0.6663975119590759
Training complete.
[92mRank 0 - Testing RMSE: 3.8261[0m
[92mRank: 0, Lengthscale: [[0.5082376 0.5058975]] [0m
[92mRank: 0, Outputscale: 0.5106613636016846 [0m
[92mRank: 0, Noise: 0.49119803309440613 [0m
Run 5 completed successfully
Running cGP 6 with agents: 121
decADMM initialized with rho: 0.85, max_iter: 5, lr: 0.0001, rank: 0, world_size: 121
Rank 0 - Epoch 2/242 loss: 0.8289426565170288
Rank 0 - Epoch 10/242 loss: 0.8235780000686646
Rank 0 - Epoch 20/242 loss: 0.8168559670448303
Rank 0 - Epoch 30/242 loss: 0.8101170659065247
Rank 0 - Epoch 40/242 loss: 0.8033618330955505
Rank 0 - Epoch 50/242 loss: 0.7965909242630005
Rank 0 - Epoch 60/242 loss: 0.7898054122924805
Rank 0 - Epoch 70/242 loss: 0.7830060124397278
Rank 0 - Epoch 80/242 loss: 0.7761937975883484
Rank 0 - Epoch 90/242 loss: 0.7693696022033691
Rank 0 - Epoch 100/242 loss: 0.7625346183776855
Rank 0 - Epoch 110/242 loss: 0.7556896805763245
Rank 0 - Epoch 120/242 loss: 0.7488359808921814
Rank 0 - Epoch 130/242 loss: 0.7419748306274414
Rank 0 - Epoch 140/242 loss: 0.7351073026657104
Rank 0 - Epoch 150/242 loss: 0.7282346487045288
Rank 0 - Epoch 160/242 loss: 0.7213583588600159
Rank 0 - Epoch 170/242 loss: 0.7144796252250671
Rank 0 - Epoch 180/242 loss: 0.7076002359390259
Rank 0 - Epoch 190/242 loss: 0.7007213830947876
Rank 0 - Epoch 200/242 loss: 0.6938450336456299
Rank 0 - Epoch 210/242 loss: 0.6869725584983826
Rank 0 - Epoch 220/242 loss: 0.6801058650016785
Rank 0 - Epoch 230/242 loss: 0.6732469797134399
Rank 0 - Epoch 240/242 loss: 0.6663975119590759
Training complete.
[92mRank 0 - Testing RMSE: 3.8261[0m
[92mRank: 0, Lengthscale: [[0.5082376 0.5058975]] [0m
[92mRank: 0, Outputscale: 0.5106613636016846 [0m
[92mRank: 0, Noise: 0.49119803309440613 [0m
Run 6 completed successfully
Running cGP 7 with agents: 121
decADMM initialized with rho: 0.85, max_iter: 5, lr: 0.0001, rank: 0, world_size: 121
Rank 0 - Epoch 2/242 loss: 0.8289426565170288
Rank 0 - Epoch 10/242 loss: 0.8235780000686646
Rank 0 - Epoch 20/242 loss: 0.8168559670448303
Rank 0 - Epoch 30/242 loss: 0.8101170659065247
Rank 0 - Epoch 40/242 loss: 0.8033618330955505
Rank 0 - Epoch 50/242 loss: 0.7965909242630005
Rank 0 - Epoch 60/242 loss: 0.7898054122924805
Rank 0 - Epoch 70/242 loss: 0.7830060124397278
Rank 0 - Epoch 80/242 loss: 0.7761937975883484
Rank 0 - Epoch 90/242 loss: 0.7693696022033691
Rank 0 - Epoch 100/242 loss: 0.7625346183776855
Rank 0 - Epoch 110/242 loss: 0.7556896805763245
Rank 0 - Epoch 120/242 loss: 0.7488359808921814
Rank 0 - Epoch 130/242 loss: 0.7419748306274414
Rank 0 - Epoch 140/242 loss: 0.7351073026657104
Rank 0 - Epoch 150/242 loss: 0.7282346487045288
Rank 0 - Epoch 160/242 loss: 0.7213583588600159
Rank 0 - Epoch 170/242 loss: 0.7144796252250671
Rank 0 - Epoch 180/242 loss: 0.7076002359390259
Rank 0 - Epoch 190/242 loss: 0.7007213830947876
Rank 0 - Epoch 200/242 loss: 0.6938450336456299
Rank 0 - Epoch 210/242 loss: 0.6869725584983826
Rank 0 - Epoch 220/242 loss: 0.6801058650016785
Rank 0 - Epoch 230/242 loss: 0.6732469797134399
Rank 0 - Epoch 240/242 loss: 0.6663975119590759
Training complete.
[92mRank 0 - Testing RMSE: 3.8261[0m
[92mRank: 0, Lengthscale: [[0.5082376 0.5058975]] [0m
[92mRank: 0, Outputscale: 0.5106613636016846 [0m
[92mRank: 0, Noise: 0.49119803309440613 [0m
Run 7 completed successfully
Running cGP 8 with agents: 121
decADMM initialized with rho: 0.85, max_iter: 5, lr: 0.0001, rank: 0, world_size: 121
Rank 0 - Epoch 2/242 loss: 0.8289426565170288
Rank 0 - Epoch 10/242 loss: 0.8235780000686646
Rank 0 - Epoch 20/242 loss: 0.8168559670448303
Rank 0 - Epoch 30/242 loss: 0.8101170659065247
Rank 0 - Epoch 40/242 loss: 0.8033618330955505
Rank 0 - Epoch 50/242 loss: 0.7965909242630005
Rank 0 - Epoch 60/242 loss: 0.7898054122924805
Rank 0 - Epoch 70/242 loss: 0.7830060124397278
Rank 0 - Epoch 80/242 loss: 0.7761937975883484
Rank 0 - Epoch 90/242 loss: 0.7693696022033691
Rank 0 - Epoch 100/242 loss: 0.7625346183776855
Rank 0 - Epoch 110/242 loss: 0.7556896805763245
Rank 0 - Epoch 120/242 loss: 0.7488359808921814
Rank 0 - Epoch 130/242 loss: 0.7419748306274414
Rank 0 - Epoch 140/242 loss: 0.7351073026657104
Rank 0 - Epoch 150/242 loss: 0.7282346487045288
Rank 0 - Epoch 160/242 loss: 0.7213583588600159
Rank 0 - Epoch 170/242 loss: 0.7144796252250671
Rank 0 - Epoch 180/242 loss: 0.7076002359390259
Rank 0 - Epoch 190/242 loss: 0.7007213830947876
Rank 0 - Epoch 200/242 loss: 0.6938450336456299
Rank 0 - Epoch 210/242 loss: 0.6869725584983826
Rank 0 - Epoch 220/242 loss: 0.6801058650016785
Rank 0 - Epoch 230/242 loss: 0.6732469797134399
Rank 0 - Epoch 240/242 loss: 0.6663975119590759
Training complete.
[92mRank 0 - Testing RMSE: 3.8261[0m
[92mRank: 0, Lengthscale: [[0.5082376 0.5058975]] [0m
[92mRank: 0, Outputscale: 0.5106613636016846 [0m
[92mRank: 0, Noise: 0.49119803309440613 [0m
Run 8 completed successfully
Running cGP 9 with agents: 121
decADMM initialized with rho: 0.85, max_iter: 5, lr: 0.0001, rank: 0, world_size: 121
Rank 0 - Epoch 2/242 loss: 0.8289426565170288
Rank 0 - Epoch 10/242 loss: 0.8235780000686646
Rank 0 - Epoch 20/242 loss: 0.8168559670448303
Rank 0 - Epoch 30/242 loss: 0.8101170659065247
Rank 0 - Epoch 40/242 loss: 0.8033618330955505
Rank 0 - Epoch 50/242 loss: 0.7965909242630005
Rank 0 - Epoch 60/242 loss: 0.7898054122924805
Rank 0 - Epoch 70/242 loss: 0.7830060124397278
Rank 0 - Epoch 80/242 loss: 0.7761937975883484
Rank 0 - Epoch 90/242 loss: 0.7693696022033691
Rank 0 - Epoch 100/242 loss: 0.7625346183776855
Rank 0 - Epoch 110/242 loss: 0.7556896805763245
Rank 0 - Epoch 120/242 loss: 0.7488359808921814
Rank 0 - Epoch 130/242 loss: 0.7419748306274414
Rank 0 - Epoch 140/242 loss: 0.7351073026657104
Rank 0 - Epoch 150/242 loss: 0.7282346487045288
Rank 0 - Epoch 160/242 loss: 0.7213583588600159
Rank 0 - Epoch 170/242 loss: 0.7144796252250671
Rank 0 - Epoch 180/242 loss: 0.7076002359390259
Rank 0 - Epoch 190/242 loss: 0.7007213830947876
Rank 0 - Epoch 200/242 loss: 0.6938450336456299
Rank 0 - Epoch 210/242 loss: 0.6869725584983826
Rank 0 - Epoch 220/242 loss: 0.6801058650016785
Rank 0 - Epoch 230/242 loss: 0.6732469797134399
Rank 0 - Epoch 240/242 loss: 0.6663975119590759
Training complete.
[92mRank 0 - Testing RMSE: 3.8261[0m
[92mRank: 0, Lengthscale: [[0.5082376 0.5058975]] [0m
[92mRank: 0, Outputscale: 0.5106613636016846 [0m
[92mRank: 0, Noise: 0.49119803309440613 [0m
Run 9 completed successfully
Running cGP 10 with agents: 121
decADMM initialized with rho: 0.85, max_iter: 5, lr: 0.0001, rank: 0, world_size: 121
Rank 0 - Epoch 2/242 loss: 0.8289426565170288
Rank 0 - Epoch 10/242 loss: 0.8235780000686646
Rank 0 - Epoch 20/242 loss: 0.8168559670448303
Rank 0 - Epoch 30/242 loss: 0.8101170659065247
Rank 0 - Epoch 40/242 loss: 0.8033618330955505
Rank 0 - Epoch 50/242 loss: 0.7965909242630005
Rank 0 - Epoch 60/242 loss: 0.7898054122924805
Rank 0 - Epoch 70/242 loss: 0.7830060124397278
Rank 0 - Epoch 80/242 loss: 0.7761937975883484
Rank 0 - Epoch 90/242 loss: 0.7693696022033691
Rank 0 - Epoch 100/242 loss: 0.7625346183776855
Rank 0 - Epoch 110/242 loss: 0.7556896805763245
Rank 0 - Epoch 120/242 loss: 0.7488359808921814
Rank 0 - Epoch 130/242 loss: 0.7419748306274414
Rank 0 - Epoch 140/242 loss: 0.7351073026657104
Rank 0 - Epoch 150/242 loss: 0.7282346487045288
Rank 0 - Epoch 160/242 loss: 0.7213583588600159
Rank 0 - Epoch 170/242 loss: 0.7144796252250671
Rank 0 - Epoch 180/242 loss: 0.7076002359390259
Rank 0 - Epoch 190/242 loss: 0.7007213830947876
Rank 0 - Epoch 200/242 loss: 0.6938450336456299
Rank 0 - Epoch 210/242 loss: 0.6869725584983826
Rank 0 - Epoch 220/242 loss: 0.6801058650016785
Rank 0 - Epoch 230/242 loss: 0.6732469797134399
Rank 0 - Epoch 240/242 loss: 0.6663975119590759
Training complete.
[92mRank 0 - Testing RMSE: 3.8261[0m
[92mRank: 0, Lengthscale: [[0.5082376 0.5058975]] [0m
[92mRank: 0, Outputscale: 0.5106613636016846 [0m
[92mRank: 0, Noise: 0.49119803309440613 [0m
Run 10 completed successfully
