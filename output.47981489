Job started on: g005
SLURM_JOB_ID: 47981489
Running pxpGP 1 with agents: 16
[92mRank 0 - sparse dataset size is: 68, local dataset: torch.Size([1089, 2]), [0m
[92mRank 0 - Training local sparse GP model with 1089 samples[0m
Epoch 1/200 - Loss: 6.587
Epoch 11/200 - Loss: 0.891
Epoch 21/200 - Loss: 0.598
Epoch 31/200 - Loss: 0.142
Converged at epoch 34 with loss -0.035
[92mRank 0 - Lengthscale: [[0.5445359 0.4112351]] [0m
[92mRank 0 - Outputscale: 1.5491752624511719 [0m
[92mRank 0 - Noise: 0.1299944669008255 [0m
Rank 0 - Augmented dataset size: 2177
Rank 0: After warm start model parameters:
Rank: 0, Lengthscale: [[0.5445359  0.41123503]]
Rank: 0, Outputscale: 1.5491752624511719
Rank: 0, Noise: 0.1299944669008255
decpxADMM initialized with rho: 0.85, lip: 1.0, tol_abs: 1e-05, tol_rel: 0.001, rank: 0, world_size: 16
[92mRank 0 - Training global model with dec-pxADMM optimizer[0m
rank 0, epoch 9, loss: 0.2955755889415741, rho: 0.2125, lip: 1.0000
rank 0, epoch 19, loss: 0.3122302293777466, rho: 0.1062, lip: 1.0000
Rank 0 - Training time: 18.61 seconds
[92mRank 0 - Testing RMSE: 0.3133[0m
[92mRank: 0, Lengthscale: [[0.6999446  0.29513964]] [0m
[92mRank: 0, Outputscale: 1.7827188968658447 [0m
[92mRank: 0, Noise: 0.07521872967481613 [0m
Run 1 completed successfully
Running pxpGP 2 with agents: 16
[92mRank 0 - sparse dataset size is: 68, local dataset: torch.Size([1089, 2]), [0m
[92mRank 0 - Training local sparse GP model with 1089 samples[0m
Epoch 1/200 - Loss: 7.501
Epoch 11/200 - Loss: 0.958
Epoch 21/200 - Loss: 0.682
Epoch 31/200 - Loss: 0.274
Converged at epoch 36 with loss -0.018
[92mRank 0 - Lengthscale: [[0.48060998 0.3957882 ]] [0m
[92mRank 0 - Outputscale: 2.04785418510437 [0m
[92mRank 0 - Noise: 0.1284116506576538 [0m
Rank 0 - Augmented dataset size: 2177
Rank 0: After warm start model parameters:
Rank: 0, Lengthscale: [[0.48060998 0.3957882 ]]
Rank: 0, Outputscale: 2.04785418510437
Rank: 0, Noise: 0.1284116506576538
decpxADMM initialized with rho: 0.85, lip: 1.0, tol_abs: 1e-05, tol_rel: 0.001, rank: 0, world_size: 16
[92mRank 0 - Training global model with dec-pxADMM optimizer[0m
rank 0, epoch 9, loss: 0.12774957716464996, rho: 0.2125, lip: 1.0000
rank 0, epoch 19, loss: 0.1200285404920578, rho: 0.0531, lip: 1.0000
Rank 0 - Training time: 19.75 seconds
[92mRank 0 - Testing RMSE: 0.3648[0m
[92mRank: 0, Lengthscale: [[0.55058926 0.35305938]] [0m
[92mRank: 0, Outputscale: 1.8525519371032715 [0m
[92mRank: 0, Noise: 0.06151881814002991 [0m
Run 2 completed successfully
Running pxpGP 3 with agents: 16
[92mRank 0 - sparse dataset size is: 68, local dataset: torch.Size([1089, 2]), [0m
[92mRank 0 - Training local sparse GP model with 1089 samples[0m
Epoch 1/200 - Loss: 7.402
Epoch 11/200 - Loss: 0.892
Epoch 21/200 - Loss: 0.609
Epoch 31/200 - Loss: 0.174
Converged at epoch 35 with loss -0.054
[92mRank 0 - Lengthscale: [[0.5004333 0.4009738]] [0m
[92mRank 0 - Outputscale: 1.6128710508346558 [0m
[92mRank 0 - Noise: 0.12432394921779633 [0m
Rank 0 - Augmented dataset size: 2177
Rank 0: After warm start model parameters:
Rank: 0, Lengthscale: [[0.5004333 0.4009738]]
Rank: 0, Outputscale: 1.6128710508346558
Rank: 0, Noise: 0.12432394921779633
decpxADMM initialized with rho: 0.85, lip: 1.0, tol_abs: 1e-05, tol_rel: 0.001, rank: 0, world_size: 16
[92mRank 0 - Training global model with dec-pxADMM optimizer[0m
rank 0, epoch 9, loss: 0.34490683674812317, rho: 0.2125, lip: 1.0000
rank 0, epoch 19, loss: 0.364023894071579, rho: 0.1062, lip: 1.0000
Rank 0 - Training time: 18.06 seconds
[92mRank 0 - Testing RMSE: 0.3147[0m
[92mRank: 0, Lengthscale: [[0.38726377 0.3361289 ]] [0m
[92mRank: 0, Outputscale: 1.1736414432525635 [0m
[92mRank: 0, Noise: 0.08563531190156937 [0m
Run 3 completed successfully
Running pxpGP 4 with agents: 16
[92mRank 0 - sparse dataset size is: 68, local dataset: torch.Size([1089, 2]), [0m
[92mRank 0 - Training local sparse GP model with 1089 samples[0m
Epoch 1/200 - Loss: 7.614
Epoch 11/200 - Loss: 0.940
Epoch 21/200 - Loss: 0.673
Epoch 31/200 - Loss: 0.229
Converged at epoch 36 with loss -0.051
[92mRank 0 - Lengthscale: [[0.5083382 0.4908684]] [0m
[92mRank 0 - Outputscale: 2.0848610401153564 [0m
[92mRank 0 - Noise: 0.12612438201904297 [0m
Rank 0 - Augmented dataset size: 2177
Rank 0: After warm start model parameters:
Rank: 0, Lengthscale: [[0.5083382 0.4908684]]
Rank: 0, Outputscale: 2.0848610401153564
Rank: 0, Noise: 0.12612438201904297
decpxADMM initialized with rho: 0.85, lip: 1.0, tol_abs: 1e-05, tol_rel: 0.001, rank: 0, world_size: 16
[92mRank 0 - Training global model with dec-pxADMM optimizer[0m
rank 0, epoch 9, loss: 0.3711773753166199, rho: 0.2125, lip: 1.0000
rank 0, epoch 19, loss: 0.3979862928390503, rho: 0.1062, lip: 1.0000
Rank 0 - Training time: 19.45 seconds
[92mRank 0 - Testing RMSE: 0.4221[0m
[92mRank: 0, Lengthscale: [[0.34773943 0.3270046 ]] [0m
[92mRank: 0, Outputscale: 1.7651032209396362 [0m
[92mRank: 0, Noise: 0.09241266548633575 [0m
Run 4 completed successfully
Running pxpGP 5 with agents: 16
[92mRank 0 - sparse dataset size is: 68, local dataset: torch.Size([1089, 2]), [0m
[92mRank 0 - Training local sparse GP model with 1089 samples[0m
Epoch 1/200 - Loss: 6.177
Epoch 11/200 - Loss: 0.896
Epoch 21/200 - Loss: 0.654
Epoch 31/200 - Loss: 0.186
Converged at epoch 35 with loss -0.046
[92mRank 0 - Lengthscale: [[0.5220779 0.3749873]] [0m
[92mRank 0 - Outputscale: 1.5819364786148071 [0m
[92mRank 0 - Noise: 0.12571631371974945 [0m
Rank 0 - Augmented dataset size: 2177
Rank 0: After warm start model parameters:
Rank: 0, Lengthscale: [[0.5220779 0.3749873]]
Rank: 0, Outputscale: 1.5819364786148071
Rank: 0, Noise: 0.12571631371974945
decpxADMM initialized with rho: 0.85, lip: 1.0, tol_abs: 1e-05, tol_rel: 0.001, rank: 0, world_size: 16
[92mRank 0 - Training global model with dec-pxADMM optimizer[0m
rank 0, epoch 9, loss: 0.32182776927948, rho: 0.2125, lip: 1.0000
rank 0, epoch 19, loss: 0.3386608958244324, rho: 0.1062, lip: 1.0000
Rank 0 - Training time: 21.47 seconds
[92mRank 0 - Testing RMSE: 0.4393[0m
[92mRank: 0, Lengthscale: [[0.33854583 0.35628247]] [0m
[92mRank: 0, Outputscale: 2.8993613719940186 [0m
[92mRank: 0, Noise: 0.07905762642621994 [0m
Run 5 completed successfully
Running pxpGP 6 with agents: 16
[92mRank 0 - sparse dataset size is: 68, local dataset: torch.Size([1089, 2]), [0m
[92mRank 0 - Training local sparse GP model with 1089 samples[0m
Epoch 1/200 - Loss: 7.591
Epoch 11/200 - Loss: 0.891
Epoch 21/200 - Loss: 0.605
Epoch 31/200 - Loss: 0.153
Converged at epoch 36 with loss -0.088
[92mRank 0 - Lengthscale: [[0.5999698 0.3934874]] [0m
[92mRank 0 - Outputscale: 1.5836385488510132 [0m
[92mRank 0 - Noise: 0.1079593151807785 [0m
Rank 0 - Augmented dataset size: 2177
Rank 0: After warm start model parameters:
Rank: 0, Lengthscale: [[0.5999698  0.39348742]]
Rank: 0, Outputscale: 1.5836385488510132
Rank: 0, Noise: 0.1079593151807785
decpxADMM initialized with rho: 0.85, lip: 1.0, tol_abs: 1e-05, tol_rel: 0.001, rank: 0, world_size: 16
[92mRank 0 - Training global model with dec-pxADMM optimizer[0m
rank 0, epoch 9, loss: 0.3198460340499878, rho: 0.4250, lip: 1.0000
rank 0, epoch 19, loss: 0.3352901339530945, rho: 0.2125, lip: 1.0000
Rank 0 - Training time: 18.17 seconds
[92mRank 0 - Testing RMSE: 0.3897[0m
[92mRank: 0, Lengthscale: [[0.42237315 0.2977939 ]] [0m
[92mRank: 0, Outputscale: 1.1111860275268555 [0m
[92mRank: 0, Noise: 0.08501812815666199 [0m
Run 6 completed successfully
Running pxpGP 7 with agents: 16
[92mRank 0 - sparse dataset size is: 68, local dataset: torch.Size([1089, 2]), [0m
[92mRank 0 - Training local sparse GP model with 1089 samples[0m
Epoch 1/200 - Loss: 6.947
Epoch 11/200 - Loss: 0.883
Epoch 21/200 - Loss: 0.606
Epoch 31/200 - Loss: 0.158
Converged at epoch 36 with loss -0.002
[92mRank 0 - Lengthscale: [[0.5952827 0.4321296]] [0m
[92mRank 0 - Outputscale: 1.5686845779418945 [0m
[92mRank 0 - Noise: 0.13400551676750183 [0m
Rank 0 - Augmented dataset size: 2177
Rank 0: After warm start model parameters:
Rank: 0, Lengthscale: [[0.5952827 0.4321296]]
Rank: 0, Outputscale: 1.5686845779418945
Rank: 0, Noise: 0.13400551676750183
decpxADMM initialized with rho: 0.85, lip: 1.0, tol_abs: 1e-05, tol_rel: 0.001, rank: 0, world_size: 16
[92mRank 0 - Training global model with dec-pxADMM optimizer[0m
rank 0, epoch 9, loss: 0.2596748471260071, rho: 0.2125, lip: 1.0000
rank 0, epoch 19, loss: 0.26595017313957214, rho: 0.0531, lip: 1.0000
Rank 0 - Training time: 20.07 seconds
[92mRank 0 - Testing RMSE: 0.4006[0m
[92mRank: 0, Lengthscale: [[0.5609557  0.20656131]] [0m
[92mRank: 0, Outputscale: 1.7704637050628662 [0m
[92mRank: 0, Noise: 0.07165103405714035 [0m
Run 7 completed successfully
Running pxpGP 8 with agents: 16
[92mRank 0 - sparse dataset size is: 68, local dataset: torch.Size([1089, 2]), [0m
[92mRank 0 - Training local sparse GP model with 1089 samples[0m
Epoch 1/200 - Loss: 7.194
Epoch 11/200 - Loss: 0.979
Epoch 21/200 - Loss: 0.667
Epoch 31/200 - Loss: 0.233
Converged at epoch 36 with loss -0.040
[92mRank 0 - Lengthscale: [[0.5471143 0.4941072]] [0m
[92mRank 0 - Outputscale: 2.050706148147583 [0m
[92mRank 0 - Noise: 0.12364016473293304 [0m
Rank 0 - Augmented dataset size: 2177
Rank 0: After warm start model parameters:
Rank: 0, Lengthscale: [[0.5471143  0.49410722]]
Rank: 0, Outputscale: 2.050706148147583
Rank: 0, Noise: 0.12364016473293304
decpxADMM initialized with rho: 0.85, lip: 1.0, tol_abs: 1e-05, tol_rel: 0.001, rank: 0, world_size: 16
[92mRank 0 - Training global model with dec-pxADMM optimizer[0m
rank 0, epoch 9, loss: 0.4476082921028137, rho: 0.4250, lip: 1.0000
rank 0, epoch 19, loss: 0.4733954668045044, rho: 0.1062, lip: 1.0000
Rank 0 - Training time: 19.45 seconds
[92mRank 0 - Testing RMSE: 0.4225[0m
[92mRank: 0, Lengthscale: [[0.23774004 0.32980004]] [0m
[92mRank: 0, Outputscale: 1.6471706628799438 [0m
[92mRank: 0, Noise: 0.08127610385417938 [0m
Run 8 completed successfully
Running pxpGP 9 with agents: 16
[92mRank 0 - sparse dataset size is: 68, local dataset: torch.Size([1089, 2]), [0m
[92mRank 0 - Training local sparse GP model with 1089 samples[0m
Epoch 1/200 - Loss: 7.101
Epoch 11/200 - Loss: 0.889
Epoch 21/200 - Loss: 0.598
Epoch 31/200 - Loss: 0.144
Converged at epoch 34 with loss -0.035
[92mRank 0 - Lengthscale: [[0.54872733 0.3910774 ]] [0m
[92mRank 0 - Outputscale: 1.5422297716140747 [0m
[92mRank 0 - Noise: 0.12785285711288452 [0m
Rank 0 - Augmented dataset size: 2177
Rank 0: After warm start model parameters:
Rank: 0, Lengthscale: [[0.5487273  0.39107743]]
Rank: 0, Outputscale: 1.5422297716140747
Rank: 0, Noise: 0.12785285711288452
decpxADMM initialized with rho: 0.85, lip: 1.0, tol_abs: 1e-05, tol_rel: 0.001, rank: 0, world_size: 16
[92mRank 0 - Training global model with dec-pxADMM optimizer[0m
rank 0, epoch 9, loss: 0.4387148320674896, rho: 0.2125, lip: 1.0000
rank 0, epoch 19, loss: 0.46867942810058594, rho: 0.1062, lip: 1.0000
Rank 0 - Training time: 16.99 seconds
[92mRank 0 - Testing RMSE: 0.3297[0m
[92mRank: 0, Lengthscale: [[0.47992247 0.29580024]] [0m
[92mRank: 0, Outputscale: 0.8636971712112427 [0m
[92mRank: 0, Noise: 0.09757237881422043 [0m
Run 9 completed successfully
Running pxpGP 10 with agents: 16
[92mRank 0 - sparse dataset size is: 68, local dataset: torch.Size([1089, 2]), [0m
[92mRank 0 - Training local sparse GP model with 1089 samples[0m
Epoch 1/200 - Loss: 7.586
Epoch 11/200 - Loss: 0.985
Epoch 21/200 - Loss: 0.705
Epoch 31/200 - Loss: 0.282
Converged at epoch 36 with loss -0.023
[92mRank 0 - Lengthscale: [[0.41528508 0.42011327]] [0m
[92mRank 0 - Outputscale: 2.0839788913726807 [0m
[92mRank 0 - Noise: 0.13231346011161804 [0m
Rank 0 - Augmented dataset size: 2177
Rank 0: After warm start model parameters:
Rank: 0, Lengthscale: [[0.41528508 0.42011327]]
Rank: 0, Outputscale: 2.0839788913726807
Rank: 0, Noise: 0.13231346011161804
decpxADMM initialized with rho: 0.85, lip: 1.0, tol_abs: 1e-05, tol_rel: 0.001, rank: 0, world_size: 16
[92mRank 0 - Training global model with dec-pxADMM optimizer[0m
rank 0, epoch 9, loss: 0.3729565441608429, rho: 0.4250, lip: 1.0000
rank 0, epoch 19, loss: 0.3955672085285187, rho: 0.1062, lip: 1.0000
Rank 0 - Training time: 21.02 seconds
[92mRank 0 - Testing RMSE: 0.4289[0m
[92mRank: 0, Lengthscale: [[0.27808663 0.29532316]] [0m
[92mRank: 0, Outputscale: 1.8993308544158936 [0m
[92mRank: 0, Noise: 0.08758094906806946 [0m
Run 10 completed successfully
Running gapxGP 1 with agents: 16
decpxADMM initialized with rho: 0.75, lip: 1.0, tol_abs: 1e-05, tol_rel: 0.001, rank: 0, world_size: 16
Rank 0 - Epoch 2/24 loss: 0.8510867953300476
Rank 0 - Epoch 10/24 loss: 0.5918471813201904
Rank 0 - Epoch 20/24 loss: 0.16349810361862183
[92mRank 0 - Testing RMSE: 0.1061[0m
[92mRank: 0, Lengthscale: [[0.6376075 0.4400506]] [0m
[92mRank: 0, Outputscale: 0.8704783916473389 [0m
[92mRank: 0, Noise: 0.10237434506416321 [0m
Run 1 completed successfully
Running gapxGP 2 with agents: 16
decpxADMM initialized with rho: 0.75, lip: 1.0, tol_abs: 1e-05, tol_rel: 0.001, rank: 0, world_size: 16
Rank 0 - Epoch 2/24 loss: 0.8482809066772461
Rank 0 - Epoch 10/24 loss: 0.5919225811958313
Rank 0 - Epoch 20/24 loss: 0.1677657663822174
[92mRank 0 - Testing RMSE: 0.1048[0m
[92mRank: 0, Lengthscale: [[0.6312174 0.4414494]] [0m
[92mRank: 0, Outputscale: 0.8701188564300537 [0m
[92mRank: 0, Noise: 0.1025678962469101 [0m
Run 2 completed successfully
Running gapxGP 3 with agents: 16
decpxADMM initialized with rho: 0.75, lip: 1.0, tol_abs: 1e-05, tol_rel: 0.001, rank: 0, world_size: 16
Rank 0 - Epoch 2/24 loss: 0.8464534282684326
Rank 0 - Epoch 10/24 loss: 0.5912436842918396
Rank 0 - Epoch 20/24 loss: 0.15865373611450195
[92mRank 0 - Testing RMSE: 0.1094[0m
[92mRank: 0, Lengthscale: [[0.6375357 0.4429926]] [0m
[92mRank: 0, Outputscale: 0.8663586378097534 [0m
[92mRank: 0, Noise: 0.10257653892040253 [0m
Run 3 completed successfully
Running gapxGP 4 with agents: 16
decpxADMM initialized with rho: 0.75, lip: 1.0, tol_abs: 1e-05, tol_rel: 0.001, rank: 0, world_size: 16
Rank 0 - Epoch 2/24 loss: 0.8442766070365906
Rank 0 - Epoch 10/24 loss: 0.5911747217178345
Rank 0 - Epoch 20/24 loss: 0.16894757747650146
[92mRank 0 - Testing RMSE: 0.1099[0m
[92mRank: 0, Lengthscale: [[0.63310397 0.44566444]] [0m
[92mRank: 0, Outputscale: 0.8658374547958374 [0m
[92mRank: 0, Noise: 0.10366750508546829 [0m
Run 4 completed successfully
Running gapxGP 5 with agents: 16
decpxADMM initialized with rho: 0.75, lip: 1.0, tol_abs: 1e-05, tol_rel: 0.001, rank: 0, world_size: 16
Rank 0 - Epoch 2/24 loss: 0.8480573296546936
Rank 0 - Epoch 10/24 loss: 0.594717800617218
Rank 0 - Epoch 20/24 loss: 0.16684946417808533
[92mRank 0 - Testing RMSE: 0.1042[0m
[92mRank: 0, Lengthscale: [[0.6328987  0.44059458]] [0m
[92mRank: 0, Outputscale: 0.8689157962799072 [0m
[92mRank: 0, Noise: 0.10322283208370209 [0m
Run 5 completed successfully
Running gapxGP 6 with agents: 16
decpxADMM initialized with rho: 0.75, lip: 1.0, tol_abs: 1e-05, tol_rel: 0.001, rank: 0, world_size: 16
Rank 0 - Epoch 2/24 loss: 0.8469589352607727
Rank 0 - Epoch 10/24 loss: 0.5883690714836121
Rank 0 - Epoch 20/24 loss: 0.16028156876564026
[92mRank 0 - Testing RMSE: 0.1070[0m
[92mRank: 0, Lengthscale: [[0.63752484 0.44115406]] [0m
[92mRank: 0, Outputscale: 0.8700830936431885 [0m
[92mRank: 0, Noise: 0.10236778110265732 [0m
Run 6 completed successfully
Running gapxGP 7 with agents: 16
decpxADMM initialized with rho: 0.75, lip: 1.0, tol_abs: 1e-05, tol_rel: 0.001, rank: 0, world_size: 16
Rank 0 - Epoch 2/24 loss: 0.8467332124710083
Rank 0 - Epoch 10/24 loss: 0.5928022861480713
Rank 0 - Epoch 20/24 loss: 0.1675889939069748
[92mRank 0 - Testing RMSE: 0.1128[0m
[92mRank: 0, Lengthscale: [[0.62859464 0.4476084 ]] [0m
[92mRank: 0, Outputscale: 0.8676033616065979 [0m
[92mRank: 0, Noise: 0.10312414914369583 [0m
Run 7 completed successfully
Running gapxGP 8 with agents: 16
decpxADMM initialized with rho: 0.75, lip: 1.0, tol_abs: 1e-05, tol_rel: 0.001, rank: 0, world_size: 16
Rank 0 - Epoch 2/24 loss: 0.8475029468536377
Rank 0 - Epoch 10/24 loss: 0.5961874723434448
Rank 0 - Epoch 20/24 loss: 0.16227231919765472
[92mRank 0 - Testing RMSE: 0.1041[0m
[92mRank: 0, Lengthscale: [[0.63585013 0.4416614 ]] [0m
[92mRank: 0, Outputscale: 0.8688712120056152 [0m
[92mRank: 0, Noise: 0.10277731716632843 [0m
Run 8 completed successfully
Running gapxGP 9 with agents: 16
decpxADMM initialized with rho: 0.75, lip: 1.0, tol_abs: 1e-05, tol_rel: 0.001, rank: 0, world_size: 16
Rank 0 - Epoch 2/24 loss: 0.8465635180473328
Rank 0 - Epoch 10/24 loss: 0.5941913723945618
Rank 0 - Epoch 20/24 loss: 0.17036084830760956
[92mRank 0 - Testing RMSE: 0.1047[0m
[92mRank: 0, Lengthscale: [[0.6327492  0.44139475]] [0m
[92mRank: 0, Outputscale: 0.8687492609024048 [0m
[92mRank: 0, Noise: 0.10334082692861557 [0m
Run 9 completed successfully
Running gapxGP 10 with agents: 16
decpxADMM initialized with rho: 0.75, lip: 1.0, tol_abs: 1e-05, tol_rel: 0.001, rank: 0, world_size: 16
Rank 0 - Epoch 2/24 loss: 0.8475901484489441
Rank 0 - Epoch 10/24 loss: 0.5925335884094238
Rank 0 - Epoch 20/24 loss: 0.1636197715997696
[92mRank 0 - Testing RMSE: 0.1064[0m
[92mRank: 0, Lengthscale: [[0.6312713  0.44342613]] [0m
[92mRank: 0, Outputscale: 0.8683100938796997 [0m
[92mRank: 0, Noise: 0.10320033878087997 [0m
Run 10 completed successfully
Running apxGP 1 with agents: 16
decpxADMM initialized with rho: 0.85, lip: 1.0, tol_abs: 1e-05, tol_rel: 0.001, rank: 0, world_size: 16
Rank 0 - Epoch 2/32 loss: 0.7681698203086853
Rank 0 - Epoch 10/32 loss: 0.5000507831573486
Rank 0 - Epoch 20/32 loss: 0.07118778675794601
Rank 0 - Epoch 30/32 loss: -0.41876500844955444
Training complete.
[92mRank 0 - Testing RMSE: 2.9496[0m
[92mRank: 0, Lengthscale: [[0.64128995 0.49548745]] [0m
[92mRank: 0, Outputscale: 0.7972060441970825 [0m
[92mRank: 0, Noise: 0.04671443626284599 [0m
Run 1 completed successfully
Running apxGP 2 with agents: 16
decpxADMM initialized with rho: 0.85, lip: 1.0, tol_abs: 1e-05, tol_rel: 0.001, rank: 0, world_size: 16
Rank 0 - Epoch 2/32 loss: 0.7681879997253418
Rank 0 - Epoch 10/32 loss: 0.5000515580177307
Rank 0 - Epoch 20/32 loss: 0.0711761862039566
Rank 0 - Epoch 30/32 loss: -0.41907986998558044
Training complete.
[92mRank 0 - Testing RMSE: 2.9490[0m
[92mRank: 0, Lengthscale: [[0.64134353 0.49547565]] [0m
[92mRank: 0, Outputscale: 0.7972012162208557 [0m
[92mRank: 0, Noise: 0.046715084463357925 [0m
Run 2 completed successfully
Running apxGP 3 with agents: 16
decpxADMM initialized with rho: 0.85, lip: 1.0, tol_abs: 1e-05, tol_rel: 0.001, rank: 0, world_size: 16
Rank 0 - Epoch 2/32 loss: 0.7681751251220703
Rank 0 - Epoch 10/32 loss: 0.5000511407852173
Rank 0 - Epoch 20/32 loss: 0.07113666832447052
Rank 0 - Epoch 30/32 loss: -0.41903167963027954
Training complete.
[92mRank 0 - Testing RMSE: 2.9502[0m
[92mRank: 0, Lengthscale: [[0.6413369 0.4953681]] [0m
[92mRank: 0, Outputscale: 0.7972163558006287 [0m
[92mRank: 0, Noise: 0.04671311005949974 [0m
Run 3 completed successfully
Running apxGP 4 with agents: 16
decpxADMM initialized with rho: 0.85, lip: 1.0, tol_abs: 1e-05, tol_rel: 0.001, rank: 0, world_size: 16
Rank 0 - Epoch 2/32 loss: 0.768171489238739
Rank 0 - Epoch 10/32 loss: 0.5000452399253845
Rank 0 - Epoch 20/32 loss: 0.0711212009191513
Rank 0 - Epoch 30/32 loss: -0.4189819097518921
Training complete.
[92mRank 0 - Testing RMSE: 2.9495[0m
[92mRank: 0, Lengthscale: [[0.6413363  0.49549478]] [0m
[92mRank: 0, Outputscale: 0.7971981763839722 [0m
[92mRank: 0, Noise: 0.04671517014503479 [0m
Run 4 completed successfully
Running apxGP 5 with agents: 16
decpxADMM initialized with rho: 0.85, lip: 1.0, tol_abs: 1e-05, tol_rel: 0.001, rank: 0, world_size: 16
Rank 0 - Epoch 2/32 loss: 0.7681843042373657
Rank 0 - Epoch 10/32 loss: 0.5000578165054321
Rank 0 - Epoch 20/32 loss: 0.07116150110960007
Rank 0 - Epoch 30/32 loss: -0.41894447803497314
Training complete.
[92mRank 0 - Testing RMSE: 2.9625[0m
[92mRank: 0, Lengthscale: [[0.6412476  0.49538893]] [0m
[92mRank: 0, Outputscale: 0.7972276210784912 [0m
[92mRank: 0, Noise: 0.04671191796660423 [0m
Run 5 completed successfully
Running apxGP 6 with agents: 16
decpxADMM initialized with rho: 0.85, lip: 1.0, tol_abs: 1e-05, tol_rel: 0.001, rank: 0, world_size: 16
Rank 0 - Epoch 2/32 loss: 0.7681747674942017
Rank 0 - Epoch 10/32 loss: 0.5000630021095276
Rank 0 - Epoch 20/32 loss: 0.07116435468196869
Rank 0 - Epoch 30/32 loss: -0.4188530147075653
Training complete.
[92mRank 0 - Testing RMSE: 2.9501[0m
[92mRank: 0, Lengthscale: [[0.6412758  0.49540085]] [0m
[92mRank: 0, Outputscale: 0.7972195148468018 [0m
[92mRank: 0, Noise: 0.04671293497085571 [0m
Run 6 completed successfully
Running apxGP 7 with agents: 16
decpxADMM initialized with rho: 0.85, lip: 1.0, tol_abs: 1e-05, tol_rel: 0.001, rank: 0, world_size: 16
Rank 0 - Epoch 2/32 loss: 0.768173098564148
Rank 0 - Epoch 10/32 loss: 0.5000565052032471
Rank 0 - Epoch 20/32 loss: 0.07119383662939072
Rank 0 - Epoch 30/32 loss: -0.41901901364326477
Training complete.
[92mRank 0 - Testing RMSE: 2.9498[0m
[92mRank: 0, Lengthscale: [[0.6412361  0.49545586]] [0m
[92mRank: 0, Outputscale: 0.7972159385681152 [0m
[92mRank: 0, Noise: 0.04671322926878929 [0m
Run 7 completed successfully
Running apxGP 8 with agents: 16
decpxADMM initialized with rho: 0.85, lip: 1.0, tol_abs: 1e-05, tol_rel: 0.001, rank: 0, world_size: 16
Rank 0 - Epoch 2/32 loss: 0.7681755423545837
Rank 0 - Epoch 10/32 loss: 0.5000669360160828
Rank 0 - Epoch 20/32 loss: 0.07118996977806091
Rank 0 - Epoch 30/32 loss: -0.41889527440071106
Training complete.
[92mRank 0 - Testing RMSE: 2.9628[0m
[92mRank: 0, Lengthscale: [[0.64136946 0.49543256]] [0m
[92mRank: 0, Outputscale: 0.7972012758255005 [0m
[92mRank: 0, Noise: 0.04671470448374748 [0m
Run 8 completed successfully
Running apxGP 9 with agents: 16
decpxADMM initialized with rho: 0.85, lip: 1.0, tol_abs: 1e-05, tol_rel: 0.001, rank: 0, world_size: 16
Rank 0 - Epoch 2/32 loss: 0.768170177936554
Rank 0 - Epoch 10/32 loss: 0.5000478625297546
Rank 0 - Epoch 20/32 loss: 0.07111251354217529
Rank 0 - Epoch 30/32 loss: -0.4190540909767151
Training complete.
[92mRank 0 - Testing RMSE: 2.9624[0m
[92mRank: 0, Lengthscale: [[0.64147496 0.49545202]] [0m
[92mRank: 0, Outputscale: 0.7971851229667664 [0m
[92mRank: 0, Noise: 0.046716734766960144 [0m
Run 9 completed successfully
Running apxGP 10 with agents: 16
decpxADMM initialized with rho: 0.85, lip: 1.0, tol_abs: 1e-05, tol_rel: 0.001, rank: 0, world_size: 16
Rank 0 - Epoch 2/32 loss: 0.7681655287742615
Rank 0 - Epoch 10/32 loss: 0.5000331997871399
Rank 0 - Epoch 20/32 loss: 0.07114110141992569
Rank 0 - Epoch 30/32 loss: -0.41887977719306946
Training complete.
[92mRank 0 - Testing RMSE: 2.9500[0m
[92mRank: 0, Lengthscale: [[0.6413402 0.4954214]] [0m
[92mRank: 0, Outputscale: 0.7972055673599243 [0m
[92mRank: 0, Noise: 0.046714358031749725 [0m
Run 10 completed successfully
Running cGP 1 with agents: 16
decADMM initialized with rho: 0.85, max_iter: 5, lr: 0.0001, rank: 0, world_size: 16
Rank 0 - Epoch 2/32 loss: 0.8225415349006653
Rank 0 - Epoch 10/32 loss: 0.8183331489562988
Rank 0 - Epoch 20/32 loss: 0.8099687695503235
Rank 0 - Epoch 30/32 loss: 0.803822934627533
Training complete.
[92mRank 0 - Testing RMSE: 3.0934[0m
[92mRank: 0, Lengthscale: [[0.666186   0.66575605]] [0m
[92mRank: 0, Outputscale: 0.6665658354759216 [0m
[92mRank: 0, Noise: 0.6637742519378662 [0m
Run 1 completed successfully
Running cGP 2 with agents: 16
decADMM initialized with rho: 0.85, max_iter: 5, lr: 0.0001, rank: 0, world_size: 16
Rank 0 - Epoch 2/32 loss: 0.8204570412635803
Rank 0 - Epoch 10/32 loss: 0.818093478679657
Rank 0 - Epoch 20/32 loss: 0.8093557357788086
Rank 0 - Epoch 30/32 loss: 0.80001300573349
Training complete.
[92mRank 0 - Testing RMSE: 3.0924[0m
[92mRank: 0, Lengthscale: [[0.6661885 0.6657569]] [0m
[92mRank: 0, Outputscale: 0.6665659546852112 [0m
[92mRank: 0, Noise: 0.663772702217102 [0m
Run 2 completed successfully
Running cGP 3 with agents: 16
decADMM initialized with rho: 0.85, max_iter: 5, lr: 0.0001, rank: 0, world_size: 16
Rank 0 - Epoch 2/32 loss: 0.8217166662216187
Rank 0 - Epoch 10/32 loss: 0.8177053928375244
Rank 0 - Epoch 20/32 loss: 0.8097178339958191
Rank 0 - Epoch 30/32 loss: 0.8068492412567139
Training complete.
[92mRank 0 - Testing RMSE: 3.0936[0m
[92mRank: 0, Lengthscale: [[0.66618824 0.66575706]] [0m
[92mRank: 0, Outputscale: 0.6665659546852112 [0m
[92mRank: 0, Noise: 0.6637707352638245 [0m
Run 3 completed successfully
Running cGP 4 with agents: 16
decADMM initialized with rho: 0.85, max_iter: 5, lr: 0.0001, rank: 0, world_size: 16
Rank 0 - Epoch 2/32 loss: 0.8246645927429199
Rank 0 - Epoch 10/32 loss: 0.8160847425460815
Rank 0 - Epoch 20/32 loss: 0.8092727065086365
Rank 0 - Epoch 30/32 loss: 0.803499698638916
Training complete.
[92mRank 0 - Testing RMSE: 3.0918[0m
[92mRank: 0, Lengthscale: [[0.6661867 0.6657566]] [0m
[92mRank: 0, Outputscale: 0.6665658354759216 [0m
[92mRank: 0, Noise: 0.6637787222862244 [0m
Run 4 completed successfully
Running cGP 5 with agents: 16
decADMM initialized with rho: 0.85, max_iter: 5, lr: 0.0001, rank: 0, world_size: 16
Rank 0 - Epoch 2/32 loss: 0.8213041424751282
Rank 0 - Epoch 10/32 loss: 0.8176345229148865
Rank 0 - Epoch 20/32 loss: 0.8075186014175415
Rank 0 - Epoch 30/32 loss: 0.8035150170326233
Training complete.
[92mRank 0 - Testing RMSE: 3.0941[0m
[92mRank: 0, Lengthscale: [[0.6661869 0.6657574]] [0m
[92mRank: 0, Outputscale: 0.6665658354759216 [0m
[92mRank: 0, Noise: 0.6637753248214722 [0m
Run 5 completed successfully
Running cGP 6 with agents: 16
decADMM initialized with rho: 0.85, max_iter: 5, lr: 0.0001, rank: 0, world_size: 16
Rank 0 - Epoch 2/32 loss: 0.8239387273788452
Rank 0 - Epoch 10/32 loss: 0.8190501928329468
Rank 0 - Epoch 20/32 loss: 0.8063707947731018
Rank 0 - Epoch 30/32 loss: 0.8086108565330505
Training complete.
[92mRank 0 - Testing RMSE: 3.0919[0m
[92mRank: 0, Lengthscale: [[0.66618824 0.6657574 ]] [0m
[92mRank: 0, Outputscale: 0.6665654182434082 [0m
[92mRank: 0, Noise: 0.6637771725654602 [0m
Run 6 completed successfully
Running cGP 7 with agents: 16
decADMM initialized with rho: 0.85, max_iter: 5, lr: 0.0001, rank: 0, world_size: 16
Rank 0 - Epoch 2/32 loss: 0.8196523189544678
Rank 0 - Epoch 10/32 loss: 0.8178971409797668
Rank 0 - Epoch 20/32 loss: 0.8117492198944092
Rank 0 - Epoch 30/32 loss: 0.7995793223381042
Training complete.
[92mRank 0 - Testing RMSE: 3.0932[0m
[92mRank: 0, Lengthscale: [[0.66618794 0.66575575]] [0m
[92mRank: 0, Outputscale: 0.6665655970573425 [0m
[92mRank: 0, Noise: 0.6637750864028931 [0m
Run 7 completed successfully
Running cGP 8 with agents: 16
decADMM initialized with rho: 0.85, max_iter: 5, lr: 0.0001, rank: 0, world_size: 16
Rank 0 - Epoch 2/32 loss: 0.8225057721138
Rank 0 - Epoch 10/32 loss: 0.8170869946479797
Rank 0 - Epoch 20/32 loss: 0.8081442713737488
Rank 0 - Epoch 30/32 loss: 0.8009620308876038
Training complete.
[92mRank 0 - Testing RMSE: 3.0915[0m
[92mRank: 0, Lengthscale: [[0.666186  0.6657584]] [0m
[92mRank: 0, Outputscale: 0.6665655374526978 [0m
[92mRank: 0, Noise: 0.6637725234031677 [0m
Run 8 completed successfully
Running cGP 9 with agents: 16
decADMM initialized with rho: 0.85, max_iter: 5, lr: 0.0001, rank: 0, world_size: 16
Rank 0 - Epoch 2/32 loss: 0.8191511034965515
Rank 0 - Epoch 10/32 loss: 0.8197663426399231
Rank 0 - Epoch 20/32 loss: 0.8113231658935547
Rank 0 - Epoch 30/32 loss: 0.8006542921066284
Training complete.
[92mRank 0 - Testing RMSE: 3.0935[0m
[92mRank: 0, Lengthscale: [[0.66618776 0.6657567 ]] [0m
[92mRank: 0, Outputscale: 0.6665659546852112 [0m
[92mRank: 0, Noise: 0.6637688875198364 [0m
Run 9 completed successfully
Running cGP 10 with agents: 16
decADMM initialized with rho: 0.85, max_iter: 5, lr: 0.0001, rank: 0, world_size: 16
Rank 0 - Epoch 2/32 loss: 0.8249590396881104
Rank 0 - Epoch 10/32 loss: 0.8162649273872375
Rank 0 - Epoch 20/32 loss: 0.8082876205444336
Rank 0 - Epoch 30/32 loss: 0.8041307330131531
Training complete.
[92mRank 0 - Testing RMSE: 3.0924[0m
[92mRank: 0, Lengthscale: [[0.66618824 0.6657553 ]] [0m
[92mRank: 0, Outputscale: 0.6665661334991455 [0m
[92mRank: 0, Noise: 0.6637778282165527 [0m
Run 10 completed successfully
Running pxpGP 1 with agents: 36
[92mRank 0 - sparse dataset size is: 13, local dataset: torch.Size([484, 2]), [0m
[92mRank 0 - Training local sparse GP model with 484 samples[0m
Epoch 1/200 - Loss: 13.700
Epoch 11/200 - Loss: 1.287
Epoch 21/200 - Loss: 1.041
Epoch 31/200 - Loss: 0.920
Epoch 41/200 - Loss: 0.818
Epoch 51/200 - Loss: 0.694
Epoch 61/200 - Loss: 0.532
Epoch 71/200 - Loss: 0.318
Epoch 81/200 - Loss: 0.111
Epoch 91/200 - Loss: 0.204
Converged at epoch 93 with loss -0.031
[92mRank 0 - Lengthscale: [[0.4930127 0.550594 ]] [0m
[92mRank 0 - Outputscale: 1.9106279611587524 [0m
[92mRank 0 - Noise: 0.12761706113815308 [0m
Rank 0 - Augmented dataset size: 952
Rank 0: After warm start model parameters:
Rank: 0, Lengthscale: [[0.4930127 0.550594 ]]
Rank: 0, Outputscale: 1.9106279611587524
Rank: 0, Noise: 0.12761706113815308
decpxADMM initialized with rho: 0.85, lip: 1.0, tol_abs: 1e-05, tol_rel: 0.001, rank: 0, world_size: 36
[92mRank 0 - Training global model with dec-pxADMM optimizer[0m
rank 0, epoch 9, loss: 0.669826328754425, rho: 0.4250, lip: 1.0000
rank 0, epoch 19, loss: 0.6591000556945801, rho: 0.1062, lip: 1.0000
rank 0, epoch 29, loss: 0.6600134968757629, rho: 0.0531, lip: 1.0000
rank 0, epoch 39, loss: 0.6413484215736389, rho: 0.0531, lip: 1.0000
rank 0, epoch 49, loss: 0.6433064341545105, rho: 0.0531, lip: 1.0000
Rank 0 - Training time: 33.77 seconds
[92mRank 0 - Testing RMSE: 0.3354[0m
[92mRank: 0, Lengthscale: [[0.56241083 0.3899019 ]] [0m
[92mRank: 0, Outputscale: 2.06390380859375 [0m
[92mRank: 0, Noise: 0.14006160199642181 [0m
Run 1 completed successfully
Running pxpGP 2 with agents: 36
[92mRank 0 - sparse dataset size is: 13, local dataset: torch.Size([484, 2]), [0m
[92mRank 0 - Training local sparse GP model with 484 samples[0m
Epoch 1/200 - Loss: 10.578
Epoch 11/200 - Loss: 1.120
Epoch 21/200 - Loss: 1.090
Epoch 31/200 - Loss: 0.934
Epoch 41/200 - Loss: 0.819
Epoch 51/200 - Loss: 0.680
Epoch 61/200 - Loss: 0.545
Epoch 71/200 - Loss: 0.314
Epoch 81/200 - Loss: 0.104
Converged at epoch 86 with loss -0.032
[92mRank 0 - Lengthscale: [[0.5494026 0.4045617]] [0m
[92mRank 0 - Outputscale: 2.020395278930664 [0m
[92mRank 0 - Noise: 0.12606355547904968 [0m
Rank 0 - Augmented dataset size: 952
Rank 0: After warm start model parameters:
Rank: 0, Lengthscale: [[0.5494026 0.4045617]]
Rank: 0, Outputscale: 2.020395278930664
Rank: 0, Noise: 0.1260635405778885
decpxADMM initialized with rho: 0.85, lip: 1.0, tol_abs: 1e-05, tol_rel: 0.001, rank: 0, world_size: 36
[92mRank 0 - Training global model with dec-pxADMM optimizer[0m
rank 0, epoch 9, loss: 0.5792117714881897, rho: 0.2125, lip: 1.0000
rank 0, epoch 19, loss: 0.5291699171066284, rho: 0.1062, lip: 1.0000
rank 0, epoch 29, loss: 0.5172792077064514, rho: 0.0531, lip: 1.0000
rank 0, epoch 39, loss: 0.5075175166130066, rho: 0.0266, lip: 1.0000
rank 0, epoch 49, loss: 0.5290473103523254, rho: 0.0266, lip: 1.0000
Rank 0 - Training time: 29.03 seconds
[92mRank 0 - Testing RMSE: 0.3569[0m
[92mRank: 0, Lengthscale: [[0.44033766 0.4122845 ]] [0m
[92mRank: 0, Outputscale: 1.433078646659851 [0m
[92mRank: 0, Noise: 0.10636086016893387 [0m
Run 2 completed successfully
Running pxpGP 3 with agents: 36
[92mRank 0 - sparse dataset size is: 13, local dataset: torch.Size([484, 2]), [0m
[92mRank 0 - Training local sparse GP model with 484 samples[0m
Epoch 1/200 - Loss: 14.472
Epoch 11/200 - Loss: 1.172
Epoch 21/200 - Loss: 1.029
Epoch 31/200 - Loss: 0.978
Epoch 41/200 - Loss: 0.840
Epoch 51/200 - Loss: 0.704
Epoch 61/200 - Loss: 0.538
Epoch 71/200 - Loss: 0.326
Epoch 81/200 - Loss: 0.085
Converged at epoch 84 with loss -0.003
[92mRank 0 - Lengthscale: [[0.7491677 0.3261532]] [0m
[92mRank 0 - Outputscale: 2.408653974533081 [0m
[92mRank 0 - Noise: 0.13798508048057556 [0m
Rank 0 - Augmented dataset size: 952
Rank 0: After warm start model parameters:
Rank: 0, Lengthscale: [[0.7491677 0.3261532]]
Rank: 0, Outputscale: 2.408653974533081
Rank: 0, Noise: 0.13798508048057556
decpxADMM initialized with rho: 0.85, lip: 1.0, tol_abs: 1e-05, tol_rel: 0.001, rank: 0, world_size: 36
[92mRank 0 - Training global model with dec-pxADMM optimizer[0m
rank 0, epoch 9, loss: 0.702060341835022, rho: 0.4250, lip: 1.0000
rank 0, epoch 19, loss: 0.6626816987991333, rho: 0.0531, lip: 1.0000
rank 0, epoch 29, loss: 0.6536816358566284, rho: 0.0531, lip: 1.0000
rank 0, epoch 39, loss: 0.6564772129058838, rho: 0.0531, lip: 1.0000
rank 0, epoch 49, loss: 0.64896559715271, rho: 0.0266, lip: 1.0000
Rank 0 - Training time: 38.50 seconds
[92mRank 0 - Testing RMSE: 0.4533[0m
[92mRank: 0, Lengthscale: [[0.57803726 0.44009572]] [0m
[92mRank: 0, Outputscale: 1.4276518821716309 [0m
[92mRank: 0, Noise: 0.16322174668312073 [0m
Run 3 completed successfully
Running pxpGP 4 with agents: 36
[92mRank 0 - sparse dataset size is: 13, local dataset: torch.Size([484, 2]), [0m
[92mRank 0 - Training local sparse GP model with 484 samples[0m
Epoch 1/200 - Loss: 13.607
Epoch 11/200 - Loss: 1.261
Epoch 21/200 - Loss: 1.056
Epoch 31/200 - Loss: 0.940
Epoch 41/200 - Loss: 0.824
Epoch 51/200 - Loss: 0.686
Epoch 61/200 - Loss: 0.513
Epoch 71/200 - Loss: 0.307
Epoch 81/200 - Loss: 0.055
Converged at epoch 83 with loss -0.001
[92mRank 0 - Lengthscale: [[0.8087286 0.4099185]] [0m
[92mRank 0 - Outputscale: 2.3950936794281006 [0m
[92mRank 0 - Noise: 0.13982321321964264 [0m
Rank 0 - Augmented dataset size: 952
Rank 0: After warm start model parameters:
Rank: 0, Lengthscale: [[0.8087286 0.4099185]]
Rank: 0, Outputscale: 2.3950936794281006
Rank: 0, Noise: 0.13982321321964264
decpxADMM initialized with rho: 0.85, lip: 1.0, tol_abs: 1e-05, tol_rel: 0.001, rank: 0, world_size: 36
[92mRank 0 - Training global model with dec-pxADMM optimizer[0m
rank 0, epoch 9, loss: 0.6400003433227539, rho: 0.4250, lip: 1.0000
rank 0, epoch 19, loss: 0.5995458364486694, rho: 0.0531, lip: 1.0000
rank 0, epoch 29, loss: 0.6073203086853027, rho: 0.0531, lip: 1.0000
rank 0, epoch 39, loss: 0.5893874168395996, rho: 0.0531, lip: 1.0000
rank 0, epoch 49, loss: 0.5940108895301819, rho: 0.0531, lip: 1.0000
Rank 0 - Training time: 24.95 seconds
[92mRank 0 - Testing RMSE: 0.3482[0m
[92mRank: 0, Lengthscale: [[0.55400157 0.40323225]] [0m
[92mRank: 0, Outputscale: 1.0982062816619873 [0m
[92mRank: 0, Noise: 0.1238451600074768 [0m
Run 4 completed successfully
Running pxpGP 5 with agents: 36
[92mRank 0 - sparse dataset size is: 13, local dataset: torch.Size([484, 2]), [0m
[92mRank 0 - Training local sparse GP model with 484 samples[0m
Epoch 1/200 - Loss: 17.076
Epoch 11/200 - Loss: 1.125
Epoch 21/200 - Loss: 1.085
Epoch 31/200 - Loss: 0.931
Epoch 41/200 - Loss: 0.862
Epoch 51/200 - Loss: 0.714
Epoch 61/200 - Loss: 0.553
Epoch 71/200 - Loss: 0.350
Epoch 81/200 - Loss: 0.144
Converged at epoch 89 with loss -0.020
[92mRank 0 - Lengthscale: [[0.5233217  0.51995856]] [0m
[92mRank 0 - Outputscale: 2.2918529510498047 [0m
[92mRank 0 - Noise: 0.11966431885957718 [0m
Rank 0 - Augmented dataset size: 952
Rank 0: After warm start model parameters:
Rank: 0, Lengthscale: [[0.5233217  0.51995856]]
Rank: 0, Outputscale: 2.2918529510498047
Rank: 0, Noise: 0.11966431885957718
decpxADMM initialized with rho: 0.85, lip: 1.0, tol_abs: 1e-05, tol_rel: 0.001, rank: 0, world_size: 36
[92mRank 0 - Training global model with dec-pxADMM optimizer[0m
rank 0, epoch 9, loss: 0.6066358089447021, rho: 0.2125, lip: 1.0000
rank 0, epoch 19, loss: 0.5853338241577148, rho: 0.0531, lip: 1.0000
rank 0, epoch 29, loss: 0.5744842290878296, rho: 0.0531, lip: 1.0000
rank 0, epoch 39, loss: 0.5691407918930054, rho: 0.0266, lip: 1.0000
rank 0, epoch 49, loss: 0.5668472051620483, rho: 0.0266, lip: 1.0000
Rank 0 - Training time: 37.83 seconds
[92mRank 0 - Testing RMSE: 0.3524[0m
[92mRank: 0, Lengthscale: [[0.5862466 0.4476818]] [0m
[92mRank: 0, Outputscale: 1.6372476816177368 [0m
[92mRank: 0, Noise: 0.12933595478534698 [0m
Run 5 completed successfully
Running pxpGP 6 with agents: 36
[92mRank 0 - sparse dataset size is: 13, local dataset: torch.Size([484, 2]), [0m
[92mRank 0 - Training local sparse GP model with 484 samples[0m
Epoch 1/200 - Loss: 11.912
Epoch 11/200 - Loss: 1.623
Epoch 21/200 - Loss: 1.038
Epoch 31/200 - Loss: 0.974
Epoch 41/200 - Loss: 0.825
Epoch 51/200 - Loss: 0.692
Epoch 61/200 - Loss: 0.515
Epoch 71/200 - Loss: 0.307
Epoch 81/200 - Loss: 0.069
Converged at epoch 85 with loss -0.023
[92mRank 0 - Lengthscale: [[0.8135244  0.41651616]] [0m
[92mRank 0 - Outputscale: 2.4121415615081787 [0m
[92mRank 0 - Noise: 0.13110551238059998 [0m
Rank 0 - Augmented dataset size: 952
Rank 0: After warm start model parameters:
Rank: 0, Lengthscale: [[0.81352437 0.41651616]]
Rank: 0, Outputscale: 2.4121415615081787
Rank: 0, Noise: 0.13110552728176117
decpxADMM initialized with rho: 0.85, lip: 1.0, tol_abs: 1e-05, tol_rel: 0.001, rank: 0, world_size: 36
[92mRank 0 - Training global model with dec-pxADMM optimizer[0m
rank 0, epoch 9, loss: 0.6247655749320984, rho: 0.4250, lip: 1.0000
rank 0, epoch 19, loss: 0.5695803165435791, rho: 0.0531, lip: 1.0000
rank 0, epoch 29, loss: 0.5635923743247986, rho: 0.0531, lip: 1.0000
rank 0, epoch 39, loss: 0.5515851378440857, rho: 0.0266, lip: 1.0000
rank 0, epoch 49, loss: 0.5643757581710815, rho: 0.0266, lip: 1.0000
Rank 0 - Training time: 26.77 seconds
[92mRank 0 - Testing RMSE: 0.2940[0m
[92mRank: 0, Lengthscale: [[0.5082276  0.46804535]] [0m
[92mRank: 0, Outputscale: 1.4803951978683472 [0m
[92mRank: 0, Noise: 0.1238606721162796 [0m
Run 6 completed successfully
Running pxpGP 7 with agents: 36
[92mRank 0 - sparse dataset size is: 13, local dataset: torch.Size([484, 2]), [0m
[92mRank 0 - Training local sparse GP model with 484 samples[0m
Epoch 1/200 - Loss: 15.347
Epoch 11/200 - Loss: 1.166
Epoch 21/200 - Loss: 1.046
Epoch 31/200 - Loss: 1.007
Epoch 41/200 - Loss: 0.881
Epoch 51/200 - Loss: 0.797
Epoch 61/200 - Loss: 0.583
Epoch 71/200 - Loss: 0.403
Epoch 81/200 - Loss: 0.175
Converged at epoch 88 with loss -0.011
[92mRank 0 - Lengthscale: [[0.49561512 0.34453154]] [0m
[92mRank 0 - Outputscale: 2.139505624771118 [0m
[92mRank 0 - Noise: 0.1359749585390091 [0m
Rank 0 - Augmented dataset size: 952
Rank 0: After warm start model parameters:
Rank: 0, Lengthscale: [[0.49561512 0.34453154]]
Rank: 0, Outputscale: 2.139505624771118
Rank: 0, Noise: 0.1359749734401703
decpxADMM initialized with rho: 0.85, lip: 1.0, tol_abs: 1e-05, tol_rel: 0.001, rank: 0, world_size: 36
[92mRank 0 - Training global model with dec-pxADMM optimizer[0m
rank 0, epoch 9, loss: 0.7138185501098633, rho: 0.2125, lip: 1.0000
rank 0, epoch 19, loss: 0.7202243804931641, rho: 0.1062, lip: 1.0000
rank 0, epoch 29, loss: 0.7156904935836792, rho: 0.0531, lip: 1.0000
rank 0, epoch 39, loss: 0.6983135938644409, rho: 0.0531, lip: 1.0000
rank 0, epoch 49, loss: 0.6982390880584717, rho: 0.0531, lip: 1.0000
Rank 0 - Training time: 23.27 seconds
[92mRank 0 - Testing RMSE: 0.4109[0m
[92mRank: 0, Lengthscale: [[0.64145845 0.41530767]] [0m
[92mRank: 0, Outputscale: 1.785689115524292 [0m
[92mRank: 0, Noise: 0.1758301854133606 [0m
Run 7 completed successfully
Running pxpGP 8 with agents: 36
[92mRank 0 - sparse dataset size is: 13, local dataset: torch.Size([484, 2]), [0m
[92mRank 0 - Training local sparse GP model with 484 samples[0m
Epoch 1/200 - Loss: 13.951
Epoch 11/200 - Loss: 1.138
Epoch 21/200 - Loss: 1.055
Epoch 31/200 - Loss: 0.959
Epoch 41/200 - Loss: 0.834
Epoch 51/200 - Loss: 0.697
Epoch 61/200 - Loss: 0.529
Epoch 71/200 - Loss: 0.325
Epoch 81/200 - Loss: 0.085
Converged at epoch 85 with loss -0.021
[92mRank 0 - Lengthscale: [[0.7760528  0.35702297]] [0m
[92mRank 0 - Outputscale: 2.381164312362671 [0m
[92mRank 0 - Noise: 0.13293525576591492 [0m
Rank 0 - Augmented dataset size: 952
Rank 0: After warm start model parameters:
Rank: 0, Lengthscale: [[0.7760528 0.357023 ]]
Rank: 0, Outputscale: 2.381164312362671
Rank: 0, Noise: 0.13293525576591492
decpxADMM initialized with rho: 0.85, lip: 1.0, tol_abs: 1e-05, tol_rel: 0.001, rank: 0, world_size: 36
[92mRank 0 - Training global model with dec-pxADMM optimizer[0m
rank 0, epoch 9, loss: 0.6771313548088074, rho: 0.4250, lip: 1.0000
rank 0, epoch 19, loss: 0.6388852596282959, rho: 0.0531, lip: 1.0000
rank 0, epoch 29, loss: 0.6358101963996887, rho: 0.0531, lip: 1.0000
rank 0, epoch 39, loss: 0.6306650042533875, rho: 0.0531, lip: 1.0000
rank 0, epoch 49, loss: 0.6434105634689331, rho: 0.0531, lip: 1.0000
Rank 0 - Training time: 48.09 seconds
[92mRank 0 - Testing RMSE: 0.3634[0m
[92mRank: 0, Lengthscale: [[0.4947343 0.4542482]] [0m
[92mRank: 0, Outputscale: 1.0184483528137207 [0m
[92mRank: 0, Noise: 0.13957862555980682 [0m
Run 8 completed successfully
Running pxpGP 9 with agents: 36
[92mRank 0 - sparse dataset size is: 13, local dataset: torch.Size([484, 2]), [0m
[92mRank 0 - Training local sparse GP model with 484 samples[0m
Epoch 1/200 - Loss: 11.498
Epoch 11/200 - Loss: 1.219
Epoch 21/200 - Loss: 1.137
Epoch 31/200 - Loss: 0.946
Epoch 41/200 - Loss: 0.837
Epoch 51/200 - Loss: 0.703
Epoch 61/200 - Loss: 0.531
Epoch 71/200 - Loss: 0.335
Epoch 81/200 - Loss: 0.088
Converged at epoch 85 with loss -0.015
[92mRank 0 - Lengthscale: [[0.5005497  0.55273354]] [0m
[92mRank 0 - Outputscale: 2.330980062484741 [0m
[92mRank 0 - Noise: 0.13078689575195312 [0m
Rank 0 - Augmented dataset size: 952
Rank 0: After warm start model parameters:
Rank: 0, Lengthscale: [[0.5005497  0.55273354]]
Rank: 0, Outputscale: 2.330980062484741
Rank: 0, Noise: 0.13078689575195312
decpxADMM initialized with rho: 0.85, lip: 1.0, tol_abs: 1e-05, tol_rel: 0.001, rank: 0, world_size: 36
[92mRank 0 - Training global model with dec-pxADMM optimizer[0m
rank 0, epoch 9, loss: 0.6769070029258728, rho: 0.4250, lip: 1.0000
rank 0, epoch 19, loss: 0.6627556085586548, rho: 0.1062, lip: 1.0000
rank 0, epoch 29, loss: 0.656773030757904, rho: 0.0266, lip: 1.0000
rank 0, epoch 39, loss: 0.6647876501083374, rho: 0.0266, lip: 1.0000
rank 0, epoch 49, loss: 0.6525048017501831, rho: 0.0266, lip: 1.0000
Rank 0 - Training time: 23.90 seconds
[92mRank 0 - Testing RMSE: 0.3921[0m
[92mRank: 0, Lengthscale: [[0.6539716  0.44853526]] [0m
[92mRank: 0, Outputscale: 1.916898250579834 [0m
[92mRank: 0, Noise: 0.16094490885734558 [0m
Run 9 completed successfully
Running pxpGP 10 with agents: 36
[92mRank 0 - sparse dataset size is: 13, local dataset: torch.Size([484, 2]), [0m
[92mRank 0 - Training local sparse GP model with 484 samples[0m
Epoch 1/200 - Loss: 15.324
Epoch 11/200 - Loss: 1.172
Epoch 21/200 - Loss: 1.050
Epoch 31/200 - Loss: 0.967
Epoch 41/200 - Loss: 0.829
Epoch 51/200 - Loss: 0.718
Epoch 61/200 - Loss: 0.532
Epoch 71/200 - Loss: 0.343
Epoch 81/200 - Loss: 0.150
Converged at epoch 85 with loss -0.009
[92mRank 0 - Lengthscale: [[0.42348117 0.555524  ]] [0m
[92mRank 0 - Outputscale: 2.272808790206909 [0m
[92mRank 0 - Noise: 0.13415208458900452 [0m
Rank 0 - Augmented dataset size: 952
Rank 0: After warm start model parameters:
Rank: 0, Lengthscale: [[0.42348114 0.555524  ]]
Rank: 0, Outputscale: 2.272808790206909
Rank: 0, Noise: 0.13415208458900452
decpxADMM initialized with rho: 0.85, lip: 1.0, tol_abs: 1e-05, tol_rel: 0.001, rank: 0, world_size: 36
[92mRank 0 - Training global model with dec-pxADMM optimizer[0m
rank 0, epoch 9, loss: 0.609722375869751, rho: 0.2125, lip: 1.0000
rank 0, epoch 19, loss: 0.5657415986061096, rho: 0.0531, lip: 1.0000
rank 0, epoch 29, loss: 0.5586406588554382, rho: 0.0531, lip: 1.0000
rank 0, epoch 39, loss: 0.5595437288284302, rho: 0.0531, lip: 1.0000
rank 0, epoch 49, loss: 0.5576420426368713, rho: 0.0531, lip: 1.0000
Rank 0 - Training time: 24.71 seconds
[92mRank 0 - Testing RMSE: 0.3204[0m
[92mRank: 0, Lengthscale: [[0.5562015  0.49968904]] [0m
[92mRank: 0, Outputscale: 1.504623293876648 [0m
[92mRank: 0, Noise: 0.11387842893600464 [0m
Run 10 completed successfully
Running gapxGP 1 with agents: 36
decpxADMM initialized with rho: 0.75, lip: 1.0, tol_abs: 1e-05, tol_rel: 0.001, rank: 0, world_size: 36
Rank 0 - Epoch 2/54 loss: 0.9566069841384888
Rank 0 - Epoch 10/54 loss: 0.7287895083427429
Rank 0 - Epoch 20/54 loss: 0.3701334297657013
Rank 0 - Epoch 30/54 loss: -0.06892715394496918
Rank 0 - Epoch 40/54 loss: -0.5014384388923645
Rank 0 - Epoch 50/54 loss: -0.9573814868927002
[92mRank 0 - Testing RMSE: 0.0509[0m
[92mRank: 0, Lengthscale: [[0.61230975 0.36635917]] [0m
[92mRank: 0, Outputscale: 1.3003616333007812 [0m
[92mRank: 0, Noise: 0.00621804827824235 [0m
Run 1 completed successfully
Running gapxGP 2 with agents: 36
decpxADMM initialized with rho: 0.75, lip: 1.0, tol_abs: 1e-05, tol_rel: 0.001, rank: 0, world_size: 36
Rank 0 - Epoch 2/54 loss: 0.9577527046203613
Rank 0 - Epoch 10/54 loss: 0.737166702747345
Rank 0 - Epoch 20/54 loss: 0.37268105149269104
Rank 0 - Epoch 30/54 loss: -0.04796219244599342
Rank 0 - Epoch 40/54 loss: -0.5015424489974976
Rank 0 - Epoch 50/54 loss: -0.9364273548126221
[92mRank 0 - Testing RMSE: 0.0501[0m
[92mRank: 0, Lengthscale: [[0.6126149  0.36531812]] [0m
[92mRank: 0, Outputscale: 1.303048014640808 [0m
[92mRank: 0, Noise: 0.006212580017745495 [0m
Run 2 completed successfully
Running gapxGP 3 with agents: 36
decpxADMM initialized with rho: 0.75, lip: 1.0, tol_abs: 1e-05, tol_rel: 0.001, rank: 0, world_size: 36
Rank 0 - Epoch 2/54 loss: 0.9453743696212769
Rank 0 - Epoch 10/54 loss: 0.7181733846664429
Rank 0 - Epoch 20/54 loss: 0.3664940893650055
Rank 0 - Epoch 30/54 loss: -0.07499419897794724
Rank 0 - Epoch 40/54 loss: -0.5249969959259033
Rank 0 - Epoch 50/54 loss: -0.9396000504493713
[92mRank 0 - Testing RMSE: 0.0409[0m
[92mRank: 0, Lengthscale: [[0.60912234 0.36568066]] [0m
[92mRank: 0, Outputscale: 1.300144910812378 [0m
[92mRank: 0, Noise: 0.0062003908678889275 [0m
Run 3 completed successfully
Running gapxGP 4 with agents: 36
decpxADMM initialized with rho: 0.75, lip: 1.0, tol_abs: 1e-05, tol_rel: 0.001, rank: 0, world_size: 36
Rank 0 - Epoch 2/54 loss: 0.950630784034729
Rank 0 - Epoch 10/54 loss: 0.7252851128578186
Rank 0 - Epoch 20/54 loss: 0.359262615442276
Rank 0 - Epoch 30/54 loss: -0.06851492077112198
Rank 0 - Epoch 40/54 loss: -0.5196564197540283
Rank 0 - Epoch 50/54 loss: -0.9404574036598206
[92mRank 0 - Testing RMSE: 0.0496[0m
[92mRank: 0, Lengthscale: [[0.6325096  0.36188105]] [0m
[92mRank: 0, Outputscale: 1.3007872104644775 [0m
[92mRank: 0, Noise: 0.006136387586593628 [0m
Run 4 completed successfully
Running gapxGP 5 with agents: 36
decpxADMM initialized with rho: 0.75, lip: 1.0, tol_abs: 1e-05, tol_rel: 0.001, rank: 0, world_size: 36
Rank 0 - Epoch 2/54 loss: 0.9478468298912048
Rank 0 - Epoch 10/54 loss: 0.7206240296363831
Rank 0 - Epoch 20/54 loss: 0.3745538294315338
Rank 0 - Epoch 30/54 loss: -0.06976227462291718
Rank 0 - Epoch 40/54 loss: -0.5120299458503723
Rank 0 - Epoch 50/54 loss: -0.9324211478233337
[92mRank 0 - Testing RMSE: 0.0536[0m
[92mRank: 0, Lengthscale: [[0.6192115  0.36428362]] [0m
[92mRank: 0, Outputscale: 1.2961033582687378 [0m
[92mRank: 0, Noise: 0.006277658976614475 [0m
Run 5 completed successfully
Running gapxGP 6 with agents: 36
decpxADMM initialized with rho: 0.75, lip: 1.0, tol_abs: 1e-05, tol_rel: 0.001, rank: 0, world_size: 36
Rank 0 - Epoch 2/54 loss: 0.9451285004615784
Rank 0 - Epoch 10/54 loss: 0.71735018491745
Rank 0 - Epoch 20/54 loss: 0.3600987195968628
Rank 0 - Epoch 30/54 loss: -0.0719868391752243
Rank 0 - Epoch 40/54 loss: -0.5078322887420654
Rank 0 - Epoch 50/54 loss: -0.9390944838523865
[92mRank 0 - Testing RMSE: 0.0583[0m
[92mRank: 0, Lengthscale: [[0.6132334  0.36087742]] [0m
[92mRank: 0, Outputscale: 1.2984057664871216 [0m
[92mRank: 0, Noise: 0.0061630369164049625 [0m
Run 6 completed successfully
Running gapxGP 7 with agents: 36
decpxADMM initialized with rho: 0.75, lip: 1.0, tol_abs: 1e-05, tol_rel: 0.001, rank: 0, world_size: 36
Rank 0 - Epoch 2/54 loss: 0.9490993022918701
Rank 0 - Epoch 10/54 loss: 0.720390796661377
Rank 0 - Epoch 20/54 loss: 0.3563838303089142
Rank 0 - Epoch 30/54 loss: -0.08004731684923172
Rank 0 - Epoch 40/54 loss: -0.5376585125923157
Rank 0 - Epoch 50/54 loss: -0.9372419714927673
[92mRank 0 - Testing RMSE: 0.0550[0m
[92mRank: 0, Lengthscale: [[0.61756897 0.36567888]] [0m
[92mRank: 0, Outputscale: 1.3016172647476196 [0m
[92mRank: 0, Noise: 0.006108786910772324 [0m
Run 7 completed successfully
Running gapxGP 8 with agents: 36
decpxADMM initialized with rho: 0.75, lip: 1.0, tol_abs: 1e-05, tol_rel: 0.001, rank: 0, world_size: 36
Rank 0 - Epoch 2/54 loss: 0.9480578899383545
Rank 0 - Epoch 10/54 loss: 0.7271577715873718
Rank 0 - Epoch 20/54 loss: 0.3602958023548126
Rank 0 - Epoch 30/54 loss: -0.05957076698541641
Rank 0 - Epoch 40/54 loss: -0.5144245624542236
Rank 0 - Epoch 50/54 loss: -0.9311351776123047
[92mRank 0 - Testing RMSE: 0.0507[0m
[92mRank: 0, Lengthscale: [[0.61458623 0.3647997 ]] [0m
[92mRank: 0, Outputscale: 1.3002303838729858 [0m
[92mRank: 0, Noise: 0.006206675432622433 [0m
Run 8 completed successfully
Running gapxGP 9 with agents: 36
decpxADMM initialized with rho: 0.75, lip: 1.0, tol_abs: 1e-05, tol_rel: 0.001, rank: 0, world_size: 36
Rank 0 - Epoch 2/54 loss: 0.9521269202232361
Rank 0 - Epoch 10/54 loss: 0.7306926250457764
Rank 0 - Epoch 20/54 loss: 0.36731716990470886
Rank 0 - Epoch 30/54 loss: -0.061012014746665955
Rank 0 - Epoch 40/54 loss: -0.5224883556365967
Rank 0 - Epoch 50/54 loss: -0.945761501789093
[92mRank 0 - Testing RMSE: 0.0560[0m
[92mRank: 0, Lengthscale: [[0.61882997 0.36474442]] [0m
[92mRank: 0, Outputscale: 1.3027944564819336 [0m
[92mRank: 0, Noise: 0.006186744198203087 [0m
Run 9 completed successfully
Running gapxGP 10 with agents: 36
decpxADMM initialized with rho: 0.75, lip: 1.0, tol_abs: 1e-05, tol_rel: 0.001, rank: 0, world_size: 36
Rank 0 - Epoch 2/54 loss: 0.9521684050559998
Rank 0 - Epoch 10/54 loss: 0.7265886664390564
Rank 0 - Epoch 20/54 loss: 0.3797774612903595
Rank 0 - Epoch 30/54 loss: -0.06428451091051102
Rank 0 - Epoch 40/54 loss: -0.5046517848968506
Rank 0 - Epoch 50/54 loss: -0.9284698963165283
[92mRank 0 - Testing RMSE: 0.0534[0m
[92mRank: 0, Lengthscale: [[0.62124634 0.36658782]] [0m
[92mRank: 0, Outputscale: 1.2987406253814697 [0m
[92mRank: 0, Noise: 0.006323725916445255 [0m
Run 10 completed successfully
Running apxGP 1 with agents: 36
decpxADMM initialized with rho: 0.85, lip: 1.0, tol_abs: 1e-05, tol_rel: 0.001, rank: 0, world_size: 36
Rank 0 - Epoch 2/72 loss: 0.7744250893592834
Rank 0 - Epoch 10/72 loss: 0.5057491660118103
Rank 0 - Epoch 20/72 loss: 0.0829792469739914
Rank 0 - Epoch 30/72 loss: -0.4025689661502838
Rank 0 - Epoch 40/72 loss: -0.9141886234283447
Rank 0 - Epoch 50/72 loss: -1.4232430458068848
Rank 0 - Epoch 60/72 loss: -1.9151555299758911
Rank 0 - Epoch 70/72 loss: -2.368401527404785
Training complete.
[92mRank 0 - Testing RMSE: 3.1046[0m
[92mRank: 0, Lengthscale: [[0.60329086 0.37779248]] [0m
[92mRank: 0, Outputscale: 1.0072561502456665 [0m
[92mRank: 0, Noise: 0.0008466379367746413 [0m
Run 1 completed successfully
Running apxGP 2 with agents: 36
decpxADMM initialized with rho: 0.85, lip: 1.0, tol_abs: 1e-05, tol_rel: 0.001, rank: 0, world_size: 36
Rank 0 - Epoch 2/72 loss: 0.7744250893592834
Rank 0 - Epoch 10/72 loss: 0.5057491660118103
Rank 0 - Epoch 20/72 loss: 0.0829792469739914
Rank 0 - Epoch 30/72 loss: -0.4025689661502838
Rank 0 - Epoch 40/72 loss: -0.9141886234283447
Rank 0 - Epoch 50/72 loss: -1.4232430458068848
Rank 0 - Epoch 60/72 loss: -1.9151555299758911
Rank 0 - Epoch 70/72 loss: -2.368401527404785
Training complete.
[92mRank 0 - Testing RMSE: 3.1046[0m
[92mRank: 0, Lengthscale: [[0.60329086 0.37779248]] [0m
[92mRank: 0, Outputscale: 1.0072561502456665 [0m
[92mRank: 0, Noise: 0.0008466379367746413 [0m
Run 2 completed successfully
Running apxGP 3 with agents: 36
decpxADMM initialized with rho: 0.85, lip: 1.0, tol_abs: 1e-05, tol_rel: 0.001, rank: 0, world_size: 36
Rank 0 - Epoch 2/72 loss: 0.7744250893592834
Rank 0 - Epoch 10/72 loss: 0.5057491660118103
Rank 0 - Epoch 20/72 loss: 0.0829792469739914
Rank 0 - Epoch 30/72 loss: -0.4025689661502838
Rank 0 - Epoch 40/72 loss: -0.9141886234283447
Rank 0 - Epoch 50/72 loss: -1.4232430458068848
Rank 0 - Epoch 60/72 loss: -1.9151555299758911
Rank 0 - Epoch 70/72 loss: -2.368401527404785
Training complete.
[92mRank 0 - Testing RMSE: 3.1046[0m
[92mRank: 0, Lengthscale: [[0.60329086 0.37779248]] [0m
[92mRank: 0, Outputscale: 1.0072561502456665 [0m
[92mRank: 0, Noise: 0.0008466379367746413 [0m
Run 3 completed successfully
Running apxGP 4 with agents: 36
decpxADMM initialized with rho: 0.85, lip: 1.0, tol_abs: 1e-05, tol_rel: 0.001, rank: 0, world_size: 36
Rank 0 - Epoch 2/72 loss: 0.7744250893592834
Rank 0 - Epoch 10/72 loss: 0.5057491660118103
Rank 0 - Epoch 20/72 loss: 0.0829792469739914
Rank 0 - Epoch 30/72 loss: -0.4025689661502838
Rank 0 - Epoch 40/72 loss: -0.9141886234283447
Rank 0 - Epoch 50/72 loss: -1.4232430458068848
Rank 0 - Epoch 60/72 loss: -1.9151555299758911
Rank 0 - Epoch 70/72 loss: -2.368401527404785
Training complete.
[92mRank 0 - Testing RMSE: 3.1046[0m
[92mRank: 0, Lengthscale: [[0.60329086 0.37779248]] [0m
[92mRank: 0, Outputscale: 1.0072561502456665 [0m
[92mRank: 0, Noise: 0.0008466379367746413 [0m
Run 4 completed successfully
Running apxGP 5 with agents: 36
decpxADMM initialized with rho: 0.85, lip: 1.0, tol_abs: 1e-05, tol_rel: 0.001, rank: 0, world_size: 36
Rank 0 - Epoch 2/72 loss: 0.7744250893592834
Rank 0 - Epoch 10/72 loss: 0.5057491660118103
Rank 0 - Epoch 20/72 loss: 0.0829792469739914
Rank 0 - Epoch 30/72 loss: -0.4025689661502838
Rank 0 - Epoch 40/72 loss: -0.9141886234283447
Rank 0 - Epoch 50/72 loss: -1.4232430458068848
Rank 0 - Epoch 60/72 loss: -1.9151555299758911
Rank 0 - Epoch 70/72 loss: -2.368401527404785
Training complete.
[92mRank 0 - Testing RMSE: 3.1046[0m
[92mRank: 0, Lengthscale: [[0.60329086 0.37779248]] [0m
[92mRank: 0, Outputscale: 1.0072561502456665 [0m
[92mRank: 0, Noise: 0.0008466379367746413 [0m
Run 5 completed successfully
Running apxGP 6 with agents: 36
decpxADMM initialized with rho: 0.85, lip: 1.0, tol_abs: 1e-05, tol_rel: 0.001, rank: 0, world_size: 36
Rank 0 - Epoch 2/72 loss: 0.7744250893592834
Rank 0 - Epoch 10/72 loss: 0.5057491660118103
Rank 0 - Epoch 20/72 loss: 0.0829792469739914
Rank 0 - Epoch 30/72 loss: -0.4025689661502838
Rank 0 - Epoch 40/72 loss: -0.9141886234283447
Rank 0 - Epoch 50/72 loss: -1.4232430458068848
Rank 0 - Epoch 60/72 loss: -1.9151555299758911
Rank 0 - Epoch 70/72 loss: -2.368401527404785
Training complete.
[92mRank 0 - Testing RMSE: 3.1046[0m
[92mRank: 0, Lengthscale: [[0.60329086 0.37779248]] [0m
[92mRank: 0, Outputscale: 1.0072561502456665 [0m
[92mRank: 0, Noise: 0.0008466379367746413 [0m
Run 6 completed successfully
Running apxGP 7 with agents: 36
decpxADMM initialized with rho: 0.85, lip: 1.0, tol_abs: 1e-05, tol_rel: 0.001, rank: 0, world_size: 36
Rank 0 - Epoch 2/72 loss: 0.7744250893592834
Rank 0 - Epoch 10/72 loss: 0.5057491660118103
Rank 0 - Epoch 20/72 loss: 0.0829792469739914
Rank 0 - Epoch 30/72 loss: -0.4025689661502838
Rank 0 - Epoch 40/72 loss: -0.9141886234283447
Rank 0 - Epoch 50/72 loss: -1.4232430458068848
Rank 0 - Epoch 60/72 loss: -1.9151555299758911
Rank 0 - Epoch 70/72 loss: -2.368401527404785
Training complete.
[92mRank 0 - Testing RMSE: 3.1046[0m
[92mRank: 0, Lengthscale: [[0.60329086 0.37779248]] [0m
[92mRank: 0, Outputscale: 1.0072561502456665 [0m
[92mRank: 0, Noise: 0.0008466379367746413 [0m
Run 7 completed successfully
Running apxGP 8 with agents: 36
decpxADMM initialized with rho: 0.85, lip: 1.0, tol_abs: 1e-05, tol_rel: 0.001, rank: 0, world_size: 36
Rank 0 - Epoch 2/72 loss: 0.7744250893592834
Rank 0 - Epoch 10/72 loss: 0.5057491660118103
Rank 0 - Epoch 20/72 loss: 0.0829792469739914
Rank 0 - Epoch 30/72 loss: -0.4025689661502838
Rank 0 - Epoch 40/72 loss: -0.9141886234283447
Rank 0 - Epoch 50/72 loss: -1.4232430458068848
Rank 0 - Epoch 60/72 loss: -1.9151555299758911
Rank 0 - Epoch 70/72 loss: -2.368401527404785
Training complete.
[92mRank 0 - Testing RMSE: 3.1046[0m
[92mRank: 0, Lengthscale: [[0.60329086 0.37779248]] [0m
[92mRank: 0, Outputscale: 1.0072561502456665 [0m
[92mRank: 0, Noise: 0.0008466379367746413 [0m
Run 8 completed successfully
Running apxGP 9 with agents: 36
decpxADMM initialized with rho: 0.85, lip: 1.0, tol_abs: 1e-05, tol_rel: 0.001, rank: 0, world_size: 36
Rank 0 - Epoch 2/72 loss: 0.7744250893592834
Rank 0 - Epoch 10/72 loss: 0.5057491660118103
Rank 0 - Epoch 20/72 loss: 0.0829792469739914
Rank 0 - Epoch 30/72 loss: -0.4025689661502838
Rank 0 - Epoch 40/72 loss: -0.9141886234283447
Rank 0 - Epoch 50/72 loss: -1.4232430458068848
Rank 0 - Epoch 60/72 loss: -1.9151555299758911
Rank 0 - Epoch 70/72 loss: -2.368401527404785
Training complete.
[92mRank 0 - Testing RMSE: 3.1046[0m
[92mRank: 0, Lengthscale: [[0.60329086 0.37779248]] [0m
[92mRank: 0, Outputscale: 1.0072561502456665 [0m
[92mRank: 0, Noise: 0.0008466379367746413 [0m
Run 9 completed successfully
Running apxGP 10 with agents: 36
decpxADMM initialized with rho: 0.85, lip: 1.0, tol_abs: 1e-05, tol_rel: 0.001, rank: 0, world_size: 36
Rank 0 - Epoch 2/72 loss: 0.7744250893592834
Rank 0 - Epoch 10/72 loss: 0.5057491660118103
Rank 0 - Epoch 20/72 loss: 0.0829792469739914
Rank 0 - Epoch 30/72 loss: -0.4025689661502838
Rank 0 - Epoch 40/72 loss: -0.9141886234283447
Rank 0 - Epoch 50/72 loss: -1.4232430458068848
Rank 0 - Epoch 60/72 loss: -1.9151555299758911
Rank 0 - Epoch 70/72 loss: -2.368401527404785
Training complete.
[92mRank 0 - Testing RMSE: 3.1046[0m
[92mRank: 0, Lengthscale: [[0.60329086 0.37779248]] [0m
[92mRank: 0, Outputscale: 1.0072561502456665 [0m
[92mRank: 0, Noise: 0.0008466379367746413 [0m
Run 10 completed successfully
Running cGP 1 with agents: 36
decADMM initialized with rho: 0.85, max_iter: 5, lr: 0.0001, rank: 0, world_size: 36
Rank 0 - Epoch 2/72 loss: 0.8310699462890625
Rank 0 - Epoch 10/72 loss: 0.8257050514221191
Rank 0 - Epoch 20/72 loss: 0.8190111517906189
Rank 0 - Epoch 30/72 loss: 0.812334418296814
Rank 0 - Epoch 40/72 loss: 0.8056783080101013
Rank 0 - Epoch 50/72 loss: 0.7990463972091675
Rank 0 - Epoch 60/72 loss: 0.7924422025680542
Rank 0 - Epoch 70/72 loss: 0.7858695387840271
Training complete.
[92mRank 0 - Testing RMSE: 3.5671[0m
[92mRank: 0, Lengthscale: [[0.63367856 0.63296306]] [0m
[92mRank: 0, Outputscale: 0.6346143484115601 [0m
[92mRank: 0, Noise: 0.627953290939331 [0m
Run 1 completed successfully
Running cGP 2 with agents: 36
decADMM initialized with rho: 0.85, max_iter: 5, lr: 0.0001, rank: 0, world_size: 36
Rank 0 - Epoch 2/72 loss: 0.8310699462890625
Rank 0 - Epoch 10/72 loss: 0.8257050514221191
Rank 0 - Epoch 20/72 loss: 0.8190111517906189
Rank 0 - Epoch 30/72 loss: 0.812334418296814
Rank 0 - Epoch 40/72 loss: 0.8056783080101013
Rank 0 - Epoch 50/72 loss: 0.7990463972091675
Rank 0 - Epoch 60/72 loss: 0.7924422025680542
Rank 0 - Epoch 70/72 loss: 0.7858695387840271
Training complete.
[92mRank 0 - Testing RMSE: 3.5671[0m
[92mRank: 0, Lengthscale: [[0.63367856 0.63296306]] [0m
[92mRank: 0, Outputscale: 0.6346143484115601 [0m
[92mRank: 0, Noise: 0.627953290939331 [0m
Run 2 completed successfully
Running cGP 3 with agents: 36
decADMM initialized with rho: 0.85, max_iter: 5, lr: 0.0001, rank: 0, world_size: 36
Rank 0 - Epoch 2/72 loss: 0.8310699462890625
Rank 0 - Epoch 10/72 loss: 0.8257050514221191
Rank 0 - Epoch 20/72 loss: 0.8190111517906189
Rank 0 - Epoch 30/72 loss: 0.812334418296814
Rank 0 - Epoch 40/72 loss: 0.8056783080101013
Rank 0 - Epoch 50/72 loss: 0.7990463972091675
Rank 0 - Epoch 60/72 loss: 0.7924422025680542
Rank 0 - Epoch 70/72 loss: 0.7858695387840271
Training complete.
[92mRank 0 - Testing RMSE: 3.5671[0m
[92mRank: 0, Lengthscale: [[0.63367856 0.63296306]] [0m
[92mRank: 0, Outputscale: 0.6346143484115601 [0m
[92mRank: 0, Noise: 0.627953290939331 [0m
Run 3 completed successfully
Running cGP 4 with agents: 36
decADMM initialized with rho: 0.85, max_iter: 5, lr: 0.0001, rank: 0, world_size: 36
Rank 0 - Epoch 2/72 loss: 0.8310699462890625
Rank 0 - Epoch 10/72 loss: 0.8257050514221191
Rank 0 - Epoch 20/72 loss: 0.8190111517906189
Rank 0 - Epoch 30/72 loss: 0.812334418296814
Rank 0 - Epoch 40/72 loss: 0.8056783080101013
Rank 0 - Epoch 50/72 loss: 0.7990463972091675
Rank 0 - Epoch 60/72 loss: 0.7924422025680542
Rank 0 - Epoch 70/72 loss: 0.7858695387840271
Training complete.
[92mRank 0 - Testing RMSE: 3.5671[0m
[92mRank: 0, Lengthscale: [[0.63367856 0.63296306]] [0m
[92mRank: 0, Outputscale: 0.6346143484115601 [0m
[92mRank: 0, Noise: 0.627953290939331 [0m
Run 4 completed successfully
Running cGP 5 with agents: 36
decADMM initialized with rho: 0.85, max_iter: 5, lr: 0.0001, rank: 0, world_size: 36
Rank 0 - Epoch 2/72 loss: 0.8310699462890625
Rank 0 - Epoch 10/72 loss: 0.8257050514221191
Rank 0 - Epoch 20/72 loss: 0.8190111517906189
Rank 0 - Epoch 30/72 loss: 0.812334418296814
Rank 0 - Epoch 40/72 loss: 0.8056783080101013
Rank 0 - Epoch 50/72 loss: 0.7990463972091675
Rank 0 - Epoch 60/72 loss: 0.7924422025680542
Rank 0 - Epoch 70/72 loss: 0.7858695387840271
Training complete.
[92mRank 0 - Testing RMSE: 3.5671[0m
[92mRank: 0, Lengthscale: [[0.63367856 0.63296306]] [0m
[92mRank: 0, Outputscale: 0.6346143484115601 [0m
[92mRank: 0, Noise: 0.627953290939331 [0m
Run 5 completed successfully
Running cGP 6 with agents: 36
decADMM initialized with rho: 0.85, max_iter: 5, lr: 0.0001, rank: 0, world_size: 36
Rank 0 - Epoch 2/72 loss: 0.8310699462890625
Rank 0 - Epoch 10/72 loss: 0.8257050514221191
Rank 0 - Epoch 20/72 loss: 0.8190111517906189
Rank 0 - Epoch 30/72 loss: 0.812334418296814
Rank 0 - Epoch 40/72 loss: 0.8056783080101013
Rank 0 - Epoch 50/72 loss: 0.7990463972091675
Rank 0 - Epoch 60/72 loss: 0.7924422025680542
Rank 0 - Epoch 70/72 loss: 0.7858695387840271
Training complete.
[92mRank 0 - Testing RMSE: 3.5671[0m
[92mRank: 0, Lengthscale: [[0.63367856 0.63296306]] [0m
[92mRank: 0, Outputscale: 0.6346143484115601 [0m
[92mRank: 0, Noise: 0.627953290939331 [0m
Run 6 completed successfully
Running cGP 7 with agents: 36
decADMM initialized with rho: 0.85, max_iter: 5, lr: 0.0001, rank: 0, world_size: 36
Rank 0 - Epoch 2/72 loss: 0.8310699462890625
Rank 0 - Epoch 10/72 loss: 0.8257050514221191
Rank 0 - Epoch 20/72 loss: 0.8190111517906189
Rank 0 - Epoch 30/72 loss: 0.812334418296814
Rank 0 - Epoch 40/72 loss: 0.8056783080101013
Rank 0 - Epoch 50/72 loss: 0.7990463972091675
Rank 0 - Epoch 60/72 loss: 0.7924422025680542
Rank 0 - Epoch 70/72 loss: 0.7858695387840271
Training complete.
[92mRank 0 - Testing RMSE: 3.5671[0m
[92mRank: 0, Lengthscale: [[0.63367856 0.63296306]] [0m
[92mRank: 0, Outputscale: 0.6346143484115601 [0m
[92mRank: 0, Noise: 0.627953290939331 [0m
Run 7 completed successfully
Running cGP 8 with agents: 36
decADMM initialized with rho: 0.85, max_iter: 5, lr: 0.0001, rank: 0, world_size: 36
Rank 0 - Epoch 2/72 loss: 0.8310699462890625
Rank 0 - Epoch 10/72 loss: 0.8257050514221191
Rank 0 - Epoch 20/72 loss: 0.8190111517906189
Rank 0 - Epoch 30/72 loss: 0.812334418296814
Rank 0 - Epoch 40/72 loss: 0.8056783080101013
Rank 0 - Epoch 50/72 loss: 0.7990463972091675
Rank 0 - Epoch 60/72 loss: 0.7924422025680542
Rank 0 - Epoch 70/72 loss: 0.7858695387840271
Training complete.
[92mRank 0 - Testing RMSE: 3.5671[0m
[92mRank: 0, Lengthscale: [[0.63367856 0.63296306]] [0m
[92mRank: 0, Outputscale: 0.6346143484115601 [0m
[92mRank: 0, Noise: 0.627953290939331 [0m
Run 8 completed successfully
Running cGP 9 with agents: 36
decADMM initialized with rho: 0.85, max_iter: 5, lr: 0.0001, rank: 0, world_size: 36
Rank 0 - Epoch 2/72 loss: 0.8310699462890625
Rank 0 - Epoch 10/72 loss: 0.8257050514221191
Rank 0 - Epoch 20/72 loss: 0.8190111517906189
Rank 0 - Epoch 30/72 loss: 0.812334418296814
Rank 0 - Epoch 40/72 loss: 0.8056783080101013
Rank 0 - Epoch 50/72 loss: 0.7990463972091675
Rank 0 - Epoch 60/72 loss: 0.7924422025680542
Rank 0 - Epoch 70/72 loss: 0.7858695387840271
Training complete.
[92mRank 0 - Testing RMSE: 3.5671[0m
[92mRank: 0, Lengthscale: [[0.63367856 0.63296306]] [0m
[92mRank: 0, Outputscale: 0.6346143484115601 [0m
[92mRank: 0, Noise: 0.627953290939331 [0m
Run 9 completed successfully
Running cGP 10 with agents: 36
decADMM initialized with rho: 0.85, max_iter: 5, lr: 0.0001, rank: 0, world_size: 36
Rank 0 - Epoch 2/72 loss: 0.8310699462890625
Rank 0 - Epoch 10/72 loss: 0.8257050514221191
Rank 0 - Epoch 20/72 loss: 0.8190111517906189
Rank 0 - Epoch 30/72 loss: 0.812334418296814
Rank 0 - Epoch 40/72 loss: 0.8056783080101013
Rank 0 - Epoch 50/72 loss: 0.7990463972091675
Rank 0 - Epoch 60/72 loss: 0.7924422025680542
Rank 0 - Epoch 70/72 loss: 0.7858695387840271
Training complete.
[92mRank 0 - Testing RMSE: 3.5671[0m
[92mRank: 0, Lengthscale: [[0.63367856 0.63296306]] [0m
[92mRank: 0, Outputscale: 0.6346143484115601 [0m
[92mRank: 0, Noise: 0.627953290939331 [0m
Run 10 completed successfully
Running pxpGP 1 with agents: 49
[92mRank 0 - sparse dataset size is: 7, local dataset: torch.Size([361, 2]), [0m
[92mRank 0 - Training local sparse GP model with 361 samples[0m
Epoch 1/200 - Loss: 9.789
Epoch 11/200 - Loss: 1.091
Epoch 21/200 - Loss: 0.997
Epoch 31/200 - Loss: 0.925
Epoch 41/200 - Loss: 0.827
Epoch 51/200 - Loss: 0.698
Epoch 61/200 - Loss: 0.539
Epoch 71/200 - Loss: 0.363
Epoch 81/200 - Loss: 0.122
Converged at epoch 87 with loss -0.011
[92mRank 0 - Lengthscale: [[0.66004246 0.50335854]] [0m
[92mRank 0 - Outputscale: 2.178799867630005 [0m
[92mRank 0 - Noise: 0.13232718408107758 [0m
Rank 0 - Augmented dataset size: 704
Rank 0: After warm start model parameters:
Rank: 0, Lengthscale: [[0.66004246 0.50335854]]
Rank: 0, Outputscale: 2.178799867630005
Rank: 0, Noise: 0.13232718408107758
decpxADMM initialized with rho: 0.85, lip: 1.0, tol_abs: 1e-05, tol_rel: 0.001, rank: 0, world_size: 49
[92mRank 0 - Training global model with dec-pxADMM optimizer[0m
rank 0, epoch 9, loss: 0.6452315449714661, rho: 0.2125, lip: 1.0000
rank 0, epoch 19, loss: 0.6314658522605896, rho: 0.1062, lip: 1.0000
rank 0, epoch 29, loss: 0.6507864594459534, rho: 0.0531, lip: 1.0000
rank 0, epoch 39, loss: 0.648286759853363, rho: 0.0531, lip: 1.0000
rank 0, epoch 49, loss: 0.6431909203529358, rho: 0.0531, lip: 1.0000
rank 0, epoch 59, loss: 0.6442651152610779, rho: 0.0531, lip: 1.0000
rank 0, epoch 69, loss: 0.641934335231781, rho: 0.0531, lip: 1.0000
Rank 0 - Training time: 45.83 seconds
[92mRank 0 - Testing RMSE: 0.3112[0m
[92mRank: 0, Lengthscale: [[0.5132656 0.3634845]] [0m
[92mRank: 0, Outputscale: 1.444382905960083 [0m
[92mRank: 0, Noise: 0.1155981570482254 [0m
Run 1 completed successfully
Running pxpGP 2 with agents: 49
[92mRank 0 - sparse dataset size is: 7, local dataset: torch.Size([361, 2]), [0m
[92mRank 0 - Training local sparse GP model with 361 samples[0m
Epoch 1/200 - Loss: 20.508
Epoch 11/200 - Loss: 1.059
Epoch 21/200 - Loss: 0.998
Epoch 31/200 - Loss: 0.914
Epoch 41/200 - Loss: 0.819
Epoch 51/200 - Loss: 0.682
Epoch 61/200 - Loss: 0.528
Epoch 71/200 - Loss: 0.336
Epoch 81/200 - Loss: 0.126
Converged at epoch 87 with loss -0.007
[92mRank 0 - Lengthscale: [[0.6646758  0.50427365]] [0m
[92mRank 0 - Outputscale: 2.190337896347046 [0m
[92mRank 0 - Noise: 0.13196411728858948 [0m
Rank 0 - Augmented dataset size: 704
Rank 0: After warm start model parameters:
Rank: 0, Lengthscale: [[0.6646758  0.50427365]]
Rank: 0, Outputscale: 2.190338134765625
Rank: 0, Noise: 0.13196410238742828
decpxADMM initialized with rho: 0.85, lip: 1.0, tol_abs: 1e-05, tol_rel: 0.001, rank: 0, world_size: 49
[92mRank 0 - Training global model with dec-pxADMM optimizer[0m
rank 0, epoch 9, loss: 0.6040299534797668, rho: 0.2125, lip: 1.0000
rank 0, epoch 19, loss: 0.5868871212005615, rho: 0.1062, lip: 1.0000
rank 0, epoch 29, loss: 0.6035813689231873, rho: 0.0531, lip: 1.0000
rank 0, epoch 39, loss: 0.5979132056236267, rho: 0.0266, lip: 1.0000
rank 0, epoch 49, loss: 0.5940743684768677, rho: 0.0266, lip: 1.0000
rank 0, epoch 59, loss: 0.6011609435081482, rho: 0.0266, lip: 1.0000
rank 0, epoch 69, loss: 0.605214536190033, rho: 0.0266, lip: 1.0000
Rank 0 - Training time: 52.23 seconds
[92mRank 0 - Testing RMSE: 0.3900[0m
[92mRank: 0, Lengthscale: [[0.5085313  0.30732906]] [0m
[92mRank: 0, Outputscale: 1.1294653415679932 [0m
[92mRank: 0, Noise: 0.1115654855966568 [0m
Run 2 completed successfully
Running pxpGP 3 with agents: 49
[92mRank 0 - sparse dataset size is: 7, local dataset: torch.Size([361, 2]), [0m
[92mRank 0 - Training local sparse GP model with 361 samples[0m
Epoch 1/200 - Loss: 14.950
Epoch 11/200 - Loss: 1.348
Epoch 21/200 - Loss: 1.050
Epoch 31/200 - Loss: 0.965
Epoch 41/200 - Loss: 0.900
Epoch 51/200 - Loss: 0.762
Epoch 61/200 - Loss: 0.631
Epoch 71/200 - Loss: 0.453
Epoch 81/200 - Loss: 0.274
Epoch 91/200 - Loss: 0.049
Converged at epoch 94 with loss -0.037
[92mRank 0 - Lengthscale: [[0.72232234 0.43438634]] [0m
[92mRank 0 - Outputscale: 2.3622212409973145 [0m
[92mRank 0 - Noise: 0.1262391358613968 [0m
Rank 0 - Augmented dataset size: 704
Rank 0: After warm start model parameters:
Rank: 0, Lengthscale: [[0.72232234 0.43438634]]
Rank: 0, Outputscale: 2.3622210025787354
Rank: 0, Noise: 0.1262391358613968
decpxADMM initialized with rho: 0.85, lip: 1.0, tol_abs: 1e-05, tol_rel: 0.001, rank: 0, world_size: 49
[92mRank 0 - Training global model with dec-pxADMM optimizer[0m
rank 0, epoch 9, loss: 0.5964508652687073, rho: 0.4250, lip: 1.0000
rank 0, epoch 19, loss: 0.5603305101394653, rho: 0.1062, lip: 1.0000
rank 0, epoch 29, loss: 0.5756455063819885, rho: 0.1062, lip: 1.0000
rank 0, epoch 39, loss: 0.5739147663116455, rho: 0.0531, lip: 1.0000
rank 0, epoch 49, loss: 0.5743847489356995, rho: 0.0531, lip: 1.0000
rank 0, epoch 59, loss: 0.5788393616676331, rho: 0.0531, lip: 1.0000
rank 0, epoch 69, loss: 0.5794009566307068, rho: 0.0266, lip: 1.0000
Rank 0 - Training time: 46.93 seconds
[92mRank 0 - Testing RMSE: 0.3415[0m
[92mRank: 0, Lengthscale: [[0.49177974 0.38005507]] [0m
[92mRank: 0, Outputscale: 1.3885468244552612 [0m
[92mRank: 0, Noise: 0.11743680387735367 [0m
Run 3 completed successfully
Running pxpGP 4 with agents: 49
[92mRank 0 - sparse dataset size is: 7, local dataset: torch.Size([361, 2]), [0m
[92mRank 0 - Training local sparse GP model with 361 samples[0m
Epoch 1/200 - Loss: 15.357
Epoch 11/200 - Loss: 1.063
Epoch 21/200 - Loss: 0.990
Epoch 31/200 - Loss: 0.933
Epoch 41/200 - Loss: 0.809
Epoch 51/200 - Loss: 0.681
Epoch 61/200 - Loss: 0.532
Epoch 71/200 - Loss: 0.339
Epoch 81/200 - Loss: 0.118
Converged at epoch 88 with loss -0.044
[92mRank 0 - Lengthscale: [[0.6258985 0.534572 ]] [0m
[92mRank 0 - Outputscale: 2.091308832168579 [0m
[92mRank 0 - Noise: 0.12465809285640717 [0m
Rank 0 - Augmented dataset size: 704
Rank 0: After warm start model parameters:
Rank: 0, Lengthscale: [[0.6258985 0.534572 ]]
Rank: 0, Outputscale: 2.091308832168579
Rank: 0, Noise: 0.12465809285640717
decpxADMM initialized with rho: 0.85, lip: 1.0, tol_abs: 1e-05, tol_rel: 0.001, rank: 0, world_size: 49
[92mRank 0 - Training global model with dec-pxADMM optimizer[0m
rank 0, epoch 9, loss: 0.6460481882095337, rho: 0.2125, lip: 1.0000
rank 0, epoch 19, loss: 0.6320211887359619, rho: 0.1062, lip: 1.0000
rank 0, epoch 29, loss: 0.6294512152671814, rho: 0.1062, lip: 1.0000
rank 0, epoch 39, loss: 0.6302236318588257, rho: 0.0266, lip: 1.0000
rank 0, epoch 49, loss: 0.6318252682685852, rho: 0.0266, lip: 1.0000
rank 0, epoch 59, loss: 0.6343240141868591, rho: 0.0266, lip: 1.0000
rank 0, epoch 69, loss: 0.6357347369194031, rho: 0.0266, lip: 1.0000
Rank 0 - Training time: 51.24 seconds
[92mRank 0 - Testing RMSE: 0.3726[0m
[92mRank: 0, Lengthscale: [[0.48576227 0.34866223]] [0m
[92mRank: 0, Outputscale: 1.4152287244796753 [0m
[92mRank: 0, Noise: 0.12349839508533478 [0m
Run 4 completed successfully
Running pxpGP 5 with agents: 49
[92mRank 0 - sparse dataset size is: 7, local dataset: torch.Size([361, 2]), [0m
[92mRank 0 - Training local sparse GP model with 361 samples[0m
Epoch 1/200 - Loss: 9.921
Epoch 11/200 - Loss: 1.091
Epoch 21/200 - Loss: 1.033
Epoch 31/200 - Loss: 0.918
Epoch 41/200 - Loss: 0.871
Epoch 51/200 - Loss: 0.706
Epoch 61/200 - Loss: 0.581
Epoch 71/200 - Loss: 0.402
Epoch 81/200 - Loss: 0.164
Epoch 91/200 - Loss: -0.039
Converged at epoch 91 with loss -0.039
[92mRank 0 - Lengthscale: [[0.5399815  0.53223807]] [0m
[92mRank 0 - Outputscale: 2.116485834121704 [0m
[92mRank 0 - Noise: 0.12355168908834457 [0m
Rank 0 - Augmented dataset size: 704
Rank 0: After warm start model parameters:
Rank: 0, Lengthscale: [[0.5399815  0.53223807]]
Rank: 0, Outputscale: 2.116485834121704
Rank: 0, Noise: 0.12355168908834457
decpxADMM initialized with rho: 0.85, lip: 1.0, tol_abs: 1e-05, tol_rel: 0.001, rank: 0, world_size: 49
[92mRank 0 - Training global model with dec-pxADMM optimizer[0m
rank 0, epoch 9, loss: 0.7020372748374939, rho: 0.2125, lip: 1.0000
rank 0, epoch 19, loss: 0.6869662404060364, rho: 0.0531, lip: 1.0000
rank 0, epoch 29, loss: 0.7157595157623291, rho: 0.0531, lip: 1.0000
rank 0, epoch 39, loss: 0.7177522778511047, rho: 0.0531, lip: 1.0000
rank 0, epoch 49, loss: 0.7118584513664246, rho: 0.0531, lip: 1.0000
rank 0, epoch 59, loss: 0.7210965752601624, rho: 0.0531, lip: 1.0000
rank 0, epoch 69, loss: 0.7245900630950928, rho: 0.0531, lip: 1.0000
Rank 0 - Training time: 32.91 seconds
[92mRank 0 - Testing RMSE: 0.3482[0m
[92mRank: 0, Lengthscale: [[0.6184101  0.38656777]] [0m
[92mRank: 0, Outputscale: 0.9521447420120239 [0m
[92mRank: 0, Noise: 0.14867311716079712 [0m
Run 5 completed successfully
Running pxpGP 6 with agents: 49
[92mRank 0 - sparse dataset size is: 7, local dataset: torch.Size([361, 2]), [0m
[92mRank 0 - Training local sparse GP model with 361 samples[0m
Epoch 1/200 - Loss: 10.470
Epoch 11/200 - Loss: 1.221
Epoch 21/200 - Loss: 1.088
Epoch 31/200 - Loss: 1.067
Epoch 41/200 - Loss: 0.937
Epoch 51/200 - Loss: 0.745
Epoch 61/200 - Loss: 0.597
Epoch 71/200 - Loss: 0.404
Epoch 81/200 - Loss: 0.207
Converged at epoch 90 with loss -0.032
[92mRank 0 - Lengthscale: [[0.6987555 0.5030268]] [0m
[92mRank 0 - Outputscale: 2.440321445465088 [0m
[92mRank 0 - Noise: 0.131265327334404 [0m
Rank 0 - Augmented dataset size: 704
Rank 0: After warm start model parameters:
Rank: 0, Lengthscale: [[0.6987555 0.5030268]]
Rank: 0, Outputscale: 2.440321445465088
Rank: 0, Noise: 0.131265327334404
decpxADMM initialized with rho: 0.85, lip: 1.0, tol_abs: 1e-05, tol_rel: 0.001, rank: 0, world_size: 49
[92mRank 0 - Training global model with dec-pxADMM optimizer[0m
rank 0, epoch 9, loss: 0.49442920088768005, rho: 0.4250, lip: 1.0000
rank 0, epoch 19, loss: 0.4503908157348633, rho: 0.1062, lip: 1.0000
rank 0, epoch 29, loss: 0.45673367381095886, rho: 0.0531, lip: 1.0000
rank 0, epoch 39, loss: 0.4548851251602173, rho: 0.0531, lip: 1.0000
rank 0, epoch 49, loss: 0.4540994465351105, rho: 0.0531, lip: 1.0000
rank 0, epoch 59, loss: 0.45994165539741516, rho: 0.0266, lip: 1.0000
rank 0, epoch 69, loss: 0.46474993228912354, rho: 0.0266, lip: 1.0000
Rank 0 - Training time: 43.65 seconds
[92mRank 0 - Testing RMSE: 0.2925[0m
[92mRank: 0, Lengthscale: [[0.50911295 0.41769877]] [0m
[92mRank: 0, Outputscale: 1.384785771369934 [0m
[92mRank: 0, Noise: 0.08537980169057846 [0m
Run 6 completed successfully
Running pxpGP 7 with agents: 49
[92mRank 0 - sparse dataset size is: 7, local dataset: torch.Size([361, 2]), [0m
[92mRank 0 - Training local sparse GP model with 361 samples[0m
Epoch 1/200 - Loss: 10.140
Epoch 11/200 - Loss: 1.076
Epoch 21/200 - Loss: 0.995
Epoch 31/200 - Loss: 0.924
Epoch 41/200 - Loss: 0.819
Epoch 51/200 - Loss: 0.707
Epoch 61/200 - Loss: 0.574
Epoch 71/200 - Loss: 0.348
Epoch 81/200 - Loss: 0.139
Converged at epoch 88 with loss -0.023
[92mRank 0 - Lengthscale: [[0.503272  0.4754796]] [0m
[92mRank 0 - Outputscale: 2.021364688873291 [0m
[92mRank 0 - Noise: 0.13151253759860992 [0m
Rank 0 - Augmented dataset size: 704
Rank 0: After warm start model parameters:
Rank: 0, Lengthscale: [[0.503272  0.4754796]]
Rank: 0, Outputscale: 2.021364688873291
Rank: 0, Noise: 0.13151252269744873
decpxADMM initialized with rho: 0.85, lip: 1.0, tol_abs: 1e-05, tol_rel: 0.001, rank: 0, world_size: 49
[92mRank 0 - Training global model with dec-pxADMM optimizer[0m
rank 0, epoch 9, loss: 0.6903870701789856, rho: 0.2125, lip: 1.0000
rank 0, epoch 19, loss: 0.6539710760116577, rho: 0.2125, lip: 1.0000
rank 0, epoch 29, loss: 0.6545854210853577, rho: 0.1062, lip: 1.0000
rank 0, epoch 39, loss: 0.6548845171928406, rho: 0.0531, lip: 1.0000
rank 0, epoch 49, loss: 0.6530023217201233, rho: 0.0531, lip: 1.0000
rank 0, epoch 59, loss: 0.6533871293067932, rho: 0.0531, lip: 1.0000
rank 0, epoch 69, loss: 0.6546000838279724, rho: 0.0133, lip: 1.0000
Rank 0 - Training time: 57.45 seconds
[92mRank 0 - Testing RMSE: 0.4163[0m
[92mRank: 0, Lengthscale: [[0.43748397 0.25635624]] [0m
[92mRank: 0, Outputscale: 1.6862536668777466 [0m
[92mRank: 0, Noise: 0.11969135701656342 [0m
Run 7 completed successfully
Running pxpGP 8 with agents: 49
[92mRank 0 - sparse dataset size is: 7, local dataset: torch.Size([361, 2]), [0m
[92mRank 0 - Training local sparse GP model with 361 samples[0m
Epoch 1/200 - Loss: 14.006
Epoch 11/200 - Loss: 1.117
Epoch 21/200 - Loss: 1.005
Epoch 31/200 - Loss: 0.930
Epoch 41/200 - Loss: 0.822
Epoch 51/200 - Loss: 0.699
Epoch 61/200 - Loss: 0.545
Epoch 71/200 - Loss: 0.357
Epoch 81/200 - Loss: 0.153
Converged at epoch 88 with loss -0.024
[92mRank 0 - Lengthscale: [[0.6357475  0.49394816]] [0m
[92mRank 0 - Outputscale: 2.1059892177581787 [0m
[92mRank 0 - Noise: 0.1333710253238678 [0m
Rank 0 - Augmented dataset size: 704
Rank 0: After warm start model parameters:
Rank: 0, Lengthscale: [[0.6357475  0.49394816]]
Rank: 0, Outputscale: 2.1059892177581787
Rank: 0, Noise: 0.1333710253238678
decpxADMM initialized with rho: 0.85, lip: 1.0, tol_abs: 1e-05, tol_rel: 0.001, rank: 0, world_size: 49
[92mRank 0 - Training global model with dec-pxADMM optimizer[0m
rank 0, epoch 9, loss: 0.6287058591842651, rho: 0.2125, lip: 1.0000
rank 0, epoch 19, loss: 0.6269151568412781, rho: 0.1062, lip: 1.0000
rank 0, epoch 29, loss: 0.6526798605918884, rho: 0.0531, lip: 1.0000
rank 0, epoch 39, loss: 0.653663694858551, rho: 0.0531, lip: 1.0000
rank 0, epoch 49, loss: 0.65211421251297, rho: 0.0531, lip: 1.0000
rank 0, epoch 59, loss: 0.6577811241149902, rho: 0.0266, lip: 1.0000
rank 0, epoch 69, loss: 0.6600585579872131, rho: 0.0266, lip: 1.0000
Rank 0 - Training time: 35.93 seconds
[92mRank 0 - Testing RMSE: 0.3190[0m
[92mRank: 0, Lengthscale: [[0.6568111  0.42286706]] [0m
[92mRank: 0, Outputscale: 1.1434319019317627 [0m
[92mRank: 0, Noise: 0.13412585854530334 [0m
Run 8 completed successfully
Running pxpGP 9 with agents: 49
[92mRank 0 - sparse dataset size is: 7, local dataset: torch.Size([361, 2]), [0m
[92mRank 0 - Training local sparse GP model with 361 samples[0m
Epoch 1/200 - Loss: 21.824
Epoch 11/200 - Loss: 1.088
Epoch 21/200 - Loss: 1.068
Epoch 31/200 - Loss: 1.003
Epoch 41/200 - Loss: 0.850
Epoch 51/200 - Loss: 0.756
Epoch 61/200 - Loss: 0.602
Epoch 71/200 - Loss: 0.420
Epoch 81/200 - Loss: 0.214
Converged at epoch 90 with loss -0.005
[92mRank 0 - Lengthscale: [[0.7096799  0.50244963]] [0m
[92mRank 0 - Outputscale: 2.372192144393921 [0m
[92mRank 0 - Noise: 0.1381523609161377 [0m
Rank 0 - Augmented dataset size: 704
Rank 0: After warm start model parameters:
Rank: 0, Lengthscale: [[0.70967984 0.50244963]]
Rank: 0, Outputscale: 2.372192144393921
Rank: 0, Noise: 0.1381523609161377
decpxADMM initialized with rho: 0.85, lip: 1.0, tol_abs: 1e-05, tol_rel: 0.001, rank: 0, world_size: 49
[92mRank 0 - Training global model with dec-pxADMM optimizer[0m
rank 0, epoch 9, loss: 0.6484056711196899, rho: 0.4250, lip: 1.0000
rank 0, epoch 19, loss: 0.6135497689247131, rho: 0.1062, lip: 1.0000
rank 0, epoch 29, loss: 0.6151056289672852, rho: 0.1062, lip: 1.0000
rank 0, epoch 39, loss: 0.6076266169548035, rho: 0.0266, lip: 1.0000
rank 0, epoch 49, loss: 0.6031267642974854, rho: 0.0266, lip: 1.0000
rank 0, epoch 59, loss: 0.6036919951438904, rho: 0.0266, lip: 1.0000
rank 0, epoch 69, loss: 0.6059699654579163, rho: 0.0266, lip: 1.0000
Rank 0 - Training time: 32.62 seconds
[92mRank 0 - Testing RMSE: 0.3211[0m
[92mRank: 0, Lengthscale: [[0.70787835 0.4414026 ]] [0m
[92mRank: 0, Outputscale: 1.8605382442474365 [0m
[92mRank: 0, Noise: 0.1393330991268158 [0m
Run 9 completed successfully
Running pxpGP 10 with agents: 49
[92mRank 0 - sparse dataset size is: 7, local dataset: torch.Size([361, 2]), [0m
[92mRank 0 - Training local sparse GP model with 361 samples[0m
Epoch 1/200 - Loss: 16.180
Epoch 11/200 - Loss: 1.146
Epoch 21/200 - Loss: 0.992
Epoch 31/200 - Loss: 0.925
Epoch 41/200 - Loss: 0.816
Epoch 51/200 - Loss: 0.691
Epoch 61/200 - Loss: 0.581
Epoch 71/200 - Loss: 0.369
Epoch 81/200 - Loss: 0.258
Converged at epoch 89 with loss -0.002
[92mRank 0 - Lengthscale: [[0.55727416 0.5246895 ]] [0m
[92mRank 0 - Outputscale: 2.1145517826080322 [0m
[92mRank 0 - Noise: 0.13130050897598267 [0m
Rank 0 - Augmented dataset size: 704
Rank 0: After warm start model parameters:
Rank: 0, Lengthscale: [[0.55727416 0.52468956]]
Rank: 0, Outputscale: 2.1145517826080322
Rank: 0, Noise: 0.13130050897598267
decpxADMM initialized with rho: 0.85, lip: 1.0, tol_abs: 1e-05, tol_rel: 0.001, rank: 0, world_size: 49
[92mRank 0 - Training global model with dec-pxADMM optimizer[0m
rank 0, epoch 9, loss: 0.5778825879096985, rho: 0.2125, lip: 1.0000
rank 0, epoch 19, loss: 0.544373095035553, rho: 0.1062, lip: 1.0000
rank 0, epoch 29, loss: 0.5429865717887878, rho: 0.0531, lip: 1.0000
rank 0, epoch 39, loss: 0.5317216515541077, rho: 0.0266, lip: 1.0000
rank 0, epoch 49, loss: 0.5288670063018799, rho: 0.0266, lip: 1.0000
rank 0, epoch 59, loss: 0.5283980369567871, rho: 0.0266, lip: 1.0000
rank 0, epoch 69, loss: 0.5284106135368347, rho: 0.0266, lip: 1.0000
Rank 0 - Training time: 33.59 seconds
[92mRank 0 - Testing RMSE: 0.3352[0m
[92mRank: 0, Lengthscale: [[0.55135477 0.3893263 ]] [0m
[92mRank: 0, Outputscale: 2.3297977447509766 [0m
[92mRank: 0, Noise: 0.10915956646203995 [0m
Run 10 completed successfully
Running gapxGP 1 with agents: 49
decpxADMM initialized with rho: 0.75, lip: 1.0, tol_abs: 1e-05, tol_rel: 0.001, rank: 0, world_size: 49
Rank 0 - Epoch 2/73 loss: 1.0005271434783936
Rank 0 - Epoch 10/73 loss: 0.7891619801521301
Rank 0 - Epoch 20/73 loss: 0.46542495489120483
Rank 0 - Epoch 30/73 loss: 0.05544102564454079
Rank 0 - Epoch 40/73 loss: -0.35464200377464294
Rank 0 - Epoch 50/73 loss: -0.7630675435066223
Rank 0 - Epoch 60/73 loss: -1.156804084777832
Rank 0 - Epoch 70/73 loss: -1.5194710493087769
[92mRank 0 - Testing RMSE: 0.0147[0m
[92mRank: 0, Lengthscale: [[0.62112886 0.36459643]] [0m
[92mRank: 0, Outputscale: 1.5629862546920776 [0m
[92mRank: 0, Noise: 0.0014071271289139986 [0m
Run 1 completed successfully
Running gapxGP 2 with agents: 49
decpxADMM initialized with rho: 0.75, lip: 1.0, tol_abs: 1e-05, tol_rel: 0.001, rank: 0, world_size: 49
Rank 0 - Epoch 2/73 loss: 0.9916731119155884
Rank 0 - Epoch 10/73 loss: 0.768352210521698
Rank 0 - Epoch 20/73 loss: 0.44345054030418396
Rank 0 - Epoch 30/73 loss: 0.04367315024137497
Rank 0 - Epoch 40/73 loss: -0.3673471510410309
Rank 0 - Epoch 50/73 loss: -0.7820266485214233
Rank 0 - Epoch 60/73 loss: -1.1815516948699951
Rank 0 - Epoch 70/73 loss: -1.5477489233016968
[92mRank 0 - Testing RMSE: 0.0144[0m
[92mRank: 0, Lengthscale: [[0.6216846  0.36654717]] [0m
[92mRank: 0, Outputscale: 1.5700764656066895 [0m
[92mRank: 0, Noise: 0.0013610830064862967 [0m
Run 2 completed successfully
Running gapxGP 3 with agents: 49
decpxADMM initialized with rho: 0.75, lip: 1.0, tol_abs: 1e-05, tol_rel: 0.001, rank: 0, world_size: 49
Rank 0 - Epoch 2/73 loss: 1.0074857473373413
Rank 0 - Epoch 10/73 loss: 0.7955723404884338
Rank 0 - Epoch 20/73 loss: 0.46843913197517395
Rank 0 - Epoch 30/73 loss: 0.05856476351618767
Rank 0 - Epoch 40/73 loss: -0.3574647009372711
Rank 0 - Epoch 50/73 loss: -0.7759634256362915
Rank 0 - Epoch 60/73 loss: -1.175913691520691
Rank 0 - Epoch 70/73 loss: -1.542069911956787
[92mRank 0 - Testing RMSE: 0.0159[0m
[92mRank: 0, Lengthscale: [[0.6226243 0.364652 ]] [0m
[92mRank: 0, Outputscale: 1.5768591165542603 [0m
[92mRank: 0, Noise: 0.0013725340832024813 [0m
Run 3 completed successfully
Running gapxGP 4 with agents: 49
decpxADMM initialized with rho: 0.75, lip: 1.0, tol_abs: 1e-05, tol_rel: 0.001, rank: 0, world_size: 49
Rank 0 - Epoch 2/73 loss: 1.0047783851623535
Rank 0 - Epoch 10/73 loss: 0.7904379963874817
Rank 0 - Epoch 20/73 loss: 0.46550095081329346
Rank 0 - Epoch 30/73 loss: 0.06118980050086975
Rank 0 - Epoch 40/73 loss: -0.35137519240379333
Rank 0 - Epoch 50/73 loss: -0.7636500597000122
Rank 0 - Epoch 60/73 loss: -1.1584116220474243
Rank 0 - Epoch 70/73 loss: -1.518229603767395
[92mRank 0 - Testing RMSE: 0.0135[0m
[92mRank: 0, Lengthscale: [[0.6263897  0.36611545]] [0m
[92mRank: 0, Outputscale: 1.5663962364196777 [0m
[92mRank: 0, Noise: 0.0014049389865249395 [0m
Run 4 completed successfully
Running gapxGP 5 with agents: 49
decpxADMM initialized with rho: 0.75, lip: 1.0, tol_abs: 1e-05, tol_rel: 0.001, rank: 0, world_size: 49
Rank 0 - Epoch 2/73 loss: 1.0000892877578735
Rank 0 - Epoch 10/73 loss: 0.7860620617866516
Rank 0 - Epoch 20/73 loss: 0.4605600833892822
Rank 0 - Epoch 30/73 loss: 0.05542386323213577
Rank 0 - Epoch 40/73 loss: -0.35582032799720764
Rank 0 - Epoch 50/73 loss: -0.77042555809021
Rank 0 - Epoch 60/73 loss: -1.1691067218780518
Rank 0 - Epoch 70/73 loss: -1.5368869304656982
[92mRank 0 - Testing RMSE: 0.0149[0m
[92mRank: 0, Lengthscale: [[0.6231467  0.36559916]] [0m
[92mRank: 0, Outputscale: 1.565359115600586 [0m
[92mRank: 0, Noise: 0.0013888813555240631 [0m
Run 5 completed successfully
Running gapxGP 6 with agents: 49
decpxADMM initialized with rho: 0.75, lip: 1.0, tol_abs: 1e-05, tol_rel: 0.001, rank: 0, world_size: 49
Rank 0 - Epoch 2/73 loss: 1.002821683883667
Rank 0 - Epoch 10/73 loss: 0.7922497987747192
Rank 0 - Epoch 20/73 loss: 0.4670470654964447
Rank 0 - Epoch 30/73 loss: 0.05440649390220642
Rank 0 - Epoch 40/73 loss: -0.36184531450271606
Rank 0 - Epoch 50/73 loss: -0.7752092480659485
Rank 0 - Epoch 60/73 loss: -1.1717307567596436
Rank 0 - Epoch 70/73 loss: -1.5363279581069946
[92mRank 0 - Testing RMSE: 0.0171[0m
[92mRank: 0, Lengthscale: [[0.6240336 0.3680061]] [0m
[92mRank: 0, Outputscale: 1.5631967782974243 [0m
[92mRank: 0, Noise: 0.0013796897837892175 [0m
Run 6 completed successfully
Running gapxGP 7 with agents: 49
decpxADMM initialized with rho: 0.75, lip: 1.0, tol_abs: 1e-05, tol_rel: 0.001, rank: 0, world_size: 49
Rank 0 - Epoch 2/73 loss: 0.9961363077163696
Rank 0 - Epoch 10/73 loss: 0.7802598476409912
Rank 0 - Epoch 20/73 loss: 0.4705241918563843
Rank 0 - Epoch 30/73 loss: 0.07963827252388
Rank 0 - Epoch 40/73 loss: -0.3314287066459656
Rank 0 - Epoch 50/73 loss: -0.745460033416748
Rank 0 - Epoch 60/73 loss: -1.1421388387680054
Rank 0 - Epoch 70/73 loss: -1.5060352087020874
[92mRank 0 - Testing RMSE: 0.0157[0m
[92mRank: 0, Lengthscale: [[0.6229432  0.36760423]] [0m
[92mRank: 0, Outputscale: 1.5652865171432495 [0m
[92mRank: 0, Noise: 0.001452466007322073 [0m
Run 7 completed successfully
Running gapxGP 8 with agents: 49
decpxADMM initialized with rho: 0.75, lip: 1.0, tol_abs: 1e-05, tol_rel: 0.001, rank: 0, world_size: 49
Rank 0 - Epoch 2/73 loss: 1.003406047821045
Rank 0 - Epoch 10/73 loss: 0.7913615107536316
Rank 0 - Epoch 20/73 loss: 0.47139492630958557
Rank 0 - Epoch 30/73 loss: 0.06378795206546783
Rank 0 - Epoch 40/73 loss: -0.3517390489578247
Rank 0 - Epoch 50/73 loss: -0.7641364336013794
Rank 0 - Epoch 60/73 loss: -1.1591920852661133
Rank 0 - Epoch 70/73 loss: -1.5230658054351807
[92mRank 0 - Testing RMSE: 0.0142[0m
[92mRank: 0, Lengthscale: [[0.62535125 0.36654365]] [0m
[92mRank: 0, Outputscale: 1.5699836015701294 [0m
[92mRank: 0, Noise: 0.0014122523134574294 [0m
Run 8 completed successfully
Running gapxGP 9 with agents: 49
decpxADMM initialized with rho: 0.75, lip: 1.0, tol_abs: 1e-05, tol_rel: 0.001, rank: 0, world_size: 49
Rank 0 - Epoch 2/73 loss: 1.008396029472351
Rank 0 - Epoch 10/73 loss: 0.7961606383323669
Rank 0 - Epoch 20/73 loss: 0.4659445583820343
Rank 0 - Epoch 30/73 loss: 0.056946150958538055
Rank 0 - Epoch 40/73 loss: -0.3551303744316101
Rank 0 - Epoch 50/73 loss: -0.7680912017822266
Rank 0 - Epoch 60/73 loss: -1.1640089750289917
Rank 0 - Epoch 70/73 loss: -1.5266624689102173
[92mRank 0 - Testing RMSE: 0.0133[0m
[92mRank: 0, Lengthscale: [[0.626472  0.3655392]] [0m
[92mRank: 0, Outputscale: 1.5741268396377563 [0m
[92mRank: 0, Noise: 0.0013906169915571809 [0m
Run 9 completed successfully
Running gapxGP 10 with agents: 49
decpxADMM initialized with rho: 0.75, lip: 1.0, tol_abs: 1e-05, tol_rel: 0.001, rank: 0, world_size: 49
Rank 0 - Epoch 2/73 loss: 0.9962124824523926
Rank 0 - Epoch 10/73 loss: 0.7823787331581116
Rank 0 - Epoch 20/73 loss: 0.46080490946769714
Rank 0 - Epoch 30/73 loss: 0.05334017425775528
Rank 0 - Epoch 40/73 loss: -0.35898515582084656
Rank 0 - Epoch 50/73 loss: -0.7724506855010986
Rank 0 - Epoch 60/73 loss: -1.1704373359680176
Rank 0 - Epoch 70/73 loss: -1.5381104946136475
[92mRank 0 - Testing RMSE: 0.0134[0m
[92mRank: 0, Lengthscale: [[0.6185232 0.3660867]] [0m
[92mRank: 0, Outputscale: 1.562408447265625 [0m
[92mRank: 0, Noise: 0.0013824772322550416 [0m
Run 10 completed successfully
Running apxGP 1 with agents: 49
decpxADMM initialized with rho: 0.85, lip: 1.0, tol_abs: 1e-05, tol_rel: 0.001, rank: 0, world_size: 49
Rank 0 - Epoch 2/98 loss: 0.7951105833053589
Rank 0 - Epoch 10/98 loss: 0.5315737724304199
Rank 0 - Epoch 20/98 loss: 0.11072081327438354
Rank 0 - Epoch 30/98 loss: -0.37529343366622925
Rank 0 - Epoch 40/98 loss: -0.8919476270675659
Rank 0 - Epoch 50/98 loss: -1.409353494644165
Rank 0 - Epoch 60/98 loss: -1.8986940383911133
Rank 0 - Epoch 70/98 loss: -2.341388702392578
Rank 0 - Epoch 80/98 loss: -2.7092044353485107
Rank 0 - Epoch 90/98 loss: -2.9711556434631348
Training complete.
[92mRank 0 - Testing RMSE: 3.0221[0m
[92mRank: 0, Lengthscale: [[0.5928212 0.3620058]] [0m
[92mRank: 0, Outputscale: 1.153544306755066 [0m
[92mRank: 0, Noise: 0.0002063704887405038 [0m
Run 1 completed successfully
Running apxGP 2 with agents: 49
decpxADMM initialized with rho: 0.85, lip: 1.0, tol_abs: 1e-05, tol_rel: 0.001, rank: 0, world_size: 49
Rank 0 - Epoch 2/98 loss: 0.7951105833053589
Rank 0 - Epoch 10/98 loss: 0.5315737724304199
Rank 0 - Epoch 20/98 loss: 0.11072081327438354
Rank 0 - Epoch 30/98 loss: -0.37529343366622925
Rank 0 - Epoch 40/98 loss: -0.8919476270675659
Rank 0 - Epoch 50/98 loss: -1.409353494644165
Rank 0 - Epoch 60/98 loss: -1.8986940383911133
Rank 0 - Epoch 70/98 loss: -2.341388702392578
Rank 0 - Epoch 80/98 loss: -2.7092044353485107
Rank 0 - Epoch 90/98 loss: -2.9711556434631348
Training complete.
[92mRank 0 - Testing RMSE: 3.0221[0m
[92mRank: 0, Lengthscale: [[0.5928212 0.3620058]] [0m
[92mRank: 0, Outputscale: 1.153544306755066 [0m
[92mRank: 0, Noise: 0.0002063704887405038 [0m
Run 2 completed successfully
Running apxGP 3 with agents: 49
decpxADMM initialized with rho: 0.85, lip: 1.0, tol_abs: 1e-05, tol_rel: 0.001, rank: 0, world_size: 49
Rank 0 - Epoch 2/98 loss: 0.7951105833053589
Rank 0 - Epoch 10/98 loss: 0.5315737724304199
Rank 0 - Epoch 20/98 loss: 0.11072081327438354
Rank 0 - Epoch 30/98 loss: -0.37529343366622925
Rank 0 - Epoch 40/98 loss: -0.8919476270675659
Rank 0 - Epoch 50/98 loss: -1.409353494644165
Rank 0 - Epoch 60/98 loss: -1.8986940383911133
Rank 0 - Epoch 70/98 loss: -2.341388702392578
Rank 0 - Epoch 80/98 loss: -2.7092044353485107
Rank 0 - Epoch 90/98 loss: -2.9711556434631348
Training complete.
[92mRank 0 - Testing RMSE: 3.0221[0m
[92mRank: 0, Lengthscale: [[0.5928212 0.3620058]] [0m
[92mRank: 0, Outputscale: 1.153544306755066 [0m
[92mRank: 0, Noise: 0.0002063704887405038 [0m
Run 3 completed successfully
Running apxGP 4 with agents: 49
decpxADMM initialized with rho: 0.85, lip: 1.0, tol_abs: 1e-05, tol_rel: 0.001, rank: 0, world_size: 49
Rank 0 - Epoch 2/98 loss: 0.7951105833053589
Rank 0 - Epoch 10/98 loss: 0.5315737724304199
Rank 0 - Epoch 20/98 loss: 0.11072081327438354
Rank 0 - Epoch 30/98 loss: -0.37529343366622925
Rank 0 - Epoch 40/98 loss: -0.8919476270675659
Rank 0 - Epoch 50/98 loss: -1.409353494644165
Rank 0 - Epoch 60/98 loss: -1.8986940383911133
Rank 0 - Epoch 70/98 loss: -2.341388702392578
Rank 0 - Epoch 80/98 loss: -2.7092044353485107
Rank 0 - Epoch 90/98 loss: -2.9711556434631348
Training complete.
[92mRank 0 - Testing RMSE: 3.0221[0m
[92mRank: 0, Lengthscale: [[0.5928212 0.3620058]] [0m
[92mRank: 0, Outputscale: 1.153544306755066 [0m
[92mRank: 0, Noise: 0.0002063704887405038 [0m
Run 4 completed successfully
Running apxGP 5 with agents: 49
decpxADMM initialized with rho: 0.85, lip: 1.0, tol_abs: 1e-05, tol_rel: 0.001, rank: 0, world_size: 49
Rank 0 - Epoch 2/98 loss: 0.7951105833053589
Rank 0 - Epoch 10/98 loss: 0.5315737724304199
Rank 0 - Epoch 20/98 loss: 0.11072081327438354
Rank 0 - Epoch 30/98 loss: -0.37529343366622925
Rank 0 - Epoch 40/98 loss: -0.8919476270675659
Rank 0 - Epoch 50/98 loss: -1.409353494644165
Rank 0 - Epoch 60/98 loss: -1.8986940383911133
Rank 0 - Epoch 70/98 loss: -2.341388702392578
Rank 0 - Epoch 80/98 loss: -2.7092044353485107
Rank 0 - Epoch 90/98 loss: -2.9711556434631348
Training complete.
[92mRank 0 - Testing RMSE: 3.0221[0m
[92mRank: 0, Lengthscale: [[0.5928212 0.3620058]] [0m
[92mRank: 0, Outputscale: 1.153544306755066 [0m
[92mRank: 0, Noise: 0.0002063704887405038 [0m
Run 5 completed successfully
Running apxGP 6 with agents: 49
decpxADMM initialized with rho: 0.85, lip: 1.0, tol_abs: 1e-05, tol_rel: 0.001, rank: 0, world_size: 49
Rank 0 - Epoch 2/98 loss: 0.7951105833053589
Rank 0 - Epoch 10/98 loss: 0.5315737724304199
Rank 0 - Epoch 20/98 loss: 0.11072081327438354
Rank 0 - Epoch 30/98 loss: -0.37529343366622925
Rank 0 - Epoch 40/98 loss: -0.8919476270675659
Rank 0 - Epoch 50/98 loss: -1.409353494644165
Rank 0 - Epoch 60/98 loss: -1.8986940383911133
Rank 0 - Epoch 70/98 loss: -2.341388702392578
Rank 0 - Epoch 80/98 loss: -2.7092044353485107
Rank 0 - Epoch 90/98 loss: -2.9711556434631348
Training complete.
[92mRank 0 - Testing RMSE: 3.0221[0m
[92mRank: 0, Lengthscale: [[0.5928212 0.3620058]] [0m
[92mRank: 0, Outputscale: 1.153544306755066 [0m
[92mRank: 0, Noise: 0.0002063704887405038 [0m
Run 6 completed successfully
Running apxGP 7 with agents: 49
decpxADMM initialized with rho: 0.85, lip: 1.0, tol_abs: 1e-05, tol_rel: 0.001, rank: 0, world_size: 49
Rank 0 - Epoch 2/98 loss: 0.7951105833053589
Rank 0 - Epoch 10/98 loss: 0.5315737724304199
Rank 0 - Epoch 20/98 loss: 0.11072081327438354
Rank 0 - Epoch 30/98 loss: -0.37529343366622925
Rank 0 - Epoch 40/98 loss: -0.8919476270675659
Rank 0 - Epoch 50/98 loss: -1.409353494644165
Rank 0 - Epoch 60/98 loss: -1.8986940383911133
Rank 0 - Epoch 70/98 loss: -2.341388702392578
Rank 0 - Epoch 80/98 loss: -2.7092044353485107
Rank 0 - Epoch 90/98 loss: -2.9711556434631348
Training complete.
[92mRank 0 - Testing RMSE: 3.0221[0m
[92mRank: 0, Lengthscale: [[0.5928212 0.3620058]] [0m
[92mRank: 0, Outputscale: 1.153544306755066 [0m
[92mRank: 0, Noise: 0.0002063704887405038 [0m
Run 7 completed successfully
Running apxGP 8 with agents: 49
decpxADMM initialized with rho: 0.85, lip: 1.0, tol_abs: 1e-05, tol_rel: 0.001, rank: 0, world_size: 49
Rank 0 - Epoch 2/98 loss: 0.7951105833053589
Rank 0 - Epoch 10/98 loss: 0.5315737724304199
Rank 0 - Epoch 20/98 loss: 0.11072081327438354
Rank 0 - Epoch 30/98 loss: -0.37529343366622925
Rank 0 - Epoch 40/98 loss: -0.8919476270675659
Rank 0 - Epoch 50/98 loss: -1.409353494644165
Rank 0 - Epoch 60/98 loss: -1.8986940383911133
Rank 0 - Epoch 70/98 loss: -2.341388702392578
Rank 0 - Epoch 80/98 loss: -2.7092044353485107
Rank 0 - Epoch 90/98 loss: -2.9711556434631348
Training complete.
[92mRank 0 - Testing RMSE: 3.0221[0m
[92mRank: 0, Lengthscale: [[0.5928212 0.3620058]] [0m
[92mRank: 0, Outputscale: 1.153544306755066 [0m
[92mRank: 0, Noise: 0.0002063704887405038 [0m
Run 8 completed successfully
Running apxGP 9 with agents: 49
decpxADMM initialized with rho: 0.85, lip: 1.0, tol_abs: 1e-05, tol_rel: 0.001, rank: 0, world_size: 49
Rank 0 - Epoch 2/98 loss: 0.7951105833053589
Rank 0 - Epoch 10/98 loss: 0.5315737724304199
Rank 0 - Epoch 20/98 loss: 0.11072081327438354
Rank 0 - Epoch 30/98 loss: -0.37529343366622925
Rank 0 - Epoch 40/98 loss: -0.8919476270675659
Rank 0 - Epoch 50/98 loss: -1.409353494644165
Rank 0 - Epoch 60/98 loss: -1.8986940383911133
Rank 0 - Epoch 70/98 loss: -2.341388702392578
Rank 0 - Epoch 80/98 loss: -2.7092044353485107
Rank 0 - Epoch 90/98 loss: -2.9711556434631348
Training complete.
[92mRank 0 - Testing RMSE: 3.0221[0m
[92mRank: 0, Lengthscale: [[0.5928212 0.3620058]] [0m
[92mRank: 0, Outputscale: 1.153544306755066 [0m
[92mRank: 0, Noise: 0.0002063704887405038 [0m
Run 9 completed successfully
Running apxGP 10 with agents: 49
decpxADMM initialized with rho: 0.85, lip: 1.0, tol_abs: 1e-05, tol_rel: 0.001, rank: 0, world_size: 49
Rank 0 - Epoch 2/98 loss: 0.7951105833053589
Rank 0 - Epoch 10/98 loss: 0.5315737724304199
Rank 0 - Epoch 20/98 loss: 0.11072081327438354
Rank 0 - Epoch 30/98 loss: -0.37529343366622925
Rank 0 - Epoch 40/98 loss: -0.8919476270675659
Rank 0 - Epoch 50/98 loss: -1.409353494644165
Rank 0 - Epoch 60/98 loss: -1.8986940383911133
Rank 0 - Epoch 70/98 loss: -2.341388702392578
Rank 0 - Epoch 80/98 loss: -2.7092044353485107
Rank 0 - Epoch 90/98 loss: -2.9711556434631348
Training complete.
[92mRank 0 - Testing RMSE: 3.0221[0m
[92mRank: 0, Lengthscale: [[0.5928212 0.3620058]] [0m
[92mRank: 0, Outputscale: 1.153544306755066 [0m
[92mRank: 0, Noise: 0.0002063704887405038 [0m
Run 10 completed successfully
Running cGP 1 with agents: 49
decADMM initialized with rho: 0.85, max_iter: 5, lr: 0.0001, rank: 0, world_size: 49
Rank 0 - Epoch 2/98 loss: 0.8505483865737915
Rank 0 - Epoch 10/98 loss: 0.8455040454864502
Rank 0 - Epoch 20/98 loss: 0.8392010927200317
Rank 0 - Epoch 30/98 loss: 0.8329039812088013
Rank 0 - Epoch 40/98 loss: 0.8266162872314453
Rank 0 - Epoch 50/98 loss: 0.820341944694519
Rank 0 - Epoch 60/98 loss: 0.8140848278999329
Rank 0 - Epoch 70/98 loss: 0.8078489899635315
Rank 0 - Epoch 80/98 loss: 0.8016384243965149
Rank 0 - Epoch 90/98 loss: 0.7954578995704651
Training complete.
[92mRank 0 - Testing RMSE: 3.5958[0m
[92mRank: 0, Lengthscale: [[0.61296743 0.6124339 ]] [0m
[92mRank: 0, Outputscale: 0.614656925201416 [0m
[92mRank: 0, Noise: 0.6054919362068176 [0m
Run 1 completed successfully
Running cGP 2 with agents: 49
decADMM initialized with rho: 0.85, max_iter: 5, lr: 0.0001, rank: 0, world_size: 49
Rank 0 - Epoch 2/98 loss: 0.8505483865737915
Rank 0 - Epoch 10/98 loss: 0.8455040454864502
Rank 0 - Epoch 20/98 loss: 0.8392010927200317
Rank 0 - Epoch 30/98 loss: 0.8329039812088013
Rank 0 - Epoch 40/98 loss: 0.8266162872314453
Rank 0 - Epoch 50/98 loss: 0.820341944694519
Rank 0 - Epoch 60/98 loss: 0.8140848278999329
Rank 0 - Epoch 70/98 loss: 0.8078489899635315
Rank 0 - Epoch 80/98 loss: 0.8016384243965149
Rank 0 - Epoch 90/98 loss: 0.7954578995704651
Training complete.
[92mRank 0 - Testing RMSE: 3.5958[0m
[92mRank: 0, Lengthscale: [[0.61296743 0.6124339 ]] [0m
[92mRank: 0, Outputscale: 0.614656925201416 [0m
[92mRank: 0, Noise: 0.6054919362068176 [0m
Run 2 completed successfully
Running cGP 3 with agents: 49
decADMM initialized with rho: 0.85, max_iter: 5, lr: 0.0001, rank: 0, world_size: 49
Rank 0 - Epoch 2/98 loss: 0.8505483865737915
Rank 0 - Epoch 10/98 loss: 0.8455040454864502
Rank 0 - Epoch 20/98 loss: 0.8392010927200317
Rank 0 - Epoch 30/98 loss: 0.8329039812088013
Rank 0 - Epoch 40/98 loss: 0.8266162872314453
Rank 0 - Epoch 50/98 loss: 0.820341944694519
Rank 0 - Epoch 60/98 loss: 0.8140848278999329
Rank 0 - Epoch 70/98 loss: 0.8078489899635315
Rank 0 - Epoch 80/98 loss: 0.8016384243965149
Rank 0 - Epoch 90/98 loss: 0.7954578995704651
Training complete.
[92mRank 0 - Testing RMSE: 3.5958[0m
[92mRank: 0, Lengthscale: [[0.61296743 0.6124339 ]] [0m
[92mRank: 0, Outputscale: 0.614656925201416 [0m
[92mRank: 0, Noise: 0.6054919362068176 [0m
Run 3 completed successfully
Running cGP 4 with agents: 49
decADMM initialized with rho: 0.85, max_iter: 5, lr: 0.0001, rank: 0, world_size: 49
Rank 0 - Epoch 2/98 loss: 0.8505483865737915
Rank 0 - Epoch 10/98 loss: 0.8455040454864502
Rank 0 - Epoch 20/98 loss: 0.8392010927200317
Rank 0 - Epoch 30/98 loss: 0.8329039812088013
Rank 0 - Epoch 40/98 loss: 0.8266162872314453
Rank 0 - Epoch 50/98 loss: 0.820341944694519
Rank 0 - Epoch 60/98 loss: 0.8140848278999329
Rank 0 - Epoch 70/98 loss: 0.8078489899635315
Rank 0 - Epoch 80/98 loss: 0.8016384243965149
Rank 0 - Epoch 90/98 loss: 0.7954578995704651
Training complete.
[92mRank 0 - Testing RMSE: 3.5958[0m
[92mRank: 0, Lengthscale: [[0.61296743 0.6124339 ]] [0m
[92mRank: 0, Outputscale: 0.614656925201416 [0m
[92mRank: 0, Noise: 0.6054919362068176 [0m
Run 4 completed successfully
Running cGP 5 with agents: 49
decADMM initialized with rho: 0.85, max_iter: 5, lr: 0.0001, rank: 0, world_size: 49
Rank 0 - Epoch 2/98 loss: 0.8505483865737915
Rank 0 - Epoch 10/98 loss: 0.8455040454864502
Rank 0 - Epoch 20/98 loss: 0.8392010927200317
Rank 0 - Epoch 30/98 loss: 0.8329039812088013
Rank 0 - Epoch 40/98 loss: 0.8266162872314453
Rank 0 - Epoch 50/98 loss: 0.820341944694519
Rank 0 - Epoch 60/98 loss: 0.8140848278999329
Rank 0 - Epoch 70/98 loss: 0.8078489899635315
Rank 0 - Epoch 80/98 loss: 0.8016384243965149
Rank 0 - Epoch 90/98 loss: 0.7954578995704651
Training complete.
[92mRank 0 - Testing RMSE: 3.5958[0m
[92mRank: 0, Lengthscale: [[0.61296743 0.6124339 ]] [0m
[92mRank: 0, Outputscale: 0.614656925201416 [0m
[92mRank: 0, Noise: 0.6054919362068176 [0m
Run 5 completed successfully
Running cGP 6 with agents: 49
decADMM initialized with rho: 0.85, max_iter: 5, lr: 0.0001, rank: 0, world_size: 49
Rank 0 - Epoch 2/98 loss: 0.8505483865737915
Rank 0 - Epoch 10/98 loss: 0.8455040454864502
Rank 0 - Epoch 20/98 loss: 0.8392010927200317
Rank 0 - Epoch 30/98 loss: 0.8329039812088013
Rank 0 - Epoch 40/98 loss: 0.8266162872314453
Rank 0 - Epoch 50/98 loss: 0.820341944694519
Rank 0 - Epoch 60/98 loss: 0.8140848278999329
Rank 0 - Epoch 70/98 loss: 0.8078489899635315
Rank 0 - Epoch 80/98 loss: 0.8016384243965149
Rank 0 - Epoch 90/98 loss: 0.7954578995704651
Training complete.
[92mRank 0 - Testing RMSE: 3.5958[0m
[92mRank: 0, Lengthscale: [[0.61296743 0.6124339 ]] [0m
[92mRank: 0, Outputscale: 0.614656925201416 [0m
[92mRank: 0, Noise: 0.6054919362068176 [0m
Run 6 completed successfully
Running cGP 7 with agents: 49
decADMM initialized with rho: 0.85, max_iter: 5, lr: 0.0001, rank: 0, world_size: 49
Rank 0 - Epoch 2/98 loss: 0.8505483865737915
Rank 0 - Epoch 10/98 loss: 0.8455040454864502
Rank 0 - Epoch 20/98 loss: 0.8392010927200317
Rank 0 - Epoch 30/98 loss: 0.8329039812088013
Rank 0 - Epoch 40/98 loss: 0.8266162872314453
Rank 0 - Epoch 50/98 loss: 0.820341944694519
Rank 0 - Epoch 60/98 loss: 0.8140848278999329
Rank 0 - Epoch 70/98 loss: 0.8078489899635315
Rank 0 - Epoch 80/98 loss: 0.8016384243965149
Rank 0 - Epoch 90/98 loss: 0.7954578995704651
Training complete.
[92mRank 0 - Testing RMSE: 3.5958[0m
[92mRank: 0, Lengthscale: [[0.61296743 0.6124339 ]] [0m
[92mRank: 0, Outputscale: 0.614656925201416 [0m
[92mRank: 0, Noise: 0.6054919362068176 [0m
Run 7 completed successfully
Running cGP 8 with agents: 49
decADMM initialized with rho: 0.85, max_iter: 5, lr: 0.0001, rank: 0, world_size: 49
Rank 0 - Epoch 2/98 loss: 0.8505483865737915
Rank 0 - Epoch 10/98 loss: 0.8455040454864502
Rank 0 - Epoch 20/98 loss: 0.8392010927200317
Rank 0 - Epoch 30/98 loss: 0.8329039812088013
Rank 0 - Epoch 40/98 loss: 0.8266162872314453
Rank 0 - Epoch 50/98 loss: 0.820341944694519
Rank 0 - Epoch 60/98 loss: 0.8140848278999329
Rank 0 - Epoch 70/98 loss: 0.8078489899635315
Rank 0 - Epoch 80/98 loss: 0.8016384243965149
Rank 0 - Epoch 90/98 loss: 0.7954578995704651
Training complete.
[92mRank 0 - Testing RMSE: 3.5958[0m
[92mRank: 0, Lengthscale: [[0.61296743 0.6124339 ]] [0m
[92mRank: 0, Outputscale: 0.614656925201416 [0m
[92mRank: 0, Noise: 0.6054919362068176 [0m
Run 8 completed successfully
Running cGP 9 with agents: 49
decADMM initialized with rho: 0.85, max_iter: 5, lr: 0.0001, rank: 0, world_size: 49
Rank 0 - Epoch 2/98 loss: 0.8505483865737915
Rank 0 - Epoch 10/98 loss: 0.8455040454864502
Rank 0 - Epoch 20/98 loss: 0.8392010927200317
Rank 0 - Epoch 30/98 loss: 0.8329039812088013
Rank 0 - Epoch 40/98 loss: 0.8266162872314453
Rank 0 - Epoch 50/98 loss: 0.820341944694519
Rank 0 - Epoch 60/98 loss: 0.8140848278999329
Rank 0 - Epoch 70/98 loss: 0.8078489899635315
Rank 0 - Epoch 80/98 loss: 0.8016384243965149
Rank 0 - Epoch 90/98 loss: 0.7954578995704651
Training complete.
[92mRank 0 - Testing RMSE: 3.5958[0m
[92mRank: 0, Lengthscale: [[0.61296743 0.6124339 ]] [0m
[92mRank: 0, Outputscale: 0.614656925201416 [0m
[92mRank: 0, Noise: 0.6054919362068176 [0m
Run 9 completed successfully
Running cGP 10 with agents: 49
decADMM initialized with rho: 0.85, max_iter: 5, lr: 0.0001, rank: 0, world_size: 49
Rank 0 - Epoch 2/98 loss: 0.8505483865737915
Rank 0 - Epoch 10/98 loss: 0.8455040454864502
Rank 0 - Epoch 20/98 loss: 0.8392010927200317
Rank 0 - Epoch 30/98 loss: 0.8329039812088013
Rank 0 - Epoch 40/98 loss: 0.8266162872314453
Rank 0 - Epoch 50/98 loss: 0.820341944694519
Rank 0 - Epoch 60/98 loss: 0.8140848278999329
Rank 0 - Epoch 70/98 loss: 0.8078489899635315
Rank 0 - Epoch 80/98 loss: 0.8016384243965149
Rank 0 - Epoch 90/98 loss: 0.7954578995704651
Training complete.
[92mRank 0 - Testing RMSE: 3.5958[0m
[92mRank: 0, Lengthscale: [[0.61296743 0.6124339 ]] [0m
[92mRank: 0, Outputscale: 0.614656925201416 [0m
[92mRank: 0, Noise: 0.6054919362068176 [0m
Run 10 completed successfully
Running pxpGP 1 with agents: 64
[92mRank 0 - sparse dataset size is: 4, local dataset: torch.Size([289, 2]), [0m
[92mRank 0 - Training local sparse GP model with 289 samples[0m
Epoch 1/200 - Loss: 14.630
Epoch 11/200 - Loss: 1.101
Epoch 21/200 - Loss: 1.017
Epoch 31/200 - Loss: 0.944
Epoch 41/200 - Loss: 0.844
Epoch 51/200 - Loss: 0.730
Epoch 61/200 - Loss: 0.578
Epoch 71/200 - Loss: 0.416
Epoch 81/200 - Loss: 0.209
Epoch 91/200 - Loss: 0.037
Converged at epoch 92 with loss -0.008
[92mRank 0 - Lengthscale: [[0.69379944 0.50430423]] [0m
[92mRank 0 - Outputscale: 2.2701172828674316 [0m
[92mRank 0 - Noise: 0.12352987378835678 [0m
Rank 0 - Augmented dataset size: 545
Rank 0: After warm start model parameters:
Rank: 0, Lengthscale: [[0.69379944 0.50430423]]
Rank: 0, Outputscale: 2.2701172828674316
Rank: 0, Noise: 0.12352985143661499
decpxADMM initialized with rho: 0.85, lip: 1.0, tol_abs: 1e-05, tol_rel: 0.001, rank: 0, world_size: 64
[92mRank 0 - Training global model with dec-pxADMM optimizer[0m
rank 0, epoch 9, loss: 0.6103771924972534, rho: 0.4250, lip: 1.0000
rank 0, epoch 19, loss: 0.6008318066596985, rho: 0.2125, lip: 1.0000
rank 0, epoch 29, loss: 0.625516951084137, rho: 0.1062, lip: 1.0000
rank 0, epoch 39, loss: 0.6258495450019836, rho: 0.0531, lip: 1.0000
rank 0, epoch 49, loss: 0.6378581523895264, rho: 0.0531, lip: 1.0000
rank 0, epoch 59, loss: 0.4778044819831848, rho: 0.0531, lip: 1.0000
rank 0, epoch 69, loss: 0.3814009130001068, rho: 0.0531, lip: 1.0000
rank 0, epoch 79, loss: 0.3539430499076843, rho: 0.0531, lip: 1.0000
rank 0, epoch 89, loss: 0.3345129191875458, rho: 0.0531, lip: 1.0000
Rank 0 - Training time: 85.97 seconds
[92mRank 0 - Testing RMSE: 0.8045[0m
[92mRank: 0, Lengthscale: [[0.14735243 0.16512543]] [0m
[92mRank: 0, Outputscale: 4.304084777832031 [0m
[92mRank: 0, Noise: 0.006826520897448063 [0m
Run 1 completed successfully
Running pxpGP 2 with agents: 64
[92mRank 0 - sparse dataset size is: 4, local dataset: torch.Size([289, 2]), [0m
[92mRank 0 - Training local sparse GP model with 289 samples[0m
Epoch 1/200 - Loss: 14.638
Epoch 11/200 - Loss: 1.272
Epoch 21/200 - Loss: 1.070
Epoch 31/200 - Loss: 0.959
Epoch 41/200 - Loss: 0.864
Epoch 51/200 - Loss: 0.749
Epoch 61/200 - Loss: 0.605
Epoch 71/200 - Loss: 0.452
Epoch 81/200 - Loss: 0.256
Epoch 91/200 - Loss: 0.050
Converged at epoch 97 with loss -0.061
[92mRank 0 - Lengthscale: [[0.7600088  0.52539396]] [0m
[92mRank 0 - Outputscale: 2.345461368560791 [0m
[92mRank 0 - Noise: 0.10686728358268738 [0m
Rank 0 - Augmented dataset size: 545
Rank 0: After warm start model parameters:
Rank: 0, Lengthscale: [[0.76000875 0.52539396]]
Rank: 0, Outputscale: 2.345461368560791
Rank: 0, Noise: 0.10686728358268738
decpxADMM initialized with rho: 0.85, lip: 1.0, tol_abs: 1e-05, tol_rel: 0.001, rank: 0, world_size: 64
[92mRank 0 - Training global model with dec-pxADMM optimizer[0m
rank 0, epoch 9, loss: 0.5185702443122864, rho: 0.4250, lip: 1.0000
rank 0, epoch 19, loss: 0.49632933735847473, rho: 0.2125, lip: 1.0000
rank 0, epoch 29, loss: 0.4534572660923004, rho: 0.2125, lip: 1.0000
rank 0, epoch 39, loss: 0.4262267053127289, rho: 0.1062, lip: 1.0000
rank 0, epoch 49, loss: 0.3601952791213989, rho: 0.1062, lip: 1.0000
rank 0, epoch 59, loss: 0.34459105134010315, rho: 0.0531, lip: 1.0000
rank 0, epoch 69, loss: 0.37229278683662415, rho: 0.0531, lip: 1.0000
rank 0, epoch 79, loss: 0.39876478910446167, rho: 0.0531, lip: 1.0000
rank 0, epoch 89, loss: 0.4238307476043701, rho: 0.0531, lip: 1.0000
Rank 0 - Training time: 70.07 seconds
[92mRank 0 - Testing RMSE: 0.7231[0m
[92mRank: 0, Lengthscale: [[0.24783763 0.10505476]] [0m
[92mRank: 0, Outputscale: 2.15885329246521 [0m
[92mRank: 0, Noise: 0.0047645894810557365 [0m
Run 2 completed successfully
Running pxpGP 3 with agents: 64
[92mRank 0 - sparse dataset size is: 4, local dataset: torch.Size([289, 2]), [0m
[92mRank 0 - Training local sparse GP model with 289 samples[0m
Epoch 1/200 - Loss: 16.574
Epoch 11/200 - Loss: 1.241
Epoch 21/200 - Loss: 1.066
Epoch 31/200 - Loss: 0.988
Epoch 41/200 - Loss: 0.870
Epoch 51/200 - Loss: 0.760
Epoch 61/200 - Loss: 0.617
Epoch 71/200 - Loss: 0.438
Epoch 81/200 - Loss: 0.242
Epoch 91/200 - Loss: 0.033
Converged at epoch 94 with loss -0.001
[92mRank 0 - Lengthscale: [[0.7555563  0.49600348]] [0m
[92mRank 0 - Outputscale: 2.3631784915924072 [0m
[92mRank 0 - Noise: 0.12330800294876099 [0m
Rank 0 - Augmented dataset size: 545
Rank 0: After warm start model parameters:
Rank: 0, Lengthscale: [[0.75555634 0.49600348]]
Rank: 0, Outputscale: 2.3631784915924072
Rank: 0, Noise: 0.12330800294876099
decpxADMM initialized with rho: 0.85, lip: 1.0, tol_abs: 1e-05, tol_rel: 0.001, rank: 0, world_size: 64
[92mRank 0 - Training global model with dec-pxADMM optimizer[0m
rank 0, epoch 9, loss: 0.5551904439926147, rho: 0.4250, lip: 1.0000
rank 0, epoch 19, loss: 0.5277471542358398, rho: 0.2125, lip: 1.0000
rank 0, epoch 29, loss: 0.5134230256080627, rho: 0.0531, lip: 1.0000
rank 0, epoch 39, loss: 0.49344363808631897, rho: 0.0266, lip: 1.0000
rank 0, epoch 49, loss: 0.4239468276500702, rho: 0.0266, lip: 1.0000
rank 0, epoch 59, loss: 0.36205601692199707, rho: 0.0266, lip: 1.0000
rank 0, epoch 69, loss: 0.29913267493247986, rho: 0.0266, lip: 1.0000
[rank 5] barrier timed out after 5s, continuing anyway
[rank 9] barrier timed out after 5s, continuing anyway
[rank 16] barrier timed out after 5s, continuing anyway
[rank 17] barrier timed out after 5s, continuing anyway
[rank 11] barrier timed out after 5s, continuing anyway
[rank 12] barrier timed out after 5s, continuing anyway
[rank 19] barrier timed out after 5s, continuing anyway
Run 3 failed, retrying...
Running pxpGP 4 with agents: 64
[92mRank 0 - sparse dataset size is: 4, local dataset: torch.Size([289, 2]), [0m
[92mRank 0 - Training local sparse GP model with 289 samples[0m
Epoch 1/200 - Loss: 14.145
Epoch 11/200 - Loss: 1.309
Epoch 21/200 - Loss: 1.060
Epoch 31/200 - Loss: 0.998
Epoch 41/200 - Loss: 0.902
Epoch 51/200 - Loss: 0.794
Epoch 61/200 - Loss: 0.639
Epoch 71/200 - Loss: 0.503
Epoch 81/200 - Loss: 0.349
Epoch 91/200 - Loss: 0.192
Converged at epoch 99 with loss -0.037
[92mRank 0 - Lengthscale: [[0.91219246 0.40697035]] [0m
[92mRank 0 - Outputscale: 2.479580879211426 [0m
[92mRank 0 - Noise: 0.11103660613298416 [0m
Rank 0 - Augmented dataset size: 545
Rank 0: After warm start model parameters:
Rank: 0, Lengthscale: [[0.91219246 0.40697035]]
Rank: 0, Outputscale: 2.479580879211426
Rank: 0, Noise: 0.11103660613298416
decpxADMM initialized with rho: 0.85, lip: 1.0, tol_abs: 1e-05, tol_rel: 0.001, rank: 0, world_size: 64
[92mRank 0 - Training global model with dec-pxADMM optimizer[0m
rank 0, epoch 9, loss: 0.571678638458252, rho: 0.4250, lip: 1.0000
rank 0, epoch 19, loss: 0.5573517084121704, rho: 0.1062, lip: 1.0000
rank 0, epoch 29, loss: 0.5311489105224609, rho: 0.0531, lip: 1.0000
rank 0, epoch 39, loss: 0.5008171796798706, rho: 0.0531, lip: 1.0000
rank 0, epoch 49, loss: 0.4860824644565582, rho: 0.0531, lip: 1.0000
rank 0, epoch 59, loss: 0.47931164503097534, rho: 0.0531, lip: 1.0000
rank 0, epoch 69, loss: 0.47764521837234497, rho: 0.0531, lip: 1.0000
rank 0, epoch 79, loss: 0.4783867299556732, rho: 0.0531, lip: 1.0000
rank 0, epoch 89, loss: 0.477839857339859, rho: 0.0266, lip: 1.0000
Rank 0 - Training time: 69.33 seconds
[92mRank 0 - Testing RMSE: 0.3162[0m
[92mRank: 0, Lengthscale: [[0.6547541  0.34474018]] [0m
[92mRank: 0, Outputscale: 2.202962875366211 [0m
[92mRank: 0, Noise: 0.08885984122753143 [0m
Run 4 completed successfully
Running pxpGP 5 with agents: 64
[92mRank 0 - sparse dataset size is: 4, local dataset: torch.Size([289, 2]), [0m
[92mRank 0 - Training local sparse GP model with 289 samples[0m
Epoch 1/200 - Loss: 11.509
Epoch 11/200 - Loss: 1.082
Epoch 21/200 - Loss: 1.018
Epoch 31/200 - Loss: 0.932
Epoch 41/200 - Loss: 0.845
Epoch 51/200 - Loss: 0.730
Epoch 61/200 - Loss: 0.569
Epoch 71/200 - Loss: 0.431
Epoch 81/200 - Loss: 0.212
Epoch 91/200 - Loss: 0.016
Converged at epoch 92 with loss -0.009
[92mRank 0 - Lengthscale: [[0.7106569 0.4974772]] [0m
[92mRank 0 - Outputscale: 2.273404359817505 [0m
[92mRank 0 - Noise: 0.12056398391723633 [0m
Rank 0 - Augmented dataset size: 545
Rank 0: After warm start model parameters:
Rank: 0, Lengthscale: [[0.71065694 0.4974772 ]]
Rank: 0, Outputscale: 2.273404359817505
Rank: 0, Noise: 0.12056400626897812
decpxADMM initialized with rho: 0.85, lip: 1.0, tol_abs: 1e-05, tol_rel: 0.001, rank: 0, world_size: 64
[92mRank 0 - Training global model with dec-pxADMM optimizer[0m
rank 0, epoch 9, loss: 0.599350094795227, rho: 0.4250, lip: 1.0000
rank 0, epoch 19, loss: 0.6929697394371033, rho: 0.2125, lip: 1.0000
rank 0, epoch 29, loss: 0.7063800096511841, rho: 0.1062, lip: 1.0000
rank 0, epoch 39, loss: 0.6788313984870911, rho: 0.0531, lip: 1.0000
rank 0, epoch 49, loss: 0.5421978235244751, rho: 0.0531, lip: 1.0000
rank 0, epoch 59, loss: 0.38133350014686584, rho: 0.0531, lip: 1.0000
rank 0, epoch 69, loss: 0.31080931425094604, rho: 0.0531, lip: 1.0000
rank 0, epoch 79, loss: 0.27512839436531067, rho: 0.0531, lip: 1.0000
rank 0, epoch 89, loss: 0.2665858268737793, rho: 0.0531, lip: 1.0000
Rank 0 - Training time: 54.76 seconds
[92mRank 0 - Testing RMSE: 0.7773[0m
[92mRank: 0, Lengthscale: [[0.40356255 0.07908941]] [0m
[92mRank: 0, Outputscale: 3.5234158039093018 [0m
[92mRank: 0, Noise: 0.00720905652269721 [0m
Run 5 completed successfully
Running pxpGP 6 with agents: 64
[92mRank 0 - sparse dataset size is: 4, local dataset: torch.Size([289, 2]), [0m
[92mRank 0 - Training local sparse GP model with 289 samples[0m
Epoch 1/200 - Loss: 14.303
Epoch 11/200 - Loss: 1.086
Epoch 21/200 - Loss: 1.011
Epoch 31/200 - Loss: 0.934
Epoch 41/200 - Loss: 0.841
Epoch 51/200 - Loss: 0.729
Epoch 61/200 - Loss: 0.585
Epoch 71/200 - Loss: 0.424
Epoch 81/200 - Loss: 0.243
Epoch 91/200 - Loss: -0.007
Converged at epoch 91 with loss -0.007
[92mRank 0 - Lengthscale: [[0.69689596 0.47990358]] [0m
[92mRank 0 - Outputscale: 2.2713615894317627 [0m
[92mRank 0 - Noise: 0.12680087983608246 [0m
Rank 0 - Augmented dataset size: 545
Rank 0: After warm start model parameters:
Rank: 0, Lengthscale: [[0.69689596 0.47990358]]
Rank: 0, Outputscale: 2.2713615894317627
Rank: 0, Noise: 0.12680087983608246
decpxADMM initialized with rho: 0.85, lip: 1.0, tol_abs: 1e-05, tol_rel: 0.001, rank: 0, world_size: 64
[92mRank 0 - Training global model with dec-pxADMM optimizer[0m
rank 0, epoch 9, loss: 0.641148030757904, rho: 0.4250, lip: 1.0000
rank 0, epoch 19, loss: 0.6299318075180054, rho: 0.1062, lip: 1.0000
rank 0, epoch 29, loss: 0.5830228328704834, rho: 0.1062, lip: 1.0000
rank 0, epoch 39, loss: 0.5625696182250977, rho: 0.0531, lip: 1.0000
rank 0, epoch 49, loss: 0.571641206741333, rho: 0.0531, lip: 1.0000
rank 0, epoch 59, loss: 0.5410227179527283, rho: 0.0531, lip: 1.0000
rank 0, epoch 69, loss: 0.5258902907371521, rho: 0.0266, lip: 1.0000
rank 0, epoch 79, loss: 0.5185694694519043, rho: 0.0133, lip: 1.0000
rank 0, epoch 89, loss: 0.48934516310691833, rho: 0.0133, lip: 1.0000
Rank 0 - Training time: 66.82 seconds
[92mRank 0 - Testing RMSE: 0.7543[0m
[92mRank: 0, Lengthscale: [[0.3487907  0.12484922]] [0m
[92mRank: 0, Outputscale: 3.0269200801849365 [0m
[92mRank: 0, Noise: 0.03135451301932335 [0m
Run 6 completed successfully
Running pxpGP 7 with agents: 64
[92mRank 0 - sparse dataset size is: 4, local dataset: torch.Size([289, 2]), [0m
[92mRank 0 - Training local sparse GP model with 289 samples[0m
Epoch 1/200 - Loss: 12.501
Epoch 11/200 - Loss: 1.097
Epoch 21/200 - Loss: 1.012
Epoch 31/200 - Loss: 0.942
Epoch 41/200 - Loss: 0.843
Epoch 51/200 - Loss: 0.722
Epoch 61/200 - Loss: 0.577
Epoch 71/200 - Loss: 0.393
Epoch 81/200 - Loss: 0.239
Epoch 91/200 - Loss: 0.039
Converged at epoch 93 with loss -0.032
[92mRank 0 - Lengthscale: [[0.7042225  0.47369722]] [0m
[92mRank 0 - Outputscale: 2.2542645931243896 [0m
[92mRank 0 - Noise: 0.11631032079458237 [0m
Rank 0 - Augmented dataset size: 545
Rank 0: After warm start model parameters:
Rank: 0, Lengthscale: [[0.7042225  0.47369722]]
Rank: 0, Outputscale: 2.2542645931243896
Rank: 0, Noise: 0.11631032079458237
decpxADMM initialized with rho: 0.85, lip: 1.0, tol_abs: 1e-05, tol_rel: 0.001, rank: 0, world_size: 64
[92mRank 0 - Training global model with dec-pxADMM optimizer[0m
rank 0, epoch 9, loss: 0.6196413636207581, rho: 0.4250, lip: 1.0000
rank 0, epoch 19, loss: 0.6146597862243652, rho: 0.2125, lip: 1.0000
rank 0, epoch 29, loss: 0.6071879863739014, rho: 0.1062, lip: 1.0000
rank 0, epoch 39, loss: 0.5883808135986328, rho: 0.0531, lip: 1.0000
rank 0, epoch 49, loss: 0.6179829835891724, rho: 0.0531, lip: 1.0000
rank 0, epoch 59, loss: 0.6064234375953674, rho: 0.0531, lip: 1.0000
rank 0, epoch 69, loss: 0.32281196117401123, rho: 0.0531, lip: 1.0000
rank 0, epoch 79, loss: 0.16708743572235107, rho: 0.0531, lip: 1.0000
rank 0, epoch 89, loss: 0.13727259635925293, rho: 0.0266, lip: 1.0000
[rank 18] barrier timed out after 5s, continuing anyway
[rank 19] barrier timed out after 5s, continuing anyway
[rank 21] barrier timed out after 5s, continuing anyway
[rank 7] barrier timed out after 5s, continuing anyway
Run 7 failed, retrying...
Running pxpGP 8 with agents: 64
[92mRank 0 - sparse dataset size is: 4, local dataset: torch.Size([289, 2]), [0m
[92mRank 0 - Training local sparse GP model with 289 samples[0m
Epoch 1/200 - Loss: 16.030
Epoch 11/200 - Loss: 1.156
Epoch 21/200 - Loss: 1.049
Epoch 31/200 - Loss: 0.965
Epoch 41/200 - Loss: 0.874
Epoch 51/200 - Loss: 0.768
Epoch 61/200 - Loss: 0.627
Epoch 71/200 - Loss: 0.462
Epoch 81/200 - Loss: 0.271
Epoch 91/200 - Loss: 0.072
Converged at epoch 95 with loss -0.019
[92mRank 0 - Lengthscale: [[0.7602069  0.50547564]] [0m
[92mRank 0 - Outputscale: 2.370910882949829 [0m
[92mRank 0 - Noise: 0.1201949417591095 [0m
Rank 0 - Augmented dataset size: 545
Rank 0: After warm start model parameters:
Rank: 0, Lengthscale: [[0.7602069  0.50547564]]
Rank: 0, Outputscale: 2.370910882949829
Rank: 0, Noise: 0.1201949417591095
decpxADMM initialized with rho: 0.85, lip: 1.0, tol_abs: 1e-05, tol_rel: 0.001, rank: 0, world_size: 64
[92mRank 0 - Training global model with dec-pxADMM optimizer[0m
rank 0, epoch 9, loss: 0.6735918521881104, rho: 0.4250, lip: 1.0000
rank 0, epoch 19, loss: 0.6268509030342102, rho: 0.2125, lip: 1.0000
rank 0, epoch 29, loss: 0.6043620109558105, rho: 0.1062, lip: 1.0000
rank 0, epoch 39, loss: 0.5854387283325195, rho: 0.0531, lip: 1.0000
rank 0, epoch 49, loss: 0.5819897055625916, rho: 0.0531, lip: 1.0000
rank 0, epoch 59, loss: 0.5775018930435181, rho: 0.0266, lip: 1.0000
rank 0, epoch 69, loss: 0.5741007924079895, rho: 0.0266, lip: 1.0000
rank 0, epoch 79, loss: 0.5743853449821472, rho: 0.0266, lip: 1.0000
rank 0, epoch 89, loss: 0.5756164193153381, rho: 0.0266, lip: 1.0000
Rank 0 - Training time: 54.65 seconds
[92mRank 0 - Testing RMSE: 0.3408[0m
[92mRank: 0, Lengthscale: [[0.594275  0.3444249]] [0m
[92mRank: 0, Outputscale: 3.0894463062286377 [0m
[92mRank: 0, Noise: 0.1086195781826973 [0m
Run 8 completed successfully
Running pxpGP 9 with agents: 64
[92mRank 0 - sparse dataset size is: 4, local dataset: torch.Size([289, 2]), [0m
[92mRank 0 - Training local sparse GP model with 289 samples[0m
Epoch 1/200 - Loss: 13.989
Epoch 11/200 - Loss: 1.185
Epoch 21/200 - Loss: 1.045
Epoch 31/200 - Loss: 0.960
Epoch 41/200 - Loss: 0.870
Epoch 51/200 - Loss: 0.754
Epoch 61/200 - Loss: 0.617
Epoch 71/200 - Loss: 0.446
Epoch 81/200 - Loss: 0.269
Epoch 91/200 - Loss: 0.145
Converged at epoch 96 with loss -0.021
[92mRank 0 - Lengthscale: [[0.7409739  0.50248545]] [0m
[92mRank 0 - Outputscale: 2.3469808101654053 [0m
[92mRank 0 - Noise: 0.11327237635850906 [0m
Rank 0 - Augmented dataset size: 545
Rank 0: After warm start model parameters:
Rank: 0, Lengthscale: [[0.7409739  0.50248545]]
Rank: 0, Outputscale: 2.3469808101654053
Rank: 0, Noise: 0.11327237635850906
decpxADMM initialized with rho: 0.85, lip: 1.0, tol_abs: 1e-05, tol_rel: 0.001, rank: 0, world_size: 64
[92mRank 0 - Training global model with dec-pxADMM optimizer[0m
rank 0, epoch 9, loss: 0.5143378973007202, rho: 0.4250, lip: 1.0000
rank 0, epoch 19, loss: 0.4810601770877838, rho: 0.1062, lip: 1.0000
rank 0, epoch 29, loss: 0.46272677183151245, rho: 0.1062, lip: 1.0000
rank 0, epoch 39, loss: 0.4812159538269043, rho: 0.0531, lip: 1.0000
rank 0, epoch 49, loss: 0.5247882008552551, rho: 0.0531, lip: 1.0000
rank 0, epoch 59, loss: 0.46282294392585754, rho: 0.0531, lip: 1.0000
rank 0, epoch 69, loss: 0.4455302059650421, rho: 0.0531, lip: 1.0000
rank 0, epoch 79, loss: 0.43304741382598877, rho: 0.0266, lip: 1.0000
rank 0, epoch 89, loss: 0.35963112115859985, rho: 0.0266, lip: 1.0000
Rank 0 - Training time: 62.84 seconds
[92mRank 0 - Testing RMSE: 0.8780[0m
[92mRank: 0, Lengthscale: [[0.10625276 0.2997666 ]] [0m
[92mRank: 0, Outputscale: 4.003135681152344 [0m
[92mRank: 0, Noise: 0.01007749978452921 [0m
Run 9 completed successfully
Running pxpGP 10 with agents: 64
[92mRank 0 - sparse dataset size is: 4, local dataset: torch.Size([289, 2]), [0m
[92mRank 0 - Training local sparse GP model with 289 samples[0m
Epoch 1/200 - Loss: 12.722
Epoch 11/200 - Loss: 1.180
Epoch 21/200 - Loss: 1.052
Epoch 31/200 - Loss: 0.962
Epoch 41/200 - Loss: 0.873
Epoch 51/200 - Loss: 0.755
Epoch 61/200 - Loss: 0.626
Epoch 71/200 - Loss: 0.447
Epoch 81/200 - Loss: 0.226
Epoch 91/200 - Loss: 0.072
Converged at epoch 94 with loss -0.032
[92mRank 0 - Lengthscale: [[0.765844   0.48796052]] [0m
[92mRank 0 - Outputscale: 2.3559205532073975 [0m
[92mRank 0 - Noise: 0.12069530785083771 [0m
Rank 0 - Augmented dataset size: 545
Rank 0: After warm start model parameters:
Rank: 0, Lengthscale: [[0.765844   0.48796052]]
Rank: 0, Outputscale: 2.3559205532073975
Rank: 0, Noise: 0.12069530785083771
decpxADMM initialized with rho: 0.85, lip: 1.0, tol_abs: 1e-05, tol_rel: 0.001, rank: 0, world_size: 64
[92mRank 0 - Training global model with dec-pxADMM optimizer[0m
rank 0, epoch 9, loss: 0.5938085317611694, rho: 0.4250, lip: 1.0000
rank 0, epoch 19, loss: 0.589257001876831, rho: 0.2125, lip: 1.0000
rank 0, epoch 29, loss: 0.5714771151542664, rho: 0.1062, lip: 1.0000
rank 0, epoch 39, loss: 0.5657291412353516, rho: 0.0531, lip: 1.0000
rank 0, epoch 49, loss: 0.5403469204902649, rho: 0.0531, lip: 1.0000
rank 0, epoch 59, loss: 0.441847562789917, rho: 0.0531, lip: 1.0000
rank 0, epoch 69, loss: 0.41906240582466125, rho: 0.0531, lip: 1.0000
rank 0, epoch 79, loss: 0.44548654556274414, rho: 0.0531, lip: 1.0000
rank 0, epoch 89, loss: 0.4586539566516876, rho: 0.0266, lip: 1.0000
Rank 0 - Training time: 73.33 seconds
[92mRank 0 - Testing RMSE: 0.8592[0m
[92mRank: 0, Lengthscale: [[0.21055962 0.16562445]] [0m
[92mRank: 0, Outputscale: 4.33983850479126 [0m
[92mRank: 0, Noise: 0.0034238952212035656 [0m
Run 10 completed successfully
Running gapxGP 1 with agents: 64
decpxADMM initialized with rho: 0.75, lip: 1.0, tol_abs: 1e-05, tol_rel: 0.001, rank: 0, world_size: 64
Rank 0 - Epoch 2/96 loss: 1.0523773431777954
Rank 0 - Epoch 10/96 loss: 0.8456792831420898
Rank 0 - Epoch 20/96 loss: 0.5519033670425415
Rank 0 - Epoch 30/96 loss: 0.17819298803806305
Rank 0 - Epoch 40/96 loss: -0.20619109272956848
Rank 0 - Epoch 50/96 loss: -0.5794190168380737
Rank 0 - Epoch 60/96 loss: -0.9372154474258423
Rank 0 - Epoch 70/96 loss: -1.2717323303222656
Rank 0 - Epoch 80/96 loss: -1.56989324092865
Rank 0 - Epoch 90/96 loss: -1.8156720399856567
[92mRank 0 - Testing RMSE: 0.0166[0m
[92mRank: 0, Lengthscale: [[0.6290837 0.3693666]] [0m
[92mRank: 0, Outputscale: 1.840672492980957 [0m
[92mRank: 0, Noise: 0.00041989507735706866 [0m
Run 1 completed successfully
Running gapxGP 2 with agents: 64
decpxADMM initialized with rho: 0.75, lip: 1.0, tol_abs: 1e-05, tol_rel: 0.001, rank: 0, world_size: 64
Rank 0 - Epoch 2/96 loss: 1.0527371168136597
Rank 0 - Epoch 10/96 loss: 0.8492003083229065
Rank 0 - Epoch 20/96 loss: 0.5720267295837402
Rank 0 - Epoch 30/96 loss: 0.20132948458194733
Rank 0 - Epoch 40/96 loss: -0.1830689162015915
Rank 0 - Epoch 50/96 loss: -0.556839644908905
Rank 0 - Epoch 60/96 loss: -0.9139236211776733
Rank 0 - Epoch 70/96 loss: -1.2490180730819702
Rank 0 - Epoch 80/96 loss: -1.549247145652771
Rank 0 - Epoch 90/96 loss: -1.7989901304244995
[92mRank 0 - Testing RMSE: 0.0171[0m
[92mRank: 0, Lengthscale: [[0.62603563 0.36948243]] [0m
[92mRank: 0, Outputscale: 1.8251999616622925 [0m
[92mRank: 0, Noise: 0.00043554743751883507 [0m
Run 2 completed successfully
Running gapxGP 3 with agents: 64
decpxADMM initialized with rho: 0.75, lip: 1.0, tol_abs: 1e-05, tol_rel: 0.001, rank: 0, world_size: 64
Rank 0 - Epoch 2/96 loss: 1.0417224168777466
Rank 0 - Epoch 10/96 loss: 0.8219475150108337
Rank 0 - Epoch 20/96 loss: 0.5179868936538696
Rank 0 - Epoch 30/96 loss: 0.1588774472475052
Rank 0 - Epoch 40/96 loss: -0.22015166282653809
Rank 0 - Epoch 50/96 loss: -0.5845624804496765
Rank 0 - Epoch 60/96 loss: -0.9368480443954468
Rank 0 - Epoch 70/96 loss: -1.267387866973877
Rank 0 - Epoch 80/96 loss: -1.5616475343704224
Rank 0 - Epoch 90/96 loss: -1.8043975830078125
[92mRank 0 - Testing RMSE: 0.0119[0m
[92mRank: 0, Lengthscale: [[0.6230125  0.36879313]] [0m
[92mRank: 0, Outputscale: 1.8173153400421143 [0m
[92mRank: 0, Noise: 0.00042310624849051237 [0m
Run 3 completed successfully
Running gapxGP 4 with agents: 64
decpxADMM initialized with rho: 0.75, lip: 1.0, tol_abs: 1e-05, tol_rel: 0.001, rank: 0, world_size: 64
Rank 0 - Epoch 2/96 loss: 1.0528680086135864
Rank 0 - Epoch 10/96 loss: 0.8458107709884644
Rank 0 - Epoch 20/96 loss: 0.5636791586875916
Rank 0 - Epoch 30/96 loss: 0.19198162853717804
Rank 0 - Epoch 40/96 loss: -0.19313080608844757
Rank 0 - Epoch 50/96 loss: -0.5645439624786377
Rank 0 - Epoch 60/96 loss: -0.9214763045310974
Rank 0 - Epoch 70/96 loss: -1.256039023399353
Rank 0 - Epoch 80/96 loss: -1.553605556488037
Rank 0 - Epoch 90/96 loss: -1.7997740507125854
[92mRank 0 - Testing RMSE: 0.0117[0m
[92mRank: 0, Lengthscale: [[0.6287796  0.36680573]] [0m
[92mRank: 0, Outputscale: 1.8270609378814697 [0m
[92mRank: 0, Noise: 0.00042927468894049525 [0m
Run 4 completed successfully
Running gapxGP 5 with agents: 64
decpxADMM initialized with rho: 0.75, lip: 1.0, tol_abs: 1e-05, tol_rel: 0.001, rank: 0, world_size: 64
Rank 0 - Epoch 2/96 loss: 1.0527002811431885
Rank 0 - Epoch 10/96 loss: 0.8446947336196899
Rank 0 - Epoch 20/96 loss: 0.5662753582000732
Rank 0 - Epoch 30/96 loss: 0.20076876878738403
Rank 0 - Epoch 40/96 loss: -0.1819244772195816
Rank 0 - Epoch 50/96 loss: -0.5536832809448242
Rank 0 - Epoch 60/96 loss: -0.9109953045845032
Rank 0 - Epoch 70/96 loss: -1.2460300922393799
Rank 0 - Epoch 80/96 loss: -1.5458486080169678
Rank 0 - Epoch 90/96 loss: -1.7944848537445068
[92mRank 0 - Testing RMSE: 0.0150[0m
[92mRank: 0, Lengthscale: [[0.6255641  0.36915076]] [0m
[92mRank: 0, Outputscale: 1.8300414085388184 [0m
[92mRank: 0, Noise: 0.00043492860277183354 [0m
Run 5 completed successfully
Running gapxGP 6 with agents: 64
decpxADMM initialized with rho: 0.75, lip: 1.0, tol_abs: 1e-05, tol_rel: 0.001, rank: 0, world_size: 64
Rank 0 - Epoch 2/96 loss: 1.0576046705245972
Rank 0 - Epoch 10/96 loss: 0.8524962067604065
Rank 0 - Epoch 20/96 loss: 0.5688286423683167
Rank 0 - Epoch 30/96 loss: 0.1946111023426056
Rank 0 - Epoch 40/96 loss: -0.19275568425655365
Rank 0 - Epoch 50/96 loss: -0.572015643119812
Rank 0 - Epoch 60/96 loss: -0.931951642036438
Rank 0 - Epoch 70/96 loss: -1.268651008605957
Rank 0 - Epoch 80/96 loss: -1.5688284635543823
Rank 0 - Epoch 90/96 loss: -1.8168123960494995
[92mRank 0 - Testing RMSE: 0.0172[0m
[92mRank: 0, Lengthscale: [[0.625226   0.36882758]] [0m
[92mRank: 0, Outputscale: 1.8348898887634277 [0m
[92mRank: 0, Noise: 0.00042380913509987295 [0m
Run 6 completed successfully
Running gapxGP 7 with agents: 64
decpxADMM initialized with rho: 0.75, lip: 1.0, tol_abs: 1e-05, tol_rel: 0.001, rank: 0, world_size: 64
Rank 0 - Epoch 2/96 loss: 1.057535171508789
Rank 0 - Epoch 10/96 loss: 0.8546078205108643
Rank 0 - Epoch 20/96 loss: 0.5602490901947021
Rank 0 - Epoch 30/96 loss: 0.1641714870929718
Rank 0 - Epoch 40/96 loss: -0.22188851237297058
Rank 0 - Epoch 50/96 loss: -0.5875549912452698
Rank 0 - Epoch 60/96 loss: -0.9360820651054382
Rank 0 - Epoch 70/96 loss: -1.2650649547576904
Rank 0 - Epoch 80/96 loss: -1.560569167137146
Rank 0 - Epoch 90/96 loss: -1.8052842617034912
[92mRank 0 - Testing RMSE: 0.0158[0m
[92mRank: 0, Lengthscale: [[0.62647414 0.37018788]] [0m
[92mRank: 0, Outputscale: 1.8278979063034058 [0m
[92mRank: 0, Noise: 0.0004241597780492157 [0m
Run 7 completed successfully
Running gapxGP 8 with agents: 64
decpxADMM initialized with rho: 0.75, lip: 1.0, tol_abs: 1e-05, tol_rel: 0.001, rank: 0, world_size: 64
Rank 0 - Epoch 2/96 loss: 1.0499777793884277
Rank 0 - Epoch 10/96 loss: 0.83399897813797
Rank 0 - Epoch 20/96 loss: 0.541713297367096
Rank 0 - Epoch 30/96 loss: 0.1833888739347458
Rank 0 - Epoch 40/96 loss: -0.1924666315317154
Rank 0 - Epoch 50/96 loss: -0.5629709362983704
Rank 0 - Epoch 60/96 loss: -0.9224843382835388
Rank 0 - Epoch 70/96 loss: -1.2593023777008057
Rank 0 - Epoch 80/96 loss: -1.5587729215621948
Rank 0 - Epoch 90/96 loss: -1.8055922985076904
[92mRank 0 - Testing RMSE: 0.0157[0m
[92mRank: 0, Lengthscale: [[0.62602836 0.36811623]] [0m
[92mRank: 0, Outputscale: 1.8365329504013062 [0m
[92mRank: 0, Noise: 0.0004255440435372293 [0m
Run 8 completed successfully
Running gapxGP 9 with agents: 64
decpxADMM initialized with rho: 0.75, lip: 1.0, tol_abs: 1e-05, tol_rel: 0.001, rank: 0, world_size: 64
Rank 0 - Epoch 2/96 loss: 1.050652265548706
Rank 0 - Epoch 10/96 loss: 0.8459286093711853
Rank 0 - Epoch 20/96 loss: 0.5634716153144836
Rank 0 - Epoch 30/96 loss: 0.1884632557630539
Rank 0 - Epoch 40/96 loss: -0.19968514144420624
Rank 0 - Epoch 50/96 loss: -0.5725924372673035
Rank 0 - Epoch 60/96 loss: -0.9285159707069397
Rank 0 - Epoch 70/96 loss: -1.2627147436141968
Rank 0 - Epoch 80/96 loss: -1.56205415725708
Rank 0 - Epoch 90/96 loss: -1.8097059726715088
[92mRank 0 - Testing RMSE: 0.0184[0m
[92mRank: 0, Lengthscale: [[0.6252774 0.3726065]] [0m
[92mRank: 0, Outputscale: 1.8288772106170654 [0m
[92mRank: 0, Noise: 0.0004264168383087963 [0m
Run 9 completed successfully
Running gapxGP 10 with agents: 64
decpxADMM initialized with rho: 0.75, lip: 1.0, tol_abs: 1e-05, tol_rel: 0.001, rank: 0, world_size: 64
Rank 0 - Epoch 2/96 loss: 1.0494121313095093
Rank 0 - Epoch 10/96 loss: 0.8379411697387695
Rank 0 - Epoch 20/96 loss: 0.548596203327179
Rank 0 - Epoch 30/96 loss: 0.17880931496620178
Rank 0 - Epoch 40/96 loss: -0.20732255280017853
Rank 0 - Epoch 50/96 loss: -0.5778706073760986
Rank 0 - Epoch 60/96 loss: -0.9338361024856567
Rank 0 - Epoch 70/96 loss: -1.2678788900375366
Rank 0 - Epoch 80/96 loss: -1.5671048164367676
Rank 0 - Epoch 90/96 loss: -1.814400315284729
[92mRank 0 - Testing RMSE: 0.0173[0m
[92mRank: 0, Lengthscale: [[0.62753713 0.3679006 ]] [0m
[92mRank: 0, Outputscale: 1.8241758346557617 [0m
[92mRank: 0, Noise: 0.00042095710523426533 [0m
Run 10 completed successfully
Running apxGP 1 with agents: 64
decpxADMM initialized with rho: 0.85, lip: 1.0, tol_abs: 1e-05, tol_rel: 0.001, rank: 0, world_size: 64
Rank 0 - Epoch 2/128 loss: 0.8122164607048035
Rank 0 - Epoch 10/128 loss: 0.5517471432685852
Rank 0 - Epoch 20/128 loss: 0.13782784342765808
Rank 0 - Epoch 30/128 loss: -0.34666088223457336
Rank 0 - Epoch 40/128 loss: -0.8568702340126038
Rank 0 - Epoch 50/128 loss: -1.3682540655136108
Rank 0 - Epoch 60/128 loss: -1.8593534231185913
Rank 0 - Epoch 70/128 loss: -2.304558515548706
Rank 0 - Epoch 80/128 loss: -2.6723480224609375
Rank 0 - Epoch 90/128 loss: -2.937546968460083
Rank 0 - Epoch 100/128 loss: -3.1044013500213623
Rank 0 - Epoch 110/128 loss: -3.202989101409912
Rank 0 - Epoch 120/128 loss: -3.2631523609161377
Training complete.
[92mRank 0 - Testing RMSE: 2.8827[0m
[92mRank: 0, Lengthscale: [[0.60338503 0.36405346]] [0m
[92mRank: 0, Outputscale: 1.328114628791809 [0m
[92mRank: 0, Noise: 0.00013415765715762973 [0m
Run 1 completed successfully
Running apxGP 2 with agents: 64
decpxADMM initialized with rho: 0.85, lip: 1.0, tol_abs: 1e-05, tol_rel: 0.001, rank: 0, world_size: 64
Rank 0 - Epoch 2/128 loss: 0.8122164607048035
Rank 0 - Epoch 10/128 loss: 0.5517471432685852
Rank 0 - Epoch 20/128 loss: 0.13782784342765808
Rank 0 - Epoch 30/128 loss: -0.34666088223457336
Rank 0 - Epoch 40/128 loss: -0.8568702340126038
Rank 0 - Epoch 50/128 loss: -1.3682540655136108
Rank 0 - Epoch 60/128 loss: -1.8593534231185913
Rank 0 - Epoch 70/128 loss: -2.304558515548706
Rank 0 - Epoch 80/128 loss: -2.6723480224609375
Rank 0 - Epoch 90/128 loss: -2.937546968460083
Rank 0 - Epoch 100/128 loss: -3.1044013500213623
Rank 0 - Epoch 110/128 loss: -3.202989101409912
Rank 0 - Epoch 120/128 loss: -3.2631523609161377
Training complete.
[92mRank 0 - Testing RMSE: 2.8827[0m
[92mRank: 0, Lengthscale: [[0.60338503 0.36405346]] [0m
[92mRank: 0, Outputscale: 1.328114628791809 [0m
[92mRank: 0, Noise: 0.00013415765715762973 [0m
Run 2 completed successfully
Running apxGP 3 with agents: 64
decpxADMM initialized with rho: 0.85, lip: 1.0, tol_abs: 1e-05, tol_rel: 0.001, rank: 0, world_size: 64
Rank 0 - Epoch 2/128 loss: 0.8122164607048035
Rank 0 - Epoch 10/128 loss: 0.5517471432685852
Rank 0 - Epoch 20/128 loss: 0.13782784342765808
Rank 0 - Epoch 30/128 loss: -0.34666088223457336
Rank 0 - Epoch 40/128 loss: -0.8568702340126038
Rank 0 - Epoch 50/128 loss: -1.3682540655136108
Rank 0 - Epoch 60/128 loss: -1.8593534231185913
Rank 0 - Epoch 70/128 loss: -2.304558515548706
Rank 0 - Epoch 80/128 loss: -2.6723480224609375
Rank 0 - Epoch 90/128 loss: -2.937546968460083
Rank 0 - Epoch 100/128 loss: -3.1044013500213623
Rank 0 - Epoch 110/128 loss: -3.202989101409912
Rank 0 - Epoch 120/128 loss: -3.2631523609161377
Training complete.
[92mRank 0 - Testing RMSE: 2.8827[0m
[92mRank: 0, Lengthscale: [[0.60338503 0.36405346]] [0m
[92mRank: 0, Outputscale: 1.328114628791809 [0m
[92mRank: 0, Noise: 0.00013415765715762973 [0m
Run 3 completed successfully
Running apxGP 4 with agents: 64
decpxADMM initialized with rho: 0.85, lip: 1.0, tol_abs: 1e-05, tol_rel: 0.001, rank: 0, world_size: 64
Rank 0 - Epoch 2/128 loss: 0.8122164607048035
Rank 0 - Epoch 10/128 loss: 0.5517471432685852
Rank 0 - Epoch 20/128 loss: 0.13782784342765808
Rank 0 - Epoch 30/128 loss: -0.34666088223457336
Rank 0 - Epoch 40/128 loss: -0.8568702340126038
Rank 0 - Epoch 50/128 loss: -1.3682540655136108
Rank 0 - Epoch 60/128 loss: -1.8593534231185913
Rank 0 - Epoch 70/128 loss: -2.304558515548706
Rank 0 - Epoch 80/128 loss: -2.6723480224609375
Rank 0 - Epoch 90/128 loss: -2.937546968460083
Rank 0 - Epoch 100/128 loss: -3.1044013500213623
Rank 0 - Epoch 110/128 loss: -3.202989101409912
Rank 0 - Epoch 120/128 loss: -3.2631523609161377
Training complete.
[92mRank 0 - Testing RMSE: 2.8827[0m
[92mRank: 0, Lengthscale: [[0.60338503 0.36405346]] [0m
[92mRank: 0, Outputscale: 1.328114628791809 [0m
[92mRank: 0, Noise: 0.00013415765715762973 [0m
Run 4 completed successfully
Running apxGP 5 with agents: 64
decpxADMM initialized with rho: 0.85, lip: 1.0, tol_abs: 1e-05, tol_rel: 0.001, rank: 0, world_size: 64
Rank 0 - Epoch 2/128 loss: 0.8122164607048035
Rank 0 - Epoch 10/128 loss: 0.5517471432685852
Rank 0 - Epoch 20/128 loss: 0.13782784342765808
Rank 0 - Epoch 30/128 loss: -0.34666088223457336
Rank 0 - Epoch 40/128 loss: -0.8568702340126038
Rank 0 - Epoch 50/128 loss: -1.3682540655136108
Rank 0 - Epoch 60/128 loss: -1.8593534231185913
Rank 0 - Epoch 70/128 loss: -2.304558515548706
Rank 0 - Epoch 80/128 loss: -2.6723480224609375
Rank 0 - Epoch 90/128 loss: -2.937546968460083
Rank 0 - Epoch 100/128 loss: -3.1044013500213623
Rank 0 - Epoch 110/128 loss: -3.202989101409912
Rank 0 - Epoch 120/128 loss: -3.2631523609161377
Training complete.
[92mRank 0 - Testing RMSE: 2.8827[0m
[92mRank: 0, Lengthscale: [[0.60338503 0.36405346]] [0m
[92mRank: 0, Outputscale: 1.328114628791809 [0m
[92mRank: 0, Noise: 0.00013415765715762973 [0m
Run 5 completed successfully
Running apxGP 6 with agents: 64
decpxADMM initialized with rho: 0.85, lip: 1.0, tol_abs: 1e-05, tol_rel: 0.001, rank: 0, world_size: 64
Rank 0 - Epoch 2/128 loss: 0.8122164607048035
Rank 0 - Epoch 10/128 loss: 0.5517471432685852
Rank 0 - Epoch 20/128 loss: 0.13782784342765808
Rank 0 - Epoch 30/128 loss: -0.34666088223457336
Rank 0 - Epoch 40/128 loss: -0.8568702340126038
Rank 0 - Epoch 50/128 loss: -1.3682540655136108
Rank 0 - Epoch 60/128 loss: -1.8593534231185913
Rank 0 - Epoch 70/128 loss: -2.304558515548706
Rank 0 - Epoch 80/128 loss: -2.6723480224609375
Rank 0 - Epoch 90/128 loss: -2.937546968460083
Rank 0 - Epoch 100/128 loss: -3.1044013500213623
Rank 0 - Epoch 110/128 loss: -3.202989101409912
Rank 0 - Epoch 120/128 loss: -3.2631523609161377
Training complete.
[92mRank 0 - Testing RMSE: 2.8827[0m
[92mRank: 0, Lengthscale: [[0.60338503 0.36405346]] [0m
[92mRank: 0, Outputscale: 1.328114628791809 [0m
[92mRank: 0, Noise: 0.00013415765715762973 [0m
Run 6 completed successfully
Running apxGP 7 with agents: 64
decpxADMM initialized with rho: 0.85, lip: 1.0, tol_abs: 1e-05, tol_rel: 0.001, rank: 0, world_size: 64
Rank 0 - Epoch 2/128 loss: 0.8122164607048035
Rank 0 - Epoch 10/128 loss: 0.5517471432685852
Rank 0 - Epoch 20/128 loss: 0.13782784342765808
Rank 0 - Epoch 30/128 loss: -0.34666088223457336
Rank 0 - Epoch 40/128 loss: -0.8568702340126038
Rank 0 - Epoch 50/128 loss: -1.3682540655136108
Rank 0 - Epoch 60/128 loss: -1.8593534231185913
Rank 0 - Epoch 70/128 loss: -2.304558515548706
Rank 0 - Epoch 80/128 loss: -2.6723480224609375
Rank 0 - Epoch 90/128 loss: -2.937546968460083
Rank 0 - Epoch 100/128 loss: -3.1044013500213623
Rank 0 - Epoch 110/128 loss: -3.202989101409912
Rank 0 - Epoch 120/128 loss: -3.2631523609161377
Training complete.
[92mRank 0 - Testing RMSE: 2.8827[0m
[92mRank: 0, Lengthscale: [[0.60338503 0.36405346]] [0m
[92mRank: 0, Outputscale: 1.328114628791809 [0m
[92mRank: 0, Noise: 0.00013415765715762973 [0m
Run 7 completed successfully
Running apxGP 8 with agents: 64
decpxADMM initialized with rho: 0.85, lip: 1.0, tol_abs: 1e-05, tol_rel: 0.001, rank: 0, world_size: 64
Rank 0 - Epoch 2/128 loss: 0.8122164607048035
Rank 0 - Epoch 10/128 loss: 0.5517471432685852
Rank 0 - Epoch 20/128 loss: 0.13782784342765808
Rank 0 - Epoch 30/128 loss: -0.34666088223457336
Rank 0 - Epoch 40/128 loss: -0.8568702340126038
Rank 0 - Epoch 50/128 loss: -1.3682540655136108
Rank 0 - Epoch 60/128 loss: -1.8593534231185913
Rank 0 - Epoch 70/128 loss: -2.304558515548706
Rank 0 - Epoch 80/128 loss: -2.6723480224609375
Rank 0 - Epoch 90/128 loss: -2.937546968460083
Rank 0 - Epoch 100/128 loss: -3.1044013500213623
Rank 0 - Epoch 110/128 loss: -3.202989101409912
Rank 0 - Epoch 120/128 loss: -3.2631523609161377
Training complete.
[92mRank 0 - Testing RMSE: 2.8827[0m
[92mRank: 0, Lengthscale: [[0.60338503 0.36405346]] [0m
[92mRank: 0, Outputscale: 1.328114628791809 [0m
[92mRank: 0, Noise: 0.00013415765715762973 [0m
Run 8 completed successfully
Running apxGP 9 with agents: 64
decpxADMM initialized with rho: 0.85, lip: 1.0, tol_abs: 1e-05, tol_rel: 0.001, rank: 0, world_size: 64
Rank 0 - Epoch 2/128 loss: 0.8122164607048035
Rank 0 - Epoch 10/128 loss: 0.5517471432685852
Rank 0 - Epoch 20/128 loss: 0.13782784342765808
Rank 0 - Epoch 30/128 loss: -0.34666088223457336
Rank 0 - Epoch 40/128 loss: -0.8568702340126038
Rank 0 - Epoch 50/128 loss: -1.3682540655136108
Rank 0 - Epoch 60/128 loss: -1.8593534231185913
Rank 0 - Epoch 70/128 loss: -2.304558515548706
Rank 0 - Epoch 80/128 loss: -2.6723480224609375
Rank 0 - Epoch 90/128 loss: -2.937546968460083
Rank 0 - Epoch 100/128 loss: -3.1044013500213623
Rank 0 - Epoch 110/128 loss: -3.202989101409912
Rank 0 - Epoch 120/128 loss: -3.2631523609161377
Training complete.
[92mRank 0 - Testing RMSE: 2.8827[0m
[92mRank: 0, Lengthscale: [[0.60338503 0.36405346]] [0m
[92mRank: 0, Outputscale: 1.328114628791809 [0m
[92mRank: 0, Noise: 0.00013415765715762973 [0m
Run 9 completed successfully
Running apxGP 10 with agents: 64
decpxADMM initialized with rho: 0.85, lip: 1.0, tol_abs: 1e-05, tol_rel: 0.001, rank: 0, world_size: 64
Rank 0 - Epoch 2/128 loss: 0.8122164607048035
Rank 0 - Epoch 10/128 loss: 0.5517471432685852
Rank 0 - Epoch 20/128 loss: 0.13782784342765808
Rank 0 - Epoch 30/128 loss: -0.34666088223457336
Rank 0 - Epoch 40/128 loss: -0.8568702340126038
Rank 0 - Epoch 50/128 loss: -1.3682540655136108
Rank 0 - Epoch 60/128 loss: -1.8593534231185913
Rank 0 - Epoch 70/128 loss: -2.304558515548706
Rank 0 - Epoch 80/128 loss: -2.6723480224609375
Rank 0 - Epoch 90/128 loss: -2.937546968460083
Rank 0 - Epoch 100/128 loss: -3.1044013500213623
Rank 0 - Epoch 110/128 loss: -3.202989101409912
Rank 0 - Epoch 120/128 loss: -3.2631523609161377
Training complete.
[92mRank 0 - Testing RMSE: 2.8827[0m
[92mRank: 0, Lengthscale: [[0.60338503 0.36405346]] [0m
[92mRank: 0, Outputscale: 1.328114628791809 [0m
[92mRank: 0, Noise: 0.00013415765715762973 [0m
Run 10 completed successfully
Running cGP 1 with agents: 64
decADMM initialized with rho: 0.85, max_iter: 5, lr: 0.0001, rank: 0, world_size: 64
Rank 0 - Epoch 2/128 loss: 0.8677321076393127
Rank 0 - Epoch 10/128 loss: 0.8630015850067139
Rank 0 - Epoch 20/128 loss: 0.857090950012207
Rank 0 - Epoch 30/128 loss: 0.8511852025985718
Rank 0 - Epoch 40/128 loss: 0.8452876806259155
Rank 0 - Epoch 50/128 loss: 0.8394011855125427
Rank 0 - Epoch 60/128 loss: 0.8335292935371399
Rank 0 - Epoch 70/128 loss: 0.8276753425598145
Rank 0 - Epoch 80/128 loss: 0.8218434453010559
Rank 0 - Epoch 90/128 loss: 0.8160370588302612
Rank 0 - Epoch 100/128 loss: 0.8102607131004333
Rank 0 - Epoch 110/128 loss: 0.8045186400413513
Rank 0 - Epoch 120/128 loss: 0.7988154888153076
Training complete.
[92mRank 0 - Testing RMSE: 3.6443[0m
[92mRank: 0, Lengthscale: [[0.5896013  0.58953935]] [0m
[92mRank: 0, Outputscale: 0.592347264289856 [0m
[92mRank: 0, Noise: 0.5802700519561768 [0m
Run 1 completed successfully
Running cGP 2 with agents: 64
decADMM initialized with rho: 0.85, max_iter: 5, lr: 0.0001, rank: 0, world_size: 64
Rank 0 - Epoch 2/128 loss: 0.8677321076393127
Rank 0 - Epoch 10/128 loss: 0.8630015850067139
Rank 0 - Epoch 20/128 loss: 0.857090950012207
Rank 0 - Epoch 30/128 loss: 0.8511852025985718
Rank 0 - Epoch 40/128 loss: 0.8452876806259155
Rank 0 - Epoch 50/128 loss: 0.8394011855125427
Rank 0 - Epoch 60/128 loss: 0.8335292935371399
Rank 0 - Epoch 70/128 loss: 0.8276753425598145
Rank 0 - Epoch 80/128 loss: 0.8218434453010559
Rank 0 - Epoch 90/128 loss: 0.8160370588302612
Rank 0 - Epoch 100/128 loss: 0.8102607131004333
Rank 0 - Epoch 110/128 loss: 0.8045186400413513
Rank 0 - Epoch 120/128 loss: 0.7988154888153076
Training complete.
[92mRank 0 - Testing RMSE: 3.6443[0m
[92mRank: 0, Lengthscale: [[0.5896013  0.58953935]] [0m
[92mRank: 0, Outputscale: 0.592347264289856 [0m
[92mRank: 0, Noise: 0.5802700519561768 [0m
Run 2 completed successfully
Running cGP 3 with agents: 64
decADMM initialized with rho: 0.85, max_iter: 5, lr: 0.0001, rank: 0, world_size: 64
Rank 0 - Epoch 2/128 loss: 0.8677321076393127
Rank 0 - Epoch 10/128 loss: 0.8630015850067139
Rank 0 - Epoch 20/128 loss: 0.857090950012207
Rank 0 - Epoch 30/128 loss: 0.8511852025985718
Rank 0 - Epoch 40/128 loss: 0.8452876806259155
Rank 0 - Epoch 50/128 loss: 0.8394011855125427
Rank 0 - Epoch 60/128 loss: 0.8335292935371399
Rank 0 - Epoch 70/128 loss: 0.8276753425598145
Rank 0 - Epoch 80/128 loss: 0.8218434453010559
Rank 0 - Epoch 90/128 loss: 0.8160370588302612
Rank 0 - Epoch 100/128 loss: 0.8102607131004333
Rank 0 - Epoch 110/128 loss: 0.8045186400413513
Rank 0 - Epoch 120/128 loss: 0.7988154888153076
Training complete.
[92mRank 0 - Testing RMSE: 3.6443[0m
[92mRank: 0, Lengthscale: [[0.5896013  0.58953935]] [0m
[92mRank: 0, Outputscale: 0.592347264289856 [0m
[92mRank: 0, Noise: 0.5802700519561768 [0m
Run 3 completed successfully
Running cGP 4 with agents: 64
decADMM initialized with rho: 0.85, max_iter: 5, lr: 0.0001, rank: 0, world_size: 64
Rank 0 - Epoch 2/128 loss: 0.8677321076393127
Rank 0 - Epoch 10/128 loss: 0.8630015850067139
Rank 0 - Epoch 20/128 loss: 0.857090950012207
Rank 0 - Epoch 30/128 loss: 0.8511852025985718
Rank 0 - Epoch 40/128 loss: 0.8452876806259155
Rank 0 - Epoch 50/128 loss: 0.8394011855125427
Rank 0 - Epoch 60/128 loss: 0.8335292935371399
Rank 0 - Epoch 70/128 loss: 0.8276753425598145
Rank 0 - Epoch 80/128 loss: 0.8218434453010559
Rank 0 - Epoch 90/128 loss: 0.8160370588302612
Rank 0 - Epoch 100/128 loss: 0.8102607131004333
Rank 0 - Epoch 110/128 loss: 0.8045186400413513
Rank 0 - Epoch 120/128 loss: 0.7988154888153076
Training complete.
[92mRank 0 - Testing RMSE: 3.6443[0m
[92mRank: 0, Lengthscale: [[0.5896013  0.58953935]] [0m
[92mRank: 0, Outputscale: 0.592347264289856 [0m
[92mRank: 0, Noise: 0.5802700519561768 [0m
Run 4 completed successfully
Running cGP 5 with agents: 64
decADMM initialized with rho: 0.85, max_iter: 5, lr: 0.0001, rank: 0, world_size: 64
Rank 0 - Epoch 2/128 loss: 0.8677321076393127
Rank 0 - Epoch 10/128 loss: 0.8630015850067139
Rank 0 - Epoch 20/128 loss: 0.857090950012207
Rank 0 - Epoch 30/128 loss: 0.8511852025985718
Rank 0 - Epoch 40/128 loss: 0.8452876806259155
Rank 0 - Epoch 50/128 loss: 0.8394011855125427
Rank 0 - Epoch 60/128 loss: 0.8335292935371399
Rank 0 - Epoch 70/128 loss: 0.8276753425598145
Rank 0 - Epoch 80/128 loss: 0.8218434453010559
Rank 0 - Epoch 90/128 loss: 0.8160370588302612
Rank 0 - Epoch 100/128 loss: 0.8102607131004333
Rank 0 - Epoch 110/128 loss: 0.8045186400413513
Rank 0 - Epoch 120/128 loss: 0.7988154888153076
Training complete.
[92mRank 0 - Testing RMSE: 3.6443[0m
[92mRank: 0, Lengthscale: [[0.5896013  0.58953935]] [0m
[92mRank: 0, Outputscale: 0.592347264289856 [0m
[92mRank: 0, Noise: 0.5802700519561768 [0m
Run 5 completed successfully
Running cGP 6 with agents: 64
decADMM initialized with rho: 0.85, max_iter: 5, lr: 0.0001, rank: 0, world_size: 64
Rank 0 - Epoch 2/128 loss: 0.8677321076393127
Rank 0 - Epoch 10/128 loss: 0.8630015850067139
Rank 0 - Epoch 20/128 loss: 0.857090950012207
Rank 0 - Epoch 30/128 loss: 0.8511852025985718
Rank 0 - Epoch 40/128 loss: 0.8452876806259155
Rank 0 - Epoch 50/128 loss: 0.8394011855125427
Rank 0 - Epoch 60/128 loss: 0.8335292935371399
Rank 0 - Epoch 70/128 loss: 0.8276753425598145
Rank 0 - Epoch 80/128 loss: 0.8218434453010559
Rank 0 - Epoch 90/128 loss: 0.8160370588302612
Rank 0 - Epoch 100/128 loss: 0.8102607131004333
Rank 0 - Epoch 110/128 loss: 0.8045186400413513
Rank 0 - Epoch 120/128 loss: 0.7988154888153076
Training complete.
[92mRank 0 - Testing RMSE: 3.6443[0m
[92mRank: 0, Lengthscale: [[0.5896013  0.58953935]] [0m
[92mRank: 0, Outputscale: 0.592347264289856 [0m
[92mRank: 0, Noise: 0.5802700519561768 [0m
Run 6 completed successfully
Running cGP 7 with agents: 64
decADMM initialized with rho: 0.85, max_iter: 5, lr: 0.0001, rank: 0, world_size: 64
Rank 0 - Epoch 2/128 loss: 0.8677321076393127
Rank 0 - Epoch 10/128 loss: 0.8630015850067139
Rank 0 - Epoch 20/128 loss: 0.857090950012207
Rank 0 - Epoch 30/128 loss: 0.8511852025985718
Rank 0 - Epoch 40/128 loss: 0.8452876806259155
Rank 0 - Epoch 50/128 loss: 0.8394011855125427
Rank 0 - Epoch 60/128 loss: 0.8335292935371399
Rank 0 - Epoch 70/128 loss: 0.8276753425598145
Rank 0 - Epoch 80/128 loss: 0.8218434453010559
Rank 0 - Epoch 90/128 loss: 0.8160370588302612
Rank 0 - Epoch 100/128 loss: 0.8102607131004333
Rank 0 - Epoch 110/128 loss: 0.8045186400413513
Rank 0 - Epoch 120/128 loss: 0.7988154888153076
Training complete.
[92mRank 0 - Testing RMSE: 3.6443[0m
[92mRank: 0, Lengthscale: [[0.5896013  0.58953935]] [0m
[92mRank: 0, Outputscale: 0.592347264289856 [0m
[92mRank: 0, Noise: 0.5802700519561768 [0m
Run 7 completed successfully
Running cGP 8 with agents: 64
decADMM initialized with rho: 0.85, max_iter: 5, lr: 0.0001, rank: 0, world_size: 64
Rank 0 - Epoch 2/128 loss: 0.8677321076393127
Rank 0 - Epoch 10/128 loss: 0.8630015850067139
Rank 0 - Epoch 20/128 loss: 0.857090950012207
Rank 0 - Epoch 30/128 loss: 0.8511852025985718
Rank 0 - Epoch 40/128 loss: 0.8452876806259155
Rank 0 - Epoch 50/128 loss: 0.8394011855125427
Rank 0 - Epoch 60/128 loss: 0.8335292935371399
Rank 0 - Epoch 70/128 loss: 0.8276753425598145
Rank 0 - Epoch 80/128 loss: 0.8218434453010559
Rank 0 - Epoch 90/128 loss: 0.8160370588302612
Rank 0 - Epoch 100/128 loss: 0.8102607131004333
Rank 0 - Epoch 110/128 loss: 0.8045186400413513
Rank 0 - Epoch 120/128 loss: 0.7988154888153076
Training complete.
[92mRank 0 - Testing RMSE: 3.6443[0m
[92mRank: 0, Lengthscale: [[0.5896013  0.58953935]] [0m
[92mRank: 0, Outputscale: 0.592347264289856 [0m
[92mRank: 0, Noise: 0.5802700519561768 [0m
Run 8 completed successfully
Running cGP 9 with agents: 64
decADMM initialized with rho: 0.85, max_iter: 5, lr: 0.0001, rank: 0, world_size: 64
Rank 0 - Epoch 2/128 loss: 0.8677321076393127
Rank 0 - Epoch 10/128 loss: 0.8630015850067139
Rank 0 - Epoch 20/128 loss: 0.857090950012207
Rank 0 - Epoch 30/128 loss: 0.8511852025985718
Rank 0 - Epoch 40/128 loss: 0.8452876806259155
Rank 0 - Epoch 50/128 loss: 0.8394011855125427
Rank 0 - Epoch 60/128 loss: 0.8335292935371399
Rank 0 - Epoch 70/128 loss: 0.8276753425598145
Rank 0 - Epoch 80/128 loss: 0.8218434453010559
Rank 0 - Epoch 90/128 loss: 0.8160370588302612
Rank 0 - Epoch 100/128 loss: 0.8102607131004333
Rank 0 - Epoch 110/128 loss: 0.8045186400413513
Rank 0 - Epoch 120/128 loss: 0.7988154888153076
Training complete.
[92mRank 0 - Testing RMSE: 3.6443[0m
[92mRank: 0, Lengthscale: [[0.5896013  0.58953935]] [0m
[92mRank: 0, Outputscale: 0.592347264289856 [0m
[92mRank: 0, Noise: 0.5802700519561768 [0m
Run 9 completed successfully
Running cGP 10 with agents: 64
decADMM initialized with rho: 0.85, max_iter: 5, lr: 0.0001, rank: 0, world_size: 64
Rank 0 - Epoch 2/128 loss: 0.8677321076393127
Rank 0 - Epoch 10/128 loss: 0.8630015850067139
Rank 0 - Epoch 20/128 loss: 0.857090950012207
Rank 0 - Epoch 30/128 loss: 0.8511852025985718
Rank 0 - Epoch 40/128 loss: 0.8452876806259155
Rank 0 - Epoch 50/128 loss: 0.8394011855125427
Rank 0 - Epoch 60/128 loss: 0.8335292935371399
Rank 0 - Epoch 70/128 loss: 0.8276753425598145
Rank 0 - Epoch 80/128 loss: 0.8218434453010559
Rank 0 - Epoch 90/128 loss: 0.8160370588302612
Rank 0 - Epoch 100/128 loss: 0.8102607131004333
Rank 0 - Epoch 110/128 loss: 0.8045186400413513
Rank 0 - Epoch 120/128 loss: 0.7988154888153076
Training complete.
[92mRank 0 - Testing RMSE: 3.6443[0m
[92mRank: 0, Lengthscale: [[0.5896013  0.58953935]] [0m
[92mRank: 0, Outputscale: 0.592347264289856 [0m
[92mRank: 0, Noise: 0.5802700519561768 [0m
Run 10 completed successfully
Running pxpGP 1 with agents: 100
[92mRank 0 - sparse dataset size is: 3, local dataset: torch.Size([169, 2]), [0m
[92mRank 0 - Training local sparse GP model with 169 samples[0m
Epoch 1/200 - Loss: 14.487
Epoch 11/200 - Loss: 1.131
Epoch 21/200 - Loss: 1.053
Epoch 31/200 - Loss: 0.963
Epoch 41/200 - Loss: 0.854
Epoch 51/200 - Loss: 0.746
Epoch 61/200 - Loss: 0.585
Epoch 71/200 - Loss: 0.439
Epoch 81/200 - Loss: 0.224
Epoch 91/200 - Loss: 0.039
Converged at epoch 93 with loss -0.009
[92mRank 0 - Lengthscale: [[0.5923226 1.5332818]] [0m
[92mRank 0 - Outputscale: 2.4898922443389893 [0m
[92mRank 0 - Noise: 0.11672820895910263 [0m
Rank 0 - Augmented dataset size: 469
Rank 0: After warm start model parameters:
Rank: 0, Lengthscale: [[0.5923226 1.5332818]]
Rank: 0, Outputscale: 2.4898922443389893
Rank: 0, Noise: 0.11672820895910263
decpxADMM initialized with rho: 0.85, lip: 1.0, tol_abs: 1e-05, tol_rel: 0.001, rank: 0, world_size: 100
[92mRank 0 - Training global model with dec-pxADMM optimizer[0m
rank 0, epoch 9, loss: 0.9913448095321655, rho: 0.4250, lip: 1.0000
rank 0, epoch 19, loss: 0.9956603646278381, rho: 0.2125, lip: 1.0000
rank 0, epoch 29, loss: 0.9579101800918579, rho: 0.1062, lip: 1.0000
rank 0, epoch 39, loss: 0.899574875831604, rho: 0.1062, lip: 1.0000
rank 0, epoch 49, loss: 0.8871268630027771, rho: 0.0531, lip: 1.0000
rank 0, epoch 59, loss: 0.885706901550293, rho: 0.0531, lip: 1.0000
rank 0, epoch 69, loss: 0.8844557404518127, rho: 0.0531, lip: 1.0000
rank 0, epoch 79, loss: 0.8823087215423584, rho: 0.0266, lip: 1.0000
rank 0, epoch 89, loss: 0.8808256983757019, rho: 0.0266, lip: 1.0000
rank 0, epoch 99, loss: 0.8800399303436279, rho: 0.0266, lip: 1.0000
rank 0, epoch 109, loss: 0.8796809315681458, rho: 0.0033, lip: 1.0000
rank 0, epoch 119, loss: 0.8797280788421631, rho: 0.0033, lip: 1.0000
rank 0, epoch 129, loss: 0.8799688220024109, rho: 0.0033, lip: 1.0000
rank 0, epoch 139, loss: 0.8802621960639954, rho: 0.0033, lip: 1.0000
rank 0, epoch 149, loss: 0.8805026412010193, rho: 0.0033, lip: 1.0000
Rank 0 - Training time: 95.63 seconds
[92mRank 0 - Testing RMSE: 0.3368[0m
[92mRank: 0, Lengthscale: [[0.7135665 0.4122353]] [0m
[92mRank: 0, Outputscale: 3.1893863677978516 [0m
[92mRank: 0, Noise: 0.21447618305683136 [0m
Run 1 completed successfully
Running pxpGP 2 with agents: 100
[92mRank 0 - sparse dataset size is: 3, local dataset: torch.Size([169, 2]), [0m
[92mRank 0 - Training local sparse GP model with 169 samples[0m
Epoch 1/200 - Loss: 13.384
Epoch 11/200 - Loss: 1.197
Epoch 21/200 - Loss: 1.042
Epoch 31/200 - Loss: 0.969
Epoch 41/200 - Loss: 0.868
Epoch 51/200 - Loss: 0.737
Epoch 61/200 - Loss: 0.598
Epoch 71/200 - Loss: 0.463
Epoch 81/200 - Loss: 0.238
Epoch 91/200 - Loss: 0.105
Converged at epoch 93 with loss -0.010
[92mRank 0 - Lengthscale: [[0.5853792 1.5884649]] [0m
[92mRank 0 - Outputscale: 2.493582248687744 [0m
[92mRank 0 - Noise: 0.11816006898880005 [0m
Rank 0 - Augmented dataset size: 469
Rank 0: After warm start model parameters:
Rank: 0, Lengthscale: [[0.5853792 1.5884649]]
Rank: 0, Outputscale: 2.493582248687744
Rank: 0, Noise: 0.11816006898880005
decpxADMM initialized with rho: 0.85, lip: 1.0, tol_abs: 1e-05, tol_rel: 0.001, rank: 0, world_size: 100
[92mRank 0 - Training global model with dec-pxADMM optimizer[0m
rank 0, epoch 9, loss: 1.0074183940887451, rho: 0.4250, lip: 1.0000
rank 0, epoch 19, loss: 1.044925332069397, rho: 0.2125, lip: 1.0000
rank 0, epoch 29, loss: 0.999972403049469, rho: 0.1062, lip: 1.0000
rank 0, epoch 39, loss: 0.9460553526878357, rho: 0.1062, lip: 1.0000
rank 0, epoch 49, loss: 0.9436214566230774, rho: 0.0531, lip: 1.0000
rank 0, epoch 59, loss: 0.9352719187736511, rho: 0.0531, lip: 1.0000
rank 0, epoch 69, loss: 0.9321485757827759, rho: 0.0531, lip: 1.0000
rank 0, epoch 79, loss: 0.9318522214889526, rho: 0.0531, lip: 1.0000
rank 0, epoch 89, loss: 0.9316598773002625, rho: 0.0531, lip: 1.0000
rank 0, epoch 99, loss: 0.9301108121871948, rho: 0.0266, lip: 1.0000
rank 0, epoch 109, loss: 0.928594708442688, rho: 0.0066, lip: 1.0000
rank 0, epoch 119, loss: 0.9276977777481079, rho: 0.0066, lip: 1.0000
rank 0, epoch 129, loss: 0.9271727204322815, rho: 0.0066, lip: 1.0000
rank 0, epoch 139, loss: 0.9267739653587341, rho: 0.0066, lip: 1.0000
rank 0, epoch 149, loss: 0.9263593554496765, rho: 0.0066, lip: 1.0000
Rank 0 - Training time: 101.46 seconds
[92mRank 0 - Testing RMSE: 0.3825[0m
[92mRank: 0, Lengthscale: [[0.6188487 0.4357752]] [0m
[92mRank: 0, Outputscale: 2.363558292388916 [0m
[92mRank: 0, Noise: 0.2985299825668335 [0m
Run 2 completed successfully
Running pxpGP 3 with agents: 100
[92mRank 0 - sparse dataset size is: 3, local dataset: torch.Size([169, 2]), [0m
[92mRank 0 - Training local sparse GP model with 169 samples[0m
Epoch 1/200 - Loss: 14.567
Epoch 11/200 - Loss: 1.116
Epoch 21/200 - Loss: 1.035
Epoch 31/200 - Loss: 0.961
Epoch 41/200 - Loss: 0.864
Epoch 51/200 - Loss: 0.757
Epoch 61/200 - Loss: 0.606
Epoch 71/200 - Loss: 0.433
Epoch 81/200 - Loss: 0.273
Epoch 91/200 - Loss: 0.139
Converged at epoch 92 with loss -0.031
[92mRank 0 - Lengthscale: [[0.5680686 1.4764837]] [0m
[92mRank 0 - Outputscale: 2.4838156700134277 [0m
[92mRank 0 - Noise: 0.12042983621358871 [0m
Rank 0 - Augmented dataset size: 469
Rank 0: After warm start model parameters:
Rank: 0, Lengthscale: [[0.5680686 1.4764837]]
Rank: 0, Outputscale: 2.4838156700134277
Rank: 0, Noise: 0.12042983621358871
decpxADMM initialized with rho: 0.85, lip: 1.0, tol_abs: 1e-05, tol_rel: 0.001, rank: 0, world_size: 100
[92mRank 0 - Training global model with dec-pxADMM optimizer[0m
rank 0, epoch 9, loss: 1.0416109561920166, rho: 0.4250, lip: 1.0000
rank 0, epoch 19, loss: 1.0340721607208252, rho: 0.2125, lip: 1.0000
rank 0, epoch 29, loss: 0.9678042531013489, rho: 0.2125, lip: 1.0000
rank 0, epoch 39, loss: 0.9195342063903809, rho: 0.0531, lip: 1.0000
rank 0, epoch 49, loss: 0.9106149673461914, rho: 0.0531, lip: 1.0000
rank 0, epoch 59, loss: 0.9091173410415649, rho: 0.0531, lip: 1.0000
rank 0, epoch 69, loss: 0.9086337685585022, rho: 0.0531, lip: 1.0000
rank 0, epoch 79, loss: 0.9079269766807556, rho: 0.0266, lip: 1.0000
rank 0, epoch 89, loss: 0.9081682562828064, rho: 0.0266, lip: 1.0000
rank 0, epoch 99, loss: 0.9087190628051758, rho: 0.0266, lip: 1.0000
rank 0, epoch 109, loss: 0.9085699915885925, rho: 0.0266, lip: 1.0000
rank 0, epoch 119, loss: 0.9080604910850525, rho: 0.0266, lip: 1.0000
rank 0, epoch 129, loss: 0.9074791669845581, rho: 0.0266, lip: 1.0000
rank 0, epoch 139, loss: 0.9066906571388245, rho: 0.0266, lip: 1.0000
rank 0, epoch 149, loss: 0.9058787226676941, rho: 0.0266, lip: 1.0000
Rank 0 - Training time: 95.87 seconds
[92mRank 0 - Testing RMSE: 0.3948[0m
[92mRank: 0, Lengthscale: [[0.7445298  0.38852406]] [0m
[92mRank: 0, Outputscale: 2.6168785095214844 [0m
[92mRank: 0, Noise: 0.24117514491081238 [0m
Run 3 completed successfully
Running pxpGP 4 with agents: 100
[92mRank 0 - sparse dataset size is: 3, local dataset: torch.Size([169, 2]), [0m
[92mRank 0 - Training local sparse GP model with 169 samples[0m
Epoch 1/200 - Loss: 11.956
Epoch 11/200 - Loss: 1.108
Epoch 21/200 - Loss: 1.049
Epoch 31/200 - Loss: 0.966
Epoch 41/200 - Loss: 0.866
Epoch 51/200 - Loss: 0.733
Epoch 61/200 - Loss: 0.598
Epoch 71/200 - Loss: 0.411
Epoch 81/200 - Loss: 0.268
Epoch 91/200 - Loss: 0.112
Converged at epoch 93 with loss -0.025
[92mRank 0 - Lengthscale: [[0.5851943 1.5673305]] [0m
[92mRank 0 - Outputscale: 2.499185085296631 [0m
[92mRank 0 - Noise: 0.11633846908807755 [0m
Rank 0 - Augmented dataset size: 469
Rank 0: After warm start model parameters:
Rank: 0, Lengthscale: [[0.5851943 1.5673305]]
Rank: 0, Outputscale: 2.499185085296631
Rank: 0, Noise: 0.11633846908807755
decpxADMM initialized with rho: 0.85, lip: 1.0, tol_abs: 1e-05, tol_rel: 0.001, rank: 0, world_size: 100
[92mRank 0 - Training global model with dec-pxADMM optimizer[0m
rank 0, epoch 9, loss: 1.0004624128341675, rho: 0.4250, lip: 1.0000
rank 0, epoch 19, loss: 1.0064631700515747, rho: 0.2125, lip: 1.0000
rank 0, epoch 29, loss: 0.9335314631462097, rho: 0.1062, lip: 1.0000
rank 0, epoch 39, loss: 0.8860700130462646, rho: 0.1062, lip: 1.0000
rank 0, epoch 49, loss: 0.8750918507575989, rho: 0.0531, lip: 1.0000
rank 0, epoch 59, loss: 0.8708050847053528, rho: 0.0531, lip: 1.0000
rank 0, epoch 69, loss: 0.8688915371894836, rho: 0.0266, lip: 1.0000
rank 0, epoch 79, loss: 0.8691221475601196, rho: 0.0266, lip: 1.0000
rank 0, epoch 89, loss: 0.8705388307571411, rho: 0.0266, lip: 1.0000
rank 0, epoch 99, loss: 0.8708739876747131, rho: 0.0266, lip: 1.0000
rank 0, epoch 109, loss: 0.8701279759407043, rho: 0.0133, lip: 1.0000
rank 0, epoch 119, loss: 0.8688998818397522, rho: 0.0133, lip: 1.0000
rank 0, epoch 129, loss: 0.8670985102653503, rho: 0.0133, lip: 1.0000
rank 0, epoch 139, loss: 0.8650394082069397, rho: 0.0133, lip: 1.0000
rank 0, epoch 149, loss: 0.8632218837738037, rho: 0.0133, lip: 1.0000
Rank 0 - Training time: 107.48 seconds
[92mRank 0 - Testing RMSE: 0.3451[0m
[92mRank: 0, Lengthscale: [[0.6063032  0.38839093]] [0m
[92mRank: 0, Outputscale: 1.8652305603027344 [0m
[92mRank: 0, Noise: 0.20530296862125397 [0m
Run 4 completed successfully
Running pxpGP 5 with agents: 100
[92mRank 0 - sparse dataset size is: 3, local dataset: torch.Size([169, 2]), [0m
[92mRank 0 - Training local sparse GP model with 169 samples[0m
Epoch 1/200 - Loss: 13.354
Epoch 11/200 - Loss: 1.135
Epoch 21/200 - Loss: 1.050
Epoch 31/200 - Loss: 0.951
Epoch 41/200 - Loss: 0.860
Epoch 51/200 - Loss: 0.730
Epoch 61/200 - Loss: 0.621
Epoch 71/200 - Loss: 0.469
Epoch 81/200 - Loss: 0.259
Epoch 91/200 - Loss: 0.086
Converged at epoch 94 with loss -0.027
[92mRank 0 - Lengthscale: [[0.5963152 1.5820472]] [0m
[92mRank 0 - Outputscale: 2.4751617908477783 [0m
[92mRank 0 - Noise: 0.11299800872802734 [0m
Rank 0 - Augmented dataset size: 469
Rank 0: After warm start model parameters:
Rank: 0, Lengthscale: [[0.5963152 1.5820472]]
Rank: 0, Outputscale: 2.4751617908477783
Rank: 0, Noise: 0.11299800872802734
decpxADMM initialized with rho: 0.85, lip: 1.0, tol_abs: 1e-05, tol_rel: 0.001, rank: 0, world_size: 100
[92mRank 0 - Training global model with dec-pxADMM optimizer[0m
rank 0, epoch 9, loss: 1.02294921875, rho: 0.4250, lip: 1.0000
rank 0, epoch 19, loss: 1.0277018547058105, rho: 0.2125, lip: 1.0000
rank 0, epoch 29, loss: 0.9577118754386902, rho: 0.2125, lip: 1.0000
rank 0, epoch 39, loss: 0.9135125279426575, rho: 0.1062, lip: 1.0000
rank 0, epoch 49, loss: 0.9058236479759216, rho: 0.0531, lip: 1.0000
rank 0, epoch 59, loss: 0.9030508995056152, rho: 0.0531, lip: 1.0000
rank 0, epoch 69, loss: 0.9012935161590576, rho: 0.0266, lip: 1.0000
rank 0, epoch 79, loss: 0.9003609418869019, rho: 0.0266, lip: 1.0000
rank 0, epoch 89, loss: 0.9005174040794373, rho: 0.0266, lip: 1.0000
rank 0, epoch 99, loss: 0.8998243808746338, rho: 0.0266, lip: 1.0000
rank 0, epoch 109, loss: 0.8988203406333923, rho: 0.0066, lip: 1.0000
rank 0, epoch 119, loss: 0.8982060551643372, rho: 0.0066, lip: 1.0000
rank 0, epoch 129, loss: 0.897676944732666, rho: 0.0066, lip: 1.0000
rank 0, epoch 139, loss: 0.8971524238586426, rho: 0.0066, lip: 1.0000
rank 0, epoch 149, loss: 0.896692156791687, rho: 0.0066, lip: 1.0000
Rank 0 - Training time: 78.22 seconds
[92mRank 0 - Testing RMSE: 0.3735[0m
[92mRank: 0, Lengthscale: [[0.689104  0.4368811]] [0m
[92mRank: 0, Outputscale: 2.5521926879882812 [0m
[92mRank: 0, Noise: 0.23713499307632446 [0m
Run 5 completed successfully
Running pxpGP 6 with agents: 100
[92mRank 0 - sparse dataset size is: 3, local dataset: torch.Size([169, 2]), [0m
[92mRank 0 - Training local sparse GP model with 169 samples[0m
Epoch 1/200 - Loss: 11.493
Epoch 11/200 - Loss: 1.133
Epoch 21/200 - Loss: 1.042
Epoch 31/200 - Loss: 0.961
Epoch 41/200 - Loss: 0.862
Epoch 51/200 - Loss: 0.746
Epoch 61/200 - Loss: 0.621
Epoch 71/200 - Loss: 0.475
Epoch 81/200 - Loss: 0.237
Epoch 91/200 - Loss: 0.033
Epoch 101/200 - Loss: -0.018
Converged at epoch 101 with loss -0.018
[92mRank 0 - Lengthscale: [[0.61824435 1.7774601 ]] [0m
[92mRank 0 - Outputscale: 2.51216983795166 [0m
[92mRank 0 - Noise: 0.08672330528497696 [0m
Rank 0 - Augmented dataset size: 469
Rank 0: After warm start model parameters:
Rank: 0, Lengthscale: [[0.61824435 1.7774601 ]]
Rank: 0, Outputscale: 2.51216983795166
Rank: 0, Noise: 0.08672330528497696
decpxADMM initialized with rho: 0.85, lip: 1.0, tol_abs: 1e-05, tol_rel: 0.001, rank: 0, world_size: 100
[92mRank 0 - Training global model with dec-pxADMM optimizer[0m
rank 0, epoch 9, loss: 1.0292243957519531, rho: 0.4250, lip: 1.0000
rank 0, epoch 19, loss: 1.0398005247116089, rho: 0.2125, lip: 1.0000
rank 0, epoch 29, loss: 1.0068188905715942, rho: 0.2125, lip: 1.0000
rank 0, epoch 39, loss: 0.9392766356468201, rho: 0.1062, lip: 1.0000
rank 0, epoch 49, loss: 0.9296174645423889, rho: 0.0531, lip: 1.0000
rank 0, epoch 59, loss: 0.9311113953590393, rho: 0.0531, lip: 1.0000
rank 0, epoch 69, loss: 0.9344192147254944, rho: 0.0266, lip: 1.0000
rank 0, epoch 79, loss: 0.9356265068054199, rho: 0.0266, lip: 1.0000
rank 0, epoch 89, loss: 0.9359975457191467, rho: 0.0266, lip: 1.0000
rank 0, epoch 99, loss: 0.9360203742980957, rho: 0.0266, lip: 1.0000
rank 0, epoch 109, loss: 0.9355881214141846, rho: 0.0266, lip: 1.0000
rank 0, epoch 119, loss: 0.9342519044876099, rho: 0.0066, lip: 1.0000
rank 0, epoch 129, loss: 0.9329898953437805, rho: 0.0066, lip: 1.0000
rank 0, epoch 139, loss: 0.9320526719093323, rho: 0.0066, lip: 1.0000
rank 0, epoch 149, loss: 0.9314197897911072, rho: 0.0066, lip: 1.0000
Rank 0 - Training time: 89.21 seconds
[92mRank 0 - Testing RMSE: 0.3887[0m
[92mRank: 0, Lengthscale: [[0.74712944 0.2969441 ]] [0m
[92mRank: 0, Outputscale: 2.534508466720581 [0m
[92mRank: 0, Noise: 0.22799280285835266 [0m
Run 6 completed successfully
Running pxpGP 7 with agents: 100
[92mRank 0 - sparse dataset size is: 3, local dataset: torch.Size([169, 2]), [0m
[92mRank 0 - Training local sparse GP model with 169 samples[0m
Epoch 1/200 - Loss: 13.123
Epoch 11/200 - Loss: 1.150
Epoch 21/200 - Loss: 1.042
Epoch 31/200 - Loss: 0.958
Epoch 41/200 - Loss: 0.858
Epoch 51/200 - Loss: 0.736
Epoch 61/200 - Loss: 0.623
Epoch 71/200 - Loss: 0.428
Epoch 81/200 - Loss: 0.316
Epoch 91/200 - Loss: 0.048
Converged at epoch 96 with loss -0.015
[92mRank 0 - Lengthscale: [[0.5874153 1.4077531]] [0m
[92mRank 0 - Outputscale: 2.5140652656555176 [0m
[92mRank 0 - Noise: 0.10286461561918259 [0m
Rank 0 - Augmented dataset size: 469
Rank 0: After warm start model parameters:
Rank: 0, Lengthscale: [[0.5874153 1.4077531]]
Rank: 0, Outputscale: 2.5140652656555176
Rank: 0, Noise: 0.10286461561918259
decpxADMM initialized with rho: 0.85, lip: 1.0, tol_abs: 1e-05, tol_rel: 0.001, rank: 0, world_size: 100
[92mRank 0 - Training global model with dec-pxADMM optimizer[0m
rank 0, epoch 9, loss: 1.0344396829605103, rho: 0.4250, lip: 1.0000
rank 0, epoch 19, loss: 1.0192110538482666, rho: 0.2125, lip: 1.0000
rank 0, epoch 29, loss: 0.9605724215507507, rho: 0.2125, lip: 1.0000
rank 0, epoch 39, loss: 0.915867030620575, rho: 0.1062, lip: 1.0000
rank 0, epoch 49, loss: 0.9107727408409119, rho: 0.0531, lip: 1.0000
rank 0, epoch 59, loss: 0.9094536304473877, rho: 0.0531, lip: 1.0000
rank 0, epoch 69, loss: 0.9081228375434875, rho: 0.0266, lip: 1.0000
rank 0, epoch 79, loss: 0.9068344831466675, rho: 0.0266, lip: 1.0000
rank 0, epoch 89, loss: 0.9064525365829468, rho: 0.0266, lip: 1.0000
rank 0, epoch 99, loss: 0.9067248106002808, rho: 0.0266, lip: 1.0000
rank 0, epoch 109, loss: 0.9066924452781677, rho: 0.0266, lip: 1.0000
rank 0, epoch 119, loss: 0.9063515067100525, rho: 0.0266, lip: 1.0000
rank 0, epoch 129, loss: 0.9059245586395264, rho: 0.0266, lip: 1.0000
rank 0, epoch 139, loss: 0.9052559733390808, rho: 0.0266, lip: 1.0000
rank 0, epoch 149, loss: 0.9042931199073792, rho: 0.0266, lip: 1.0000
Rank 0 - Training time: 93.20 seconds
[92mRank 0 - Testing RMSE: 0.3827[0m
[92mRank: 0, Lengthscale: [[0.6857315  0.41019905]] [0m
[92mRank: 0, Outputscale: 2.946038246154785 [0m
[92mRank: 0, Noise: 0.23628315329551697 [0m
Run 7 completed successfully
Running pxpGP 8 with agents: 100
[92mRank 0 - sparse dataset size is: 3, local dataset: torch.Size([169, 2]), [0m
[92mRank 0 - Training local sparse GP model with 169 samples[0m
Epoch 1/200 - Loss: 13.929
Epoch 11/200 - Loss: 1.118
Epoch 21/200 - Loss: 1.035
Epoch 31/200 - Loss: 0.964
Epoch 41/200 - Loss: 0.857
Epoch 51/200 - Loss: 0.736
Epoch 61/200 - Loss: 0.598
Epoch 71/200 - Loss: 0.419
Epoch 81/200 - Loss: 0.207
Epoch 91/200 - Loss: 0.127
Converged at epoch 97 with loss -0.046
[92mRank 0 - Lengthscale: [[0.59152836 1.5353725 ]] [0m
[92mRank 0 - Outputscale: 2.50317120552063 [0m
[92mRank 0 - Noise: 0.09811148792505264 [0m
Rank 0 - Augmented dataset size: 469
Rank 0: After warm start model parameters:
Rank: 0, Lengthscale: [[0.59152836 1.5353725 ]]
Rank: 0, Outputscale: 2.50317120552063
Rank: 0, Noise: 0.09811148792505264
decpxADMM initialized with rho: 0.85, lip: 1.0, tol_abs: 1e-05, tol_rel: 0.001, rank: 0, world_size: 100
[92mRank 0 - Training global model with dec-pxADMM optimizer[0m
rank 0, epoch 9, loss: 1.0010749101638794, rho: 0.4250, lip: 1.0000
rank 0, epoch 19, loss: 0.9753506183624268, rho: 0.2125, lip: 1.0000
rank 0, epoch 29, loss: 0.9546325206756592, rho: 0.1062, lip: 1.0000
rank 0, epoch 39, loss: 0.9059157967567444, rho: 0.1062, lip: 1.0000
rank 0, epoch 49, loss: 0.8923877477645874, rho: 0.0266, lip: 1.0000
rank 0, epoch 59, loss: 0.8898545503616333, rho: 0.0266, lip: 1.0000
rank 0, epoch 69, loss: 0.8896087408065796, rho: 0.0266, lip: 1.0000
rank 0, epoch 79, loss: 0.8895313143730164, rho: 0.0266, lip: 1.0000
rank 0, epoch 89, loss: 0.8899917602539062, rho: 0.0266, lip: 1.0000
rank 0, epoch 99, loss: 0.8909018635749817, rho: 0.0266, lip: 1.0000
rank 0, epoch 109, loss: 0.8913541436195374, rho: 0.0266, lip: 1.0000
rank 0, epoch 119, loss: 0.8911418318748474, rho: 0.0266, lip: 1.0000
rank 0, epoch 129, loss: 0.8903176784515381, rho: 0.0266, lip: 1.0000
rank 0, epoch 139, loss: 0.8891249895095825, rho: 0.0266, lip: 1.0000
rank 0, epoch 149, loss: 0.8880667090415955, rho: 0.0266, lip: 1.0000
Rank 0 - Training time: 97.22 seconds
[92mRank 0 - Testing RMSE: 0.3677[0m
[92mRank: 0, Lengthscale: [[0.72873163 0.3922884 ]] [0m
[92mRank: 0, Outputscale: 2.6603071689605713 [0m
[92mRank: 0, Noise: 0.22299394011497498 [0m
Run 8 completed successfully
Running pxpGP 9 with agents: 100
[92mRank 0 - sparse dataset size is: 3, local dataset: torch.Size([169, 2]), [0m
[92mRank 0 - Training local sparse GP model with 169 samples[0m
Epoch 1/200 - Loss: 13.819
Epoch 11/200 - Loss: 1.139
Epoch 21/200 - Loss: 1.041
Epoch 31/200 - Loss: 0.963
Epoch 41/200 - Loss: 0.859
Epoch 51/200 - Loss: 0.743
Epoch 61/200 - Loss: 0.607
Epoch 71/200 - Loss: 0.426
Epoch 81/200 - Loss: 0.267
Epoch 91/200 - Loss: 0.061
Converged at epoch 92 with loss -0.023
[92mRank 0 - Lengthscale: [[0.5915562 1.636777 ]] [0m
[92mRank 0 - Outputscale: 2.481132745742798 [0m
[92mRank 0 - Noise: 0.12286220490932465 [0m
Rank 0 - Augmented dataset size: 469
Rank 0: After warm start model parameters:
Rank: 0, Lengthscale: [[0.5915562 1.636777 ]]
Rank: 0, Outputscale: 2.481132745742798
Rank: 0, Noise: 0.12286220490932465
decpxADMM initialized with rho: 0.85, lip: 1.0, tol_abs: 1e-05, tol_rel: 0.001, rank: 0, world_size: 100
[92mRank 0 - Training global model with dec-pxADMM optimizer[0m
rank 0, epoch 9, loss: 1.041693091392517, rho: 0.4250, lip: 1.0000
rank 0, epoch 19, loss: 1.0473394393920898, rho: 0.2125, lip: 1.0000
rank 0, epoch 29, loss: 1.0085211992263794, rho: 0.1062, lip: 1.0000
rank 0, epoch 39, loss: 0.9474971294403076, rho: 0.1062, lip: 1.0000
rank 0, epoch 49, loss: 0.9350029230117798, rho: 0.0531, lip: 1.0000
rank 0, epoch 59, loss: 0.9314092993736267, rho: 0.0531, lip: 1.0000
rank 0, epoch 69, loss: 0.929990828037262, rho: 0.0531, lip: 1.0000
rank 0, epoch 79, loss: 0.9298123717308044, rho: 0.0531, lip: 1.0000
rank 0, epoch 89, loss: 0.9305298328399658, rho: 0.0531, lip: 1.0000
rank 0, epoch 99, loss: 0.9298992156982422, rho: 0.0531, lip: 1.0000
rank 0, epoch 109, loss: 0.9285395741462708, rho: 0.0133, lip: 1.0000
rank 0, epoch 119, loss: 0.9277104735374451, rho: 0.0133, lip: 1.0000
rank 0, epoch 129, loss: 0.9273924827575684, rho: 0.0133, lip: 1.0000
rank 0, epoch 139, loss: 0.9272893667221069, rho: 0.0133, lip: 1.0000
rank 0, epoch 149, loss: 0.9271689057350159, rho: 0.0133, lip: 1.0000
Rank 0 - Training time: 91.53 seconds
[92mRank 0 - Testing RMSE: 0.4020[0m
[92mRank: 0, Lengthscale: [[0.73081285 0.42975974]] [0m
[92mRank: 0, Outputscale: 2.9440195560455322 [0m
[92mRank: 0, Noise: 0.2482716590166092 [0m
Run 9 completed successfully
Running pxpGP 10 with agents: 100
[92mRank 0 - sparse dataset size is: 3, local dataset: torch.Size([169, 2]), [0m
[92mRank 0 - Training local sparse GP model with 169 samples[0m
Epoch 1/200 - Loss: 13.859
Epoch 11/200 - Loss: 1.102
Epoch 21/200 - Loss: 1.039
Epoch 31/200 - Loss: 0.972
Epoch 41/200 - Loss: 0.866
Epoch 51/200 - Loss: 0.742
Epoch 61/200 - Loss: 0.613
Epoch 71/200 - Loss: 0.438
Epoch 81/200 - Loss: 0.220
Epoch 91/200 - Loss: 0.110
Converged at epoch 94 with loss -0.008
[92mRank 0 - Lengthscale: [[0.59523535 1.4816694 ]] [0m
[92mRank 0 - Outputscale: 2.4944281578063965 [0m
[92mRank 0 - Noise: 0.11278823018074036 [0m
Rank 0 - Augmented dataset size: 469
Rank 0: After warm start model parameters:
Rank: 0, Lengthscale: [[0.59523535 1.4816694 ]]
Rank: 0, Outputscale: 2.4944281578063965
Rank: 0, Noise: 0.11278824508190155
decpxADMM initialized with rho: 0.85, lip: 1.0, tol_abs: 1e-05, tol_rel: 0.001, rank: 0, world_size: 100
[92mRank 0 - Training global model with dec-pxADMM optimizer[0m
rank 0, epoch 9, loss: 1.0054528713226318, rho: 0.4250, lip: 1.0000
rank 0, epoch 19, loss: 0.9889520406723022, rho: 0.2125, lip: 1.0000
rank 0, epoch 29, loss: 0.9609176516532898, rho: 0.1062, lip: 1.0000
rank 0, epoch 39, loss: 0.8930997252464294, rho: 0.1062, lip: 1.0000
rank 0, epoch 49, loss: 0.8814171552658081, rho: 0.0531, lip: 1.0000
rank 0, epoch 59, loss: 0.8798808455467224, rho: 0.0531, lip: 1.0000
rank 0, epoch 69, loss: 0.8786237239837646, rho: 0.0266, lip: 1.0000
rank 0, epoch 79, loss: 0.8782683610916138, rho: 0.0266, lip: 1.0000
rank 0, epoch 89, loss: 0.8793214559555054, rho: 0.0266, lip: 1.0000
rank 0, epoch 99, loss: 0.8804259896278381, rho: 0.0266, lip: 1.0000
rank 0, epoch 109, loss: 0.8807601928710938, rho: 0.0266, lip: 1.0000
rank 0, epoch 119, loss: 0.8802226185798645, rho: 0.0266, lip: 1.0000
rank 0, epoch 129, loss: 0.879164457321167, rho: 0.0266, lip: 1.0000
rank 0, epoch 139, loss: 0.8778939247131348, rho: 0.0266, lip: 1.0000
rank 0, epoch 149, loss: 0.8765881061553955, rho: 0.0266, lip: 1.0000
Rank 0 - Training time: 88.56 seconds
[92mRank 0 - Testing RMSE: 0.3875[0m
[92mRank: 0, Lengthscale: [[0.7664186 0.396418 ]] [0m
[92mRank: 0, Outputscale: 3.0869386196136475 [0m
[92mRank: 0, Noise: 0.2141081839799881 [0m
Run 10 completed successfully
Running gapxGP 1 with agents: 100
decpxADMM initialized with rho: 0.75, lip: 1.0, tol_abs: 1e-05, tol_rel: 0.001, rank: 0, world_size: 100
Rank 0 - Epoch 2/150 loss: 1.1064478158950806
Rank 0 - Epoch 10/150 loss: 0.9059475064277649
Rank 0 - Epoch 20/150 loss: 0.6503036618232727
Rank 0 - Epoch 30/150 loss: 0.3067494034767151
Rank 0 - Epoch 40/150 loss: -0.05685516446828842
Rank 0 - Epoch 50/150 loss: -0.40697377920150757
Rank 0 - Epoch 60/150 loss: -0.7395975589752197
Rank 0 - Epoch 70/150 loss: -1.0440380573272705
Rank 0 - Epoch 80/150 loss: -1.3160293102264404
Rank 0 - Epoch 90/150 loss: -1.5476791858673096
Rank 0 - Epoch 100/150 loss: -1.730794906616211
Rank 0 - Epoch 110/150 loss: -1.745237112045288
Run 1 failed, retrying...
Running gapxGP 2 with agents: 100
decpxADMM initialized with rho: 0.75, lip: 1.0, tol_abs: 1e-05, tol_rel: 0.001, rank: 0, world_size: 100
Rank 0 - Epoch 2/150 loss: 1.1243642568588257
Rank 0 - Epoch 10/150 loss: 0.9314925074577332
Rank 0 - Epoch 20/150 loss: 0.6770074367523193
Rank 0 - Epoch 30/150 loss: 0.3216949701309204
Rank 0 - Epoch 40/150 loss: -0.037955813109874725
Rank 0 - Epoch 50/150 loss: -0.3850294053554535
Rank 0 - Epoch 60/150 loss: -0.7127430438995361
Rank 0 - Epoch 70/150 loss: -1.0127990245819092
Rank 0 - Epoch 80/150 loss: -1.282387614250183
Rank 0 - Epoch 90/150 loss: -1.5125494003295898
Rank 0 - Epoch 100/150 loss: -1.695576548576355
Rank 0 - Epoch 110/150 loss: -1.2669981718063354
Run 2 failed, retrying...
Running gapxGP 3 with agents: 100
decpxADMM initialized with rho: 0.75, lip: 1.0, tol_abs: 1e-05, tol_rel: 0.001, rank: 0, world_size: 100
Rank 0 - Epoch 2/150 loss: 1.1236329078674316
Rank 0 - Epoch 10/150 loss: 0.9280886054039001
Rank 0 - Epoch 20/150 loss: 0.6665458083152771
Rank 0 - Epoch 30/150 loss: 0.31985944509506226
Rank 0 - Epoch 40/150 loss: -0.04253469407558441
Rank 0 - Epoch 50/150 loss: -0.38973748683929443
Rank 0 - Epoch 60/150 loss: -0.7166122198104858
Rank 0 - Epoch 70/150 loss: -1.0164968967437744
Rank 0 - Epoch 80/150 loss: -1.2854493856430054
Rank 0 - Epoch 90/150 loss: -1.5151736736297607
Rank 0 - Epoch 100/150 loss: -1.6979000568389893
Rank 0 - Epoch 110/150 loss: -1.818885326385498
Rank 0 - Epoch 120/150 loss: -1.4532328844070435
Run 3 failed, retrying...
Running gapxGP 4 with agents: 100
decpxADMM initialized with rho: 0.75, lip: 1.0, tol_abs: 1e-05, tol_rel: 0.001, rank: 0, world_size: 100
Rank 0 - Epoch 2/150 loss: 1.122938632965088
Rank 0 - Epoch 10/150 loss: 0.9283707737922668
Rank 0 - Epoch 20/150 loss: 0.6660562753677368
Rank 0 - Epoch 30/150 loss: 0.31832924485206604
Rank 0 - Epoch 40/150 loss: -0.04189028590917587
Rank 0 - Epoch 50/150 loss: -0.39262303709983826
Rank 0 - Epoch 60/150 loss: -0.7234431505203247
Rank 0 - Epoch 70/150 loss: -1.0264548063278198
Rank 0 - Epoch 80/150 loss: -1.298050880432129
Rank 0 - Epoch 90/150 loss: -1.5300408601760864
Rank 0 - Epoch 100/150 loss: -1.7130194902420044
Rank 0 - Epoch 110/150 loss: -1.7383354902267456
Rank 0 - Epoch 120/150 loss: -1.805607795715332
Run 4 failed, retrying...
Running gapxGP 5 with agents: 100
decpxADMM initialized with rho: 0.75, lip: 1.0, tol_abs: 1e-05, tol_rel: 0.001, rank: 0, world_size: 100
Rank 0 - Epoch 2/150 loss: 1.1013333797454834
Rank 0 - Epoch 10/150 loss: 0.8989805579185486
Rank 0 - Epoch 20/150 loss: 0.6337484121322632
Rank 0 - Epoch 30/150 loss: 0.2933528423309326
Rank 0 - Epoch 40/150 loss: -0.060509417206048965
Rank 0 - Epoch 50/150 loss: -0.40056875348091125
Rank 0 - Epoch 60/150 loss: -0.7284053564071655
Rank 0 - Epoch 70/150 loss: -1.031528353691101
Rank 0 - Epoch 80/150 loss: -1.3026033639907837
Rank 0 - Epoch 90/150 loss: -1.533980369567871
Rank 0 - Epoch 100/150 loss: -1.717920184135437
Rank 0 - Epoch 110/150 loss: -1.2566477060317993
Rank 0 - Epoch 120/150 loss: -1.9315721988677979
Run 5 failed, retrying...
Running gapxGP 6 with agents: 100
decpxADMM initialized with rho: 0.75, lip: 1.0, tol_abs: 1e-05, tol_rel: 0.001, rank: 0, world_size: 100
Rank 0 - Epoch 2/150 loss: 1.1199469566345215
Rank 0 - Epoch 10/150 loss: 0.9176281690597534
Rank 0 - Epoch 20/150 loss: 0.6471359729766846
Rank 0 - Epoch 30/150 loss: 0.2931261956691742
Rank 0 - Epoch 40/150 loss: -0.06595529615879059
Rank 0 - Epoch 50/150 loss: -0.41144636273384094
Rank 0 - Epoch 60/150 loss: -0.7371605038642883
Rank 0 - Epoch 70/150 loss: -1.035312294960022
Rank 0 - Epoch 80/150 loss: -1.3028253316879272
Rank 0 - Epoch 90/150 loss: -1.5318585634231567
Rank 0 - Epoch 100/150 loss: -1.7141692638397217
Rank 0 - Epoch 110/150 loss: -1.721398115158081
Rank 0 - Epoch 120/150 loss: -1.839600682258606
Run 6 failed, retrying...
Running gapxGP 7 with agents: 100
decpxADMM initialized with rho: 0.75, lip: 1.0, tol_abs: 1e-05, tol_rel: 0.001, rank: 0, world_size: 100
Rank 0 - Epoch 2/150 loss: 1.1170518398284912
Rank 0 - Epoch 10/150 loss: 0.9118508696556091
Rank 0 - Epoch 20/150 loss: 0.6511039137840271
Rank 0 - Epoch 30/150 loss: 0.31447118520736694
Rank 0 - Epoch 40/150 loss: -0.04507596790790558
Rank 0 - Epoch 50/150 loss: -0.39467334747314453
Rank 0 - Epoch 60/150 loss: -0.724770724773407
Rank 0 - Epoch 70/150 loss: -1.027094841003418
Rank 0 - Epoch 80/150 loss: -1.295350432395935
Rank 0 - Epoch 90/150 loss: -1.5239601135253906
Rank 0 - Epoch 100/150 loss: -1.7054414749145508
Rank 0 - Epoch 110/150 loss: -1.8004016876220703
Rank 0 - Epoch 120/150 loss: -1.91182541847229
Run 7 failed, retrying...
Running gapxGP 8 with agents: 100
decpxADMM initialized with rho: 0.75, lip: 1.0, tol_abs: 1e-05, tol_rel: 0.001, rank: 0, world_size: 100
Rank 0 - Epoch 2/150 loss: 1.1155797243118286
Rank 0 - Epoch 10/150 loss: 0.913908064365387
Rank 0 - Epoch 20/150 loss: 0.6491066813468933
Rank 0 - Epoch 30/150 loss: 0.30925989151000977
Rank 0 - Epoch 40/150 loss: -0.04645299166440964
Rank 0 - Epoch 50/150 loss: -0.3938051164150238
Rank 0 - Epoch 60/150 loss: -0.7274323105812073
Rank 0 - Epoch 70/150 loss: -1.032101035118103
Rank 0 - Epoch 80/150 loss: -1.3040860891342163
Rank 0 - Epoch 90/150 loss: -1.535396933555603
Rank 0 - Epoch 100/150 loss: -1.7180293798446655
Rank 0 - Epoch 110/150 loss: -1.8043996095657349
Run 8 failed, retrying...
Running gapxGP 9 with agents: 100
decpxADMM initialized with rho: 0.75, lip: 1.0, tol_abs: 1e-05, tol_rel: 0.001, rank: 0, world_size: 100
Rank 0 - Epoch 2/150 loss: 1.1183944940567017
Rank 0 - Epoch 10/150 loss: 0.9221673607826233
Rank 0 - Epoch 20/150 loss: 0.6661747694015503
Rank 0 - Epoch 30/150 loss: 0.3175596296787262
Rank 0 - Epoch 40/150 loss: -0.038632895797491074
Rank 0 - Epoch 50/150 loss: -0.3812900185585022
Rank 0 - Epoch 60/150 loss: -0.7074280977249146
Rank 0 - Epoch 70/150 loss: -1.0063542127609253
Rank 0 - Epoch 80/150 loss: -1.2750424146652222
Rank 0 - Epoch 90/150 loss: -1.5058279037475586
Rank 0 - Epoch 100/150 loss: -1.6876726150512695
Rank 0 - Epoch 110/150 loss: -1.6385600566864014
Rank 0 - Epoch 120/150 loss: -1.725730538368225
Run 9 failed, retrying...
Running gapxGP 10 with agents: 100
decpxADMM initialized with rho: 0.75, lip: 1.0, tol_abs: 1e-05, tol_rel: 0.001, rank: 0, world_size: 100
Rank 0 - Epoch 2/150 loss: 1.1088889837265015
Rank 0 - Epoch 10/150 loss: 0.9086169004440308
Rank 0 - Epoch 20/150 loss: 0.6459813117980957
Rank 0 - Epoch 30/150 loss: 0.2946736812591553
Rank 0 - Epoch 40/150 loss: -0.074343241751194
Rank 0 - Epoch 50/150 loss: -0.4196631908416748
Rank 0 - Epoch 60/150 loss: -0.7463635802268982
Rank 0 - Epoch 70/150 loss: -1.0468409061431885
Rank 0 - Epoch 80/150 loss: -1.3149772882461548
Rank 0 - Epoch 90/150 loss: -1.5433802604675293
Rank 0 - Epoch 100/150 loss: -1.7247003316879272
Rank 0 - Epoch 110/150 loss: -1.7589389085769653
Run 10 failed, retrying...
Running apxGP 1 with agents: 100
decpxADMM initialized with rho: 0.85, lip: 1.0, tol_abs: 1e-05, tol_rel: 0.001, rank: 0, world_size: 100
Rank 0 - Epoch 2/200 loss: 0.8707923889160156
Rank 0 - Epoch 10/200 loss: 0.6063382625579834
Rank 0 - Epoch 20/200 loss: 0.19688068330287933
Rank 0 - Epoch 30/200 loss: -0.26771941781044006
Rank 0 - Epoch 40/200 loss: -0.7730921506881714
Rank 0 - Epoch 50/200 loss: -1.2815368175506592
Rank 0 - Epoch 60/200 loss: -1.7713897228240967
Rank 0 - Epoch 70/200 loss: -2.217581272125244
Rank 0 - Epoch 80/200 loss: -2.58242130279541
Rank 0 - Epoch 90/200 loss: -2.847325325012207
Rank 0 - Epoch 100/200 loss: -3.01718807220459
Rank 0 - Epoch 110/200 loss: -3.1197502613067627
Rank 0 - Epoch 120/200 loss: -3.183104991912842
Rank 0 - Epoch 130/200 loss: -3.223391532897949
Rank 0 - Epoch 140/200 loss: -3.2506263256073
Rank 0 - Epoch 150/200 loss: -3.270388603210449
Rank 0 - Epoch 160/200 loss: -3.284893274307251
Rank 0 - Epoch 170/200 loss: -3.2963054180145264
Rank 0 - Epoch 180/200 loss: -3.3058905601501465
Rank 0 - Epoch 190/200 loss: -3.3135159015655518
Rank 0 - Epoch 200/200 loss: -3.3195507526397705
Training complete.
[92mRank 0 - Testing RMSE: 2.5491[0m
[92mRank: 0, Lengthscale: [[0.6089159 0.3808926]] [0m
[92mRank: 0, Outputscale: 1.674721598625183 [0m
[92mRank: 0, Noise: 0.00011096002708654851 [0m
Run 1 completed successfully
Running apxGP 2 with agents: 100
decpxADMM initialized with rho: 0.85, lip: 1.0, tol_abs: 1e-05, tol_rel: 0.001, rank: 0, world_size: 100
Rank 0 - Epoch 2/200 loss: 0.8707923889160156
Rank 0 - Epoch 10/200 loss: 0.6063382625579834
Rank 0 - Epoch 20/200 loss: 0.19688068330287933
Rank 0 - Epoch 30/200 loss: -0.26771941781044006
Rank 0 - Epoch 40/200 loss: -0.7730921506881714
Rank 0 - Epoch 50/200 loss: -1.2815368175506592
Rank 0 - Epoch 60/200 loss: -1.7713897228240967
Rank 0 - Epoch 70/200 loss: -2.217581272125244
Rank 0 - Epoch 80/200 loss: -2.58242130279541
Rank 0 - Epoch 90/200 loss: -2.847325325012207
Rank 0 - Epoch 100/200 loss: -3.01718807220459
Rank 0 - Epoch 110/200 loss: -3.1197502613067627
Rank 0 - Epoch 120/200 loss: -3.183104991912842
Rank 0 - Epoch 130/200 loss: -3.223391532897949
Rank 0 - Epoch 140/200 loss: -3.2506263256073
Rank 0 - Epoch 150/200 loss: -3.270388603210449
Rank 0 - Epoch 160/200 loss: -3.284893274307251
Rank 0 - Epoch 170/200 loss: -3.2963054180145264
Rank 0 - Epoch 180/200 loss: -3.3058905601501465
Rank 0 - Epoch 190/200 loss: -3.3135159015655518
Rank 0 - Epoch 200/200 loss: -3.3195507526397705
Training complete.
[92mRank 0 - Testing RMSE: 2.5491[0m
[92mRank: 0, Lengthscale: [[0.6089159 0.3808926]] [0m
[92mRank: 0, Outputscale: 1.674721598625183 [0m
[92mRank: 0, Noise: 0.00011096002708654851 [0m
Run 2 completed successfully
Running apxGP 3 with agents: 100
decpxADMM initialized with rho: 0.85, lip: 1.0, tol_abs: 1e-05, tol_rel: 0.001, rank: 0, world_size: 100
Rank 0 - Epoch 2/200 loss: 0.8707923889160156
Rank 0 - Epoch 10/200 loss: 0.6063382625579834
Rank 0 - Epoch 20/200 loss: 0.19688068330287933
Rank 0 - Epoch 30/200 loss: -0.26771941781044006
Rank 0 - Epoch 40/200 loss: -0.7730921506881714
Rank 0 - Epoch 50/200 loss: -1.2815368175506592
Rank 0 - Epoch 60/200 loss: -1.7713897228240967
Rank 0 - Epoch 70/200 loss: -2.217581272125244
Rank 0 - Epoch 80/200 loss: -2.58242130279541
Rank 0 - Epoch 90/200 loss: -2.847325325012207
Rank 0 - Epoch 100/200 loss: -3.01718807220459
Rank 0 - Epoch 110/200 loss: -3.1197502613067627
Rank 0 - Epoch 120/200 loss: -3.183104991912842
Rank 0 - Epoch 130/200 loss: -3.223391532897949
Rank 0 - Epoch 140/200 loss: -3.2506263256073
Rank 0 - Epoch 150/200 loss: -3.270388603210449
Rank 0 - Epoch 160/200 loss: -3.284893274307251
Rank 0 - Epoch 170/200 loss: -3.2963054180145264
Rank 0 - Epoch 180/200 loss: -3.3058905601501465
Rank 0 - Epoch 190/200 loss: -3.3135159015655518
Rank 0 - Epoch 200/200 loss: -3.3195507526397705
Training complete.
[92mRank 0 - Testing RMSE: 2.5491[0m
[92mRank: 0, Lengthscale: [[0.6089159 0.3808926]] [0m
[92mRank: 0, Outputscale: 1.674721598625183 [0m
[92mRank: 0, Noise: 0.00011096002708654851 [0m
Run 3 completed successfully
Running apxGP 4 with agents: 100
decpxADMM initialized with rho: 0.85, lip: 1.0, tol_abs: 1e-05, tol_rel: 0.001, rank: 0, world_size: 100
Rank 0 - Epoch 2/200 loss: 0.8707923889160156
Rank 0 - Epoch 10/200 loss: 0.6063382625579834
Rank 0 - Epoch 20/200 loss: 0.19688068330287933
Rank 0 - Epoch 30/200 loss: -0.26771941781044006
Rank 0 - Epoch 40/200 loss: -0.7730921506881714
Rank 0 - Epoch 50/200 loss: -1.2815368175506592
Rank 0 - Epoch 60/200 loss: -1.7713897228240967
Rank 0 - Epoch 70/200 loss: -2.217581272125244
Rank 0 - Epoch 80/200 loss: -2.58242130279541
Rank 0 - Epoch 90/200 loss: -2.847325325012207
Rank 0 - Epoch 100/200 loss: -3.01718807220459
Rank 0 - Epoch 110/200 loss: -3.1197502613067627
Rank 0 - Epoch 120/200 loss: -3.183104991912842
Rank 0 - Epoch 130/200 loss: -3.223391532897949
Rank 0 - Epoch 140/200 loss: -3.2506263256073
Rank 0 - Epoch 150/200 loss: -3.270388603210449
Rank 0 - Epoch 160/200 loss: -3.284893274307251
Rank 0 - Epoch 170/200 loss: -3.2963054180145264
Rank 0 - Epoch 180/200 loss: -3.3058905601501465
Rank 0 - Epoch 190/200 loss: -3.3135159015655518
Rank 0 - Epoch 200/200 loss: -3.3195507526397705
Training complete.
[92mRank 0 - Testing RMSE: 2.5491[0m
[92mRank: 0, Lengthscale: [[0.6089159 0.3808926]] [0m
[92mRank: 0, Outputscale: 1.674721598625183 [0m
[92mRank: 0, Noise: 0.00011096002708654851 [0m
Run 4 completed successfully
Running apxGP 5 with agents: 100
decpxADMM initialized with rho: 0.85, lip: 1.0, tol_abs: 1e-05, tol_rel: 0.001, rank: 0, world_size: 100
Rank 0 - Epoch 2/200 loss: 0.8707923889160156
Rank 0 - Epoch 10/200 loss: 0.6063382625579834
Rank 0 - Epoch 20/200 loss: 0.19688068330287933
Rank 0 - Epoch 30/200 loss: -0.26771941781044006
Rank 0 - Epoch 40/200 loss: -0.7730921506881714
Rank 0 - Epoch 50/200 loss: -1.2815368175506592
Rank 0 - Epoch 60/200 loss: -1.7713897228240967
Rank 0 - Epoch 70/200 loss: -2.217581272125244
Rank 0 - Epoch 80/200 loss: -2.58242130279541
Rank 0 - Epoch 90/200 loss: -2.847325325012207
Rank 0 - Epoch 100/200 loss: -3.01718807220459
Rank 0 - Epoch 110/200 loss: -3.1197502613067627
Rank 0 - Epoch 120/200 loss: -3.183104991912842
Rank 0 - Epoch 130/200 loss: -3.223391532897949
Rank 0 - Epoch 140/200 loss: -3.2506263256073
Rank 0 - Epoch 150/200 loss: -3.270388603210449
Rank 0 - Epoch 160/200 loss: -3.284893274307251
Rank 0 - Epoch 170/200 loss: -3.2963054180145264
Rank 0 - Epoch 180/200 loss: -3.3058905601501465
Rank 0 - Epoch 190/200 loss: -3.3135159015655518
Rank 0 - Epoch 200/200 loss: -3.3195507526397705
Training complete.
[92mRank 0 - Testing RMSE: 2.5491[0m
[92mRank: 0, Lengthscale: [[0.6089159 0.3808926]] [0m
[92mRank: 0, Outputscale: 1.674721598625183 [0m
[92mRank: 0, Noise: 0.00011096002708654851 [0m
Run 5 completed successfully
Running apxGP 6 with agents: 100
decpxADMM initialized with rho: 0.85, lip: 1.0, tol_abs: 1e-05, tol_rel: 0.001, rank: 0, world_size: 100
Rank 0 - Epoch 2/200 loss: 0.8707923889160156
Rank 0 - Epoch 10/200 loss: 0.6063382625579834
Rank 0 - Epoch 20/200 loss: 0.19688068330287933
Rank 0 - Epoch 30/200 loss: -0.26771941781044006
Rank 0 - Epoch 40/200 loss: -0.7730921506881714
Rank 0 - Epoch 50/200 loss: -1.2815368175506592
Rank 0 - Epoch 60/200 loss: -1.7713897228240967
Rank 0 - Epoch 70/200 loss: -2.217581272125244
Rank 0 - Epoch 80/200 loss: -2.58242130279541
Rank 0 - Epoch 90/200 loss: -2.847325325012207
Rank 0 - Epoch 100/200 loss: -3.01718807220459
Rank 0 - Epoch 110/200 loss: -3.1197502613067627
Rank 0 - Epoch 120/200 loss: -3.183104991912842
Rank 0 - Epoch 130/200 loss: -3.223391532897949
Rank 0 - Epoch 140/200 loss: -3.2506263256073
Rank 0 - Epoch 150/200 loss: -3.270388603210449
Rank 0 - Epoch 160/200 loss: -3.284893274307251
Rank 0 - Epoch 170/200 loss: -3.2963054180145264
Rank 0 - Epoch 180/200 loss: -3.3058905601501465
Rank 0 - Epoch 190/200 loss: -3.3135159015655518
Rank 0 - Epoch 200/200 loss: -3.3195507526397705
Training complete.
[92mRank 0 - Testing RMSE: 2.5491[0m
[92mRank: 0, Lengthscale: [[0.6089159 0.3808926]] [0m
[92mRank: 0, Outputscale: 1.674721598625183 [0m
[92mRank: 0, Noise: 0.00011096002708654851 [0m
Run 6 completed successfully
Running apxGP 7 with agents: 100
decpxADMM initialized with rho: 0.85, lip: 1.0, tol_abs: 1e-05, tol_rel: 0.001, rank: 0, world_size: 100
Rank 0 - Epoch 2/200 loss: 0.8707923889160156
Rank 0 - Epoch 10/200 loss: 0.6063382625579834
Rank 0 - Epoch 20/200 loss: 0.19688068330287933
Rank 0 - Epoch 30/200 loss: -0.26771941781044006
Rank 0 - Epoch 40/200 loss: -0.7730921506881714
Rank 0 - Epoch 50/200 loss: -1.2815368175506592
Rank 0 - Epoch 60/200 loss: -1.7713897228240967
Rank 0 - Epoch 70/200 loss: -2.217581272125244
Rank 0 - Epoch 80/200 loss: -2.58242130279541
Rank 0 - Epoch 90/200 loss: -2.847325325012207
Rank 0 - Epoch 100/200 loss: -3.01718807220459
Rank 0 - Epoch 110/200 loss: -3.1197502613067627
Rank 0 - Epoch 120/200 loss: -3.183104991912842
Rank 0 - Epoch 130/200 loss: -3.223391532897949
Rank 0 - Epoch 140/200 loss: -3.2506263256073
Rank 0 - Epoch 150/200 loss: -3.270388603210449
Rank 0 - Epoch 160/200 loss: -3.284893274307251
Rank 0 - Epoch 170/200 loss: -3.2963054180145264
Rank 0 - Epoch 180/200 loss: -3.3058905601501465
Rank 0 - Epoch 190/200 loss: -3.3135159015655518
Rank 0 - Epoch 200/200 loss: -3.3195507526397705
Training complete.
[92mRank 0 - Testing RMSE: 2.5491[0m
[92mRank: 0, Lengthscale: [[0.6089159 0.3808926]] [0m
[92mRank: 0, Outputscale: 1.674721598625183 [0m
[92mRank: 0, Noise: 0.00011096002708654851 [0m
Run 7 completed successfully
Running apxGP 8 with agents: 100
decpxADMM initialized with rho: 0.85, lip: 1.0, tol_abs: 1e-05, tol_rel: 0.001, rank: 0, world_size: 100
Rank 0 - Epoch 2/200 loss: 0.8707923889160156
Rank 0 - Epoch 10/200 loss: 0.6063382625579834
Rank 0 - Epoch 20/200 loss: 0.19688068330287933
Rank 0 - Epoch 30/200 loss: -0.26771941781044006
Rank 0 - Epoch 40/200 loss: -0.7730921506881714
Rank 0 - Epoch 50/200 loss: -1.2815368175506592
Rank 0 - Epoch 60/200 loss: -1.7713897228240967
Rank 0 - Epoch 70/200 loss: -2.217581272125244
Rank 0 - Epoch 80/200 loss: -2.58242130279541
Rank 0 - Epoch 90/200 loss: -2.847325325012207
Rank 0 - Epoch 100/200 loss: -3.01718807220459
Rank 0 - Epoch 110/200 loss: -3.1197502613067627
Rank 0 - Epoch 120/200 loss: -3.183104991912842
Rank 0 - Epoch 130/200 loss: -3.223391532897949
Rank 0 - Epoch 140/200 loss: -3.2506263256073
Rank 0 - Epoch 150/200 loss: -3.270388603210449
Rank 0 - Epoch 160/200 loss: -3.284893274307251
Rank 0 - Epoch 170/200 loss: -3.2963054180145264
Rank 0 - Epoch 180/200 loss: -3.3058905601501465
Rank 0 - Epoch 190/200 loss: -3.3135159015655518
Rank 0 - Epoch 200/200 loss: -3.3195507526397705
Training complete.
[92mRank 0 - Testing RMSE: 2.5491[0m
[92mRank: 0, Lengthscale: [[0.6089159 0.3808926]] [0m
[92mRank: 0, Outputscale: 1.674721598625183 [0m
[92mRank: 0, Noise: 0.00011096002708654851 [0m
Run 8 completed successfully
Running apxGP 9 with agents: 100
decpxADMM initialized with rho: 0.85, lip: 1.0, tol_abs: 1e-05, tol_rel: 0.001, rank: 0, world_size: 100
Rank 0 - Epoch 2/200 loss: 0.8707923889160156
Rank 0 - Epoch 10/200 loss: 0.6063382625579834
Rank 0 - Epoch 20/200 loss: 0.19688068330287933
Rank 0 - Epoch 30/200 loss: -0.26771941781044006
Rank 0 - Epoch 40/200 loss: -0.7730921506881714
Rank 0 - Epoch 50/200 loss: -1.2815368175506592
Rank 0 - Epoch 60/200 loss: -1.7713897228240967
Rank 0 - Epoch 70/200 loss: -2.217581272125244
Rank 0 - Epoch 80/200 loss: -2.58242130279541
Rank 0 - Epoch 90/200 loss: -2.847325325012207
Rank 0 - Epoch 100/200 loss: -3.01718807220459
Rank 0 - Epoch 110/200 loss: -3.1197502613067627
Rank 0 - Epoch 120/200 loss: -3.183104991912842
Rank 0 - Epoch 130/200 loss: -3.223391532897949
Rank 0 - Epoch 140/200 loss: -3.2506263256073
Rank 0 - Epoch 150/200 loss: -3.270388603210449
Rank 0 - Epoch 160/200 loss: -3.284893274307251
Rank 0 - Epoch 170/200 loss: -3.2963054180145264
Rank 0 - Epoch 180/200 loss: -3.3058905601501465
Rank 0 - Epoch 190/200 loss: -3.3135159015655518
Rank 0 - Epoch 200/200 loss: -3.3195507526397705
Training complete.
[92mRank 0 - Testing RMSE: 2.5491[0m
[92mRank: 0, Lengthscale: [[0.6089159 0.3808926]] [0m
[92mRank: 0, Outputscale: 1.674721598625183 [0m
[92mRank: 0, Noise: 0.00011096002708654851 [0m
Run 9 completed successfully
Running apxGP 10 with agents: 100
decpxADMM initialized with rho: 0.85, lip: 1.0, tol_abs: 1e-05, tol_rel: 0.001, rank: 0, world_size: 100
Rank 0 - Epoch 2/200 loss: 0.8707923889160156
Rank 0 - Epoch 10/200 loss: 0.6063382625579834
Rank 0 - Epoch 20/200 loss: 0.19688068330287933
Rank 0 - Epoch 30/200 loss: -0.26771941781044006
Rank 0 - Epoch 40/200 loss: -0.7730921506881714
Rank 0 - Epoch 50/200 loss: -1.2815368175506592
Rank 0 - Epoch 60/200 loss: -1.7713897228240967
Rank 0 - Epoch 70/200 loss: -2.217581272125244
Rank 0 - Epoch 80/200 loss: -2.58242130279541
Rank 0 - Epoch 90/200 loss: -2.847325325012207
Rank 0 - Epoch 100/200 loss: -3.01718807220459
Rank 0 - Epoch 110/200 loss: -3.1197502613067627
Rank 0 - Epoch 120/200 loss: -3.183104991912842
Rank 0 - Epoch 130/200 loss: -3.223391532897949
Rank 0 - Epoch 140/200 loss: -3.2506263256073
Rank 0 - Epoch 150/200 loss: -3.270388603210449
Rank 0 - Epoch 160/200 loss: -3.284893274307251
Rank 0 - Epoch 170/200 loss: -3.2963054180145264
Rank 0 - Epoch 180/200 loss: -3.3058905601501465
Rank 0 - Epoch 190/200 loss: -3.3135159015655518
Rank 0 - Epoch 200/200 loss: -3.3195507526397705
Training complete.
[92mRank 0 - Testing RMSE: 2.5491[0m
[92mRank: 0, Lengthscale: [[0.6089159 0.3808926]] [0m
[92mRank: 0, Outputscale: 1.674721598625183 [0m
[92mRank: 0, Noise: 0.00011096002708654851 [0m
Run 10 completed successfully
Running cGP 1 with agents: 100
decADMM initialized with rho: 0.85, max_iter: 5, lr: 0.0001, rank: 0, world_size: 100
Rank 0 - Epoch 2/200 loss: 0.9293854236602783
Rank 0 - Epoch 10/200 loss: 0.9253507256507874
Rank 0 - Epoch 20/200 loss: 0.9203202128410339
Rank 0 - Epoch 30/200 loss: 0.915306031703949
Rank 0 - Epoch 40/200 loss: 0.9103105664253235
Rank 0 - Epoch 50/200 loss: 0.9053359031677246
Rank 0 - Epoch 60/200 loss: 0.9003846645355225
Rank 0 - Epoch 70/200 loss: 0.8954593539237976
Rank 0 - Epoch 80/200 loss: 0.890562891960144
Rank 0 - Epoch 90/200 loss: 0.8856980204582214
Rank 0 - Epoch 100/200 loss: 0.8808680176734924
Rank 0 - Epoch 110/200 loss: 0.8760760426521301
Rank 0 - Epoch 120/200 loss: 0.8713257312774658
Rank 0 - Epoch 130/200 loss: 0.8666204214096069
Rank 0 - Epoch 140/200 loss: 0.861964225769043
Rank 0 - Epoch 150/200 loss: 0.8573613166809082
Rank 0 - Epoch 160/200 loss: 0.8528158664703369
Rank 0 - Epoch 170/200 loss: 0.8483325839042664
Rank 0 - Epoch 180/200 loss: 0.8439162373542786
Rank 0 - Epoch 190/200 loss: 0.8395718932151794
Rank 0 - Epoch 200/200 loss: 0.8353050947189331
Training complete.
[92mRank 0 - Testing RMSE: 3.7945[0m
[92mRank: 0, Lengthscale: [[0.53542674 0.5374938 ]] [0m
[92mRank: 0, Outputscale: 0.5426582098007202 [0m
[92mRank: 0, Noise: 0.5229225754737854 [0m
Run 1 completed successfully
Running cGP 2 with agents: 100
decADMM initialized with rho: 0.85, max_iter: 5, lr: 0.0001, rank: 0, world_size: 100
Rank 0 - Epoch 2/200 loss: 0.9293854236602783
Rank 0 - Epoch 10/200 loss: 0.9253507256507874
Rank 0 - Epoch 20/200 loss: 0.9203202128410339
Rank 0 - Epoch 30/200 loss: 0.915306031703949
Rank 0 - Epoch 40/200 loss: 0.9103105664253235
Rank 0 - Epoch 50/200 loss: 0.9053359031677246
Rank 0 - Epoch 60/200 loss: 0.9003846645355225
Rank 0 - Epoch 70/200 loss: 0.8954593539237976
Rank 0 - Epoch 80/200 loss: 0.890562891960144
Rank 0 - Epoch 90/200 loss: 0.8856980204582214
Rank 0 - Epoch 100/200 loss: 0.8808680176734924
Rank 0 - Epoch 110/200 loss: 0.8760760426521301
Rank 0 - Epoch 120/200 loss: 0.8713257312774658
Rank 0 - Epoch 130/200 loss: 0.8666204214096069
Rank 0 - Epoch 140/200 loss: 0.861964225769043
Rank 0 - Epoch 150/200 loss: 0.8573613166809082
Rank 0 - Epoch 160/200 loss: 0.8528158664703369
Rank 0 - Epoch 170/200 loss: 0.8483325839042664
Rank 0 - Epoch 180/200 loss: 0.8439162373542786
Rank 0 - Epoch 190/200 loss: 0.8395718932151794
Rank 0 - Epoch 200/200 loss: 0.8353050947189331
Training complete.
[92mRank 0 - Testing RMSE: 3.7945[0m
[92mRank: 0, Lengthscale: [[0.53542674 0.5374938 ]] [0m
[92mRank: 0, Outputscale: 0.5426582098007202 [0m
[92mRank: 0, Noise: 0.5229225754737854 [0m
Run 2 completed successfully
Running cGP 3 with agents: 100
decADMM initialized with rho: 0.85, max_iter: 5, lr: 0.0001, rank: 0, world_size: 100
Rank 0 - Epoch 2/200 loss: 0.9293854236602783
Rank 0 - Epoch 10/200 loss: 0.9253507256507874
Rank 0 - Epoch 20/200 loss: 0.9203202128410339
Rank 0 - Epoch 30/200 loss: 0.915306031703949
Rank 0 - Epoch 40/200 loss: 0.9103105664253235
Rank 0 - Epoch 50/200 loss: 0.9053359031677246
Rank 0 - Epoch 60/200 loss: 0.9003846645355225
Rank 0 - Epoch 70/200 loss: 0.8954593539237976
Rank 0 - Epoch 80/200 loss: 0.890562891960144
Rank 0 - Epoch 90/200 loss: 0.8856980204582214
Rank 0 - Epoch 100/200 loss: 0.8808680176734924
Rank 0 - Epoch 110/200 loss: 0.8760760426521301
Rank 0 - Epoch 120/200 loss: 0.8713257312774658
Rank 0 - Epoch 130/200 loss: 0.8666204214096069
Rank 0 - Epoch 140/200 loss: 0.861964225769043
Rank 0 - Epoch 150/200 loss: 0.8573613166809082
Rank 0 - Epoch 160/200 loss: 0.8528158664703369
Rank 0 - Epoch 170/200 loss: 0.8483325839042664
Rank 0 - Epoch 180/200 loss: 0.8439162373542786
Rank 0 - Epoch 190/200 loss: 0.8395718932151794
Rank 0 - Epoch 200/200 loss: 0.8353050947189331
Training complete.
[92mRank 0 - Testing RMSE: 3.7945[0m
[92mRank: 0, Lengthscale: [[0.53542674 0.5374938 ]] [0m
[92mRank: 0, Outputscale: 0.5426582098007202 [0m
[92mRank: 0, Noise: 0.5229225754737854 [0m
Run 3 completed successfully
Running cGP 4 with agents: 100
decADMM initialized with rho: 0.85, max_iter: 5, lr: 0.0001, rank: 0, world_size: 100
Rank 0 - Epoch 2/200 loss: 0.9293854236602783
Rank 0 - Epoch 10/200 loss: 0.9253507256507874
Rank 0 - Epoch 20/200 loss: 0.9203202128410339
Rank 0 - Epoch 30/200 loss: 0.915306031703949
Rank 0 - Epoch 40/200 loss: 0.9103105664253235
Rank 0 - Epoch 50/200 loss: 0.9053359031677246
Rank 0 - Epoch 60/200 loss: 0.9003846645355225
Rank 0 - Epoch 70/200 loss: 0.8954593539237976
Rank 0 - Epoch 80/200 loss: 0.890562891960144
Rank 0 - Epoch 90/200 loss: 0.8856980204582214
Rank 0 - Epoch 100/200 loss: 0.8808680176734924
Rank 0 - Epoch 110/200 loss: 0.8760760426521301
Rank 0 - Epoch 120/200 loss: 0.8713257312774658
Rank 0 - Epoch 130/200 loss: 0.8666204214096069
Rank 0 - Epoch 140/200 loss: 0.861964225769043
Rank 0 - Epoch 150/200 loss: 0.8573613166809082
Rank 0 - Epoch 160/200 loss: 0.8528158664703369
Rank 0 - Epoch 170/200 loss: 0.8483325839042664
Rank 0 - Epoch 180/200 loss: 0.8439162373542786
Rank 0 - Epoch 190/200 loss: 0.8395718932151794
Rank 0 - Epoch 200/200 loss: 0.8353050947189331
Training complete.
[92mRank 0 - Testing RMSE: 3.7945[0m
[92mRank: 0, Lengthscale: [[0.53542674 0.5374938 ]] [0m
[92mRank: 0, Outputscale: 0.5426582098007202 [0m
[92mRank: 0, Noise: 0.5229225754737854 [0m
Run 4 completed successfully
Running cGP 5 with agents: 100
decADMM initialized with rho: 0.85, max_iter: 5, lr: 0.0001, rank: 0, world_size: 100
Rank 0 - Epoch 2/200 loss: 0.9293854236602783
Rank 0 - Epoch 10/200 loss: 0.9253507256507874
Rank 0 - Epoch 20/200 loss: 0.9203202128410339
Rank 0 - Epoch 30/200 loss: 0.915306031703949
Rank 0 - Epoch 40/200 loss: 0.9103105664253235
Rank 0 - Epoch 50/200 loss: 0.9053359031677246
Rank 0 - Epoch 60/200 loss: 0.9003846645355225
Rank 0 - Epoch 70/200 loss: 0.8954593539237976
Rank 0 - Epoch 80/200 loss: 0.890562891960144
Rank 0 - Epoch 90/200 loss: 0.8856980204582214
Rank 0 - Epoch 100/200 loss: 0.8808680176734924
Rank 0 - Epoch 110/200 loss: 0.8760760426521301
Rank 0 - Epoch 120/200 loss: 0.8713257312774658
Rank 0 - Epoch 130/200 loss: 0.8666204214096069
Rank 0 - Epoch 140/200 loss: 0.861964225769043
Rank 0 - Epoch 150/200 loss: 0.8573613166809082
Rank 0 - Epoch 160/200 loss: 0.8528158664703369
Rank 0 - Epoch 170/200 loss: 0.8483325839042664
Rank 0 - Epoch 180/200 loss: 0.8439162373542786
Rank 0 - Epoch 190/200 loss: 0.8395718932151794
Rank 0 - Epoch 200/200 loss: 0.8353050947189331
Training complete.
[92mRank 0 - Testing RMSE: 3.7945[0m
[92mRank: 0, Lengthscale: [[0.53542674 0.5374938 ]] [0m
[92mRank: 0, Outputscale: 0.5426582098007202 [0m
[92mRank: 0, Noise: 0.5229225754737854 [0m
Run 5 completed successfully
Running cGP 6 with agents: 100
decADMM initialized with rho: 0.85, max_iter: 5, lr: 0.0001, rank: 0, world_size: 100
Rank 0 - Epoch 2/200 loss: 0.9293854236602783
Rank 0 - Epoch 10/200 loss: 0.9253507256507874
Rank 0 - Epoch 20/200 loss: 0.9203202128410339
Rank 0 - Epoch 30/200 loss: 0.915306031703949
Rank 0 - Epoch 40/200 loss: 0.9103105664253235
Rank 0 - Epoch 50/200 loss: 0.9053359031677246
Rank 0 - Epoch 60/200 loss: 0.9003846645355225
Rank 0 - Epoch 70/200 loss: 0.8954593539237976
Rank 0 - Epoch 80/200 loss: 0.890562891960144
Rank 0 - Epoch 90/200 loss: 0.8856980204582214
Rank 0 - Epoch 100/200 loss: 0.8808680176734924
Rank 0 - Epoch 110/200 loss: 0.8760760426521301
Rank 0 - Epoch 120/200 loss: 0.8713257312774658
Rank 0 - Epoch 130/200 loss: 0.8666204214096069
Rank 0 - Epoch 140/200 loss: 0.861964225769043
Rank 0 - Epoch 150/200 loss: 0.8573613166809082
Rank 0 - Epoch 160/200 loss: 0.8528158664703369
Rank 0 - Epoch 170/200 loss: 0.8483325839042664
Rank 0 - Epoch 180/200 loss: 0.8439162373542786
Rank 0 - Epoch 190/200 loss: 0.8395718932151794
Rank 0 - Epoch 200/200 loss: 0.8353050947189331
Training complete.
[92mRank 0 - Testing RMSE: 3.7945[0m
[92mRank: 0, Lengthscale: [[0.53542674 0.5374938 ]] [0m
[92mRank: 0, Outputscale: 0.5426582098007202 [0m
[92mRank: 0, Noise: 0.5229225754737854 [0m
Run 6 completed successfully
Running cGP 7 with agents: 100
decADMM initialized with rho: 0.85, max_iter: 5, lr: 0.0001, rank: 0, world_size: 100
Rank 0 - Epoch 2/200 loss: 0.9293854236602783
Rank 0 - Epoch 10/200 loss: 0.9253507256507874
Rank 0 - Epoch 20/200 loss: 0.9203202128410339
Rank 0 - Epoch 30/200 loss: 0.915306031703949
Rank 0 - Epoch 40/200 loss: 0.9103105664253235
Rank 0 - Epoch 50/200 loss: 0.9053359031677246
Rank 0 - Epoch 60/200 loss: 0.9003846645355225
Rank 0 - Epoch 70/200 loss: 0.8954593539237976
Rank 0 - Epoch 80/200 loss: 0.890562891960144
Rank 0 - Epoch 90/200 loss: 0.8856980204582214
Rank 0 - Epoch 100/200 loss: 0.8808680176734924
Rank 0 - Epoch 110/200 loss: 0.8760760426521301
Rank 0 - Epoch 120/200 loss: 0.8713257312774658
Rank 0 - Epoch 130/200 loss: 0.8666204214096069
Rank 0 - Epoch 140/200 loss: 0.861964225769043
Rank 0 - Epoch 150/200 loss: 0.8573613166809082
Rank 0 - Epoch 160/200 loss: 0.8528158664703369
Rank 0 - Epoch 170/200 loss: 0.8483325839042664
Rank 0 - Epoch 180/200 loss: 0.8439162373542786
Rank 0 - Epoch 190/200 loss: 0.8395718932151794
Rank 0 - Epoch 200/200 loss: 0.8353050947189331
Training complete.
[92mRank 0 - Testing RMSE: 3.7945[0m
[92mRank: 0, Lengthscale: [[0.53542674 0.5374938 ]] [0m
[92mRank: 0, Outputscale: 0.5426582098007202 [0m
[92mRank: 0, Noise: 0.5229225754737854 [0m
Run 7 completed successfully
Running cGP 8 with agents: 100
decADMM initialized with rho: 0.85, max_iter: 5, lr: 0.0001, rank: 0, world_size: 100
Rank 0 - Epoch 2/200 loss: 0.9293854236602783
Rank 0 - Epoch 10/200 loss: 0.9253507256507874
Rank 0 - Epoch 20/200 loss: 0.9203202128410339
Rank 0 - Epoch 30/200 loss: 0.915306031703949
Rank 0 - Epoch 40/200 loss: 0.9103105664253235
Rank 0 - Epoch 50/200 loss: 0.9053359031677246
Rank 0 - Epoch 60/200 loss: 0.9003846645355225
Rank 0 - Epoch 70/200 loss: 0.8954593539237976
Rank 0 - Epoch 80/200 loss: 0.890562891960144
Rank 0 - Epoch 90/200 loss: 0.8856980204582214
Rank 0 - Epoch 100/200 loss: 0.8808680176734924
Rank 0 - Epoch 110/200 loss: 0.8760760426521301
Rank 0 - Epoch 120/200 loss: 0.8713257312774658
Rank 0 - Epoch 130/200 loss: 0.8666204214096069
Rank 0 - Epoch 140/200 loss: 0.861964225769043
Rank 0 - Epoch 150/200 loss: 0.8573613166809082
Rank 0 - Epoch 160/200 loss: 0.8528158664703369
Rank 0 - Epoch 170/200 loss: 0.8483325839042664
Rank 0 - Epoch 180/200 loss: 0.8439162373542786
Rank 0 - Epoch 190/200 loss: 0.8395718932151794
Rank 0 - Epoch 200/200 loss: 0.8353050947189331
Training complete.
[92mRank 0 - Testing RMSE: 3.7945[0m
[92mRank: 0, Lengthscale: [[0.53542674 0.5374938 ]] [0m
[92mRank: 0, Outputscale: 0.5426582098007202 [0m
[92mRank: 0, Noise: 0.5229225754737854 [0m
Run 8 completed successfully
Running cGP 9 with agents: 100
decADMM initialized with rho: 0.85, max_iter: 5, lr: 0.0001, rank: 0, world_size: 100
Rank 0 - Epoch 2/200 loss: 0.9293854236602783
Rank 0 - Epoch 10/200 loss: 0.9253507256507874
Rank 0 - Epoch 20/200 loss: 0.9203202128410339
Rank 0 - Epoch 30/200 loss: 0.915306031703949
Rank 0 - Epoch 40/200 loss: 0.9103105664253235
Rank 0 - Epoch 50/200 loss: 0.9053359031677246
Rank 0 - Epoch 60/200 loss: 0.9003846645355225
Rank 0 - Epoch 70/200 loss: 0.8954593539237976
Rank 0 - Epoch 80/200 loss: 0.890562891960144
Rank 0 - Epoch 90/200 loss: 0.8856980204582214
Rank 0 - Epoch 100/200 loss: 0.8808680176734924
Rank 0 - Epoch 110/200 loss: 0.8760760426521301
Rank 0 - Epoch 120/200 loss: 0.8713257312774658
Rank 0 - Epoch 130/200 loss: 0.8666204214096069
Rank 0 - Epoch 140/200 loss: 0.861964225769043
Rank 0 - Epoch 150/200 loss: 0.8573613166809082
Rank 0 - Epoch 160/200 loss: 0.8528158664703369
Rank 0 - Epoch 170/200 loss: 0.8483325839042664
Rank 0 - Epoch 180/200 loss: 0.8439162373542786
Rank 0 - Epoch 190/200 loss: 0.8395718932151794
Rank 0 - Epoch 200/200 loss: 0.8353050947189331
Training complete.
[92mRank 0 - Testing RMSE: 3.7945[0m
[92mRank: 0, Lengthscale: [[0.53542674 0.5374938 ]] [0m
[92mRank: 0, Outputscale: 0.5426582098007202 [0m
[92mRank: 0, Noise: 0.5229225754737854 [0m
Run 9 completed successfully
Running cGP 10 with agents: 100
decADMM initialized with rho: 0.85, max_iter: 5, lr: 0.0001, rank: 0, world_size: 100
Rank 0 - Epoch 2/200 loss: 0.9293854236602783
Rank 0 - Epoch 10/200 loss: 0.9253507256507874
Rank 0 - Epoch 20/200 loss: 0.9203202128410339
Rank 0 - Epoch 30/200 loss: 0.915306031703949
Rank 0 - Epoch 40/200 loss: 0.9103105664253235
Rank 0 - Epoch 50/200 loss: 0.9053359031677246
Rank 0 - Epoch 60/200 loss: 0.9003846645355225
Rank 0 - Epoch 70/200 loss: 0.8954593539237976
Rank 0 - Epoch 80/200 loss: 0.890562891960144
Rank 0 - Epoch 90/200 loss: 0.8856980204582214
Rank 0 - Epoch 100/200 loss: 0.8808680176734924
Rank 0 - Epoch 110/200 loss: 0.8760760426521301
Rank 0 - Epoch 120/200 loss: 0.8713257312774658
Rank 0 - Epoch 130/200 loss: 0.8666204214096069
Rank 0 - Epoch 140/200 loss: 0.861964225769043
Rank 0 - Epoch 150/200 loss: 0.8573613166809082
Rank 0 - Epoch 160/200 loss: 0.8528158664703369
Rank 0 - Epoch 170/200 loss: 0.8483325839042664
Rank 0 - Epoch 180/200 loss: 0.8439162373542786
Rank 0 - Epoch 190/200 loss: 0.8395718932151794
Rank 0 - Epoch 200/200 loss: 0.8353050947189331
Training complete.
[92mRank 0 - Testing RMSE: 3.7945[0m
[92mRank: 0, Lengthscale: [[0.53542674 0.5374938 ]] [0m
[92mRank: 0, Outputscale: 0.5426582098007202 [0m
[92mRank: 0, Noise: 0.5229225754737854 [0m
Run 10 completed successfully
Running pxpGP 1 with agents: 121
[92mRank 0 - sparse dataset size is: 3, local dataset: torch.Size([144, 2]), [0m
[92mRank 0 - Training local sparse GP model with 144 samples[0m
Epoch 1/200 - Loss: 11.436
Epoch 11/200 - Loss: 1.188
Epoch 21/200 - Loss: 1.039
Epoch 31/200 - Loss: 0.961
Epoch 41/200 - Loss: 0.852
Epoch 51/200 - Loss: 0.726
Epoch 61/200 - Loss: 0.556
Epoch 71/200 - Loss: 0.454
Epoch 81/200 - Loss: 0.214
Converged at epoch 90 with loss -0.006
[92mRank 0 - Lengthscale: [[0.59110624 0.8893864 ]] [0m
[92mRank 0 - Outputscale: 2.484673023223877 [0m
[92mRank 0 - Noise: 0.1131051555275917 [0m
Rank 0 - Augmented dataset size: 507
Rank 0: After warm start model parameters:
Rank: 0, Lengthscale: [[0.5911063 0.8893864]]
Rank: 0, Outputscale: 2.484673023223877
Rank: 0, Noise: 0.1131051555275917
decpxADMM initialized with rho: 0.85, lip: 1.0, tol_abs: 1e-05, tol_rel: 0.001, rank: 0, world_size: 121
[92mRank 0 - Training global model with dec-pxADMM optimizer[0m
rank 0, epoch 9, loss: 0.9794870615005493, rho: 0.4250, lip: 1.0000
rank 0, epoch 19, loss: 0.941321611404419, rho: 0.2125, lip: 1.0000
rank 0, epoch 29, loss: 0.9068504571914673, rho: 0.1062, lip: 1.0000
rank 0, epoch 39, loss: 0.9039402008056641, rho: 0.1062, lip: 1.0000
rank 0, epoch 49, loss: 0.8997558355331421, rho: 0.0531, lip: 1.0000
rank 0, epoch 59, loss: 0.9005006551742554, rho: 0.0266, lip: 1.0000
rank 0, epoch 69, loss: 0.9016446471214294, rho: 0.0266, lip: 1.0000
rank 0, epoch 79, loss: 0.9019759893417358, rho: 0.0266, lip: 1.0000
rank 0, epoch 89, loss: 0.9008952975273132, rho: 0.0133, lip: 1.0000
rank 0, epoch 99, loss: 0.8996005654335022, rho: 0.0133, lip: 1.0000
rank 0, epoch 109, loss: 0.8989336490631104, rho: 0.0133, lip: 1.0000
rank 0, epoch 119, loss: 0.8989167809486389, rho: 0.0133, lip: 1.0000
rank 0, epoch 129, loss: 0.8991549015045166, rho: 0.0133, lip: 1.0000
rank 0, epoch 139, loss: 0.8994690775871277, rho: 0.0133, lip: 1.0000
rank 0, epoch 149, loss: 0.9000561833381653, rho: 0.0133, lip: 1.0000
rank 0, epoch 159, loss: 0.9009779095649719, rho: 0.0133, lip: 1.0000
rank 0, epoch 169, loss: 0.9019540548324585, rho: 0.0133, lip: 1.0000
rank 0, epoch 179, loss: 0.9025717377662659, rho: 0.0133, lip: 1.0000
Rank 0 - Training time: 123.77 seconds
[92mRank 0 - Testing RMSE: 0.3059[0m
[92mRank: 0, Lengthscale: [[0.6249105 0.4835895]] [0m
[92mRank: 0, Outputscale: 4.115093231201172 [0m
[92mRank: 0, Noise: 0.2498084008693695 [0m
Run 1 completed successfully
Running pxpGP 2 with agents: 121
[92mRank 0 - sparse dataset size is: 3, local dataset: torch.Size([144, 2]), [0m
[92mRank 0 - Training local sparse GP model with 144 samples[0m
Epoch 1/200 - Loss: 12.848
Epoch 11/200 - Loss: 1.112
Epoch 21/200 - Loss: 1.038
Epoch 31/200 - Loss: 0.964
Epoch 41/200 - Loss: 0.848
Epoch 51/200 - Loss: 0.713
Epoch 61/200 - Loss: 0.565
Epoch 71/200 - Loss: 0.415
Epoch 81/200 - Loss: 0.154
Epoch 91/200 - Loss: -0.004
Converged at epoch 91 with loss -0.004
[92mRank 0 - Lengthscale: [[0.58400667 0.9426171 ]] [0m
[92mRank 0 - Outputscale: 2.5111777782440186 [0m
[92mRank 0 - Noise: 0.1087174266576767 [0m
Rank 0 - Augmented dataset size: 507
Rank 0: After warm start model parameters:
Rank: 0, Lengthscale: [[0.58400667 0.9426172 ]]
Rank: 0, Outputscale: 2.5111777782440186
Rank: 0, Noise: 0.10871744155883789
decpxADMM initialized with rho: 0.85, lip: 1.0, tol_abs: 1e-05, tol_rel: 0.001, rank: 0, world_size: 121
[92mRank 0 - Training global model with dec-pxADMM optimizer[0m
rank 0, epoch 9, loss: 1.0077369213104248, rho: 0.4250, lip: 1.0000
rank 0, epoch 19, loss: 1.0118104219436646, rho: 0.2125, lip: 1.0000
rank 0, epoch 29, loss: 0.967506468296051, rho: 0.1062, lip: 1.0000
rank 0, epoch 39, loss: 0.9643975496292114, rho: 0.1062, lip: 1.0000
rank 0, epoch 49, loss: 0.9645495414733887, rho: 0.0531, lip: 1.0000
rank 0, epoch 59, loss: 0.9669300317764282, rho: 0.0531, lip: 1.0000
rank 0, epoch 69, loss: 0.9578806757926941, rho: 0.0531, lip: 1.0000
rank 0, epoch 79, loss: 0.9484285712242126, rho: 0.0266, lip: 1.0000
rank 0, epoch 89, loss: 0.9453731179237366, rho: 0.0266, lip: 1.0000
rank 0, epoch 99, loss: 0.9449763894081116, rho: 0.0266, lip: 1.0000
rank 0, epoch 109, loss: 0.9451130032539368, rho: 0.0266, lip: 1.0000
rank 0, epoch 119, loss: 0.9447470903396606, rho: 0.0266, lip: 1.0000
rank 0, epoch 129, loss: 0.9442925453186035, rho: 0.0066, lip: 1.0000
rank 0, epoch 139, loss: 0.9440507292747498, rho: 0.0066, lip: 1.0000
rank 0, epoch 149, loss: 0.9439404606819153, rho: 0.0066, lip: 1.0000
rank 0, epoch 159, loss: 0.94390869140625, rho: 0.0066, lip: 1.0000
rank 0, epoch 169, loss: 0.9438146948814392, rho: 0.0066, lip: 1.0000
rank 0, epoch 179, loss: 0.9435487389564514, rho: 0.0066, lip: 1.0000
Rank 0 - Training time: 147.48 seconds
[92mRank 0 - Testing RMSE: 0.3647[0m
[92mRank: 0, Lengthscale: [[0.7981856 0.5429009]] [0m
[92mRank: 0, Outputscale: 3.337167501449585 [0m
[92mRank: 0, Noise: 0.2957245111465454 [0m
Run 2 completed successfully
Running pxpGP 3 with agents: 121
[92mRank 0 - sparse dataset size is: 3, local dataset: torch.Size([144, 2]), [0m
[92mRank 0 - Training local sparse GP model with 144 samples[0m
Epoch 1/200 - Loss: 13.425
Epoch 11/200 - Loss: 1.239
Epoch 21/200 - Loss: 1.048
Epoch 31/200 - Loss: 0.968
Epoch 41/200 - Loss: 0.861
Epoch 51/200 - Loss: 0.753
Epoch 61/200 - Loss: 0.593
Epoch 71/200 - Loss: 0.422
Epoch 81/200 - Loss: 0.161
Epoch 91/200 - Loss: -0.024
Converged at epoch 91 with loss -0.024
[92mRank 0 - Lengthscale: [[0.58382    0.90246487]] [0m
[92mRank 0 - Outputscale: 2.484384059906006 [0m
[92mRank 0 - Noise: 0.11179225891828537 [0m
Rank 0 - Augmented dataset size: 507
Rank 0: After warm start model parameters:
Rank: 0, Lengthscale: [[0.58382    0.90246487]]
Rank: 0, Outputscale: 2.484384059906006
Rank: 0, Noise: 0.11179225891828537
decpxADMM initialized with rho: 0.85, lip: 1.0, tol_abs: 1e-05, tol_rel: 0.001, rank: 0, world_size: 121
[92mRank 0 - Training global model with dec-pxADMM optimizer[0m
rank 0, epoch 9, loss: 1.0038747787475586, rho: 0.4250, lip: 1.0000
rank 0, epoch 19, loss: 0.982205867767334, rho: 0.2125, lip: 1.0000
rank 0, epoch 29, loss: 0.9420357346534729, rho: 0.1062, lip: 1.0000
rank 0, epoch 39, loss: 0.9407281279563904, rho: 0.1062, lip: 1.0000
rank 0, epoch 49, loss: 0.9310761094093323, rho: 0.0531, lip: 1.0000
rank 0, epoch 59, loss: 0.927200973033905, rho: 0.0531, lip: 1.0000
rank 0, epoch 69, loss: 0.9266737699508667, rho: 0.0531, lip: 1.0000
rank 0, epoch 79, loss: 0.9257112145423889, rho: 0.0266, lip: 1.0000
rank 0, epoch 89, loss: 0.9247522354125977, rho: 0.0266, lip: 1.0000
rank 0, epoch 99, loss: 0.9244488477706909, rho: 0.0266, lip: 1.0000
rank 0, epoch 109, loss: 0.9245175123214722, rho: 0.0266, lip: 1.0000
rank 0, epoch 119, loss: 0.9244962334632874, rho: 0.0266, lip: 1.0000
rank 0, epoch 129, loss: 0.9242046475410461, rho: 0.0266, lip: 1.0000
rank 0, epoch 139, loss: 0.9239556193351746, rho: 0.0066, lip: 1.0000
rank 0, epoch 149, loss: 0.9239144325256348, rho: 0.0066, lip: 1.0000
rank 0, epoch 159, loss: 0.9239754676818848, rho: 0.0066, lip: 1.0000
rank 0, epoch 169, loss: 0.9240027070045471, rho: 0.0066, lip: 1.0000
rank 0, epoch 179, loss: 0.9239298701286316, rho: 0.0066, lip: 1.0000
Rank 0 - Training time: 142.81 seconds
[92mRank 0 - Testing RMSE: 0.3403[0m
[92mRank: 0, Lengthscale: [[0.51448464 0.45431322]] [0m
[92mRank: 0, Outputscale: 2.2315897941589355 [0m
[92mRank: 0, Noise: 0.25760117173194885 [0m
Run 3 completed successfully
Running pxpGP 4 with agents: 121
[92mRank 0 - sparse dataset size is: 3, local dataset: torch.Size([144, 2]), [0m
[92mRank 0 - Training local sparse GP model with 144 samples[0m
Epoch 1/200 - Loss: 11.420
Epoch 11/200 - Loss: 1.167
Epoch 21/200 - Loss: 1.040
Epoch 31/200 - Loss: 0.958
Epoch 41/200 - Loss: 0.861
Epoch 51/200 - Loss: 0.740
Epoch 61/200 - Loss: 0.563
Epoch 71/200 - Loss: 0.382
Epoch 81/200 - Loss: 0.189
Epoch 91/200 - Loss: 0.080
Converged at epoch 93 with loss -0.036
[92mRank 0 - Lengthscale: [[0.6003517 0.8473477]] [0m
[92mRank 0 - Outputscale: 2.484224319458008 [0m
[92mRank 0 - Noise: 0.10107387602329254 [0m
Rank 0 - Augmented dataset size: 507
Rank 0: After warm start model parameters:
Rank: 0, Lengthscale: [[0.6003517 0.8473477]]
Rank: 0, Outputscale: 2.484224319458008
Rank: 0, Noise: 0.10107387602329254
decpxADMM initialized with rho: 0.85, lip: 1.0, tol_abs: 1e-05, tol_rel: 0.001, rank: 0, world_size: 121
[92mRank 0 - Training global model with dec-pxADMM optimizer[0m
rank 0, epoch 9, loss: 1.086851716041565, rho: 0.4250, lip: 1.0000
rank 0, epoch 19, loss: 1.0731253623962402, rho: 0.2125, lip: 1.0000
rank 0, epoch 29, loss: 1.0326905250549316, rho: 0.2125, lip: 1.0000
rank 0, epoch 39, loss: 1.0161149501800537, rho: 0.1062, lip: 1.0000
rank 0, epoch 49, loss: 1.0104763507843018, rho: 0.0531, lip: 1.0000
rank 0, epoch 59, loss: 1.0082727670669556, rho: 0.0531, lip: 1.0000
rank 0, epoch 69, loss: 1.0038498640060425, rho: 0.0531, lip: 1.0000
rank 0, epoch 79, loss: 1.0009651184082031, rho: 0.0266, lip: 1.0000
rank 0, epoch 89, loss: 1.0009098052978516, rho: 0.0266, lip: 1.0000
rank 0, epoch 99, loss: 1.0020310878753662, rho: 0.0266, lip: 1.0000
rank 0, epoch 109, loss: 1.0029422044754028, rho: 0.0266, lip: 1.0000
rank 0, epoch 119, loss: 1.002747654914856, rho: 0.0266, lip: 1.0000
rank 0, epoch 129, loss: 1.001600980758667, rho: 0.0066, lip: 1.0000
rank 0, epoch 139, loss: 1.0008670091629028, rho: 0.0066, lip: 1.0000
rank 0, epoch 149, loss: 1.0007078647613525, rho: 0.0066, lip: 1.0000
rank 0, epoch 159, loss: 1.000868558883667, rho: 0.0066, lip: 1.0000
rank 0, epoch 169, loss: 1.001152515411377, rho: 0.0066, lip: 1.0000
rank 0, epoch 179, loss: 1.0014055967330933, rho: 0.0066, lip: 1.0000
Rank 0 - Training time: 112.21 seconds
[92mRank 0 - Testing RMSE: 0.3689[0m
[92mRank: 0, Lengthscale: [[0.68893784 0.5545919 ]] [0m
[92mRank: 0, Outputscale: 3.474019765853882 [0m
[92mRank: 0, Noise: 0.31806960701942444 [0m
Run 4 completed successfully
Running pxpGP 5 with agents: 121
[92mRank 0 - sparse dataset size is: 3, local dataset: torch.Size([144, 2]), [0m
[92mRank 0 - Training local sparse GP model with 144 samples[0m
Epoch 1/200 - Loss: 14.816
Epoch 11/200 - Loss: 1.170
Epoch 21/200 - Loss: 1.051
Epoch 31/200 - Loss: 0.968
Epoch 41/200 - Loss: 0.876
Epoch 51/200 - Loss: 0.731
Epoch 61/200 - Loss: 0.557
Epoch 71/200 - Loss: 0.366
Epoch 81/200 - Loss: 0.184
Epoch 91/200 - Loss: -0.013
Converged at epoch 91 with loss -0.013
[92mRank 0 - Lengthscale: [[0.55713713 1.6165897 ]] [0m
[92mRank 0 - Outputscale: 2.4827628135681152 [0m
[92mRank 0 - Noise: 0.11237939447164536 [0m
Rank 0 - Augmented dataset size: 507
Rank 0: After warm start model parameters:
Rank: 0, Lengthscale: [[0.55713713 1.6165897 ]]
Rank: 0, Outputscale: 2.4827628135681152
Rank: 0, Noise: 0.11237939447164536
decpxADMM initialized with rho: 0.85, lip: 1.0, tol_abs: 1e-05, tol_rel: 0.001, rank: 0, world_size: 121
[92mRank 0 - Training global model with dec-pxADMM optimizer[0m
rank 0, epoch 9, loss: 0.9551838636398315, rho: 0.4250, lip: 1.0000
rank 0, epoch 19, loss: 0.9498936533927917, rho: 0.2125, lip: 1.0000
rank 0, epoch 29, loss: 0.9025076031684875, rho: 0.1062, lip: 1.0000
rank 0, epoch 39, loss: 0.9129008054733276, rho: 0.1062, lip: 1.0000
rank 0, epoch 49, loss: 0.9000297784805298, rho: 0.0133, lip: 1.0000
rank 0, epoch 59, loss: 0.8924635648727417, rho: 0.0133, lip: 1.0000
rank 0, epoch 69, loss: 0.8888422250747681, rho: 0.0133, lip: 1.0000
rank 0, epoch 79, loss: 0.8873426914215088, rho: 0.0133, lip: 1.0000
rank 0, epoch 89, loss: 0.8865159153938293, rho: 0.0133, lip: 1.0000
rank 0, epoch 99, loss: 0.8858647346496582, rho: 0.0133, lip: 1.0000
rank 0, epoch 109, loss: 0.8856973648071289, rho: 0.0133, lip: 1.0000
rank 0, epoch 119, loss: 0.885582685470581, rho: 0.0133, lip: 1.0000
rank 0, epoch 129, loss: 0.8852612376213074, rho: 0.0133, lip: 1.0000
rank 0, epoch 139, loss: 0.8850279450416565, rho: 0.0066, lip: 1.0000
rank 0, epoch 149, loss: 0.8850216865539551, rho: 0.0066, lip: 1.0000
rank 0, epoch 159, loss: 0.8851238489151001, rho: 0.0066, lip: 1.0000
rank 0, epoch 169, loss: 0.8852486610412598, rho: 0.0066, lip: 1.0000
rank 0, epoch 179, loss: 0.8852680325508118, rho: 0.0066, lip: 1.0000
Rank 0 - Training time: 151.95 seconds
[92mRank 0 - Testing RMSE: 0.2928[0m
[92mRank: 0, Lengthscale: [[0.6879978 0.3784722]] [0m
[92mRank: 0, Outputscale: 2.8322181701660156 [0m
[92mRank: 0, Noise: 0.23570342361927032 [0m
Run 5 completed successfully
Running pxpGP 6 with agents: 121
[92mRank 0 - sparse dataset size is: 3, local dataset: torch.Size([144, 2]), [0m
[92mRank 0 - Training local sparse GP model with 144 samples[0m
Epoch 1/200 - Loss: 13.618
Epoch 11/200 - Loss: 1.287
Epoch 21/200 - Loss: 1.049
Epoch 31/200 - Loss: 0.961
Epoch 41/200 - Loss: 0.874
Epoch 51/200 - Loss: 0.735
Epoch 61/200 - Loss: 0.623
Epoch 71/200 - Loss: 0.384
Epoch 81/200 - Loss: 0.179
Epoch 91/200 - Loss: 0.163
Converged at epoch 92 with loss -0.092
[92mRank 0 - Lengthscale: [[0.5840398 0.8620902]] [0m
[92mRank 0 - Outputscale: 2.5000741481781006 [0m
[92mRank 0 - Noise: 0.10737966001033783 [0m
Rank 0 - Augmented dataset size: 507
Rank 0: After warm start model parameters:
Rank: 0, Lengthscale: [[0.5840398 0.8620902]]
Rank: 0, Outputscale: 2.5000741481781006
Rank: 0, Noise: 0.10737966001033783
decpxADMM initialized with rho: 0.85, lip: 1.0, tol_abs: 1e-05, tol_rel: 0.001, rank: 0, world_size: 121
[92mRank 0 - Training global model with dec-pxADMM optimizer[0m
rank 0, epoch 9, loss: 1.014633297920227, rho: 0.4250, lip: 1.0000
rank 0, epoch 19, loss: 0.9998320937156677, rho: 0.2125, lip: 1.0000
rank 0, epoch 29, loss: 0.9467678070068359, rho: 0.1062, lip: 1.0000
rank 0, epoch 39, loss: 0.9454212784767151, rho: 0.1062, lip: 1.0000
rank 0, epoch 49, loss: 0.9419331550598145, rho: 0.0266, lip: 1.0000
rank 0, epoch 59, loss: 0.9405001401901245, rho: 0.0266, lip: 1.0000
rank 0, epoch 69, loss: 0.9399160146713257, rho: 0.0266, lip: 1.0000
rank 0, epoch 79, loss: 0.9386017918586731, rho: 0.0266, lip: 1.0000
rank 0, epoch 89, loss: 0.936923086643219, rho: 0.0266, lip: 1.0000
rank 0, epoch 99, loss: 0.9358305931091309, rho: 0.0266, lip: 1.0000
rank 0, epoch 109, loss: 0.9353407621383667, rho: 0.0266, lip: 1.0000
rank 0, epoch 119, loss: 0.9352097511291504, rho: 0.0266, lip: 1.0000
rank 0, epoch 129, loss: 0.9352616667747498, rho: 0.0066, lip: 1.0000
rank 0, epoch 139, loss: 0.935401439666748, rho: 0.0066, lip: 1.0000
rank 0, epoch 149, loss: 0.9356028437614441, rho: 0.0066, lip: 1.0000
rank 0, epoch 159, loss: 0.9358251094818115, rho: 0.0066, lip: 1.0000
rank 0, epoch 169, loss: 0.9360063672065735, rho: 0.0066, lip: 1.0000
rank 0, epoch 179, loss: 0.9360671043395996, rho: 0.0066, lip: 1.0000
Rank 0 - Training time: 165.41 seconds
[92mRank 0 - Testing RMSE: 0.3191[0m
[92mRank: 0, Lengthscale: [[0.6285474 0.5041823]] [0m
[92mRank: 0, Outputscale: 2.966881513595581 [0m
[92mRank: 0, Noise: 0.26879796385765076 [0m
Run 6 completed successfully
Running pxpGP 7 with agents: 121
[92mRank 0 - sparse dataset size is: 3, local dataset: torch.Size([144, 2]), [0m
[92mRank 0 - Training local sparse GP model with 144 samples[0m
Epoch 1/200 - Loss: 11.951
Epoch 11/200 - Loss: 1.106
Epoch 21/200 - Loss: 1.031
Epoch 31/200 - Loss: 0.958
Epoch 41/200 - Loss: 0.855
Epoch 51/200 - Loss: 0.733
Epoch 61/200 - Loss: 0.543
Epoch 71/200 - Loss: 0.349
Epoch 81/200 - Loss: 0.152
Converged at epoch 88 with loss -0.020
[92mRank 0 - Lengthscale: [[0.57151103 0.9014602 ]] [0m
[92mRank 0 - Outputscale: 2.4758853912353516 [0m
[92mRank 0 - Noise: 0.11902862787246704 [0m
Rank 0 - Augmented dataset size: 507
Rank 0: After warm start model parameters:
Rank: 0, Lengthscale: [[0.57151103 0.9014602 ]]
Rank: 0, Outputscale: 2.4758853912353516
Rank: 0, Noise: 0.11902862787246704
decpxADMM initialized with rho: 0.85, lip: 1.0, tol_abs: 1e-05, tol_rel: 0.001, rank: 0, world_size: 121
[92mRank 0 - Training global model with dec-pxADMM optimizer[0m
rank 0, epoch 9, loss: 0.9729665517807007, rho: 0.4250, lip: 1.0000
rank 0, epoch 19, loss: 0.9629892110824585, rho: 0.2125, lip: 1.0000
rank 0, epoch 29, loss: 0.9148279428482056, rho: 0.2125, lip: 1.0000
rank 0, epoch 39, loss: 0.9167420268058777, rho: 0.1062, lip: 1.0000
rank 0, epoch 49, loss: 0.9117230772972107, rho: 0.0531, lip: 1.0000
rank 0, epoch 59, loss: 0.9084845185279846, rho: 0.0531, lip: 1.0000
rank 0, epoch 69, loss: 0.9058064818382263, rho: 0.0531, lip: 1.0000
rank 0, epoch 79, loss: 0.904322624206543, rho: 0.0531, lip: 1.0000
rank 0, epoch 89, loss: 0.9039890766143799, rho: 0.0266, lip: 1.0000
rank 0, epoch 99, loss: 0.9046980142593384, rho: 0.0266, lip: 1.0000
rank 0, epoch 109, loss: 0.9058079719543457, rho: 0.0266, lip: 1.0000
rank 0, epoch 119, loss: 0.9064911603927612, rho: 0.0266, lip: 1.0000
rank 0, epoch 129, loss: 0.9062071442604065, rho: 0.0266, lip: 1.0000
rank 0, epoch 139, loss: 0.9053288102149963, rho: 0.0266, lip: 1.0000
rank 0, epoch 149, loss: 0.9042462110519409, rho: 0.0266, lip: 1.0000
rank 0, epoch 159, loss: 0.9029390811920166, rho: 0.0266, lip: 1.0000
rank 0, epoch 169, loss: 0.9016870856285095, rho: 0.0133, lip: 1.0000
rank 0, epoch 179, loss: 0.9008718132972717, rho: 0.0133, lip: 1.0000
Rank 0 - Training time: 149.53 seconds
[92mRank 0 - Testing RMSE: 0.3040[0m
[92mRank: 0, Lengthscale: [[0.72629684 0.37712386]] [0m
[92mRank: 0, Outputscale: 1.878382921218872 [0m
[92mRank: 0, Noise: 0.2502947151660919 [0m
Run 7 completed successfully
Running pxpGP 8 with agents: 121
[92mRank 0 - sparse dataset size is: 3, local dataset: torch.Size([144, 2]), [0m
[92mRank 0 - Training local sparse GP model with 144 samples[0m
Epoch 1/200 - Loss: 14.782
Epoch 11/200 - Loss: 1.236
Epoch 21/200 - Loss: 1.046
Epoch 31/200 - Loss: 0.963
Epoch 41/200 - Loss: 0.866
Epoch 51/200 - Loss: 0.727
Epoch 61/200 - Loss: 0.573
Epoch 71/200 - Loss: 0.413
Epoch 81/200 - Loss: 0.205
Converged at epoch 89 with loss -0.006
[92mRank 0 - Lengthscale: [[0.587982  0.8936676]] [0m
[92mRank 0 - Outputscale: 2.468578577041626 [0m
[92mRank 0 - Noise: 0.12135753780603409 [0m
Rank 0 - Augmented dataset size: 507
Rank 0: After warm start model parameters:
Rank: 0, Lengthscale: [[0.587982  0.8936676]]
Rank: 0, Outputscale: 2.468578577041626
Rank: 0, Noise: 0.12135753780603409
decpxADMM initialized with rho: 0.85, lip: 1.0, tol_abs: 1e-05, tol_rel: 0.001, rank: 0, world_size: 121
[92mRank 0 - Training global model with dec-pxADMM optimizer[0m
rank 0, epoch 9, loss: 0.9982532858848572, rho: 0.4250, lip: 1.0000
rank 0, epoch 19, loss: 1.0072095394134521, rho: 0.2125, lip: 1.0000
rank 0, epoch 29, loss: 0.9387917518615723, rho: 0.1062, lip: 1.0000
rank 0, epoch 39, loss: 0.9213542342185974, rho: 0.1062, lip: 1.0000
rank 0, epoch 49, loss: 0.9254249334335327, rho: 0.0531, lip: 1.0000
rank 0, epoch 59, loss: 0.9349218606948853, rho: 0.0133, lip: 1.0000
rank 0, epoch 69, loss: 0.9349170327186584, rho: 0.0133, lip: 1.0000
rank 0, epoch 79, loss: 0.9281102418899536, rho: 0.0133, lip: 1.0000
rank 0, epoch 89, loss: 0.9208093285560608, rho: 0.0133, lip: 1.0000
rank 0, epoch 99, loss: 0.9161503911018372, rho: 0.0133, lip: 1.0000
rank 0, epoch 109, loss: 0.9143739938735962, rho: 0.0133, lip: 1.0000
rank 0, epoch 119, loss: 0.914010763168335, rho: 0.0133, lip: 1.0000
rank 0, epoch 129, loss: 0.9144119620323181, rho: 0.0133, lip: 1.0000
rank 0, epoch 139, loss: 0.91515052318573, rho: 0.0133, lip: 1.0000
rank 0, epoch 149, loss: 0.9157043099403381, rho: 0.0133, lip: 1.0000
rank 0, epoch 159, loss: 0.9159006476402283, rho: 0.0133, lip: 1.0000
rank 0, epoch 169, loss: 0.9158309698104858, rho: 0.0133, lip: 1.0000
rank 0, epoch 179, loss: 0.9157149791717529, rho: 0.0066, lip: 1.0000
Rank 0 - Training time: 125.88 seconds
[92mRank 0 - Testing RMSE: 0.3374[0m
[92mRank: 0, Lengthscale: [[0.7209964  0.57270986]] [0m
[92mRank: 0, Outputscale: 3.708528995513916 [0m
[92mRank: 0, Noise: 0.2745017111301422 [0m
Run 8 completed successfully
Running pxpGP 9 with agents: 121
[92mRank 0 - sparse dataset size is: 3, local dataset: torch.Size([144, 2]), [0m
[92mRank 0 - Training local sparse GP model with 144 samples[0m
Epoch 1/200 - Loss: 10.039
Epoch 11/200 - Loss: 1.255
Epoch 21/200 - Loss: 1.044
Epoch 31/200 - Loss: 0.961
Epoch 41/200 - Loss: 0.853
Epoch 51/200 - Loss: 0.729
Epoch 61/200 - Loss: 0.578
Epoch 71/200 - Loss: 0.395
Epoch 81/200 - Loss: 0.162
Epoch 91/200 - Loss: -0.042
Converged at epoch 91 with loss -0.042
[92mRank 0 - Lengthscale: [[0.57778317 0.9345854 ]] [0m
[92mRank 0 - Outputscale: 2.478989839553833 [0m
[92mRank 0 - Noise: 0.11084383726119995 [0m
Rank 0 - Augmented dataset size: 507
Rank 0: After warm start model parameters:
Rank: 0, Lengthscale: [[0.57778317 0.9345854 ]]
Rank: 0, Outputscale: 2.478990077972412
Rank: 0, Noise: 0.11084383726119995
decpxADMM initialized with rho: 0.85, lip: 1.0, tol_abs: 1e-05, tol_rel: 0.001, rank: 0, world_size: 121
[92mRank 0 - Training global model with dec-pxADMM optimizer[0m
rank 0, epoch 9, loss: 0.9892967343330383, rho: 0.4250, lip: 1.0000
rank 0, epoch 19, loss: 0.9799233078956604, rho: 0.2125, lip: 1.0000
rank 0, epoch 29, loss: 0.9469125866889954, rho: 0.1062, lip: 1.0000
rank 0, epoch 39, loss: 0.9412520527839661, rho: 0.1062, lip: 1.0000
rank 0, epoch 49, loss: 0.9310979247093201, rho: 0.0531, lip: 1.0000
rank 0, epoch 59, loss: 0.9282454252243042, rho: 0.0531, lip: 1.0000
rank 0, epoch 69, loss: 0.9280030727386475, rho: 0.0531, lip: 1.0000
rank 0, epoch 79, loss: 0.9273714423179626, rho: 0.0133, lip: 1.0000
rank 0, epoch 89, loss: 0.9264658093452454, rho: 0.0133, lip: 1.0000
rank 0, epoch 99, loss: 0.9257642030715942, rho: 0.0133, lip: 1.0000
rank 0, epoch 109, loss: 0.9254847764968872, rho: 0.0133, lip: 1.0000
rank 0, epoch 119, loss: 0.925513744354248, rho: 0.0133, lip: 1.0000
rank 0, epoch 129, loss: 0.9258322715759277, rho: 0.0066, lip: 1.0000
rank 0, epoch 139, loss: 0.9264260530471802, rho: 0.0066, lip: 1.0000
rank 0, epoch 149, loss: 0.9271754026412964, rho: 0.0066, lip: 1.0000
rank 0, epoch 159, loss: 0.9278453588485718, rho: 0.0066, lip: 1.0000
rank 0, epoch 169, loss: 0.9282389283180237, rho: 0.0066, lip: 1.0000
rank 0, epoch 179, loss: 0.9283377528190613, rho: 0.0066, lip: 1.0000
Rank 0 - Training time: 133.39 seconds
[92mRank 0 - Testing RMSE: 0.2894[0m
[92mRank: 0, Lengthscale: [[0.601493   0.44673914]] [0m
[92mRank: 0, Outputscale: 3.701073408126831 [0m
[92mRank: 0, Noise: 0.27762284874916077 [0m
Run 9 completed successfully
Running pxpGP 10 with agents: 121
[92mRank 0 - sparse dataset size is: 3, local dataset: torch.Size([144, 2]), [0m
[92mRank 0 - Training local sparse GP model with 144 samples[0m
Epoch 1/200 - Loss: 10.601
Epoch 11/200 - Loss: 1.287
Epoch 21/200 - Loss: 1.038
Epoch 31/200 - Loss: 0.959
Epoch 41/200 - Loss: 0.858
Epoch 51/200 - Loss: 0.727
Epoch 61/200 - Loss: 0.574
Epoch 71/200 - Loss: 0.378
Epoch 81/200 - Loss: 0.180
Converged at epoch 90 with loss -0.003
[92mRank 0 - Lengthscale: [[0.5933406  0.88370717]] [0m
[92mRank 0 - Outputscale: 2.4699227809906006 [0m
[92mRank 0 - Noise: 0.11259745806455612 [0m
Rank 0 - Augmented dataset size: 507
Rank 0: After warm start model parameters:
Rank: 0, Lengthscale: [[0.5933406 0.8837072]]
Rank: 0, Outputscale: 2.4699227809906006
Rank: 0, Noise: 0.11259745806455612
decpxADMM initialized with rho: 0.85, lip: 1.0, tol_abs: 1e-05, tol_rel: 0.001, rank: 0, world_size: 121
[92mRank 0 - Training global model with dec-pxADMM optimizer[0m
rank 0, epoch 9, loss: 0.9818676114082336, rho: 0.4250, lip: 1.0000
rank 0, epoch 19, loss: 0.9645867347717285, rho: 0.2125, lip: 1.0000
rank 0, epoch 29, loss: 0.9218682646751404, rho: 0.1062, lip: 1.0000
rank 0, epoch 39, loss: 0.9192119836807251, rho: 0.0531, lip: 1.0000
rank 0, epoch 49, loss: 0.9126725196838379, rho: 0.0266, lip: 1.0000
rank 0, epoch 59, loss: 0.9094571471214294, rho: 0.0266, lip: 1.0000
rank 0, epoch 69, loss: 0.9078971147537231, rho: 0.0266, lip: 1.0000
rank 0, epoch 79, loss: 0.9065535068511963, rho: 0.0266, lip: 1.0000
rank 0, epoch 89, loss: 0.9055187702178955, rho: 0.0133, lip: 1.0000
rank 0, epoch 99, loss: 0.905404806137085, rho: 0.0133, lip: 1.0000
rank 0, epoch 109, loss: 0.906084418296814, rho: 0.0133, lip: 1.0000
rank 0, epoch 119, loss: 0.9067386388778687, rho: 0.0133, lip: 1.0000
rank 0, epoch 129, loss: 0.9063984155654907, rho: 0.0133, lip: 1.0000
rank 0, epoch 139, loss: 0.9054684042930603, rho: 0.0133, lip: 1.0000
rank 0, epoch 149, loss: 0.9047675728797913, rho: 0.0133, lip: 1.0000
rank 0, epoch 159, loss: 0.9040735960006714, rho: 0.0133, lip: 1.0000
rank 0, epoch 169, loss: 0.9031597971916199, rho: 0.0133, lip: 1.0000
rank 0, epoch 179, loss: 0.9021568298339844, rho: 0.0133, lip: 1.0000
Rank 0 - Training time: 152.30 seconds
[92mRank 0 - Testing RMSE: 0.2973[0m
[92mRank: 0, Lengthscale: [[0.7395386  0.41296312]] [0m
[92mRank: 0, Outputscale: 3.2027525901794434 [0m
[92mRank: 0, Noise: 0.241530641913414 [0m
Run 10 completed successfully
Running gapxGP 1 with agents: 121
decpxADMM initialized with rho: 0.75, lip: 1.0, tol_abs: 1e-05, tol_rel: 0.001, rank: 0, world_size: 121
Rank 0 - Epoch 2/181 loss: 1.10466730594635
Rank 0 - Epoch 10/181 loss: 0.906933605670929
Rank 0 - Epoch 20/181 loss: 0.6451213955879211
Rank 0 - Epoch 30/181 loss: 0.2895689606666565
Rank 0 - Epoch 40/181 loss: -0.07644568383693695
Rank 0 - Epoch 50/181 loss: -0.431690514087677
Rank 0 - Epoch 60/181 loss: -0.7714441418647766
Rank 0 - Epoch 70/181 loss: -1.0817798376083374
Rank 0 - Epoch 80/181 loss: -1.3553755283355713
Rank 0 - Epoch 90/181 loss: -1.586067795753479
Rank 0 - Epoch 100/181 loss: -1.7671760320663452
Rank 0 - Epoch 110/181 loss: -1.8480452299118042
Run 1 failed, retrying...
Running gapxGP 2 with agents: 121
decpxADMM initialized with rho: 0.75, lip: 1.0, tol_abs: 1e-05, tol_rel: 0.001, rank: 0, world_size: 121
Rank 0 - Epoch 2/181 loss: 1.1062192916870117
Rank 0 - Epoch 10/181 loss: 0.9110740423202515
Rank 0 - Epoch 20/181 loss: 0.6492389440536499
Rank 0 - Epoch 30/181 loss: 0.29354962706565857
Rank 0 - Epoch 40/181 loss: -0.07459253072738647
Rank 0 - Epoch 50/181 loss: -0.43045347929000854
Rank 0 - Epoch 60/181 loss: -0.7685205340385437
Rank 0 - Epoch 70/181 loss: -1.0782967805862427
Rank 0 - Epoch 80/181 loss: -1.3533661365509033
Rank 0 - Epoch 90/181 loss: -1.586924433708191
Rank 0 - Epoch 100/181 loss: -1.7692546844482422
Rank 0 - Epoch 110/181 loss: -1.7918967008590698
Rank 0 - Epoch 120/181 loss: -1.8878934383392334
Run 2 failed, retrying...
Running gapxGP 3 with agents: 121
decpxADMM initialized with rho: 0.75, lip: 1.0, tol_abs: 1e-05, tol_rel: 0.001, rank: 0, world_size: 121
Rank 0 - Epoch 2/181 loss: 1.1088627576828003
Rank 0 - Epoch 10/181 loss: 0.9089639186859131
Rank 0 - Epoch 20/181 loss: 0.6365166306495667
Rank 0 - Epoch 30/181 loss: 0.2710016667842865
Rank 0 - Epoch 40/181 loss: -0.0999688059091568
Rank 0 - Epoch 50/181 loss: -0.45655569434165955
Rank 0 - Epoch 60/181 loss: -0.7962205410003662
Rank 0 - Epoch 70/181 loss: -1.1052621603012085
Rank 0 - Epoch 80/181 loss: -1.378326416015625
Rank 0 - Epoch 90/181 loss: -1.608095645904541
Rank 0 - Epoch 100/181 loss: -1.7838796377182007
Rank 0 - Epoch 110/181 loss: -1.7593204975128174
Rank 0 - Epoch 120/181 loss: -1.2946438789367676
Run 3 failed, retrying...
Running gapxGP 4 with agents: 121
decpxADMM initialized with rho: 0.75, lip: 1.0, tol_abs: 1e-05, tol_rel: 0.001, rank: 0, world_size: 121
Rank 0 - Epoch 2/181 loss: 1.1119476556777954
Rank 0 - Epoch 10/181 loss: 0.9154425859451294
Rank 0 - Epoch 20/181 loss: 0.6392967104911804
Rank 0 - Epoch 30/181 loss: 0.27479812502861023
Rank 0 - Epoch 40/181 loss: -0.091567263007164
Rank 0 - Epoch 50/181 loss: -0.4474610686302185
Rank 0 - Epoch 60/181 loss: -0.7880188226699829
Rank 0 - Epoch 70/181 loss: -1.0983521938323975
Rank 0 - Epoch 80/181 loss: -1.3712092638015747
Rank 0 - Epoch 90/181 loss: -1.6009567975997925
Rank 0 - Epoch 100/181 loss: -1.7810271978378296
Rank 0 - Epoch 110/181 loss: -1.8403428792953491
Rank 0 - Epoch 120/181 loss: -1.95159912109375
Run 4 failed, retrying...
Running gapxGP 5 with agents: 121
decpxADMM initialized with rho: 0.75, lip: 1.0, tol_abs: 1e-05, tol_rel: 0.001, rank: 0, world_size: 121
Rank 0 - Epoch 2/181 loss: 1.1148425340652466
Rank 0 - Epoch 10/181 loss: 0.9226279854774475
Rank 0 - Epoch 20/181 loss: 0.6604797840118408
Rank 0 - Epoch 30/181 loss: 0.29644957184791565
Rank 0 - Epoch 40/181 loss: -0.071709044277668
Rank 0 - Epoch 50/181 loss: -0.430021733045578
Rank 0 - Epoch 60/181 loss: -0.7708229422569275
Rank 0 - Epoch 70/181 loss: -1.081184983253479
Rank 0 - Epoch 80/181 loss: -1.3563716411590576
Rank 0 - Epoch 90/181 loss: -1.5887655019760132
Rank 0 - Epoch 100/181 loss: -1.771386742591858
Rank 0 - Epoch 110/181 loss: -1.8738356828689575
Rank 0 - Epoch 120/181 loss: -1.9658055305480957
Run 5 failed, retrying...
Running gapxGP 6 with agents: 121
decpxADMM initialized with rho: 0.75, lip: 1.0, tol_abs: 1e-05, tol_rel: 0.001, rank: 0, world_size: 121
Rank 0 - Epoch 2/181 loss: 1.1056036949157715
Rank 0 - Epoch 10/181 loss: 0.9112907648086548
Rank 0 - Epoch 20/181 loss: 0.6627262830734253
Rank 0 - Epoch 30/181 loss: 0.31235551834106445
Rank 0 - Epoch 40/181 loss: -0.05938720703125
Rank 0 - Epoch 50/181 loss: -0.4214637279510498
Rank 0 - Epoch 60/181 loss: -0.7673923373222351
Rank 0 - Epoch 70/181 loss: -1.08256196975708
Rank 0 - Epoch 80/181 loss: -1.3603191375732422
Rank 0 - Epoch 90/181 loss: -1.5947216749191284
Rank 0 - Epoch 100/181 loss: -1.7782975435256958
Rank 0 - Epoch 110/181 loss: -1.8678460121154785
Rank 0 - Epoch 120/181 loss: -1.2974674701690674
Run 6 failed, retrying...
Running gapxGP 7 with agents: 121
decpxADMM initialized with rho: 0.75, lip: 1.0, tol_abs: 1e-05, tol_rel: 0.001, rank: 0, world_size: 121
Rank 0 - Epoch 2/181 loss: 1.1125832796096802
Rank 0 - Epoch 10/181 loss: 0.9169914722442627
Rank 0 - Epoch 20/181 loss: 0.6498300433158875
Rank 0 - Epoch 30/181 loss: 0.2836606502532959
Rank 0 - Epoch 40/181 loss: -0.0804070383310318
Rank 0 - Epoch 50/181 loss: -0.43537017703056335
Rank 0 - Epoch 60/181 loss: -0.7757328748703003
Rank 0 - Epoch 70/181 loss: -1.0855953693389893
Rank 0 - Epoch 80/181 loss: -1.3595595359802246
Rank 0 - Epoch 90/181 loss: -1.5908161401748657
Rank 0 - Epoch 100/181 loss: -1.7712620496749878
Rank 0 - Epoch 110/181 loss: -1.718522310256958
Run 7 failed, retrying...
Running gapxGP 8 with agents: 121
decpxADMM initialized with rho: 0.75, lip: 1.0, tol_abs: 1e-05, tol_rel: 0.001, rank: 0, world_size: 121
Rank 0 - Epoch 2/181 loss: 1.1115199327468872
Rank 0 - Epoch 10/181 loss: 0.9210612773895264
Rank 0 - Epoch 20/181 loss: 0.6646527051925659
Rank 0 - Epoch 30/181 loss: 0.30192530155181885
Rank 0 - Epoch 40/181 loss: -0.0651618093252182
Rank 0 - Epoch 50/181 loss: -0.42083099484443665
Rank 0 - Epoch 60/181 loss: -0.7611657977104187
Rank 0 - Epoch 70/181 loss: -1.0715736150741577
Rank 0 - Epoch 80/181 loss: -1.347176432609558
Rank 0 - Epoch 90/181 loss: -1.5806591510772705
Rank 0 - Epoch 100/181 loss: -1.76457941532135
Rank 0 - Epoch 110/181 loss: -1.8529759645462036
Run 8 failed, retrying...
Running gapxGP 9 with agents: 121
decpxADMM initialized with rho: 0.75, lip: 1.0, tol_abs: 1e-05, tol_rel: 0.001, rank: 0, world_size: 121
Rank 0 - Epoch 2/181 loss: 1.1099640130996704
Rank 0 - Epoch 10/181 loss: 0.9106076955795288
Rank 0 - Epoch 20/181 loss: 0.636340856552124
Rank 0 - Epoch 30/181 loss: 0.2754276692867279
Rank 0 - Epoch 40/181 loss: -0.0869855135679245
Rank 0 - Epoch 50/181 loss: -0.43985602259635925
Rank 0 - Epoch 60/181 loss: -0.7771725058555603
Rank 0 - Epoch 70/181 loss: -1.0865751504898071
Rank 0 - Epoch 80/181 loss: -1.361616611480713
Rank 0 - Epoch 90/181 loss: -1.592846393585205
Rank 0 - Epoch 100/181 loss: -1.7704744338989258
Rank 0 - Epoch 110/181 loss: -1.70647132396698
Run 9 failed, retrying...
Running gapxGP 10 with agents: 121
decpxADMM initialized with rho: 0.75, lip: 1.0, tol_abs: 1e-05, tol_rel: 0.001, rank: 0, world_size: 121
Rank 0 - Epoch 2/181 loss: 1.115856647491455
Rank 0 - Epoch 10/181 loss: 0.9162061214447021
Rank 0 - Epoch 20/181 loss: 0.6460700631141663
Rank 0 - Epoch 30/181 loss: 0.28420597314834595
Rank 0 - Epoch 40/181 loss: -0.08396009355783463
Rank 0 - Epoch 50/181 loss: -0.44022974371910095
Rank 0 - Epoch 60/181 loss: -0.7806836366653442
Rank 0 - Epoch 70/181 loss: -1.0916074514389038
Rank 0 - Epoch 80/181 loss: -1.3666890859603882
Rank 0 - Epoch 90/181 loss: -1.5988236665725708
Rank 0 - Epoch 100/181 loss: -1.778342366218567
Rank 0 - Epoch 110/181 loss: -1.7538747787475586
Run 10 failed, retrying...
Running apxGP 1 with agents: 121
decpxADMM initialized with rho: 0.85, lip: 1.0, tol_abs: 1e-05, tol_rel: 0.001, rank: 0, world_size: 121
Rank 0 - Epoch 2/200 loss: 0.8947873711585999
Rank 0 - Epoch 10/200 loss: 0.6303754448890686
Rank 0 - Epoch 20/200 loss: 0.21923834085464478
Rank 0 - Epoch 30/200 loss: -0.24065940082073212
Rank 0 - Epoch 40/200 loss: -0.7414460778236389
Rank 0 - Epoch 50/200 loss: -1.2523152828216553
Rank 0 - Epoch 60/200 loss: -1.7354035377502441
Rank 0 - Epoch 70/200 loss: -2.1795480251312256
Rank 0 - Epoch 80/200 loss: -2.546499729156494
Rank 0 - Epoch 90/200 loss: -2.812148094177246
Rank 0 - Epoch 100/200 loss: -2.984290599822998
Rank 0 - Epoch 110/200 loss: -3.0882318019866943
Rank 0 - Epoch 120/200 loss: -3.1518614292144775
Rank 0 - Epoch 130/200 loss: -3.193242311477661
Rank 0 - Epoch 140/200 loss: -3.2217626571655273
Rank 0 - Epoch 150/200 loss: -3.2419559955596924
Rank 0 - Epoch 160/200 loss: -3.2575488090515137
Rank 0 - Epoch 170/200 loss: -3.2689285278320312
Rank 0 - Epoch 180/200 loss: -3.278252124786377
Rank 0 - Epoch 190/200 loss: -3.2855000495910645
Rank 0 - Epoch 200/200 loss: -3.292078971862793
Training complete.
[92mRank 0 - Testing RMSE: 2.4977[0m
[92mRank: 0, Lengthscale: [[0.60688025 0.39285874]] [0m
[92mRank: 0, Outputscale: 1.7209962606430054 [0m
[92mRank: 0, Noise: 0.00011122102296212688 [0m
Run 1 completed successfully
Running apxGP 2 with agents: 121
decpxADMM initialized with rho: 0.85, lip: 1.0, tol_abs: 1e-05, tol_rel: 0.001, rank: 0, world_size: 121
Rank 0 - Epoch 2/200 loss: 0.8947873711585999
Rank 0 - Epoch 10/200 loss: 0.6303754448890686
Rank 0 - Epoch 20/200 loss: 0.21923834085464478
Rank 0 - Epoch 30/200 loss: -0.24065940082073212
Rank 0 - Epoch 40/200 loss: -0.7414460778236389
Rank 0 - Epoch 50/200 loss: -1.2523152828216553
Rank 0 - Epoch 60/200 loss: -1.7354035377502441
Rank 0 - Epoch 70/200 loss: -2.1795480251312256
Rank 0 - Epoch 80/200 loss: -2.546499729156494
Rank 0 - Epoch 90/200 loss: -2.812148094177246
Rank 0 - Epoch 100/200 loss: -2.984290599822998
Rank 0 - Epoch 110/200 loss: -3.0882318019866943
Rank 0 - Epoch 120/200 loss: -3.1518614292144775
Rank 0 - Epoch 130/200 loss: -3.193242311477661
Rank 0 - Epoch 140/200 loss: -3.2217626571655273
Rank 0 - Epoch 150/200 loss: -3.2419559955596924
Rank 0 - Epoch 160/200 loss: -3.2575488090515137
Rank 0 - Epoch 170/200 loss: -3.2689285278320312
Rank 0 - Epoch 180/200 loss: -3.278252124786377
Rank 0 - Epoch 190/200 loss: -3.2855000495910645
Rank 0 - Epoch 200/200 loss: -3.292078971862793
Training complete.
[92mRank 0 - Testing RMSE: 2.4977[0m
[92mRank: 0, Lengthscale: [[0.60688025 0.39285874]] [0m
[92mRank: 0, Outputscale: 1.7209962606430054 [0m
[92mRank: 0, Noise: 0.00011122102296212688 [0m
Run 2 completed successfully
Running apxGP 3 with agents: 121
decpxADMM initialized with rho: 0.85, lip: 1.0, tol_abs: 1e-05, tol_rel: 0.001, rank: 0, world_size: 121
Rank 0 - Epoch 2/200 loss: 0.8947873711585999
Rank 0 - Epoch 10/200 loss: 0.6303754448890686
Rank 0 - Epoch 20/200 loss: 0.21923834085464478
Rank 0 - Epoch 30/200 loss: -0.24065940082073212
Rank 0 - Epoch 40/200 loss: -0.7414460778236389
Rank 0 - Epoch 50/200 loss: -1.2523152828216553
Rank 0 - Epoch 60/200 loss: -1.7354035377502441
Rank 0 - Epoch 70/200 loss: -2.1795480251312256
Rank 0 - Epoch 80/200 loss: -2.546499729156494
Rank 0 - Epoch 90/200 loss: -2.812148094177246
Rank 0 - Epoch 100/200 loss: -2.984290599822998
Rank 0 - Epoch 110/200 loss: -3.0882318019866943
Rank 0 - Epoch 120/200 loss: -3.1518614292144775
Rank 0 - Epoch 130/200 loss: -3.193242311477661
Rank 0 - Epoch 140/200 loss: -3.2217626571655273
Rank 0 - Epoch 150/200 loss: -3.2419559955596924
Rank 0 - Epoch 160/200 loss: -3.2575488090515137
Rank 0 - Epoch 170/200 loss: -3.2689285278320312
Rank 0 - Epoch 180/200 loss: -3.278252124786377
Rank 0 - Epoch 190/200 loss: -3.2855000495910645
Rank 0 - Epoch 200/200 loss: -3.292078971862793
Training complete.
[92mRank 0 - Testing RMSE: 2.4977[0m
[92mRank: 0, Lengthscale: [[0.60688025 0.39285874]] [0m
[92mRank: 0, Outputscale: 1.7209962606430054 [0m
[92mRank: 0, Noise: 0.00011122102296212688 [0m
Run 3 completed successfully
Running apxGP 4 with agents: 121
decpxADMM initialized with rho: 0.85, lip: 1.0, tol_abs: 1e-05, tol_rel: 0.001, rank: 0, world_size: 121
Rank 0 - Epoch 2/200 loss: 0.8947873711585999
Rank 0 - Epoch 10/200 loss: 0.6303754448890686
Rank 0 - Epoch 20/200 loss: 0.21923834085464478
Rank 0 - Epoch 30/200 loss: -0.24065940082073212
Rank 0 - Epoch 40/200 loss: -0.7414460778236389
Rank 0 - Epoch 50/200 loss: -1.2523152828216553
Rank 0 - Epoch 60/200 loss: -1.7354035377502441
Rank 0 - Epoch 70/200 loss: -2.1795480251312256
Rank 0 - Epoch 80/200 loss: -2.546499729156494
Rank 0 - Epoch 90/200 loss: -2.812148094177246
Rank 0 - Epoch 100/200 loss: -2.984290599822998
Rank 0 - Epoch 110/200 loss: -3.0882318019866943
Rank 0 - Epoch 120/200 loss: -3.1518614292144775
Rank 0 - Epoch 130/200 loss: -3.193242311477661
Rank 0 - Epoch 140/200 loss: -3.2217626571655273
Rank 0 - Epoch 150/200 loss: -3.2419559955596924
Rank 0 - Epoch 160/200 loss: -3.2575488090515137
Rank 0 - Epoch 170/200 loss: -3.2689285278320312
Rank 0 - Epoch 180/200 loss: -3.278252124786377
Rank 0 - Epoch 190/200 loss: -3.2855000495910645
Rank 0 - Epoch 200/200 loss: -3.292078971862793
Training complete.
[92mRank 0 - Testing RMSE: 2.4977[0m
[92mRank: 0, Lengthscale: [[0.60688025 0.39285874]] [0m
[92mRank: 0, Outputscale: 1.7209962606430054 [0m
[92mRank: 0, Noise: 0.00011122102296212688 [0m
Run 4 completed successfully
Running apxGP 5 with agents: 121
decpxADMM initialized with rho: 0.85, lip: 1.0, tol_abs: 1e-05, tol_rel: 0.001, rank: 0, world_size: 121
Rank 0 - Epoch 2/200 loss: 0.8947873711585999
Rank 0 - Epoch 10/200 loss: 0.6303754448890686
Rank 0 - Epoch 20/200 loss: 0.21923834085464478
Rank 0 - Epoch 30/200 loss: -0.24065940082073212
Rank 0 - Epoch 40/200 loss: -0.7414460778236389
Rank 0 - Epoch 50/200 loss: -1.2523152828216553
Rank 0 - Epoch 60/200 loss: -1.7354035377502441
Rank 0 - Epoch 70/200 loss: -2.1795480251312256
Rank 0 - Epoch 80/200 loss: -2.546499729156494
Rank 0 - Epoch 90/200 loss: -2.812148094177246
Rank 0 - Epoch 100/200 loss: -2.984290599822998
Rank 0 - Epoch 110/200 loss: -3.0882318019866943
Rank 0 - Epoch 120/200 loss: -3.1518614292144775
Rank 0 - Epoch 130/200 loss: -3.193242311477661
Rank 0 - Epoch 140/200 loss: -3.2217626571655273
Rank 0 - Epoch 150/200 loss: -3.2419559955596924
Rank 0 - Epoch 160/200 loss: -3.2575488090515137
Rank 0 - Epoch 170/200 loss: -3.2689285278320312
Rank 0 - Epoch 180/200 loss: -3.278252124786377
Rank 0 - Epoch 190/200 loss: -3.2855000495910645
Rank 0 - Epoch 200/200 loss: -3.292078971862793
Training complete.
[92mRank 0 - Testing RMSE: 2.4977[0m
[92mRank: 0, Lengthscale: [[0.60688025 0.39285874]] [0m
[92mRank: 0, Outputscale: 1.7209962606430054 [0m
[92mRank: 0, Noise: 0.00011122102296212688 [0m
Run 5 completed successfully
Running apxGP 6 with agents: 121
decpxADMM initialized with rho: 0.85, lip: 1.0, tol_abs: 1e-05, tol_rel: 0.001, rank: 0, world_size: 121
Rank 0 - Epoch 2/200 loss: 0.8947873711585999
Rank 0 - Epoch 10/200 loss: 0.6303754448890686
Rank 0 - Epoch 20/200 loss: 0.21923834085464478
Rank 0 - Epoch 30/200 loss: -0.24065940082073212
Rank 0 - Epoch 40/200 loss: -0.7414460778236389
Rank 0 - Epoch 50/200 loss: -1.2523152828216553
Rank 0 - Epoch 60/200 loss: -1.7354035377502441
Rank 0 - Epoch 70/200 loss: -2.1795480251312256
Rank 0 - Epoch 80/200 loss: -2.546499729156494
Rank 0 - Epoch 90/200 loss: -2.812148094177246
Rank 0 - Epoch 100/200 loss: -2.984290599822998
Rank 0 - Epoch 110/200 loss: -3.0882318019866943
Rank 0 - Epoch 120/200 loss: -3.1518614292144775
Rank 0 - Epoch 130/200 loss: -3.193242311477661
Rank 0 - Epoch 140/200 loss: -3.2217626571655273
Rank 0 - Epoch 150/200 loss: -3.2419559955596924
Rank 0 - Epoch 160/200 loss: -3.2575488090515137
Rank 0 - Epoch 170/200 loss: -3.2689285278320312
Rank 0 - Epoch 180/200 loss: -3.278252124786377
Rank 0 - Epoch 190/200 loss: -3.2855000495910645
Rank 0 - Epoch 200/200 loss: -3.292078971862793
Training complete.
[92mRank 0 - Testing RMSE: 2.4977[0m
[92mRank: 0, Lengthscale: [[0.60688025 0.39285874]] [0m
[92mRank: 0, Outputscale: 1.7209962606430054 [0m
[92mRank: 0, Noise: 0.00011122102296212688 [0m
Run 6 completed successfully
Running apxGP 7 with agents: 121
decpxADMM initialized with rho: 0.85, lip: 1.0, tol_abs: 1e-05, tol_rel: 0.001, rank: 0, world_size: 121
Rank 0 - Epoch 2/200 loss: 0.8947873711585999
Rank 0 - Epoch 10/200 loss: 0.6303754448890686
Rank 0 - Epoch 20/200 loss: 0.21923834085464478
Rank 0 - Epoch 30/200 loss: -0.24065940082073212
Rank 0 - Epoch 40/200 loss: -0.7414460778236389
Rank 0 - Epoch 50/200 loss: -1.2523152828216553
Rank 0 - Epoch 60/200 loss: -1.7354035377502441
Rank 0 - Epoch 70/200 loss: -2.1795480251312256
Rank 0 - Epoch 80/200 loss: -2.546499729156494
Rank 0 - Epoch 90/200 loss: -2.812148094177246
Rank 0 - Epoch 100/200 loss: -2.984290599822998
Rank 0 - Epoch 110/200 loss: -3.0882318019866943
Rank 0 - Epoch 120/200 loss: -3.1518614292144775
Rank 0 - Epoch 130/200 loss: -3.193242311477661
Rank 0 - Epoch 140/200 loss: -3.2217626571655273
Rank 0 - Epoch 150/200 loss: -3.2419559955596924
Rank 0 - Epoch 160/200 loss: -3.2575488090515137
Rank 0 - Epoch 170/200 loss: -3.2689285278320312
Rank 0 - Epoch 180/200 loss: -3.278252124786377
Rank 0 - Epoch 190/200 loss: -3.2855000495910645
Rank 0 - Epoch 200/200 loss: -3.292078971862793
Training complete.
[92mRank 0 - Testing RMSE: 2.4977[0m
[92mRank: 0, Lengthscale: [[0.60688025 0.39285874]] [0m
[92mRank: 0, Outputscale: 1.7209962606430054 [0m
[92mRank: 0, Noise: 0.00011122102296212688 [0m
Run 7 completed successfully
Running apxGP 8 with agents: 121
decpxADMM initialized with rho: 0.85, lip: 1.0, tol_abs: 1e-05, tol_rel: 0.001, rank: 0, world_size: 121
Rank 0 - Epoch 2/200 loss: 0.8947873711585999
Rank 0 - Epoch 10/200 loss: 0.6303754448890686
Rank 0 - Epoch 20/200 loss: 0.21923834085464478
Rank 0 - Epoch 30/200 loss: -0.24065940082073212
Rank 0 - Epoch 40/200 loss: -0.7414460778236389
Rank 0 - Epoch 50/200 loss: -1.2523152828216553
Rank 0 - Epoch 60/200 loss: -1.7354035377502441
Rank 0 - Epoch 70/200 loss: -2.1795480251312256
Rank 0 - Epoch 80/200 loss: -2.546499729156494
Rank 0 - Epoch 90/200 loss: -2.812148094177246
Rank 0 - Epoch 100/200 loss: -2.984290599822998
Rank 0 - Epoch 110/200 loss: -3.0882318019866943
Rank 0 - Epoch 120/200 loss: -3.1518614292144775
Rank 0 - Epoch 130/200 loss: -3.193242311477661
Rank 0 - Epoch 140/200 loss: -3.2217626571655273
Rank 0 - Epoch 150/200 loss: -3.2419559955596924
Rank 0 - Epoch 160/200 loss: -3.2575488090515137
Rank 0 - Epoch 170/200 loss: -3.2689285278320312
Rank 0 - Epoch 180/200 loss: -3.278252124786377
Rank 0 - Epoch 190/200 loss: -3.2855000495910645
Rank 0 - Epoch 200/200 loss: -3.292078971862793
Training complete.
[92mRank 0 - Testing RMSE: 2.4977[0m
[92mRank: 0, Lengthscale: [[0.60688025 0.39285874]] [0m
[92mRank: 0, Outputscale: 1.7209962606430054 [0m
[92mRank: 0, Noise: 0.00011122102296212688 [0m
Run 8 completed successfully
Running apxGP 9 with agents: 121
decpxADMM initialized with rho: 0.85, lip: 1.0, tol_abs: 1e-05, tol_rel: 0.001, rank: 0, world_size: 121
Rank 0 - Epoch 2/200 loss: 0.8947873711585999
Rank 0 - Epoch 10/200 loss: 0.6303754448890686
Rank 0 - Epoch 20/200 loss: 0.21923834085464478
Rank 0 - Epoch 30/200 loss: -0.24065940082073212
Rank 0 - Epoch 40/200 loss: -0.7414460778236389
Rank 0 - Epoch 50/200 loss: -1.2523152828216553
Rank 0 - Epoch 60/200 loss: -1.7354035377502441
Rank 0 - Epoch 70/200 loss: -2.1795480251312256
Rank 0 - Epoch 80/200 loss: -2.546499729156494
Rank 0 - Epoch 90/200 loss: -2.812148094177246
Rank 0 - Epoch 100/200 loss: -2.984290599822998
Rank 0 - Epoch 110/200 loss: -3.0882318019866943
Rank 0 - Epoch 120/200 loss: -3.1518614292144775
Rank 0 - Epoch 130/200 loss: -3.193242311477661
Rank 0 - Epoch 140/200 loss: -3.2217626571655273
Rank 0 - Epoch 150/200 loss: -3.2419559955596924
Rank 0 - Epoch 160/200 loss: -3.2575488090515137
Rank 0 - Epoch 170/200 loss: -3.2689285278320312
Rank 0 - Epoch 180/200 loss: -3.278252124786377
Rank 0 - Epoch 190/200 loss: -3.2855000495910645
Rank 0 - Epoch 200/200 loss: -3.292078971862793
Training complete.
[92mRank 0 - Testing RMSE: 2.4977[0m
[92mRank: 0, Lengthscale: [[0.60688025 0.39285874]] [0m
[92mRank: 0, Outputscale: 1.7209962606430054 [0m
[92mRank: 0, Noise: 0.00011122102296212688 [0m
Run 9 completed successfully
Running apxGP 10 with agents: 121
decpxADMM initialized with rho: 0.85, lip: 1.0, tol_abs: 1e-05, tol_rel: 0.001, rank: 0, world_size: 121
Rank 0 - Epoch 2/200 loss: 0.8947873711585999
Rank 0 - Epoch 10/200 loss: 0.6303754448890686
Rank 0 - Epoch 20/200 loss: 0.21923834085464478
Rank 0 - Epoch 30/200 loss: -0.24065940082073212
Rank 0 - Epoch 40/200 loss: -0.7414460778236389
Rank 0 - Epoch 50/200 loss: -1.2523152828216553
Rank 0 - Epoch 60/200 loss: -1.7354035377502441
Rank 0 - Epoch 70/200 loss: -2.1795480251312256
Rank 0 - Epoch 80/200 loss: -2.546499729156494
Rank 0 - Epoch 90/200 loss: -2.812148094177246
Rank 0 - Epoch 100/200 loss: -2.984290599822998
Rank 0 - Epoch 110/200 loss: -3.0882318019866943
Rank 0 - Epoch 120/200 loss: -3.1518614292144775
Rank 0 - Epoch 130/200 loss: -3.193242311477661
Rank 0 - Epoch 140/200 loss: -3.2217626571655273
Rank 0 - Epoch 150/200 loss: -3.2419559955596924
Rank 0 - Epoch 160/200 loss: -3.2575488090515137
Rank 0 - Epoch 170/200 loss: -3.2689285278320312
Rank 0 - Epoch 180/200 loss: -3.278252124786377
Rank 0 - Epoch 190/200 loss: -3.2855000495910645
Rank 0 - Epoch 200/200 loss: -3.292078971862793
Training complete.
[92mRank 0 - Testing RMSE: 2.4977[0m
[92mRank: 0, Lengthscale: [[0.60688025 0.39285874]] [0m
[92mRank: 0, Outputscale: 1.7209962606430054 [0m
[92mRank: 0, Noise: 0.00011122102296212688 [0m
Run 10 completed successfully
Running cGP 1 with agents: 121
decADMM initialized with rho: 0.85, max_iter: 5, lr: 0.0001, rank: 0, world_size: 121
Rank 0 - Epoch 2/200 loss: 0.9540190100669861
Rank 0 - Epoch 10/200 loss: 0.9502301812171936
Rank 0 - Epoch 20/200 loss: 0.9455096125602722
Rank 0 - Epoch 30/200 loss: 0.940807580947876
Rank 0 - Epoch 40/200 loss: 0.9361268281936646
Rank 0 - Epoch 50/200 loss: 0.9314692616462708
Rank 0 - Epoch 60/200 loss: 0.9268376231193542
Rank 0 - Epoch 70/200 loss: 0.9222338795661926
Rank 0 - Epoch 80/200 loss: 0.9176613688468933
Rank 0 - Epoch 90/200 loss: 0.913122296333313
Rank 0 - Epoch 100/200 loss: 0.9086199998855591
Rank 0 - Epoch 110/200 loss: 0.9041572213172913
Rank 0 - Epoch 120/200 loss: 0.8997376561164856
Rank 0 - Epoch 130/200 loss: 0.8953644633293152
Rank 0 - Epoch 140/200 loss: 0.8910413384437561
Rank 0 - Epoch 150/200 loss: 0.8867720365524292
Rank 0 - Epoch 160/200 loss: 0.8825609683990479
Rank 0 - Epoch 170/200 loss: 0.8784120082855225
Rank 0 - Epoch 180/200 loss: 0.874329686164856
Rank 0 - Epoch 190/200 loss: 0.8703189492225647
Rank 0 - Epoch 200/200 loss: 0.866384744644165
Training complete.
[92mRank 0 - Testing RMSE: 3.8006[0m
[92mRank: 0, Lengthscale: [[0.53504163 0.5376022 ]] [0m
[92mRank: 0, Outputscale: 0.5433241724967957 [0m
[92mRank: 0, Noise: 0.5230584144592285 [0m
Run 1 completed successfully
Running cGP 2 with agents: 121
decADMM initialized with rho: 0.85, max_iter: 5, lr: 0.0001, rank: 0, world_size: 121
Rank 0 - Epoch 2/200 loss: 0.9540190100669861
Rank 0 - Epoch 10/200 loss: 0.9502301812171936
Rank 0 - Epoch 20/200 loss: 0.9455096125602722
Rank 0 - Epoch 30/200 loss: 0.940807580947876
Rank 0 - Epoch 40/200 loss: 0.9361268281936646
Rank 0 - Epoch 50/200 loss: 0.9314692616462708
Rank 0 - Epoch 60/200 loss: 0.9268376231193542
Rank 0 - Epoch 70/200 loss: 0.9222338795661926
Rank 0 - Epoch 80/200 loss: 0.9176613688468933
Rank 0 - Epoch 90/200 loss: 0.913122296333313
Rank 0 - Epoch 100/200 loss: 0.9086199998855591
Rank 0 - Epoch 110/200 loss: 0.9041572213172913
Rank 0 - Epoch 120/200 loss: 0.8997376561164856
Rank 0 - Epoch 130/200 loss: 0.8953644633293152
Rank 0 - Epoch 140/200 loss: 0.8910413384437561
Rank 0 - Epoch 150/200 loss: 0.8867720365524292
Rank 0 - Epoch 160/200 loss: 0.8825609683990479
Rank 0 - Epoch 170/200 loss: 0.8784120082855225
Rank 0 - Epoch 180/200 loss: 0.874329686164856
Rank 0 - Epoch 190/200 loss: 0.8703189492225647
Rank 0 - Epoch 200/200 loss: 0.866384744644165
Training complete.
[92mRank 0 - Testing RMSE: 3.8006[0m
[92mRank: 0, Lengthscale: [[0.53504163 0.5376022 ]] [0m
[92mRank: 0, Outputscale: 0.5433241724967957 [0m
[92mRank: 0, Noise: 0.5230584144592285 [0m
Run 2 completed successfully
Running cGP 3 with agents: 121
decADMM initialized with rho: 0.85, max_iter: 5, lr: 0.0001, rank: 0, world_size: 121
Rank 0 - Epoch 2/200 loss: 0.9540190100669861
Rank 0 - Epoch 10/200 loss: 0.9502301812171936
Rank 0 - Epoch 20/200 loss: 0.9455096125602722
Rank 0 - Epoch 30/200 loss: 0.940807580947876
Rank 0 - Epoch 40/200 loss: 0.9361268281936646
Rank 0 - Epoch 50/200 loss: 0.9314692616462708
Rank 0 - Epoch 60/200 loss: 0.9268376231193542
Rank 0 - Epoch 70/200 loss: 0.9222338795661926
Rank 0 - Epoch 80/200 loss: 0.9176613688468933
Rank 0 - Epoch 90/200 loss: 0.913122296333313
Rank 0 - Epoch 100/200 loss: 0.9086199998855591
Rank 0 - Epoch 110/200 loss: 0.9041572213172913
Rank 0 - Epoch 120/200 loss: 0.8997376561164856
Rank 0 - Epoch 130/200 loss: 0.8953644633293152
Rank 0 - Epoch 140/200 loss: 0.8910413384437561
Rank 0 - Epoch 150/200 loss: 0.8867720365524292
Rank 0 - Epoch 160/200 loss: 0.8825609683990479
Rank 0 - Epoch 170/200 loss: 0.8784120082855225
Rank 0 - Epoch 180/200 loss: 0.874329686164856
Rank 0 - Epoch 190/200 loss: 0.8703189492225647
Rank 0 - Epoch 200/200 loss: 0.866384744644165
Training complete.
[92mRank 0 - Testing RMSE: 3.8006[0m
[92mRank: 0, Lengthscale: [[0.53504163 0.5376022 ]] [0m
[92mRank: 0, Outputscale: 0.5433241724967957 [0m
[92mRank: 0, Noise: 0.5230584144592285 [0m
Run 3 completed successfully
Running cGP 4 with agents: 121
decADMM initialized with rho: 0.85, max_iter: 5, lr: 0.0001, rank: 0, world_size: 121
Rank 0 - Epoch 2/200 loss: 0.9540190100669861
Rank 0 - Epoch 10/200 loss: 0.9502301812171936
Rank 0 - Epoch 20/200 loss: 0.9455096125602722
Rank 0 - Epoch 30/200 loss: 0.940807580947876
Rank 0 - Epoch 40/200 loss: 0.9361268281936646
Rank 0 - Epoch 50/200 loss: 0.9314692616462708
Rank 0 - Epoch 60/200 loss: 0.9268376231193542
Rank 0 - Epoch 70/200 loss: 0.9222338795661926
Rank 0 - Epoch 80/200 loss: 0.9176613688468933
Rank 0 - Epoch 90/200 loss: 0.913122296333313
Rank 0 - Epoch 100/200 loss: 0.9086199998855591
Rank 0 - Epoch 110/200 loss: 0.9041572213172913
Rank 0 - Epoch 120/200 loss: 0.8997376561164856
Rank 0 - Epoch 130/200 loss: 0.8953644633293152
Rank 0 - Epoch 140/200 loss: 0.8910413384437561
Rank 0 - Epoch 150/200 loss: 0.8867720365524292
Rank 0 - Epoch 160/200 loss: 0.8825609683990479
Rank 0 - Epoch 170/200 loss: 0.8784120082855225
Rank 0 - Epoch 180/200 loss: 0.874329686164856
Rank 0 - Epoch 190/200 loss: 0.8703189492225647
Rank 0 - Epoch 200/200 loss: 0.866384744644165
Training complete.
[92mRank 0 - Testing RMSE: 3.8006[0m
[92mRank: 0, Lengthscale: [[0.53504163 0.5376022 ]] [0m
[92mRank: 0, Outputscale: 0.5433241724967957 [0m
[92mRank: 0, Noise: 0.5230584144592285 [0m
Run 4 completed successfully
Running cGP 5 with agents: 121
decADMM initialized with rho: 0.85, max_iter: 5, lr: 0.0001, rank: 0, world_size: 121
Rank 0 - Epoch 2/200 loss: 0.9540190100669861
Rank 0 - Epoch 10/200 loss: 0.9502301812171936
Rank 0 - Epoch 20/200 loss: 0.9455096125602722
Rank 0 - Epoch 30/200 loss: 0.940807580947876
Rank 0 - Epoch 40/200 loss: 0.9361268281936646
Rank 0 - Epoch 50/200 loss: 0.9314692616462708
Rank 0 - Epoch 60/200 loss: 0.9268376231193542
Rank 0 - Epoch 70/200 loss: 0.9222338795661926
Rank 0 - Epoch 80/200 loss: 0.9176613688468933
Rank 0 - Epoch 90/200 loss: 0.913122296333313
Rank 0 - Epoch 100/200 loss: 0.9086199998855591
Rank 0 - Epoch 110/200 loss: 0.9041572213172913
Rank 0 - Epoch 120/200 loss: 0.8997376561164856
Rank 0 - Epoch 130/200 loss: 0.8953644633293152
Rank 0 - Epoch 140/200 loss: 0.8910413384437561
Rank 0 - Epoch 150/200 loss: 0.8867720365524292
Rank 0 - Epoch 160/200 loss: 0.8825609683990479
Rank 0 - Epoch 170/200 loss: 0.8784120082855225
Rank 0 - Epoch 180/200 loss: 0.874329686164856
Rank 0 - Epoch 190/200 loss: 0.8703189492225647
Rank 0 - Epoch 200/200 loss: 0.866384744644165
Training complete.
[92mRank 0 - Testing RMSE: 3.8006[0m
[92mRank: 0, Lengthscale: [[0.53504163 0.5376022 ]] [0m
[92mRank: 0, Outputscale: 0.5433241724967957 [0m
[92mRank: 0, Noise: 0.5230584144592285 [0m
Run 5 completed successfully
Running cGP 6 with agents: 121
decADMM initialized with rho: 0.85, max_iter: 5, lr: 0.0001, rank: 0, world_size: 121
Rank 0 - Epoch 2/200 loss: 0.9540190100669861
Rank 0 - Epoch 10/200 loss: 0.9502301812171936
Rank 0 - Epoch 20/200 loss: 0.9455096125602722
Rank 0 - Epoch 30/200 loss: 0.940807580947876
Rank 0 - Epoch 40/200 loss: 0.9361268281936646
Rank 0 - Epoch 50/200 loss: 0.9314692616462708
Rank 0 - Epoch 60/200 loss: 0.9268376231193542
Rank 0 - Epoch 70/200 loss: 0.9222338795661926
Rank 0 - Epoch 80/200 loss: 0.9176613688468933
Rank 0 - Epoch 90/200 loss: 0.913122296333313
Rank 0 - Epoch 100/200 loss: 0.9086199998855591
Rank 0 - Epoch 110/200 loss: 0.9041572213172913
Rank 0 - Epoch 120/200 loss: 0.8997376561164856
Rank 0 - Epoch 130/200 loss: 0.8953644633293152
Rank 0 - Epoch 140/200 loss: 0.8910413384437561
Rank 0 - Epoch 150/200 loss: 0.8867720365524292
Rank 0 - Epoch 160/200 loss: 0.8825609683990479
Rank 0 - Epoch 170/200 loss: 0.8784120082855225
Rank 0 - Epoch 180/200 loss: 0.874329686164856
Rank 0 - Epoch 190/200 loss: 0.8703189492225647
Rank 0 - Epoch 200/200 loss: 0.866384744644165
Training complete.
[92mRank 0 - Testing RMSE: 3.8006[0m
[92mRank: 0, Lengthscale: [[0.53504163 0.5376022 ]] [0m
[92mRank: 0, Outputscale: 0.5433241724967957 [0m
[92mRank: 0, Noise: 0.5230584144592285 [0m
Run 6 completed successfully
Running cGP 7 with agents: 121
decADMM initialized with rho: 0.85, max_iter: 5, lr: 0.0001, rank: 0, world_size: 121
Rank 0 - Epoch 2/200 loss: 0.9540190100669861
Rank 0 - Epoch 10/200 loss: 0.9502301812171936
Rank 0 - Epoch 20/200 loss: 0.9455096125602722
Rank 0 - Epoch 30/200 loss: 0.940807580947876
Rank 0 - Epoch 40/200 loss: 0.9361268281936646
Rank 0 - Epoch 50/200 loss: 0.9314692616462708
Rank 0 - Epoch 60/200 loss: 0.9268376231193542
Rank 0 - Epoch 70/200 loss: 0.9222338795661926
Rank 0 - Epoch 80/200 loss: 0.9176613688468933
Rank 0 - Epoch 90/200 loss: 0.913122296333313
Rank 0 - Epoch 100/200 loss: 0.9086199998855591
Rank 0 - Epoch 110/200 loss: 0.9041572213172913
Rank 0 - Epoch 120/200 loss: 0.8997376561164856
Rank 0 - Epoch 130/200 loss: 0.8953644633293152
Rank 0 - Epoch 140/200 loss: 0.8910413384437561
Rank 0 - Epoch 150/200 loss: 0.8867720365524292
Rank 0 - Epoch 160/200 loss: 0.8825609683990479
Rank 0 - Epoch 170/200 loss: 0.8784120082855225
Rank 0 - Epoch 180/200 loss: 0.874329686164856
Rank 0 - Epoch 190/200 loss: 0.8703189492225647
Rank 0 - Epoch 200/200 loss: 0.866384744644165
Training complete.
[92mRank 0 - Testing RMSE: 3.8006[0m
[92mRank: 0, Lengthscale: [[0.53504163 0.5376022 ]] [0m
[92mRank: 0, Outputscale: 0.5433241724967957 [0m
[92mRank: 0, Noise: 0.5230584144592285 [0m
Run 7 completed successfully
Running cGP 8 with agents: 121
decADMM initialized with rho: 0.85, max_iter: 5, lr: 0.0001, rank: 0, world_size: 121
Rank 0 - Epoch 2/200 loss: 0.9540190100669861
Rank 0 - Epoch 10/200 loss: 0.9502301812171936
Rank 0 - Epoch 20/200 loss: 0.9455096125602722
Rank 0 - Epoch 30/200 loss: 0.940807580947876
Rank 0 - Epoch 40/200 loss: 0.9361268281936646
Rank 0 - Epoch 50/200 loss: 0.9314692616462708
Rank 0 - Epoch 60/200 loss: 0.9268376231193542
Rank 0 - Epoch 70/200 loss: 0.9222338795661926
Rank 0 - Epoch 80/200 loss: 0.9176613688468933
Rank 0 - Epoch 90/200 loss: 0.913122296333313
Rank 0 - Epoch 100/200 loss: 0.9086199998855591
Rank 0 - Epoch 110/200 loss: 0.9041572213172913
Rank 0 - Epoch 120/200 loss: 0.8997376561164856
Rank 0 - Epoch 130/200 loss: 0.8953644633293152
Rank 0 - Epoch 140/200 loss: 0.8910413384437561
Rank 0 - Epoch 150/200 loss: 0.8867720365524292
Rank 0 - Epoch 160/200 loss: 0.8825609683990479
Rank 0 - Epoch 170/200 loss: 0.8784120082855225
Rank 0 - Epoch 180/200 loss: 0.874329686164856
Rank 0 - Epoch 190/200 loss: 0.8703189492225647
Rank 0 - Epoch 200/200 loss: 0.866384744644165
Training complete.
[92mRank 0 - Testing RMSE: 3.8006[0m
[92mRank: 0, Lengthscale: [[0.53504163 0.5376022 ]] [0m
[92mRank: 0, Outputscale: 0.5433241724967957 [0m
[92mRank: 0, Noise: 0.5230584144592285 [0m
Run 8 completed successfully
Running cGP 9 with agents: 121
decADMM initialized with rho: 0.85, max_iter: 5, lr: 0.0001, rank: 0, world_size: 121
Rank 0 - Epoch 2/200 loss: 0.9540190100669861
Rank 0 - Epoch 10/200 loss: 0.9502301812171936
Rank 0 - Epoch 20/200 loss: 0.9455096125602722
Rank 0 - Epoch 30/200 loss: 0.940807580947876
Rank 0 - Epoch 40/200 loss: 0.9361268281936646
Rank 0 - Epoch 50/200 loss: 0.9314692616462708
Rank 0 - Epoch 60/200 loss: 0.9268376231193542
Rank 0 - Epoch 70/200 loss: 0.9222338795661926
Rank 0 - Epoch 80/200 loss: 0.9176613688468933
Rank 0 - Epoch 90/200 loss: 0.913122296333313
Rank 0 - Epoch 100/200 loss: 0.9086199998855591
Rank 0 - Epoch 110/200 loss: 0.9041572213172913
Rank 0 - Epoch 120/200 loss: 0.8997376561164856
Rank 0 - Epoch 130/200 loss: 0.8953644633293152
Rank 0 - Epoch 140/200 loss: 0.8910413384437561
Rank 0 - Epoch 150/200 loss: 0.8867720365524292
Rank 0 - Epoch 160/200 loss: 0.8825609683990479
Rank 0 - Epoch 170/200 loss: 0.8784120082855225
Rank 0 - Epoch 180/200 loss: 0.874329686164856
Rank 0 - Epoch 190/200 loss: 0.8703189492225647
Rank 0 - Epoch 200/200 loss: 0.866384744644165
Training complete.
[92mRank 0 - Testing RMSE: 3.8006[0m
[92mRank: 0, Lengthscale: [[0.53504163 0.5376022 ]] [0m
[92mRank: 0, Outputscale: 0.5433241724967957 [0m
[92mRank: 0, Noise: 0.5230584144592285 [0m
Run 9 completed successfully
Running cGP 10 with agents: 121
decADMM initialized with rho: 0.85, max_iter: 5, lr: 0.0001, rank: 0, world_size: 121
Rank 0 - Epoch 2/200 loss: 0.9540190100669861
Rank 0 - Epoch 10/200 loss: 0.9502301812171936
Rank 0 - Epoch 20/200 loss: 0.9455096125602722
Rank 0 - Epoch 30/200 loss: 0.940807580947876
Rank 0 - Epoch 40/200 loss: 0.9361268281936646
Rank 0 - Epoch 50/200 loss: 0.9314692616462708
Rank 0 - Epoch 60/200 loss: 0.9268376231193542
Rank 0 - Epoch 70/200 loss: 0.9222338795661926
Rank 0 - Epoch 80/200 loss: 0.9176613688468933
Rank 0 - Epoch 90/200 loss: 0.913122296333313
Rank 0 - Epoch 100/200 loss: 0.9086199998855591
Rank 0 - Epoch 110/200 loss: 0.9041572213172913
Rank 0 - Epoch 120/200 loss: 0.8997376561164856
Rank 0 - Epoch 130/200 loss: 0.8953644633293152
Rank 0 - Epoch 140/200 loss: 0.8910413384437561
Rank 0 - Epoch 150/200 loss: 0.8867720365524292
Rank 0 - Epoch 160/200 loss: 0.8825609683990479
Rank 0 - Epoch 170/200 loss: 0.8784120082855225
Rank 0 - Epoch 180/200 loss: 0.874329686164856
Rank 0 - Epoch 190/200 loss: 0.8703189492225647
Rank 0 - Epoch 200/200 loss: 0.866384744644165
Training complete.
[92mRank 0 - Testing RMSE: 3.8006[0m
[92mRank: 0, Lengthscale: [[0.53504163 0.5376022 ]] [0m
[92mRank: 0, Outputscale: 0.5433241724967957 [0m
[92mRank: 0, Noise: 0.5230584144592285 [0m
Run 10 completed successfully
