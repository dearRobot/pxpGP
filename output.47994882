Job started on: g005
SLURM_JOB_ID: 47994882
Running pxpGP 1 with agents: 16
[92mRank 0 - sparse dataset size is: 126, local dataset: torch.Size([2025, 2]), [0m
[92mRank 0 - Training local sparse GP model with 2025 samples[0m
Epoch 1/200 - Loss: 2.410
Epoch 11/200 - Loss: 0.664
Converged at epoch 19 with loss -0.011
[92mRank 0 - Lengthscale: [[0.53368086 0.49515194]] [0m
[92mRank 0 - Outputscale: 1.8684595823287964 [0m
[92mRank 0 - Noise: 0.14094892144203186 [0m
Rank 0 - Augmented dataset size: 4041
Rank 0: After warm start model parameters:
Rank: 0, Lengthscale: [[0.5336809  0.49515194]]
Rank: 0, Outputscale: 1.8684595823287964
Rank: 0, Noise: 0.14094892144203186
decpxADMM initialized with rho: 0.85, lip: 1.0, tol_abs: 1e-05, tol_rel: 0.001, rank: 0, world_size: 16
[92mRank 0 - Training global model with dec-pxADMM optimizer[0m
rank 0, epoch 9, loss: 0.4773746430873871, rho: 0.2125, lip: 1.0000
rank 0, epoch 19, loss: 0.483997642993927, rho: 0.1062, lip: 1.0000
Rank 0 - Training time: 30.33 seconds
[92mRank 0 - Testing RMSE: 0.3773[0m
[92mRank: 0, Lengthscale: [[0.4816035  0.23688078]] [0m
[92mRank: 0, Outputscale: 1.7083351612091064 [0m
[92mRank: 0, Noise: 0.12271536141633987 [0m
Run 1 completed successfully
Running pxpGP 2 with agents: 16
[92mRank 0 - sparse dataset size is: 126, local dataset: torch.Size([2025, 2]), [0m
[92mRank 0 - Training local sparse GP model with 2025 samples[0m
Epoch 1/200 - Loss: 2.373
Epoch 11/200 - Loss: 0.736
Converged at epoch 20 with loss -0.066
[92mRank 0 - Lengthscale: [[0.30955964 0.35443005]] [0m
[92mRank 0 - Outputscale: 1.9880293607711792 [0m
[92mRank 0 - Noise: 0.12208489328622818 [0m
Rank 0 - Augmented dataset size: 4041
Rank 0: After warm start model parameters:
Rank: 0, Lengthscale: [[0.3095596  0.35443008]]
Rank: 0, Outputscale: 1.9880293607711792
Rank: 0, Noise: 0.12208489328622818
decpxADMM initialized with rho: 0.85, lip: 1.0, tol_abs: 1e-05, tol_rel: 0.001, rank: 0, world_size: 16
[92mRank 0 - Training global model with dec-pxADMM optimizer[0m
rank 0, epoch 9, loss: 0.3197266459465027, rho: 0.2125, lip: 1.0000
rank 0, epoch 19, loss: 0.31923702359199524, rho: 0.1062, lip: 1.0000
Rank 0 - Training time: 32.78 seconds
[92mRank 0 - Testing RMSE: 0.3909[0m
[92mRank: 0, Lengthscale: [[0.4261559  0.28646442]] [0m
[92mRank: 0, Outputscale: 1.7002438306808472 [0m
[92mRank: 0, Noise: 0.08723139762878418 [0m
Run 2 completed successfully
Running pxpGP 3 with agents: 16
[92mRank 0 - sparse dataset size is: 126, local dataset: torch.Size([2025, 2]), [0m
[92mRank 0 - Training local sparse GP model with 2025 samples[0m
Epoch 1/200 - Loss: 2.790
Epoch 11/200 - Loss: 0.722
Converged at epoch 20 with loss -0.018
[92mRank 0 - Lengthscale: [[0.22270142 0.41948318]] [0m
[92mRank 0 - Outputscale: 2.0913450717926025 [0m
[92mRank 0 - Noise: 0.12841445207595825 [0m
Rank 0 - Augmented dataset size: 4041
Rank 0: After warm start model parameters:
Rank: 0, Lengthscale: [[0.22270142 0.41948318]]
Rank: 0, Outputscale: 2.0913450717926025
Rank: 0, Noise: 0.12841445207595825
decpxADMM initialized with rho: 0.85, lip: 1.0, tol_abs: 1e-05, tol_rel: 0.001, rank: 0, world_size: 16
[92mRank 0 - Training global model with dec-pxADMM optimizer[0m
rank 0, epoch 9, loss: 0.4260734021663666, rho: 0.4250, lip: 1.0000
rank 0, epoch 19, loss: 0.4349013864994049, rho: 0.2125, lip: 1.0000
Rank 0 - Training time: 30.91 seconds
[92mRank 0 - Testing RMSE: 0.3616[0m
[92mRank: 0, Lengthscale: [[0.26884797 0.3491887 ]] [0m
[92mRank: 0, Outputscale: 1.545224905014038 [0m
[92mRank: 0, Noise: 0.11004676669836044 [0m
Run 3 completed successfully
Running pxpGP 4 with agents: 16
[92mRank 0 - sparse dataset size is: 126, local dataset: torch.Size([2025, 2]), [0m
[92mRank 0 - Training local sparse GP model with 2025 samples[0m
Epoch 1/200 - Loss: 2.200
Epoch 11/200 - Loss: 0.652
Converged at epoch 19 with loss -0.021
[92mRank 0 - Lengthscale: [[0.4242457 0.4747936]] [0m
[92mRank 0 - Outputscale: 1.7585254907608032 [0m
[92mRank 0 - Noise: 0.13437111675739288 [0m
Rank 0 - Augmented dataset size: 4041
Rank 0: After warm start model parameters:
Rank: 0, Lengthscale: [[0.42424574 0.4747936 ]]
Rank: 0, Outputscale: 1.7585254907608032
Rank: 0, Noise: 0.13437111675739288
decpxADMM initialized with rho: 0.85, lip: 1.0, tol_abs: 1e-05, tol_rel: 0.001, rank: 0, world_size: 16
[92mRank 0 - Training global model with dec-pxADMM optimizer[0m
rank 0, epoch 9, loss: 0.279436320066452, rho: 0.2125, lip: 1.0000
rank 0, epoch 19, loss: 0.29194214940071106, rho: 0.1062, lip: 1.0000
Rank 0 - Training time: 30.47 seconds
[92mRank 0 - Testing RMSE: 0.3240[0m
[92mRank: 0, Lengthscale: [[0.43957856 0.30061907]] [0m
[92mRank: 0, Outputscale: 0.96451735496521 [0m
[92mRank: 0, Noise: 0.08326027542352676 [0m
Run 4 completed successfully
Running pxpGP 5 with agents: 16
[92mRank 0 - sparse dataset size is: 126, local dataset: torch.Size([2025, 2]), [0m
[92mRank 0 - Training local sparse GP model with 2025 samples[0m
Epoch 1/200 - Loss: 2.009
Epoch 11/200 - Loss: 0.660
Converged at epoch 19 with loss -0.023
[92mRank 0 - Lengthscale: [[0.36277562 0.40483496]] [0m
[92mRank 0 - Outputscale: 1.557669758796692 [0m
[92mRank 0 - Noise: 0.13582542538642883 [0m
Rank 0 - Augmented dataset size: 4041
Rank 0: After warm start model parameters:
Rank: 0, Lengthscale: [[0.36277565 0.40483496]]
Rank: 0, Outputscale: 1.557669758796692
Rank: 0, Noise: 0.13582542538642883
decpxADMM initialized with rho: 0.85, lip: 1.0, tol_abs: 1e-05, tol_rel: 0.001, rank: 0, world_size: 16
[92mRank 0 - Training global model with dec-pxADMM optimizer[0m
rank 0, epoch 9, loss: 0.3637205958366394, rho: 0.2125, lip: 1.0000
rank 0, epoch 19, loss: 0.37808871269226074, rho: 0.1062, lip: 1.0000
Rank 0 - Training time: 32.44 seconds
[92mRank 0 - Testing RMSE: 0.3358[0m
[92mRank: 0, Lengthscale: [[0.35174164 0.27225512]] [0m
[92mRank: 0, Outputscale: 1.7548744678497314 [0m
[92mRank: 0, Noise: 0.09564083814620972 [0m
Run 5 completed successfully
Running pxpGP 6 with agents: 16
[92mRank 0 - sparse dataset size is: 126, local dataset: torch.Size([2025, 2]), [0m
[92mRank 0 - Training local sparse GP model with 2025 samples[0m
Epoch 1/200 - Loss: 2.032
Epoch 11/200 - Loss: 0.651
Converged at epoch 19 with loss -0.010
[92mRank 0 - Lengthscale: [[0.41659242 0.45108175]] [0m
[92mRank 0 - Outputscale: 1.6766008138656616 [0m
[92mRank 0 - Noise: 0.1366645246744156 [0m
Rank 0 - Augmented dataset size: 4041
Rank 0: After warm start model parameters:
Rank: 0, Lengthscale: [[0.41659242 0.45108172]]
Rank: 0, Outputscale: 1.6766009330749512
Rank: 0, Noise: 0.1366645246744156
decpxADMM initialized with rho: 0.85, lip: 1.0, tol_abs: 1e-05, tol_rel: 0.001, rank: 0, world_size: 16
[92mRank 0 - Training global model with dec-pxADMM optimizer[0m
rank 0, epoch 9, loss: 0.3755265176296234, rho: 0.2125, lip: 1.0000
rank 0, epoch 19, loss: 0.39506658911705017, rho: 0.1062, lip: 1.0000
Rank 0 - Training time: 29.28 seconds
[92mRank 0 - Testing RMSE: 0.3776[0m
[92mRank: 0, Lengthscale: [[0.4081648  0.30339924]] [0m
[92mRank: 0, Outputscale: 1.0006543397903442 [0m
[92mRank: 0, Noise: 0.10380593687295914 [0m
Run 6 completed successfully
Running pxpGP 7 with agents: 16
[92mRank 0 - sparse dataset size is: 126, local dataset: torch.Size([2025, 2]), [0m
[92mRank 0 - Training local sparse GP model with 2025 samples[0m
Epoch 1/200 - Loss: 2.490
Epoch 11/200 - Loss: 0.666
Converged at epoch 20 with loss -0.068
[92mRank 0 - Lengthscale: [[0.43862852 0.44338447]] [0m
[92mRank 0 - Outputscale: 1.6020292043685913 [0m
[92mRank 0 - Noise: 0.11661959439516068 [0m
Rank 0 - Augmented dataset size: 4041
Rank 0: After warm start model parameters:
Rank: 0, Lengthscale: [[0.43862852 0.4433844 ]]
Rank: 0, Outputscale: 1.6020292043685913
Rank: 0, Noise: 0.11661959439516068
decpxADMM initialized with rho: 0.85, lip: 1.0, tol_abs: 1e-05, tol_rel: 0.001, rank: 0, world_size: 16
[92mRank 0 - Training global model with dec-pxADMM optimizer[0m
rank 0, epoch 9, loss: 0.4079153537750244, rho: 0.2125, lip: 1.0000
rank 0, epoch 19, loss: 0.40498635172843933, rho: 0.0531, lip: 1.0000
Rank 0 - Training time: 30.50 seconds
[92mRank 0 - Testing RMSE: 0.2950[0m
[92mRank: 0, Lengthscale: [[0.41025797 0.31472397]] [0m
[92mRank: 0, Outputscale: 1.5443158149719238 [0m
[92mRank: 0, Noise: 0.09894031286239624 [0m
Run 7 completed successfully
Running pxpGP 8 with agents: 16
[92mRank 0 - sparse dataset size is: 126, local dataset: torch.Size([2025, 2]), [0m
[92mRank 0 - Training local sparse GP model with 2025 samples[0m
Epoch 1/200 - Loss: 2.318
Epoch 11/200 - Loss: 0.651
Epoch 21/200 - Loss: -0.206
Converged at epoch 21 with loss -0.206
[92mRank 0 - Lengthscale: [[0.5153527  0.38237345]] [0m
[92mRank 0 - Outputscale: 1.657869815826416 [0m
[92mRank 0 - Noise: 0.08894588053226471 [0m
Rank 0 - Augmented dataset size: 4041
Rank 0: After warm start model parameters:
Rank: 0, Lengthscale: [[0.5153527  0.38237345]]
Rank: 0, Outputscale: 1.6578699350357056
Rank: 0, Noise: 0.08894588053226471
decpxADMM initialized with rho: 0.85, lip: 1.0, tol_abs: 1e-05, tol_rel: 0.001, rank: 0, world_size: 16
[92mRank 0 - Training global model with dec-pxADMM optimizer[0m
rank 0, epoch 9, loss: 0.41389206051826477, rho: 0.2125, lip: 1.0000
rank 0, epoch 19, loss: 0.422769159078598, rho: 0.1062, lip: 1.0000
Rank 0 - Training time: 27.89 seconds
[92mRank 0 - Testing RMSE: 0.3248[0m
[92mRank: 0, Lengthscale: [[0.5218409 0.2652181]] [0m
[92mRank: 0, Outputscale: 0.9762188196182251 [0m
[92mRank: 0, Noise: 0.11083529144525528 [0m
Run 8 completed successfully
Running pxpGP 9 with agents: 16
[92mRank 0 - sparse dataset size is: 126, local dataset: torch.Size([2025, 2]), [0m
[92mRank 0 - Training local sparse GP model with 2025 samples[0m
Epoch 1/200 - Loss: 1.959
Epoch 11/200 - Loss: 0.642
Converged at epoch 20 with loss -0.015
[92mRank 0 - Lengthscale: [[0.71050966 0.28136054]] [0m
[92mRank 0 - Outputscale: 1.6634442806243896 [0m
[92mRank 0 - Noise: 0.13353216648101807 [0m
Rank 0 - Augmented dataset size: 4041
Rank 0: After warm start model parameters:
Rank: 0, Lengthscale: [[0.71050966 0.28136054]]
Rank: 0, Outputscale: 1.6634442806243896
Rank: 0, Noise: 0.13353216648101807
decpxADMM initialized with rho: 0.85, lip: 1.0, tol_abs: 1e-05, tol_rel: 0.001, rank: 0, world_size: 16
[92mRank 0 - Training global model with dec-pxADMM optimizer[0m
rank 0, epoch 9, loss: 0.3278256356716156, rho: 0.2125, lip: 1.0000
rank 0, epoch 19, loss: 0.33841389417648315, rho: 0.0531, lip: 1.0000
Rank 0 - Training time: 33.71 seconds
[92mRank 0 - Testing RMSE: 0.2955[0m
[92mRank: 0, Lengthscale: [[0.41112727 0.26923642]] [0m
[92mRank: 0, Outputscale: 1.7984578609466553 [0m
[92mRank: 0, Noise: 0.08624611049890518 [0m
Run 9 completed successfully
Running pxpGP 10 with agents: 16
[92mRank 0 - sparse dataset size is: 126, local dataset: torch.Size([2025, 2]), [0m
[92mRank 0 - Training local sparse GP model with 2025 samples[0m
Epoch 1/200 - Loss: 2.915
Epoch 11/200 - Loss: 0.650
Converged at epoch 19 with loss -0.038
[92mRank 0 - Lengthscale: [[0.4649254 0.4094942]] [0m
[92mRank 0 - Outputscale: 1.6705846786499023 [0m
[92mRank 0 - Noise: 0.13338491320610046 [0m
Rank 0 - Augmented dataset size: 4041
Rank 0: After warm start model parameters:
Rank: 0, Lengthscale: [[0.46492538 0.40949416]]
Rank: 0, Outputscale: 1.6705846786499023
Rank: 0, Noise: 0.13338491320610046
decpxADMM initialized with rho: 0.85, lip: 1.0, tol_abs: 1e-05, tol_rel: 0.001, rank: 0, world_size: 16
[92mRank 0 - Training global model with dec-pxADMM optimizer[0m
rank 0, epoch 9, loss: 0.37782999873161316, rho: 0.2125, lip: 1.0000
rank 0, epoch 19, loss: 0.3872130811214447, rho: 0.1062, lip: 1.0000
Rank 0 - Training time: 29.89 seconds
[92mRank 0 - Testing RMSE: 0.3248[0m
[92mRank: 0, Lengthscale: [[0.49180853 0.31527236]] [0m
[92mRank: 0, Outputscale: 2.313913583755493 [0m
[92mRank: 0, Noise: 0.11325839906930923 [0m
Run 10 completed successfully
Running gapxGP 1 with agents: 16
decpxADMM initialized with rho: 0.75, lip: 1.0, tol_abs: 1e-05, tol_rel: 0.001, rank: 0, world_size: 16
Rank 0 - Epoch 2/24 loss: 0.7969507575035095
Rank 0 - Epoch 10/24 loss: 0.5188834071159363
Rank 0 - Epoch 20/24 loss: 0.059218600392341614
[92mRank 0 - Testing RMSE: 0.0818[0m
[92mRank: 0, Lengthscale: [[0.6250491  0.43569845]] [0m
[92mRank: 0, Outputscale: 0.8095657229423523 [0m
[92mRank: 0, Noise: 0.09323952347040176 [0m
Run 1 completed successfully
Running gapxGP 2 with agents: 16
decpxADMM initialized with rho: 0.75, lip: 1.0, tol_abs: 1e-05, tol_rel: 0.001, rank: 0, world_size: 16
Rank 0 - Epoch 2/24 loss: 0.7951911091804504
Rank 0 - Epoch 10/24 loss: 0.5189072489738464
Rank 0 - Epoch 20/24 loss: 0.06066679581999779
[92mRank 0 - Testing RMSE: 0.0843[0m
[92mRank: 0, Lengthscale: [[0.62315786 0.438748  ]] [0m
[92mRank: 0, Outputscale: 0.8097972273826599 [0m
[92mRank: 0, Noise: 0.093157559633255 [0m
Run 2 completed successfully
Running gapxGP 3 with agents: 16
decpxADMM initialized with rho: 0.75, lip: 1.0, tol_abs: 1e-05, tol_rel: 0.001, rank: 0, world_size: 16
Rank 0 - Epoch 2/24 loss: 0.7960806488990784
Rank 0 - Epoch 10/24 loss: 0.5176767706871033
Rank 0 - Epoch 20/24 loss: 0.061469435691833496
[92mRank 0 - Testing RMSE: 0.0868[0m
[92mRank: 0, Lengthscale: [[0.6240202  0.44036245]] [0m
[92mRank: 0, Outputscale: 0.8087257146835327 [0m
[92mRank: 0, Noise: 0.09330730885267258 [0m
Run 3 completed successfully
Running gapxGP 4 with agents: 16
decpxADMM initialized with rho: 0.75, lip: 1.0, tol_abs: 1e-05, tol_rel: 0.001, rank: 0, world_size: 16
Rank 0 - Epoch 2/24 loss: 0.7936350703239441
Rank 0 - Epoch 10/24 loss: 0.5193654894828796
Rank 0 - Epoch 20/24 loss: 0.06442668288946152
[92mRank 0 - Testing RMSE: 0.0889[0m
[92mRank: 0, Lengthscale: [[0.6256564  0.44111204]] [0m
[92mRank: 0, Outputscale: 0.8074918985366821 [0m
[92mRank: 0, Noise: 0.0937451496720314 [0m
Run 4 completed successfully
Running gapxGP 5 with agents: 16
decpxADMM initialized with rho: 0.75, lip: 1.0, tol_abs: 1e-05, tol_rel: 0.001, rank: 0, world_size: 16
Rank 0 - Epoch 2/24 loss: 0.796775758266449
Rank 0 - Epoch 10/24 loss: 0.5165895223617554
Rank 0 - Epoch 20/24 loss: 0.05942320451140404
[92mRank 0 - Testing RMSE: 0.0877[0m
[92mRank: 0, Lengthscale: [[0.6253163  0.43968666]] [0m
[92mRank: 0, Outputscale: 0.8099268078804016 [0m
[92mRank: 0, Noise: 0.09284765273332596 [0m
Run 5 completed successfully
Running gapxGP 6 with agents: 16
decpxADMM initialized with rho: 0.75, lip: 1.0, tol_abs: 1e-05, tol_rel: 0.001, rank: 0, world_size: 16
Rank 0 - Epoch 2/24 loss: 0.7933727502822876
Rank 0 - Epoch 10/24 loss: 0.5161004066467285
Rank 0 - Epoch 20/24 loss: 0.05720629543066025
[92mRank 0 - Testing RMSE: 0.0854[0m
[92mRank: 0, Lengthscale: [[0.6271266  0.44085217]] [0m
[92mRank: 0, Outputscale: 0.8076505064964294 [0m
[92mRank: 0, Noise: 0.09309113025665283 [0m
Run 6 completed successfully
Running gapxGP 7 with agents: 16
decpxADMM initialized with rho: 0.75, lip: 1.0, tol_abs: 1e-05, tol_rel: 0.001, rank: 0, world_size: 16
Rank 0 - Epoch 2/24 loss: 0.7934359312057495
Rank 0 - Epoch 10/24 loss: 0.5197479724884033
Rank 0 - Epoch 20/24 loss: 0.06050154194235802
[92mRank 0 - Testing RMSE: 0.0871[0m
[92mRank: 0, Lengthscale: [[0.62488556 0.44156855]] [0m
[92mRank: 0, Outputscale: 0.8075265288352966 [0m
[92mRank: 0, Noise: 0.0934278592467308 [0m
Run 7 completed successfully
Running gapxGP 8 with agents: 16
decpxADMM initialized with rho: 0.75, lip: 1.0, tol_abs: 1e-05, tol_rel: 0.001, rank: 0, world_size: 16
Rank 0 - Epoch 2/24 loss: 0.7945823669433594
Rank 0 - Epoch 10/24 loss: 0.5190384984016418
Rank 0 - Epoch 20/24 loss: 0.06332864612340927
[92mRank 0 - Testing RMSE: 0.0921[0m
[92mRank: 0, Lengthscale: [[0.6254916  0.44077474]] [0m
[92mRank: 0, Outputscale: 0.8084114193916321 [0m
[92mRank: 0, Noise: 0.09339795261621475 [0m
Run 8 completed successfully
Running gapxGP 9 with agents: 16
decpxADMM initialized with rho: 0.75, lip: 1.0, tol_abs: 1e-05, tol_rel: 0.001, rank: 0, world_size: 16
Rank 0 - Epoch 2/24 loss: 0.7933079600334167
Rank 0 - Epoch 10/24 loss: 0.5173022150993347
Rank 0 - Epoch 20/24 loss: 0.05920238792896271
[92mRank 0 - Testing RMSE: 0.0939[0m
[92mRank: 0, Lengthscale: [[0.6251294 0.4430277]] [0m
[92mRank: 0, Outputscale: 0.8083808422088623 [0m
[92mRank: 0, Noise: 0.09331563115119934 [0m
Run 9 completed successfully
Running gapxGP 10 with agents: 16
decpxADMM initialized with rho: 0.75, lip: 1.0, tol_abs: 1e-05, tol_rel: 0.001, rank: 0, world_size: 16
Rank 0 - Epoch 2/24 loss: 0.7934983372688293
Rank 0 - Epoch 10/24 loss: 0.51666259765625
Rank 0 - Epoch 20/24 loss: 0.06037900224328041
[92mRank 0 - Testing RMSE: 0.0904[0m
[92mRank: 0, Lengthscale: [[0.6253437  0.44102785]] [0m
[92mRank: 0, Outputscale: 0.8077564239501953 [0m
[92mRank: 0, Noise: 0.09343972057104111 [0m
Run 10 completed successfully
Running apxGP 1 with agents: 16
decpxADMM initialized with rho: 0.85, lip: 1.0, tol_abs: 1e-05, tol_rel: 0.001, rank: 0, world_size: 16
Rank 0 - Epoch 2/32 loss: 0.7350082397460938
Rank 0 - Epoch 10/32 loss: 0.45897525548934937
Rank 0 - Epoch 20/32 loss: 0.0235319621860981
Rank 0 - Epoch 30/32 loss: -0.47412532567977905
Training complete.
[92mRank 0 - Testing RMSE: 2.9625[0m
[92mRank: 0, Lengthscale: [[0.6489993  0.52079093]] [0m
[92mRank: 0, Outputscale: 0.7617258429527283 [0m
[92mRank: 0, Noise: 0.04462829977273941 [0m
Run 1 completed successfully
Running apxGP 2 with agents: 16
decpxADMM initialized with rho: 0.85, lip: 1.0, tol_abs: 1e-05, tol_rel: 0.001, rank: 0, world_size: 16
Rank 0 - Epoch 2/32 loss: 0.7350084185600281
Rank 0 - Epoch 10/32 loss: 0.45897388458251953
Rank 0 - Epoch 20/32 loss: 0.023514118045568466
Rank 0 - Epoch 30/32 loss: -0.4741729497909546
Training complete.
[92mRank 0 - Testing RMSE: 2.9625[0m
[92mRank: 0, Lengthscale: [[0.64901644 0.52077276]] [0m
[92mRank: 0, Outputscale: 0.761725127696991 [0m
[92mRank: 0, Noise: 0.04462839290499687 [0m
Run 2 completed successfully
Running apxGP 3 with agents: 16
decpxADMM initialized with rho: 0.85, lip: 1.0, tol_abs: 1e-05, tol_rel: 0.001, rank: 0, world_size: 16
Rank 0 - Epoch 2/32 loss: 0.7350114583969116
Rank 0 - Epoch 10/32 loss: 0.45898541808128357
Rank 0 - Epoch 20/32 loss: 0.023607855662703514
Rank 0 - Epoch 30/32 loss: -0.4741940200328827
Training complete.
[92mRank 0 - Testing RMSE: 2.9624[0m
[92mRank: 0, Lengthscale: [[0.64908296 0.5208381 ]] [0m
[92mRank: 0, Outputscale: 0.7617087364196777 [0m
[92mRank: 0, Noise: 0.0446302592754364 [0m
Run 3 completed successfully
Running apxGP 4 with agents: 16
decpxADMM initialized with rho: 0.85, lip: 1.0, tol_abs: 1e-05, tol_rel: 0.001, rank: 0, world_size: 16
Rank 0 - Epoch 2/32 loss: 0.735016942024231
Rank 0 - Epoch 10/32 loss: 0.45897921919822693
Rank 0 - Epoch 20/32 loss: 0.023512188345193863
Rank 0 - Epoch 30/32 loss: -0.47420451045036316
Training complete.
[92mRank 0 - Testing RMSE: 2.9624[0m
[92mRank: 0, Lengthscale: [[0.64907926 0.52081406]] [0m
[92mRank: 0, Outputscale: 0.761711597442627 [0m
[92mRank: 0, Noise: 0.0446300208568573 [0m
Run 4 completed successfully
Running apxGP 5 with agents: 16
decpxADMM initialized with rho: 0.85, lip: 1.0, tol_abs: 1e-05, tol_rel: 0.001, rank: 0, world_size: 16
Rank 0 - Epoch 2/32 loss: 0.7350082397460938
Rank 0 - Epoch 10/32 loss: 0.45897966623306274
Rank 0 - Epoch 20/32 loss: 0.02350628189742565
Rank 0 - Epoch 30/32 loss: -0.47405585646629333
Training complete.
[92mRank 0 - Testing RMSE: 2.9623[0m
[92mRank: 0, Lengthscale: [[0.6491058  0.52088743]] [0m
[92mRank: 0, Outputscale: 0.7616962790489197 [0m
[92mRank: 0, Noise: 0.04463189095258713 [0m
Run 5 completed successfully
Running apxGP 6 with agents: 16
decpxADMM initialized with rho: 0.85, lip: 1.0, tol_abs: 1e-05, tol_rel: 0.001, rank: 0, world_size: 16
Rank 0 - Epoch 2/32 loss: 0.7350045442581177
Rank 0 - Epoch 10/32 loss: 0.458981990814209
Rank 0 - Epoch 20/32 loss: 0.023520266637206078
Rank 0 - Epoch 30/32 loss: -0.47419729828834534
Training complete.
[92mRank 0 - Testing RMSE: 2.9622[0m
[92mRank: 0, Lengthscale: [[0.64918154 0.5208789 ]] [0m
[92mRank: 0, Outputscale: 0.7616907954216003 [0m
[92mRank: 0, Noise: 0.04463230445981026 [0m
Run 6 completed successfully
Running apxGP 7 with agents: 16
decpxADMM initialized with rho: 0.85, lip: 1.0, tol_abs: 1e-05, tol_rel: 0.001, rank: 0, world_size: 16
Rank 0 - Epoch 2/32 loss: 0.7350106239318848
Rank 0 - Epoch 10/32 loss: 0.45897695422172546
Rank 0 - Epoch 20/32 loss: 0.0235193632543087
Rank 0 - Epoch 30/32 loss: -0.4741460382938385
Training complete.
[92mRank 0 - Testing RMSE: 2.9625[0m
[92mRank: 0, Lengthscale: [[0.6490029 0.5208275]] [0m
[92mRank: 0, Outputscale: 0.7617191076278687 [0m
[92mRank: 0, Noise: 0.04462916776537895 [0m
Run 7 completed successfully
Running apxGP 8 with agents: 16
decpxADMM initialized with rho: 0.85, lip: 1.0, tol_abs: 1e-05, tol_rel: 0.001, rank: 0, world_size: 16
Rank 0 - Epoch 2/32 loss: 0.7350134253501892
Rank 0 - Epoch 10/32 loss: 0.4589826166629791
Rank 0 - Epoch 20/32 loss: 0.02348964288830757
Rank 0 - Epoch 30/32 loss: -0.474226713180542
Training complete.
[92mRank 0 - Testing RMSE: 2.9624[0m
[92mRank: 0, Lengthscale: [[0.64910626 0.52078485]] [0m
[92mRank: 0, Outputscale: 0.7617102265357971 [0m
[92mRank: 0, Noise: 0.044630128890275955 [0m
Run 8 completed successfully
Running apxGP 9 with agents: 16
decpxADMM initialized with rho: 0.85, lip: 1.0, tol_abs: 1e-05, tol_rel: 0.001, rank: 0, world_size: 16
Rank 0 - Epoch 2/32 loss: 0.7350084185600281
Rank 0 - Epoch 10/32 loss: 0.45897018909454346
Rank 0 - Epoch 20/32 loss: 0.023509837687015533
Rank 0 - Epoch 30/32 loss: -0.47400161623954773
Training complete.
[92mRank 0 - Testing RMSE: 2.9624[0m
[92mRank: 0, Lengthscale: [[0.64903754 0.5208533 ]] [0m
[92mRank: 0, Outputscale: 0.761711835861206 [0m
[92mRank: 0, Noise: 0.04462997615337372 [0m
Run 9 completed successfully
Running apxGP 10 with agents: 16
decpxADMM initialized with rho: 0.85, lip: 1.0, tol_abs: 1e-05, tol_rel: 0.001, rank: 0, world_size: 16
Rank 0 - Epoch 2/32 loss: 0.7350143790245056
Rank 0 - Epoch 10/32 loss: 0.458957701921463
Rank 0 - Epoch 20/32 loss: 0.023525390774011612
Rank 0 - Epoch 30/32 loss: -0.47409817576408386
Training complete.
[92mRank 0 - Testing RMSE: 2.9625[0m
[92mRank: 0, Lengthscale: [[0.6490291  0.52080226]] [0m
[92mRank: 0, Outputscale: 0.7617186903953552 [0m
[92mRank: 0, Noise: 0.04462913051247597 [0m
Run 10 completed successfully
Running cGP 1 with agents: 16
decADMM initialized with rho: 0.85, max_iter: 5, lr: 0.0001, rank: 0, world_size: 16
Rank 0 - Epoch 2/32 loss: 0.7918401956558228
Rank 0 - Epoch 10/32 loss: 0.7858901619911194
Rank 0 - Epoch 20/32 loss: 0.7784541845321655
Rank 0 - Epoch 30/32 loss: 0.7709917426109314
Training complete.
[92mRank 0 - Testing RMSE: 3.0765[0m
[92mRank: 0, Lengthscale: [[0.6662061  0.66582036]] [0m
[92mRank: 0, Outputscale: 0.6664887070655823 [0m
[92mRank: 0, Noise: 0.6636995077133179 [0m
Run 1 completed successfully
Running cGP 2 with agents: 16
decADMM initialized with rho: 0.85, max_iter: 5, lr: 0.0001, rank: 0, world_size: 16
Rank 0 - Epoch 2/32 loss: 0.7918326258659363
Rank 0 - Epoch 10/32 loss: 0.7858847379684448
Rank 0 - Epoch 20/32 loss: 0.778444230556488
Rank 0 - Epoch 30/32 loss: 0.7709948420524597
Training complete.
[92mRank 0 - Testing RMSE: 3.0765[0m
[92mRank: 0, Lengthscale: [[0.6662061  0.66582036]] [0m
[92mRank: 0, Outputscale: 0.6664886474609375 [0m
[92mRank: 0, Noise: 0.6636995077133179 [0m
Run 2 completed successfully
Running cGP 3 with agents: 16
decADMM initialized with rho: 0.85, max_iter: 5, lr: 0.0001, rank: 0, world_size: 16
Rank 0 - Epoch 2/32 loss: 0.7918301820755005
Rank 0 - Epoch 10/32 loss: 0.7858887910842896
Rank 0 - Epoch 20/32 loss: 0.7784512639045715
Rank 0 - Epoch 30/32 loss: 0.7709982991218567
Training complete.
[92mRank 0 - Testing RMSE: 3.0765[0m
[92mRank: 0, Lengthscale: [[0.6662062  0.66582036]] [0m
[92mRank: 0, Outputscale: 0.6664886474609375 [0m
[92mRank: 0, Noise: 0.6636995077133179 [0m
Run 3 completed successfully
Running cGP 4 with agents: 16
decADMM initialized with rho: 0.85, max_iter: 5, lr: 0.0001, rank: 0, world_size: 16
Rank 0 - Epoch 2/32 loss: 0.7918329834938049
Rank 0 - Epoch 10/32 loss: 0.7858890891075134
Rank 0 - Epoch 20/32 loss: 0.7784500122070312
Rank 0 - Epoch 30/32 loss: 0.7709937691688538
Training complete.
[92mRank 0 - Testing RMSE: 3.0765[0m
[92mRank: 0, Lengthscale: [[0.6662061  0.66582036]] [0m
[92mRank: 0, Outputscale: 0.6664886474609375 [0m
[92mRank: 0, Noise: 0.6636995077133179 [0m
Run 4 completed successfully
Running cGP 5 with agents: 16
decADMM initialized with rho: 0.85, max_iter: 5, lr: 0.0001, rank: 0, world_size: 16
Rank 0 - Epoch 2/32 loss: 0.7918384671211243
Rank 0 - Epoch 10/32 loss: 0.7858939170837402
Rank 0 - Epoch 20/32 loss: 0.7784460783004761
Rank 0 - Epoch 30/32 loss: 0.7709932923316956
Training complete.
[92mRank 0 - Testing RMSE: 3.0765[0m
[92mRank: 0, Lengthscale: [[0.6662061  0.66582036]] [0m
[92mRank: 0, Outputscale: 0.6664887070655823 [0m
[92mRank: 0, Noise: 0.6636995077133179 [0m
Run 5 completed successfully
Running cGP 6 with agents: 16
decADMM initialized with rho: 0.85, max_iter: 5, lr: 0.0001, rank: 0, world_size: 16
Rank 0 - Epoch 2/32 loss: 0.7918347120285034
Rank 0 - Epoch 10/32 loss: 0.785894513130188
Rank 0 - Epoch 20/32 loss: 0.7784470319747925
Rank 0 - Epoch 30/32 loss: 0.771000862121582
Training complete.
[92mRank 0 - Testing RMSE: 3.0765[0m
[92mRank: 0, Lengthscale: [[0.6662061  0.66582036]] [0m
[92mRank: 0, Outputscale: 0.6664887070655823 [0m
[92mRank: 0, Noise: 0.6636995077133179 [0m
Run 6 completed successfully
Running cGP 7 with agents: 16
decADMM initialized with rho: 0.85, max_iter: 5, lr: 0.0001, rank: 0, world_size: 16
Rank 0 - Epoch 2/32 loss: 0.7918391227722168
Rank 0 - Epoch 10/32 loss: 0.7858911156654358
Rank 0 - Epoch 20/32 loss: 0.778452455997467
Rank 0 - Epoch 30/32 loss: 0.7709934115409851
Training complete.
[92mRank 0 - Testing RMSE: 3.0765[0m
[92mRank: 0, Lengthscale: [[0.6662061  0.66582036]] [0m
[92mRank: 0, Outputscale: 0.6664887070655823 [0m
[92mRank: 0, Noise: 0.6636995077133179 [0m
Run 7 completed successfully
Running cGP 8 with agents: 16
decADMM initialized with rho: 0.85, max_iter: 5, lr: 0.0001, rank: 0, world_size: 16
Rank 0 - Epoch 2/32 loss: 0.791837751865387
Rank 0 - Epoch 10/32 loss: 0.7858892679214478
Rank 0 - Epoch 20/32 loss: 0.7784513235092163
Rank 0 - Epoch 30/32 loss: 0.7710053324699402
Training complete.
[92mRank 0 - Testing RMSE: 3.0765[0m
[92mRank: 0, Lengthscale: [[0.6662061  0.66582036]] [0m
[92mRank: 0, Outputscale: 0.6664887070655823 [0m
[92mRank: 0, Noise: 0.6636995077133179 [0m
Run 8 completed successfully
Running cGP 9 with agents: 16
decADMM initialized with rho: 0.85, max_iter: 5, lr: 0.0001, rank: 0, world_size: 16
Rank 0 - Epoch 2/32 loss: 0.7918329238891602
Rank 0 - Epoch 10/32 loss: 0.7858932018280029
Rank 0 - Epoch 20/32 loss: 0.778452455997467
Rank 0 - Epoch 30/32 loss: 0.771000862121582
Training complete.
[92mRank 0 - Testing RMSE: 3.0765[0m
[92mRank: 0, Lengthscale: [[0.6662061  0.66582036]] [0m
[92mRank: 0, Outputscale: 0.6664886474609375 [0m
[92mRank: 0, Noise: 0.6636995077133179 [0m
Run 9 completed successfully
Running cGP 10 with agents: 16
decADMM initialized with rho: 0.85, max_iter: 5, lr: 0.0001, rank: 0, world_size: 16
Rank 0 - Epoch 2/32 loss: 0.7918336987495422
Rank 0 - Epoch 10/32 loss: 0.7858901023864746
Rank 0 - Epoch 20/32 loss: 0.7784469127655029
Rank 0 - Epoch 30/32 loss: 0.770995020866394
Training complete.
[92mRank 0 - Testing RMSE: 3.0765[0m
[92mRank: 0, Lengthscale: [[0.6662061  0.66582036]] [0m
[92mRank: 0, Outputscale: 0.6664886474609375 [0m
[92mRank: 0, Noise: 0.6636995077133179 [0m
Run 10 completed successfully
Running pxpGP 1 with agents: 36
[92mRank 0 - sparse dataset size is: 25, local dataset: torch.Size([900, 2]), [0m
[92mRank 0 - Training local sparse GP model with 900 samples[0m
Epoch 1/200 - Loss: 9.679
Epoch 11/200 - Loss: 1.075
Epoch 21/200 - Loss: 0.869
Epoch 31/200 - Loss: 0.668
Epoch 41/200 - Loss: 0.353
Converged at epoch 50 with loss -0.004
[92mRank 0 - Lengthscale: [[0.63776565 0.2894572 ]] [0m
[92mRank 0 - Outputscale: 2.1717875003814697 [0m
[92mRank 0 - Noise: 0.14262571930885315 [0m
Rank 0 - Augmented dataset size: 1800
Rank 0: After warm start model parameters:
Rank: 0, Lengthscale: [[0.63776565 0.2894572 ]]
Rank: 0, Outputscale: 2.1717875003814697
Rank: 0, Noise: 0.14262571930885315
decpxADMM initialized with rho: 0.85, lip: 1.0, tol_abs: 1e-05, tol_rel: 0.001, rank: 0, world_size: 36
[92mRank 0 - Training global model with dec-pxADMM optimizer[0m
rank 0, epoch 9, loss: 0.549056887626648, rho: 0.4250, lip: 1.0000
rank 0, epoch 19, loss: 0.5309723019599915, rho: 0.2125, lip: 1.0000
rank 0, epoch 29, loss: 0.5292315483093262, rho: 0.0531, lip: 1.0000
rank 0, epoch 39, loss: 0.5306466817855835, rho: 0.0531, lip: 1.0000
rank 0, epoch 49, loss: 0.5269484519958496, rho: 0.0266, lip: 1.0000
Rank 0 - Training time: 81.88 seconds
[92mRank 0 - Testing RMSE: 0.3377[0m
[92mRank: 0, Lengthscale: [[0.60457194 0.36445516]] [0m
[92mRank: 0, Outputscale: 3.104797124862671 [0m
[92mRank: 0, Noise: 0.12948046624660492 [0m
Run 1 completed successfully
Running pxpGP 2 with agents: 36
[92mRank 0 - sparse dataset size is: 25, local dataset: torch.Size([900, 2]), [0m
[92mRank 0 - Training local sparse GP model with 900 samples[0m
Epoch 1/200 - Loss: 9.573
Epoch 11/200 - Loss: 0.999
Epoch 21/200 - Loss: 0.851
Epoch 31/200 - Loss: 0.610
Epoch 41/200 - Loss: 0.294
Converged at epoch 50 with loss -0.029
[92mRank 0 - Lengthscale: [[0.47732264 0.42124593]] [0m
[92mRank 0 - Outputscale: 1.848258376121521 [0m
[92mRank 0 - Noise: 0.1261514574289322 [0m
Rank 0 - Augmented dataset size: 1800
Rank 0: After warm start model parameters:
Rank: 0, Lengthscale: [[0.47732264 0.42124593]]
Rank: 0, Outputscale: 1.848258376121521
Rank: 0, Noise: 0.1261514574289322
decpxADMM initialized with rho: 0.85, lip: 1.0, tol_abs: 1e-05, tol_rel: 0.001, rank: 0, world_size: 36
[92mRank 0 - Training global model with dec-pxADMM optimizer[0m
rank 0, epoch 9, loss: 0.5642699003219604, rho: 0.4250, lip: 1.0000
rank 0, epoch 19, loss: 0.5811569094657898, rho: 0.1062, lip: 1.0000
rank 0, epoch 29, loss: 0.5588763952255249, rho: 0.0531, lip: 1.0000
rank 0, epoch 39, loss: 0.562473714351654, rho: 0.0266, lip: 1.0000
rank 0, epoch 49, loss: 0.5719643831253052, rho: 0.0266, lip: 1.0000
Rank 0 - Training time: 134.12 seconds
[92mRank 0 - Testing RMSE: 0.4216[0m
[92mRank: 0, Lengthscale: [[0.28524593 0.35013196]] [0m
[92mRank: 0, Outputscale: 1.4371269941329956 [0m
[92mRank: 0, Noise: 0.12129615247249603 [0m
Run 2 completed successfully
Running pxpGP 3 with agents: 36
[92mRank 0 - sparse dataset size is: 25, local dataset: torch.Size([900, 2]), [0m
[92mRank 0 - Training local sparse GP model with 900 samples[0m
Epoch 1/200 - Loss: 10.733
Epoch 11/200 - Loss: 1.009
Epoch 21/200 - Loss: 0.841
Epoch 31/200 - Loss: 0.630
Epoch 41/200 - Loss: 0.309
Converged at epoch 49 with loss -0.002
[92mRank 0 - Lengthscale: [[0.4516046  0.42733487]] [0m
[92mRank 0 - Outputscale: 1.8083759546279907 [0m
[92mRank 0 - Noise: 0.1416875720024109 [0m
Rank 0 - Augmented dataset size: 1800
Rank 0: After warm start model parameters:
Rank: 0, Lengthscale: [[0.45160463 0.42733487]]
Rank: 0, Outputscale: 1.8083759546279907
Rank: 0, Noise: 0.1416875720024109
decpxADMM initialized with rho: 0.85, lip: 1.0, tol_abs: 1e-05, tol_rel: 0.001, rank: 0, world_size: 36
[92mRank 0 - Training global model with dec-pxADMM optimizer[0m
rank 0, epoch 9, loss: 0.6229295134544373, rho: 0.4250, lip: 1.0000
rank 0, epoch 19, loss: 0.6368849873542786, rho: 0.1062, lip: 1.0000
rank 0, epoch 29, loss: 0.6308594942092896, rho: 0.0266, lip: 1.0000
rank 0, epoch 39, loss: 0.6248100996017456, rho: 0.0266, lip: 1.0000
rank 0, epoch 49, loss: 0.6281464099884033, rho: 0.0266, lip: 1.0000
Rank 0 - Training time: 169.43 seconds
[92mRank 0 - Testing RMSE: 0.4553[0m
[92mRank: 0, Lengthscale: [[0.22864425 0.35958436]] [0m
[92mRank: 0, Outputscale: 1.5753822326660156 [0m
[92mRank: 0, Noise: 0.12581463158130646 [0m
Run 3 completed successfully
Running pxpGP 4 with agents: 36
[92mRank 0 - sparse dataset size is: 25, local dataset: torch.Size([900, 2]), [0m
[92mRank 0 - Training local sparse GP model with 900 samples[0m
Epoch 1/200 - Loss: 10.600
Epoch 11/200 - Loss: 1.043
Epoch 21/200 - Loss: 0.862
Epoch 31/200 - Loss: 0.639
Epoch 41/200 - Loss: 0.324
Converged at epoch 50 with loss -0.032
[92mRank 0 - Lengthscale: [[0.38631827 0.5147541 ]] [0m
[92mRank 0 - Outputscale: 2.0514471530914307 [0m
[92mRank 0 - Noise: 0.13450877368450165 [0m
Rank 0 - Augmented dataset size: 1800
Rank 0: After warm start model parameters:
Rank: 0, Lengthscale: [[0.38631824 0.5147542 ]]
Rank: 0, Outputscale: 2.0514471530914307
Rank: 0, Noise: 0.13450877368450165
decpxADMM initialized with rho: 0.85, lip: 1.0, tol_abs: 1e-05, tol_rel: 0.001, rank: 0, world_size: 36
[92mRank 0 - Training global model with dec-pxADMM optimizer[0m
rank 0, epoch 9, loss: 0.5505070090293884, rho: 0.4250, lip: 1.0000
rank 0, epoch 19, loss: 0.5485624670982361, rho: 0.1062, lip: 1.0000
rank 0, epoch 29, loss: 0.5509079694747925, rho: 0.1062, lip: 1.0000
rank 0, epoch 39, loss: 0.5461490154266357, rho: 0.0531, lip: 1.0000
rank 0, epoch 49, loss: 0.5655242800712585, rho: 0.0266, lip: 1.0000
Rank 0 - Training time: 125.51 seconds
[92mRank 0 - Testing RMSE: 0.4294[0m
[92mRank: 0, Lengthscale: [[0.2986815  0.47354764]] [0m
[92mRank: 0, Outputscale: 2.148974657058716 [0m
[92mRank: 0, Noise: 0.13183702528476715 [0m
Run 4 completed successfully
Running pxpGP 5 with agents: 36
[92mRank 0 - sparse dataset size is: 25, local dataset: torch.Size([900, 2]), [0m
[92mRank 0 - Training local sparse GP model with 900 samples[0m
Epoch 1/200 - Loss: 10.351
Epoch 11/200 - Loss: 1.046
Epoch 21/200 - Loss: 0.878
Epoch 31/200 - Loss: 0.657
Epoch 41/200 - Loss: 0.345
Converged at epoch 50 with loss -0.014
[92mRank 0 - Lengthscale: [[0.3677497  0.57129353]] [0m
[92mRank 0 - Outputscale: 2.230414390563965 [0m
[92mRank 0 - Noise: 0.140712708234787 [0m
Rank 0 - Augmented dataset size: 1800
Rank 0: After warm start model parameters:
Rank: 0, Lengthscale: [[0.3677497 0.5712935]]
Rank: 0, Outputscale: 2.230414390563965
Rank: 0, Noise: 0.14071272313594818
decpxADMM initialized with rho: 0.85, lip: 1.0, tol_abs: 1e-05, tol_rel: 0.001, rank: 0, world_size: 36
[92mRank 0 - Training global model with dec-pxADMM optimizer[0m
rank 0, epoch 9, loss: 0.5635202527046204, rho: 0.4250, lip: 1.0000
rank 0, epoch 19, loss: 0.5629470944404602, rho: 0.1062, lip: 1.0000
rank 0, epoch 29, loss: 0.5700128078460693, rho: 0.1062, lip: 1.0000
rank 0, epoch 39, loss: 0.578469455242157, rho: 0.0531, lip: 1.0000
rank 0, epoch 49, loss: 0.5815330147743225, rho: 0.0531, lip: 1.0000
Rank 0 - Training time: 74.58 seconds
[92mRank 0 - Testing RMSE: 0.3349[0m
[92mRank: 0, Lengthscale: [[0.38943756 0.4798768 ]] [0m
[92mRank: 0, Outputscale: 2.0855026245117188 [0m
[92mRank: 0, Noise: 0.14832039177417755 [0m
Run 5 completed successfully
Running pxpGP 6 with agents: 36
[92mRank 0 - sparse dataset size is: 25, local dataset: torch.Size([900, 2]), [0m
[92mRank 0 - Training local sparse GP model with 900 samples[0m
Epoch 1/200 - Loss: 10.343
Epoch 11/200 - Loss: 1.024
Epoch 21/200 - Loss: 0.867
Epoch 31/200 - Loss: 0.649
Epoch 41/200 - Loss: 0.341
Converged at epoch 50 with loss -0.008
[92mRank 0 - Lengthscale: [[0.514335  0.4499029]] [0m
[92mRank 0 - Outputscale: 1.9267518520355225 [0m
[92mRank 0 - Noise: 0.14190629124641418 [0m
Rank 0 - Augmented dataset size: 1800
Rank 0: After warm start model parameters:
Rank: 0, Lengthscale: [[0.514335   0.44990292]]
Rank: 0, Outputscale: 1.926751971244812
Rank: 0, Noise: 0.1419062614440918
decpxADMM initialized with rho: 0.85, lip: 1.0, tol_abs: 1e-05, tol_rel: 0.001, rank: 0, world_size: 36
[92mRank 0 - Training global model with dec-pxADMM optimizer[0m
rank 0, epoch 9, loss: 0.5475166440010071, rho: 0.4250, lip: 1.0000
rank 0, epoch 19, loss: 0.5474875569343567, rho: 0.1062, lip: 1.0000
rank 0, epoch 29, loss: 0.5499765276908875, rho: 0.0531, lip: 1.0000
rank 0, epoch 39, loss: 0.5482187271118164, rho: 0.0531, lip: 1.0000
rank 0, epoch 49, loss: 0.5485800504684448, rho: 0.0266, lip: 1.0000
Rank 0 - Training time: 87.13 seconds
[92mRank 0 - Testing RMSE: 0.3599[0m
[92mRank: 0, Lengthscale: [[0.5159745  0.36955225]] [0m
[92mRank: 0, Outputscale: 3.272939443588257 [0m
[92mRank: 0, Noise: 0.13240660727024078 [0m
Run 6 completed successfully
Running pxpGP 7 with agents: 36
[92mRank 0 - sparse dataset size is: 25, local dataset: torch.Size([900, 2]), [0m
[92mRank 0 - Training local sparse GP model with 900 samples[0m
Epoch 1/200 - Loss: 10.629
Epoch 11/200 - Loss: 1.026
Epoch 21/200 - Loss: 0.881
Epoch 31/200 - Loss: 0.653
Epoch 41/200 - Loss: 0.348
Epoch 51/200 - Loss: -0.055
Converged at epoch 51 with loss -0.055
[92mRank 0 - Lengthscale: [[0.5025163  0.30913216]] [0m
[92mRank 0 - Outputscale: 1.9367212057113647 [0m
[92mRank 0 - Noise: 0.12820976972579956 [0m
Rank 0 - Augmented dataset size: 1800
Rank 0: After warm start model parameters:
Rank: 0, Lengthscale: [[0.5025163  0.30913216]]
Rank: 0, Outputscale: 1.9367212057113647
Rank: 0, Noise: 0.12820976972579956
decpxADMM initialized with rho: 0.85, lip: 1.0, tol_abs: 1e-05, tol_rel: 0.001, rank: 0, world_size: 36
[92mRank 0 - Training global model with dec-pxADMM optimizer[0m
rank 0, epoch 9, loss: 0.5349419713020325, rho: 0.2125, lip: 1.0000
rank 0, epoch 19, loss: 0.537050724029541, rho: 0.1062, lip: 1.0000
rank 0, epoch 29, loss: 0.5227552056312561, rho: 0.0266, lip: 1.0000
rank 0, epoch 39, loss: 0.5320017337799072, rho: 0.0266, lip: 1.0000
rank 0, epoch 49, loss: 0.537833571434021, rho: 0.0266, lip: 1.0000
Rank 0 - Training time: 89.03 seconds
[92mRank 0 - Testing RMSE: 0.4138[0m
[92mRank: 0, Lengthscale: [[0.32384554 0.34013003]] [0m
[92mRank: 0, Outputscale: 1.996231198310852 [0m
[92mRank: 0, Noise: 0.11694096028804779 [0m
Run 7 completed successfully
Running pxpGP 8 with agents: 36
[92mRank 0 - sparse dataset size is: 25, local dataset: torch.Size([900, 2]), [0m
[92mRank 0 - Training local sparse GP model with 900 samples[0m
Epoch 1/200 - Loss: 10.523
Epoch 11/200 - Loss: 1.061
Epoch 21/200 - Loss: 0.881
Epoch 31/200 - Loss: 0.648
Epoch 41/200 - Loss: 0.331
Converged at epoch 50 with loss -0.032
[92mRank 0 - Lengthscale: [[0.667315   0.40728596]] [0m
[92mRank 0 - Outputscale: 2.128896474838257 [0m
[92mRank 0 - Noise: 0.1359645575284958 [0m
Rank 0 - Augmented dataset size: 1800
Rank 0: After warm start model parameters:
Rank: 0, Lengthscale: [[0.667315   0.40728596]]
Rank: 0, Outputscale: 2.128896474838257
Rank: 0, Noise: 0.1359645575284958
decpxADMM initialized with rho: 0.85, lip: 1.0, tol_abs: 1e-05, tol_rel: 0.001, rank: 0, world_size: 36
[92mRank 0 - Training global model with dec-pxADMM optimizer[0m
rank 0, epoch 9, loss: 0.5488595962524414, rho: 0.4250, lip: 1.0000
rank 0, epoch 19, loss: 0.5705274939537048, rho: 0.1062, lip: 1.0000
rank 0, epoch 29, loss: 0.5900205373764038, rho: 0.0531, lip: 1.0000
rank 0, epoch 39, loss: 0.5933595299720764, rho: 0.0531, lip: 1.0000
rank 0, epoch 49, loss: 0.5903615951538086, rho: 0.0266, lip: 1.0000
Rank 0 - Training time: 197.93 seconds
[92mRank 0 - Testing RMSE: 0.4498[0m
[92mRank: 0, Lengthscale: [[0.19525667 0.4677421 ]] [0m
[92mRank: 0, Outputscale: 2.7563815116882324 [0m
[92mRank: 0, Noise: 0.12238053232431412 [0m
Run 8 completed successfully
Running pxpGP 9 with agents: 36
[92mRank 0 - sparse dataset size is: 25, local dataset: torch.Size([900, 2]), [0m
[92mRank 0 - Training local sparse GP model with 900 samples[0m
Epoch 1/200 - Loss: 10.504
Epoch 11/200 - Loss: 1.039
Epoch 21/200 - Loss: 0.878
Epoch 31/200 - Loss: 0.683
Epoch 41/200 - Loss: 0.379
Epoch 51/200 - Loss: -0.018
Converged at epoch 51 with loss -0.018
[92mRank 0 - Lengthscale: [[0.7041956  0.37372643]] [0m
[92mRank 0 - Outputscale: 2.2246644496917725 [0m
[92mRank 0 - Noise: 0.14029882848262787 [0m
Rank 0 - Augmented dataset size: 1800
Rank 0: After warm start model parameters:
Rank: 0, Lengthscale: [[0.7041956  0.37372643]]
Rank: 0, Outputscale: 2.2246644496917725
Rank: 0, Noise: 0.14029882848262787
decpxADMM initialized with rho: 0.85, lip: 1.0, tol_abs: 1e-05, tol_rel: 0.001, rank: 0, world_size: 36
[92mRank 0 - Training global model with dec-pxADMM optimizer[0m
rank 0, epoch 9, loss: 0.628893256187439, rho: 0.4250, lip: 1.0000
rank 0, epoch 19, loss: 0.6108704805374146, rho: 0.1062, lip: 1.0000
rank 0, epoch 29, loss: 0.6164946556091309, rho: 0.0531, lip: 1.0000
rank 0, epoch 39, loss: 0.6184496283531189, rho: 0.0531, lip: 1.0000
rank 0, epoch 49, loss: 0.6244718432426453, rho: 0.0531, lip: 1.0000
Rank 0 - Training time: 84.52 seconds
[92mRank 0 - Testing RMSE: 0.4220[0m
[92mRank: 0, Lengthscale: [[0.35230643 0.40842342]] [0m
[92mRank: 0, Outputscale: 2.7686798572540283 [0m
[92mRank: 0, Noise: 0.15593208372592926 [0m
Run 9 completed successfully
Running pxpGP 10 with agents: 36
[92mRank 0 - sparse dataset size is: 25, local dataset: torch.Size([900, 2]), [0m
[92mRank 0 - Training local sparse GP model with 900 samples[0m
Epoch 1/200 - Loss: 10.443
Epoch 11/200 - Loss: 1.000
Epoch 21/200 - Loss: 0.857
Epoch 31/200 - Loss: 0.640
Epoch 41/200 - Loss: 0.335
Converged at epoch 50 with loss -0.015
[92mRank 0 - Lengthscale: [[0.43524012 0.4382603 ]] [0m
[92mRank 0 - Outputscale: 1.8360657691955566 [0m
[92mRank 0 - Noise: 0.1400408148765564 [0m
Rank 0 - Augmented dataset size: 1800
Rank 0: After warm start model parameters:
Rank: 0, Lengthscale: [[0.43524012 0.4382603 ]]
Rank: 0, Outputscale: 1.836065649986267
Rank: 0, Noise: 0.1400408148765564
decpxADMM initialized with rho: 0.85, lip: 1.0, tol_abs: 1e-05, tol_rel: 0.001, rank: 0, world_size: 36
[92mRank 0 - Training global model with dec-pxADMM optimizer[0m
rank 0, epoch 9, loss: 0.6004206538200378, rho: 0.4250, lip: 1.0000
rank 0, epoch 19, loss: 0.6287496089935303, rho: 0.1062, lip: 1.0000
rank 0, epoch 29, loss: 0.6473112106323242, rho: 0.1062, lip: 1.0000
rank 0, epoch 39, loss: 0.6718301773071289, rho: 0.1062, lip: 1.0000
rank 0, epoch 49, loss: 0.6963090300559998, rho: 0.0531, lip: 1.0000
Rank 0 - Training time: 224.43 seconds
[92mRank 0 - Testing RMSE: 0.5666[0m
[92mRank: 0, Lengthscale: [[0.07877439 0.45247358]] [0m
[92mRank: 0, Outputscale: 2.9009182453155518 [0m
[92mRank: 0, Noise: 0.11214234679937363 [0m
Run 10 completed successfully
Running gapxGP 1 with agents: 36
decpxADMM initialized with rho: 0.75, lip: 1.0, tol_abs: 1e-05, tol_rel: 0.001, rank: 0, world_size: 36
Rank 0 - Epoch 2/54 loss: 0.858867347240448
Rank 0 - Epoch 10/54 loss: 0.6106219291687012
Rank 0 - Epoch 20/54 loss: 0.19349561631679535
Rank 0 - Epoch 30/54 loss: -0.288756400346756
Rank 0 - Epoch 40/54 loss: -0.800684928894043
Rank 0 - Epoch 50/54 loss: -1.274075984954834
[92mRank 0 - Testing RMSE: 0.0519[0m
[92mRank: 0, Lengthscale: [[0.6120085 0.3590283]] [0m
[92mRank: 0, Outputscale: 1.0998979806900024 [0m
[92mRank: 0, Noise: 0.00406790804117918 [0m
Run 1 completed successfully
Running gapxGP 2 with agents: 36
decpxADMM initialized with rho: 0.75, lip: 1.0, tol_abs: 1e-05, tol_rel: 0.001, rank: 0, world_size: 36
Rank 0 - Epoch 2/54 loss: 0.8585443496704102
Rank 0 - Epoch 10/54 loss: 0.6101668477058411
Rank 0 - Epoch 20/54 loss: 0.18979030847549438
Rank 0 - Epoch 30/54 loss: -0.2969406843185425
Rank 0 - Epoch 40/54 loss: -0.8029450178146362
Rank 0 - Epoch 50/54 loss: -1.288740873336792
[92mRank 0 - Testing RMSE: 0.0557[0m
[92mRank: 0, Lengthscale: [[0.6097994  0.35815495]] [0m
[92mRank: 0, Outputscale: 1.1023378372192383 [0m
[92mRank: 0, Noise: 0.004032281693071127 [0m
Run 2 completed successfully
Running gapxGP 3 with agents: 36
decpxADMM initialized with rho: 0.75, lip: 1.0, tol_abs: 1e-05, tol_rel: 0.001, rank: 0, world_size: 36
Rank 0 - Epoch 2/54 loss: 0.8563519716262817
Rank 0 - Epoch 10/54 loss: 0.6090219020843506
Rank 0 - Epoch 20/54 loss: 0.19580408930778503
Rank 0 - Epoch 30/54 loss: -0.2893650233745575
Rank 0 - Epoch 40/54 loss: -0.8081855773925781
Rank 0 - Epoch 50/54 loss: -1.272649884223938
[92mRank 0 - Testing RMSE: 0.0520[0m
[92mRank: 0, Lengthscale: [[0.61055994 0.36165404]] [0m
[92mRank: 0, Outputscale: 1.100271224975586 [0m
[92mRank: 0, Noise: 0.004062371794134378 [0m
Run 3 completed successfully
Running gapxGP 4 with agents: 36
decpxADMM initialized with rho: 0.75, lip: 1.0, tol_abs: 1e-05, tol_rel: 0.001, rank: 0, world_size: 36
Rank 0 - Epoch 2/54 loss: 0.8645927906036377
Rank 0 - Epoch 10/54 loss: 0.6202539801597595
Rank 0 - Epoch 20/54 loss: 0.1985967755317688
Rank 0 - Epoch 30/54 loss: -0.2883738875389099
Rank 0 - Epoch 40/54 loss: -0.7821733951568604
Rank 0 - Epoch 50/54 loss: -1.2591205835342407
[92mRank 0 - Testing RMSE: 0.0475[0m
[92mRank: 0, Lengthscale: [[0.60942364 0.35871503]] [0m
[92mRank: 0, Outputscale: 1.1031384468078613 [0m
[92mRank: 0, Noise: 0.004093814175575972 [0m
Run 4 completed successfully
Running gapxGP 5 with agents: 36
decpxADMM initialized with rho: 0.75, lip: 1.0, tol_abs: 1e-05, tol_rel: 0.001, rank: 0, world_size: 36
Rank 0 - Epoch 2/54 loss: 0.8603272438049316
Rank 0 - Epoch 10/54 loss: 0.614155113697052
Rank 0 - Epoch 20/54 loss: 0.1921212077140808
Rank 0 - Epoch 30/54 loss: -0.28710973262786865
Rank 0 - Epoch 40/54 loss: -0.7973850965499878
Rank 0 - Epoch 50/54 loss: -1.2573707103729248
[92mRank 0 - Testing RMSE: 0.0558[0m
[92mRank: 0, Lengthscale: [[0.6109315 0.3567129]] [0m
[92mRank: 0, Outputscale: 1.1013526916503906 [0m
[92mRank: 0, Noise: 0.004066818859428167 [0m
Run 5 completed successfully
Running gapxGP 6 with agents: 36
decpxADMM initialized with rho: 0.75, lip: 1.0, tol_abs: 1e-05, tol_rel: 0.001, rank: 0, world_size: 36
Rank 0 - Epoch 2/54 loss: 0.8603265285491943
Rank 0 - Epoch 10/54 loss: 0.6114203929901123
Rank 0 - Epoch 20/54 loss: 0.18815244734287262
Rank 0 - Epoch 30/54 loss: -0.2990642189979553
Rank 0 - Epoch 40/54 loss: -0.7965503334999084
Rank 0 - Epoch 50/54 loss: -1.2668925523757935
[92mRank 0 - Testing RMSE: 0.0545[0m
[92mRank: 0, Lengthscale: [[0.6084929  0.35953063]] [0m
[92mRank: 0, Outputscale: 1.1035938262939453 [0m
[92mRank: 0, Noise: 0.0040481844916939735 [0m
Run 6 completed successfully
Running gapxGP 7 with agents: 36
decpxADMM initialized with rho: 0.75, lip: 1.0, tol_abs: 1e-05, tol_rel: 0.001, rank: 0, world_size: 36
Rank 0 - Epoch 2/54 loss: 0.8561968207359314
Rank 0 - Epoch 10/54 loss: 0.6092104911804199
Rank 0 - Epoch 20/54 loss: 0.1986447125673294
Rank 0 - Epoch 30/54 loss: -0.2834795117378235
Rank 0 - Epoch 40/54 loss: -0.7901536822319031
Rank 0 - Epoch 50/54 loss: -1.2803006172180176
[92mRank 0 - Testing RMSE: 0.0534[0m
[92mRank: 0, Lengthscale: [[0.6118988  0.35565877]] [0m
[92mRank: 0, Outputscale: 1.1011712551116943 [0m
[92mRank: 0, Noise: 0.004108702763915062 [0m
Run 7 completed successfully
Running gapxGP 8 with agents: 36
decpxADMM initialized with rho: 0.75, lip: 1.0, tol_abs: 1e-05, tol_rel: 0.001, rank: 0, world_size: 36
Rank 0 - Epoch 2/54 loss: 0.8598810434341431
Rank 0 - Epoch 10/54 loss: 0.6094261407852173
Rank 0 - Epoch 20/54 loss: 0.19323799014091492
Rank 0 - Epoch 30/54 loss: -0.28947919607162476
Rank 0 - Epoch 40/54 loss: -0.8026261925697327
Rank 0 - Epoch 50/54 loss: -1.2759449481964111
[92mRank 0 - Testing RMSE: 0.0459[0m
[92mRank: 0, Lengthscale: [[0.60687685 0.35623893]] [0m
[92mRank: 0, Outputscale: 1.1017707586288452 [0m
[92mRank: 0, Noise: 0.004047431517392397 [0m
Run 8 completed successfully
Running gapxGP 9 with agents: 36
decpxADMM initialized with rho: 0.75, lip: 1.0, tol_abs: 1e-05, tol_rel: 0.001, rank: 0, world_size: 36
Rank 0 - Epoch 2/54 loss: 0.8614013195037842
Rank 0 - Epoch 10/54 loss: 0.613917887210846
Rank 0 - Epoch 20/54 loss: 0.18617668747901917
Rank 0 - Epoch 30/54 loss: -0.2940002679824829
Rank 0 - Epoch 40/54 loss: -0.8003398180007935
Rank 0 - Epoch 50/54 loss: -1.2747893333435059
[92mRank 0 - Testing RMSE: 0.0464[0m
[92mRank: 0, Lengthscale: [[0.6084161  0.36424816]] [0m
[92mRank: 0, Outputscale: 1.1035540103912354 [0m
[92mRank: 0, Noise: 0.004043229389935732 [0m
Run 9 completed successfully
Running gapxGP 10 with agents: 36
decpxADMM initialized with rho: 0.75, lip: 1.0, tol_abs: 1e-05, tol_rel: 0.001, rank: 0, world_size: 36
Rank 0 - Epoch 2/54 loss: 0.8603546023368835
Rank 0 - Epoch 10/54 loss: 0.6133942008018494
Rank 0 - Epoch 20/54 loss: 0.1976083219051361
Rank 0 - Epoch 30/54 loss: -0.2880893051624298
Rank 0 - Epoch 40/54 loss: -0.8065573573112488
Rank 0 - Epoch 50/54 loss: -1.2810345888137817
[92mRank 0 - Testing RMSE: 0.0412[0m
[92mRank: 0, Lengthscale: [[0.6088377  0.35874972]] [0m
[92mRank: 0, Outputscale: 1.101523995399475 [0m
[92mRank: 0, Noise: 0.004056797828525305 [0m
Run 10 completed successfully
Running apxGP 1 with agents: 36
decpxADMM initialized with rho: 0.85, lip: 1.0, tol_abs: 1e-05, tol_rel: 0.001, rank: 0, world_size: 36
Rank 0 - Epoch 2/72 loss: 0.7347801923751831
Rank 0 - Epoch 10/72 loss: 0.45909538865089417
Rank 0 - Epoch 20/72 loss: 0.027802599593997
Rank 0 - Epoch 30/72 loss: -0.4680902659893036
Rank 0 - Epoch 40/72 loss: -0.9931976795196533
Rank 0 - Epoch 50/72 loss: -1.5177056789398193
Rank 0 - Epoch 60/72 loss: -2.0238006114959717
Rank 0 - Epoch 70/72 loss: -2.487778663635254
Training complete.
[92mRank 0 - Testing RMSE: 3.2899[0m
[92mRank: 0, Lengthscale: [[0.6037421  0.38543743]] [0m
[92mRank: 0, Outputscale: 0.9037767648696899 [0m
[92mRank: 0, Noise: 0.000758855720050633 [0m
Run 1 completed successfully
Running apxGP 2 with agents: 36
decpxADMM initialized with rho: 0.85, lip: 1.0, tol_abs: 1e-05, tol_rel: 0.001, rank: 0, world_size: 36
Rank 0 - Epoch 2/72 loss: 0.734779953956604
Rank 0 - Epoch 10/72 loss: 0.4590960443019867
Rank 0 - Epoch 20/72 loss: 0.02780422568321228
Rank 0 - Epoch 30/72 loss: -0.46809110045433044
Rank 0 - Epoch 40/72 loss: -0.9931685328483582
Rank 0 - Epoch 50/72 loss: -1.5176163911819458
Rank 0 - Epoch 60/72 loss: -2.0238561630249023
Rank 0 - Epoch 70/72 loss: -2.4877686500549316
Training complete.
[92mRank 0 - Testing RMSE: 3.2892[0m
[92mRank: 0, Lengthscale: [[0.60338664 0.3853674 ]] [0m
[92mRank: 0, Outputscale: 0.9038177132606506 [0m
[92mRank: 0, Noise: 0.0007587854051962495 [0m
Run 2 completed successfully
Running apxGP 3 with agents: 36
decpxADMM initialized with rho: 0.85, lip: 1.0, tol_abs: 1e-05, tol_rel: 0.001, rank: 0, world_size: 36
Rank 0 - Epoch 2/72 loss: 0.7347801327705383
Rank 0 - Epoch 10/72 loss: 0.45909592509269714
Rank 0 - Epoch 20/72 loss: 0.027803480625152588
Rank 0 - Epoch 30/72 loss: -0.4680875539779663
Rank 0 - Epoch 40/72 loss: -0.9932069182395935
Rank 0 - Epoch 50/72 loss: -1.517636775970459
Rank 0 - Epoch 60/72 loss: -2.0239951610565186
Rank 0 - Epoch 70/72 loss: -2.4877376556396484
Training complete.
[92mRank 0 - Testing RMSE: 3.2898[0m
[92mRank: 0, Lengthscale: [[0.6033726  0.38565943]] [0m
[92mRank: 0, Outputscale: 0.9037585258483887 [0m
[92mRank: 0, Noise: 0.0007589019369333982 [0m
Run 3 completed successfully
Running apxGP 4 with agents: 36
decpxADMM initialized with rho: 0.85, lip: 1.0, tol_abs: 1e-05, tol_rel: 0.001, rank: 0, world_size: 36
Rank 0 - Epoch 2/72 loss: 0.7347797155380249
Rank 0 - Epoch 10/72 loss: 0.4590963125228882
Rank 0 - Epoch 20/72 loss: 0.027803616598248482
Rank 0 - Epoch 30/72 loss: -0.4680863320827484
Rank 0 - Epoch 40/72 loss: -0.9932183027267456
Rank 0 - Epoch 50/72 loss: -1.5176011323928833
Rank 0 - Epoch 60/72 loss: -2.023730754852295
Rank 0 - Epoch 70/72 loss: -2.4877262115478516
Training complete.
[92mRank 0 - Testing RMSE: 3.2907[0m
[92mRank: 0, Lengthscale: [[0.60348755 0.3854332 ]] [0m
[92mRank: 0, Outputscale: 0.9038106203079224 [0m
[92mRank: 0, Noise: 0.000758813985157758 [0m
Run 4 completed successfully
Running apxGP 5 with agents: 36
decpxADMM initialized with rho: 0.85, lip: 1.0, tol_abs: 1e-05, tol_rel: 0.001, rank: 0, world_size: 36
Rank 0 - Epoch 2/72 loss: 0.7347800135612488
Rank 0 - Epoch 10/72 loss: 0.4590960741043091
Rank 0 - Epoch 20/72 loss: 0.027804633602499962
Rank 0 - Epoch 30/72 loss: -0.46808865666389465
Rank 0 - Epoch 40/72 loss: -0.9932073354721069
Rank 0 - Epoch 50/72 loss: -1.517591118812561
Rank 0 - Epoch 60/72 loss: -2.0237064361572266
Rank 0 - Epoch 70/72 loss: -2.4879233837127686
Training complete.
[92mRank 0 - Testing RMSE: 3.2906[0m
[92mRank: 0, Lengthscale: [[0.603498  0.3854231]] [0m
[92mRank: 0, Outputscale: 0.9037637710571289 [0m
[92mRank: 0, Noise: 0.0007588601438328624 [0m
Run 5 completed successfully
Running apxGP 6 with agents: 36
decpxADMM initialized with rho: 0.85, lip: 1.0, tol_abs: 1e-05, tol_rel: 0.001, rank: 0, world_size: 36
Rank 0 - Epoch 2/72 loss: 0.7347801327705383
Rank 0 - Epoch 10/72 loss: 0.4590962529182434
Rank 0 - Epoch 20/72 loss: 0.0278032086789608
Rank 0 - Epoch 30/72 loss: -0.46808838844299316
Rank 0 - Epoch 40/72 loss: -0.9931703209877014
Rank 0 - Epoch 50/72 loss: -1.5176899433135986
Rank 0 - Epoch 60/72 loss: -2.02384090423584
Rank 0 - Epoch 70/72 loss: -2.4882986545562744
Training complete.
[92mRank 0 - Testing RMSE: 3.2899[0m
[92mRank: 0, Lengthscale: [[0.60345644 0.38576347]] [0m
[92mRank: 0, Outputscale: 0.9037342667579651 [0m
[92mRank: 0, Noise: 0.0007589311571791768 [0m
Run 6 completed successfully
Running apxGP 7 with agents: 36
decpxADMM initialized with rho: 0.85, lip: 1.0, tol_abs: 1e-05, tol_rel: 0.001, rank: 0, world_size: 36
Rank 0 - Epoch 2/72 loss: 0.7347800135612488
Rank 0 - Epoch 10/72 loss: 0.4590965509414673
Rank 0 - Epoch 20/72 loss: 0.027804633602499962
Rank 0 - Epoch 30/72 loss: -0.46808430552482605
Rank 0 - Epoch 40/72 loss: -0.9931982159614563
Rank 0 - Epoch 50/72 loss: -1.5176397562026978
Rank 0 - Epoch 60/72 loss: -2.023750066757202
Rank 0 - Epoch 70/72 loss: -2.48708176612854
Training complete.
[92mRank 0 - Testing RMSE: 3.2881[0m
[92mRank: 0, Lengthscale: [[0.60351133 0.38541245]] [0m
[92mRank: 0, Outputscale: 0.9037871956825256 [0m
[92mRank: 0, Noise: 0.0007588309235870838 [0m
Run 7 completed successfully
Running apxGP 8 with agents: 36
decpxADMM initialized with rho: 0.85, lip: 1.0, tol_abs: 1e-05, tol_rel: 0.001, rank: 0, world_size: 36
Rank 0 - Epoch 2/72 loss: 0.7347800135612488
Rank 0 - Epoch 10/72 loss: 0.45909619331359863
Rank 0 - Epoch 20/72 loss: 0.02780524268746376
Rank 0 - Epoch 30/72 loss: -0.4680838882923126
Rank 0 - Epoch 40/72 loss: -0.9931749105453491
Rank 0 - Epoch 50/72 loss: -1.5175691843032837
Rank 0 - Epoch 60/72 loss: -2.0235090255737305
Rank 0 - Epoch 70/72 loss: -2.4876368045806885
Training complete.
[92mRank 0 - Testing RMSE: 3.2890[0m
[92mRank: 0, Lengthscale: [[0.6037513 0.3852806]] [0m
[92mRank: 0, Outputscale: 0.9037704467773438 [0m
[92mRank: 0, Noise: 0.0007588937296532094 [0m
Run 8 completed successfully
Running apxGP 9 with agents: 36
decpxADMM initialized with rho: 0.85, lip: 1.0, tol_abs: 1e-05, tol_rel: 0.001, rank: 0, world_size: 36
Rank 0 - Epoch 2/72 loss: 0.7347798943519592
Rank 0 - Epoch 10/72 loss: 0.45909664034843445
Rank 0 - Epoch 20/72 loss: 0.027803616598248482
Rank 0 - Epoch 30/72 loss: -0.4680878221988678
Rank 0 - Epoch 40/72 loss: -0.9931773543357849
Rank 0 - Epoch 50/72 loss: -1.5176419019699097
Rank 0 - Epoch 60/72 loss: -2.023578643798828
Rank 0 - Epoch 70/72 loss: -2.487927198410034
Training complete.
[92mRank 0 - Testing RMSE: 3.2904[0m
[92mRank: 0, Lengthscale: [[0.60359454 0.38562405]] [0m
[92mRank: 0, Outputscale: 0.9037593603134155 [0m
[92mRank: 0, Noise: 0.0007588783628307283 [0m
Run 9 completed successfully
Running apxGP 10 with agents: 36
decpxADMM initialized with rho: 0.85, lip: 1.0, tol_abs: 1e-05, tol_rel: 0.001, rank: 0, world_size: 36
Rank 0 - Epoch 2/72 loss: 0.734779953956604
Rank 0 - Epoch 10/72 loss: 0.45909643173217773
Rank 0 - Epoch 20/72 loss: 0.02780354768037796
Rank 0 - Epoch 30/72 loss: -0.46808186173439026
Rank 0 - Epoch 40/72 loss: -0.9932100176811218
Rank 0 - Epoch 50/72 loss: -1.5175659656524658
Rank 0 - Epoch 60/72 loss: -2.02363657951355
Rank 0 - Epoch 70/72 loss: -2.4870965480804443
Training complete.
[92mRank 0 - Testing RMSE: 3.2907[0m
[92mRank: 0, Lengthscale: [[0.60347927 0.38539177]] [0m
[92mRank: 0, Outputscale: 0.9037922620773315 [0m
[92mRank: 0, Noise: 0.000758832844439894 [0m
Run 10 completed successfully
Running cGP 1 with agents: 36
decADMM initialized with rho: 0.85, max_iter: 5, lr: 0.0001, rank: 0, world_size: 36
Rank 0 - Epoch 2/72 loss: 0.7909806966781616
Rank 0 - Epoch 10/72 loss: 0.7827951312065125
Rank 0 - Epoch 20/72 loss: 0.7778522372245789
Rank 0 - Epoch 30/72 loss: 0.7759169936180115
Rank 0 - Epoch 40/72 loss: 0.7650378346443176
Rank 0 - Epoch 50/72 loss: 0.7605214715003967
Rank 0 - Epoch 60/72 loss: 0.7524797320365906
Rank 0 - Epoch 70/72 loss: 0.7471833229064941
Training complete.
[92mRank 0 - Testing RMSE: 3.6018[0m
[92mRank: 0, Lengthscale: [[0.6337261 0.6331744]] [0m
[92mRank: 0, Outputscale: 0.6342794895172119 [0m
[92mRank: 0, Noise: 0.6278731226921082 [0m
Run 1 completed successfully
Running cGP 2 with agents: 36
decADMM initialized with rho: 0.85, max_iter: 5, lr: 0.0001, rank: 0, world_size: 36
Rank 0 - Epoch 2/72 loss: 0.7925664782524109
Rank 0 - Epoch 10/72 loss: 0.7869507670402527
Rank 0 - Epoch 20/72 loss: 0.7822211384773254
Rank 0 - Epoch 30/72 loss: 0.7757113575935364
Rank 0 - Epoch 40/72 loss: 0.7648064494132996
Rank 0 - Epoch 50/72 loss: 0.7565327882766724
Rank 0 - Epoch 60/72 loss: 0.7490519285202026
Rank 0 - Epoch 70/72 loss: 0.7442770004272461
Training complete.
[92mRank 0 - Testing RMSE: 3.6018[0m
[92mRank: 0, Lengthscale: [[0.6337288 0.6331729]] [0m
[92mRank: 0, Outputscale: 0.634279191493988 [0m
[92mRank: 0, Noise: 0.6278830766677856 [0m
Run 2 completed successfully
Running cGP 3 with agents: 36
decADMM initialized with rho: 0.85, max_iter: 5, lr: 0.0001, rank: 0, world_size: 36
Rank 0 - Epoch 2/72 loss: 0.790381669998169
Rank 0 - Epoch 10/72 loss: 0.7862494587898254
Rank 0 - Epoch 20/72 loss: 0.7768545150756836
Rank 0 - Epoch 30/72 loss: 0.7727697491645813
Rank 0 - Epoch 40/72 loss: 0.7685171961784363
Rank 0 - Epoch 50/72 loss: 0.7556788325309753
Rank 0 - Epoch 60/72 loss: 0.7512650489807129
Rank 0 - Epoch 70/72 loss: 0.7434226870536804
Training complete.
[92mRank 0 - Testing RMSE: 3.6018[0m
[92mRank: 0, Lengthscale: [[0.63372535 0.6331718 ]] [0m
[92mRank: 0, Outputscale: 0.6342785358428955 [0m
[92mRank: 0, Noise: 0.6278775334358215 [0m
Run 3 completed successfully
Running cGP 4 with agents: 36
decADMM initialized with rho: 0.85, max_iter: 5, lr: 0.0001, rank: 0, world_size: 36
Rank 0 - Epoch 2/72 loss: 0.7912688255310059
Rank 0 - Epoch 10/72 loss: 0.7851813435554504
Rank 0 - Epoch 20/72 loss: 0.7803136110305786
Rank 0 - Epoch 30/72 loss: 0.7743023037910461
Rank 0 - Epoch 40/72 loss: 0.7678552865982056
Rank 0 - Epoch 50/72 loss: 0.761203408241272
Rank 0 - Epoch 60/72 loss: 0.7537784576416016
Rank 0 - Epoch 70/72 loss: 0.7442588210105896
Training complete.
[92mRank 0 - Testing RMSE: 3.6018[0m
[92mRank: 0, Lengthscale: [[0.6337242  0.63316774]] [0m
[92mRank: 0, Outputscale: 0.6342795491218567 [0m
[92mRank: 0, Noise: 0.627875566482544 [0m
Run 4 completed successfully
Running cGP 5 with agents: 36
decADMM initialized with rho: 0.85, max_iter: 5, lr: 0.0001, rank: 0, world_size: 36
Rank 0 - Epoch 2/72 loss: 0.7897822260856628
Rank 0 - Epoch 10/72 loss: 0.7921155691146851
Rank 0 - Epoch 20/72 loss: 0.7810788154602051
Rank 0 - Epoch 30/72 loss: 0.7741544842720032
Rank 0 - Epoch 40/72 loss: 0.7653916478157043
Rank 0 - Epoch 50/72 loss: 0.7618177533149719
Rank 0 - Epoch 60/72 loss: 0.7546135187149048
Rank 0 - Epoch 70/72 loss: 0.7438821196556091
Training complete.
[92mRank 0 - Testing RMSE: 3.6018[0m
[92mRank: 0, Lengthscale: [[0.6337223  0.63317233]] [0m
[92mRank: 0, Outputscale: 0.6342783570289612 [0m
[92mRank: 0, Noise: 0.627876877784729 [0m
Run 5 completed successfully
Running cGP 6 with agents: 36
decADMM initialized with rho: 0.85, max_iter: 5, lr: 0.0001, rank: 0, world_size: 36
Rank 0 - Epoch 2/72 loss: 0.7898939847946167
Rank 0 - Epoch 10/72 loss: 0.7838925123214722
Rank 0 - Epoch 20/72 loss: 0.7781201004981995
Rank 0 - Epoch 30/72 loss: 0.7798097133636475
Rank 0 - Epoch 40/72 loss: 0.769475519657135
Rank 0 - Epoch 50/72 loss: 0.7587122917175293
Rank 0 - Epoch 60/72 loss: 0.7506129145622253
Rank 0 - Epoch 70/72 loss: 0.7452999353408813
Training complete.
[92mRank 0 - Testing RMSE: 3.6018[0m
[92mRank: 0, Lengthscale: [[0.6337249  0.63317186]] [0m
[92mRank: 0, Outputscale: 0.634278416633606 [0m
[92mRank: 0, Noise: 0.6278755068778992 [0m
Run 6 completed successfully
Running cGP 7 with agents: 36
decADMM initialized with rho: 0.85, max_iter: 5, lr: 0.0001, rank: 0, world_size: 36
Rank 0 - Epoch 2/72 loss: 0.7892593741416931
Rank 0 - Epoch 10/72 loss: 0.7880288362503052
Rank 0 - Epoch 20/72 loss: 0.7782564759254456
Rank 0 - Epoch 30/72 loss: 0.774188756942749
Rank 0 - Epoch 40/72 loss: 0.7617462277412415
Rank 0 - Epoch 50/72 loss: 0.7588803172111511
Rank 0 - Epoch 60/72 loss: 0.7513735890388489
Rank 0 - Epoch 70/72 loss: 0.7468337416648865
Training complete.
[92mRank 0 - Testing RMSE: 3.6018[0m
[92mRank: 0, Lengthscale: [[0.63372725 0.63317186]] [0m
[92mRank: 0, Outputscale: 0.6342796683311462 [0m
[92mRank: 0, Noise: 0.6278745532035828 [0m
Run 7 completed successfully
Running cGP 8 with agents: 36
decADMM initialized with rho: 0.85, max_iter: 5, lr: 0.0001, rank: 0, world_size: 36
Rank 0 - Epoch 2/72 loss: 0.7936242818832397
Rank 0 - Epoch 10/72 loss: 0.786361813545227
Rank 0 - Epoch 20/72 loss: 0.7795918583869934
Rank 0 - Epoch 30/72 loss: 0.7733254432678223
Rank 0 - Epoch 40/72 loss: 0.7634121179580688
Rank 0 - Epoch 50/72 loss: 0.7594017386436462
Rank 0 - Epoch 60/72 loss: 0.7490231394767761
Rank 0 - Epoch 70/72 loss: 0.7456858158111572
Training complete.
[92mRank 0 - Testing RMSE: 3.6018[0m
[92mRank: 0, Lengthscale: [[0.63372624 0.63317305]] [0m
[92mRank: 0, Outputscale: 0.6342787146568298 [0m
[92mRank: 0, Noise: 0.6278777122497559 [0m
Run 8 completed successfully
Running cGP 9 with agents: 36
decADMM initialized with rho: 0.85, max_iter: 5, lr: 0.0001, rank: 0, world_size: 36
Rank 0 - Epoch 2/72 loss: 0.7918127179145813
Rank 0 - Epoch 10/72 loss: 0.7817447781562805
Rank 0 - Epoch 20/72 loss: 0.7802701592445374
Rank 0 - Epoch 30/72 loss: 0.7744852304458618
Rank 0 - Epoch 40/72 loss: 0.7664276957511902
Rank 0 - Epoch 50/72 loss: 0.7585142850875854
Rank 0 - Epoch 60/72 loss: 0.7545245885848999
Rank 0 - Epoch 70/72 loss: 0.7434515953063965
Training complete.
[92mRank 0 - Testing RMSE: 3.6018[0m
[92mRank: 0, Lengthscale: [[0.6337259 0.6331725]] [0m
[92mRank: 0, Outputscale: 0.6342784762382507 [0m
[92mRank: 0, Noise: 0.627880334854126 [0m
Run 9 completed successfully
Running cGP 10 with agents: 36
decADMM initialized with rho: 0.85, max_iter: 5, lr: 0.0001, rank: 0, world_size: 36
Rank 0 - Epoch 2/72 loss: 0.7934743762016296
Rank 0 - Epoch 10/72 loss: 0.7856369614601135
Rank 0 - Epoch 20/72 loss: 0.7785301804542542
Rank 0 - Epoch 30/72 loss: 0.772052526473999
Rank 0 - Epoch 40/72 loss: 0.7640010714530945
Rank 0 - Epoch 50/72 loss: 0.7558442950248718
Rank 0 - Epoch 60/72 loss: 0.7487446665763855
Rank 0 - Epoch 70/72 loss: 0.7459461092948914
Training complete.
[92mRank 0 - Testing RMSE: 3.6018[0m
[92mRank: 0, Lengthscale: [[0.63372445 0.63317275]] [0m
[92mRank: 0, Outputscale: 0.6342788338661194 [0m
[92mRank: 0, Noise: 0.6278671622276306 [0m
Run 10 completed successfully
Running pxpGP 1 with agents: 49
[92mRank 0 - sparse dataset size is: 13, local dataset: torch.Size([676, 2]), [0m
[92mRank 0 - Training local sparse GP model with 676 samples[0m
Epoch 1/200 - Loss: 13.342
Epoch 11/200 - Loss: 1.244
Epoch 21/200 - Loss: 1.012
Epoch 31/200 - Loss: 0.879
Epoch 41/200 - Loss: 0.791
Epoch 51/200 - Loss: 0.526
Epoch 61/200 - Loss: 0.285
Epoch 71/200 - Loss: -0.002
Converged at epoch 71 with loss -0.002
[92mRank 0 - Lengthscale: [[0.54997754 0.19876705]] [0m
[92mRank 0 - Outputscale: 2.2048962116241455 [0m
[92mRank 0 - Noise: 0.12595434486865997 [0m
Rank 0 - Augmented dataset size: 1313
Rank 0: After warm start model parameters:
Rank: 0, Lengthscale: [[0.54997754 0.19876705]]
Rank: 0, Outputscale: 2.2048962116241455
Rank: 0, Noise: 0.12595434486865997
decpxADMM initialized with rho: 0.85, lip: 1.0, tol_abs: 1e-05, tol_rel: 0.001, rank: 0, world_size: 49
[92mRank 0 - Training global model with dec-pxADMM optimizer[0m
rank 0, epoch 9, loss: 0.7134339213371277, rho: 0.4250, lip: 1.0000
rank 0, epoch 19, loss: 0.7212117910385132, rho: 0.1062, lip: 1.0000
rank 0, epoch 29, loss: 0.7473664879798889, rho: 0.1062, lip: 1.0000
rank 0, epoch 39, loss: 0.7273178696632385, rho: 0.0266, lip: 1.0000
rank 0, epoch 49, loss: 0.7232328653335571, rho: 0.0266, lip: 1.0000
rank 0, epoch 59, loss: 0.7308489680290222, rho: 0.0266, lip: 1.0000
rank 0, epoch 69, loss: 0.728389322757721, rho: 0.0266, lip: 1.0000
Rank 0 - Training time: 99.45 seconds
[92mRank 0 - Testing RMSE: 0.4449[0m
[92mRank: 0, Lengthscale: [[0.6707319 0.2258151]] [0m
[92mRank: 0, Outputscale: 1.3290188312530518 [0m
[92mRank: 0, Noise: 0.1774894744157791 [0m
Run 1 completed successfully
Running pxpGP 2 with agents: 49
[92mRank 0 - sparse dataset size is: 13, local dataset: torch.Size([676, 2]), [0m
[92mRank 0 - Training local sparse GP model with 676 samples[0m
Epoch 1/200 - Loss: 12.721
Epoch 11/200 - Loss: 1.091
Epoch 21/200 - Loss: 1.000
Epoch 31/200 - Loss: 0.916
Epoch 41/200 - Loss: 0.728
Epoch 51/200 - Loss: 0.529
Epoch 61/200 - Loss: 0.302
Epoch 71/200 - Loss: -0.045
Converged at epoch 71 with loss -0.045
[92mRank 0 - Lengthscale: [[0.55523026 0.280716  ]] [0m
[92mRank 0 - Outputscale: 2.4629740715026855 [0m
[92mRank 0 - Noise: 0.12290448695421219 [0m
Rank 0 - Augmented dataset size: 1313
Rank 0: After warm start model parameters:
Rank: 0, Lengthscale: [[0.55523026 0.28071597]]
Rank: 0, Outputscale: 2.4629740715026855
Rank: 0, Noise: 0.12290448695421219
decpxADMM initialized with rho: 0.85, lip: 1.0, tol_abs: 1e-05, tol_rel: 0.001, rank: 0, world_size: 49
[92mRank 0 - Training global model with dec-pxADMM optimizer[0m
rank 0, epoch 9, loss: 0.6196742653846741, rho: 0.2125, lip: 1.0000
rank 0, epoch 19, loss: 0.5963199138641357, rho: 0.1062, lip: 1.0000
rank 0, epoch 29, loss: 0.5975136160850525, rho: 0.0531, lip: 1.0000
rank 0, epoch 39, loss: 0.592930793762207, rho: 0.0531, lip: 1.0000
rank 0, epoch 49, loss: 0.5888658165931702, rho: 0.0531, lip: 1.0000
rank 0, epoch 59, loss: 0.5887300372123718, rho: 0.0266, lip: 1.0000
rank 0, epoch 69, loss: 0.5946555733680725, rho: 0.0266, lip: 1.0000
Rank 0 - Training time: 104.21 seconds
[92mRank 0 - Testing RMSE: 0.3903[0m
[92mRank: 0, Lengthscale: [[0.50662196 0.33820868]] [0m
[92mRank: 0, Outputscale: 1.366666316986084 [0m
[92mRank: 0, Noise: 0.13218192756175995 [0m
Run 2 completed successfully
Running pxpGP 3 with agents: 49
[92mRank 0 - sparse dataset size is: 13, local dataset: torch.Size([676, 2]), [0m
[92mRank 0 - Training local sparse GP model with 676 samples[0m
Epoch 1/200 - Loss: 13.141
Epoch 11/200 - Loss: 1.093
Epoch 21/200 - Loss: 1.000
Epoch 31/200 - Loss: 0.930
Epoch 41/200 - Loss: 0.733
Epoch 51/200 - Loss: 0.517
Epoch 61/200 - Loss: 0.254
Converged at epoch 70 with loss -0.035
[92mRank 0 - Lengthscale: [[0.681685   0.22549695]] [0m
[92mRank 0 - Outputscale: 2.327450752258301 [0m
[92mRank 0 - Noise: 0.12748827040195465 [0m
Rank 0 - Augmented dataset size: 1313
Rank 0: After warm start model parameters:
Rank: 0, Lengthscale: [[0.68168503 0.22549698]]
Rank: 0, Outputscale: 2.327450752258301
Rank: 0, Noise: 0.12748825550079346
decpxADMM initialized with rho: 0.85, lip: 1.0, tol_abs: 1e-05, tol_rel: 0.001, rank: 0, world_size: 49
[92mRank 0 - Training global model with dec-pxADMM optimizer[0m
rank 0, epoch 9, loss: 0.7524000406265259, rho: 0.4250, lip: 1.0000
rank 0, epoch 19, loss: 0.7397226691246033, rho: 0.1062, lip: 1.0000
rank 0, epoch 29, loss: 0.7526769638061523, rho: 0.1062, lip: 1.0000
rank 0, epoch 39, loss: 0.7466310858726501, rho: 0.0266, lip: 1.0000
rank 0, epoch 49, loss: 0.745435357093811, rho: 0.0266, lip: 1.0000
rank 0, epoch 59, loss: 0.7610750794410706, rho: 0.0266, lip: 1.0000
rank 0, epoch 69, loss: 0.7589091658592224, rho: 0.0266, lip: 1.0000
Rank 0 - Training time: 61.82 seconds
[92mRank 0 - Testing RMSE: 0.4584[0m
[92mRank: 0, Lengthscale: [[0.6258957  0.33179715]] [0m
[92mRank: 0, Outputscale: 0.8701844811439514 [0m
[92mRank: 0, Noise: 0.18906719982624054 [0m
Run 3 completed successfully
Running pxpGP 4 with agents: 49
[92mRank 0 - sparse dataset size is: 13, local dataset: torch.Size([676, 2]), [0m
[92mRank 0 - Training local sparse GP model with 676 samples[0m
Epoch 1/200 - Loss: 11.578
Epoch 11/200 - Loss: 1.127
Epoch 21/200 - Loss: 1.003
Epoch 31/200 - Loss: 0.882
Epoch 41/200 - Loss: 0.712
Epoch 51/200 - Loss: 0.512
Epoch 61/200 - Loss: 0.254
Converged at epoch 70 with loss -0.022
[92mRank 0 - Lengthscale: [[0.6186143  0.21990544]] [0m
[92mRank 0 - Outputscale: 2.2897868156433105 [0m
[92mRank 0 - Noise: 0.1254338175058365 [0m
Rank 0 - Augmented dataset size: 1313
Rank 0: After warm start model parameters:
Rank: 0, Lengthscale: [[0.6186143  0.21990545]]
Rank: 0, Outputscale: 2.2897868156433105
Rank: 0, Noise: 0.1254338175058365
decpxADMM initialized with rho: 0.85, lip: 1.0, tol_abs: 1e-05, tol_rel: 0.001, rank: 0, world_size: 49
[92mRank 0 - Training global model with dec-pxADMM optimizer[0m
rank 0, epoch 9, loss: 0.6863521337509155, rho: 0.4250, lip: 1.0000
rank 0, epoch 19, loss: 0.6783268451690674, rho: 0.2125, lip: 1.0000
rank 0, epoch 29, loss: 0.684782087802887, rho: 0.1062, lip: 1.0000
rank 0, epoch 39, loss: 0.6776189804077148, rho: 0.0531, lip: 1.0000
rank 0, epoch 49, loss: 0.6739704012870789, rho: 0.0266, lip: 1.0000
rank 0, epoch 59, loss: 0.6805729269981384, rho: 0.0266, lip: 1.0000
rank 0, epoch 69, loss: 0.6908409595489502, rho: 0.0266, lip: 1.0000
Rank 0 - Training time: 81.77 seconds
[92mRank 0 - Testing RMSE: 0.4195[0m
[92mRank: 0, Lengthscale: [[0.57023615 0.29857764]] [0m
[92mRank: 0, Outputscale: 1.1640684604644775 [0m
[92mRank: 0, Noise: 0.16269665956497192 [0m
Run 4 completed successfully
Running pxpGP 5 with agents: 49
[92mRank 0 - sparse dataset size is: 13, local dataset: torch.Size([676, 2]), [0m
[92mRank 0 - Training local sparse GP model with 676 samples[0m
Epoch 1/200 - Loss: 12.308
Epoch 11/200 - Loss: 1.292
Epoch 21/200 - Loss: 1.100
Epoch 31/200 - Loss: 0.994
Epoch 41/200 - Loss: 0.751
Epoch 51/200 - Loss: 0.547
Epoch 61/200 - Loss: 0.289
Epoch 71/200 - Loss: -0.005
Converged at epoch 71 with loss -0.005
[92mRank 0 - Lengthscale: [[0.28082234 0.4035286 ]] [0m
[92mRank 0 - Outputscale: 2.3287243843078613 [0m
[92mRank 0 - Noise: 0.12816740572452545 [0m
Rank 0 - Augmented dataset size: 1313
Rank 0: After warm start model parameters:
Rank: 0, Lengthscale: [[0.28082234 0.40352857]]
Rank: 0, Outputscale: 2.3287243843078613
Rank: 0, Noise: 0.12816742062568665
decpxADMM initialized with rho: 0.85, lip: 1.0, tol_abs: 1e-05, tol_rel: 0.001, rank: 0, world_size: 49
[92mRank 0 - Training global model with dec-pxADMM optimizer[0m
rank 0, epoch 9, loss: 0.6997269988059998, rho: 0.4250, lip: 1.0000
rank 0, epoch 19, loss: 0.6613069176673889, rho: 0.2125, lip: 1.0000
rank 0, epoch 29, loss: 0.6739217638969421, rho: 0.2125, lip: 1.0000
rank 0, epoch 39, loss: 0.6609412431716919, rho: 0.0531, lip: 1.0000
rank 0, epoch 49, loss: 0.6627217531204224, rho: 0.0531, lip: 1.0000
rank 0, epoch 59, loss: 0.6689538955688477, rho: 0.0133, lip: 1.0000
rank 0, epoch 69, loss: 0.6689515113830566, rho: 0.0133, lip: 1.0000
Rank 0 - Training time: 76.01 seconds
[92mRank 0 - Testing RMSE: 0.4184[0m
[92mRank: 0, Lengthscale: [[0.5466212  0.30437124]] [0m
[92mRank: 0, Outputscale: 1.2177977561950684 [0m
[92mRank: 0, Noise: 0.160570427775383 [0m
Run 5 completed successfully
Running pxpGP 6 with agents: 49
[92mRank 0 - sparse dataset size is: 13, local dataset: torch.Size([676, 2]), [0m
[92mRank 0 - Training local sparse GP model with 676 samples[0m
Epoch 1/200 - Loss: 12.031
Epoch 11/200 - Loss: 1.268
Epoch 21/200 - Loss: 1.039
Epoch 31/200 - Loss: 0.891
Epoch 41/200 - Loss: 0.794
Epoch 51/200 - Loss: 0.561
Epoch 61/200 - Loss: 0.422
Converged at epoch 70 with loss -0.001
[92mRank 0 - Lengthscale: [[0.7090556  0.24220416]] [0m
[92mRank 0 - Outputscale: 2.3621702194213867 [0m
[92mRank 0 - Noise: 0.1415901631116867 [0m
Rank 0 - Augmented dataset size: 1313
Rank 0: After warm start model parameters:
Rank: 0, Lengthscale: [[0.70905566 0.24220416]]
Rank: 0, Outputscale: 2.3621702194213867
Rank: 0, Noise: 0.1415901631116867
decpxADMM initialized with rho: 0.85, lip: 1.0, tol_abs: 1e-05, tol_rel: 0.001, rank: 0, world_size: 49
[92mRank 0 - Training global model with dec-pxADMM optimizer[0m
rank 0, epoch 9, loss: 0.7034324407577515, rho: 0.4250, lip: 1.0000
rank 0, epoch 19, loss: 0.6860990524291992, rho: 0.2125, lip: 1.0000
rank 0, epoch 29, loss: 0.6852370500564575, rho: 0.1062, lip: 1.0000
rank 0, epoch 39, loss: 0.6716094017028809, rho: 0.0531, lip: 1.0000
rank 0, epoch 49, loss: 0.6824881434440613, rho: 0.0531, lip: 1.0000
rank 0, epoch 59, loss: 0.6812810897827148, rho: 0.0531, lip: 1.0000
rank 0, epoch 69, loss: 0.6862120628356934, rho: 0.0531, lip: 1.0000
Rank 0 - Training time: 120.05 seconds
[92mRank 0 - Testing RMSE: 0.4374[0m
[92mRank: 0, Lengthscale: [[0.5554457 0.2459364]] [0m
[92mRank: 0, Outputscale: 1.4575364589691162 [0m
[92mRank: 0, Noise: 0.16731584072113037 [0m
Run 6 completed successfully
Running pxpGP 7 with agents: 49
[92mRank 0 - sparse dataset size is: 13, local dataset: torch.Size([676, 2]), [0m
[92mRank 0 - Training local sparse GP model with 676 samples[0m
Epoch 1/200 - Loss: 13.897
Epoch 11/200 - Loss: 1.143
Epoch 21/200 - Loss: 1.051
Epoch 31/200 - Loss: 0.975
Epoch 41/200 - Loss: 0.785
Epoch 51/200 - Loss: 0.567
Epoch 61/200 - Loss: 0.277
Converged at epoch 70 with loss -0.008
[92mRank 0 - Lengthscale: [[0.72237074 0.30728373]] [0m
[92mRank 0 - Outputscale: 2.461693048477173 [0m
[92mRank 0 - Noise: 0.13944287598133087 [0m
Rank 0 - Augmented dataset size: 1313
Rank 0: After warm start model parameters:
Rank: 0, Lengthscale: [[0.7223708  0.30728373]]
Rank: 0, Outputscale: 2.461693048477173
Rank: 0, Noise: 0.13944287598133087
decpxADMM initialized with rho: 0.85, lip: 1.0, tol_abs: 1e-05, tol_rel: 0.001, rank: 0, world_size: 49
[92mRank 0 - Training global model with dec-pxADMM optimizer[0m
rank 0, epoch 9, loss: 0.7204676866531372, rho: 0.4250, lip: 1.0000
rank 0, epoch 19, loss: 0.7005099654197693, rho: 0.0531, lip: 1.0000
rank 0, epoch 29, loss: 0.7215250134468079, rho: 0.0531, lip: 1.0000
rank 0, epoch 39, loss: 0.7091400623321533, rho: 0.0531, lip: 1.0000
rank 0, epoch 49, loss: 0.7170420289039612, rho: 0.0266, lip: 1.0000
rank 0, epoch 59, loss: 0.7333265542984009, rho: 0.0266, lip: 1.0000
rank 0, epoch 69, loss: 0.7301372289657593, rho: 0.0266, lip: 1.0000
Rank 0 - Training time: 77.47 seconds
[92mRank 0 - Testing RMSE: 0.4221[0m
[92mRank: 0, Lengthscale: [[0.5529808  0.38660297]] [0m
[92mRank: 0, Outputscale: 0.8159240484237671 [0m
[92mRank: 0, Noise: 0.18950669467449188 [0m
Run 7 completed successfully
Running pxpGP 8 with agents: 49
[92mRank 0 - sparse dataset size is: 13, local dataset: torch.Size([676, 2]), [0m
[92mRank 0 - Training local sparse GP model with 676 samples[0m
Epoch 1/200 - Loss: 11.702
Epoch 11/200 - Loss: 1.157
Epoch 21/200 - Loss: 1.176
Epoch 31/200 - Loss: 0.973
Epoch 41/200 - Loss: 0.832
Epoch 51/200 - Loss: 0.606
Epoch 61/200 - Loss: 0.375
Epoch 71/200 - Loss: 0.086
Converged at epoch 74 with loss -0.016
[92mRank 0 - Lengthscale: [[0.38721445 0.35886973]] [0m
[92mRank 0 - Outputscale: 2.256690263748169 [0m
[92mRank 0 - Noise: 0.13225418329238892 [0m
Rank 0 - Augmented dataset size: 1313
Rank 0: After warm start model parameters:
Rank: 0, Lengthscale: [[0.38721445 0.35886973]]
Rank: 0, Outputscale: 2.256690263748169
Rank: 0, Noise: 0.1322541981935501
decpxADMM initialized with rho: 0.85, lip: 1.0, tol_abs: 1e-05, tol_rel: 0.001, rank: 0, world_size: 49
[92mRank 0 - Training global model with dec-pxADMM optimizer[0m
rank 0, epoch 9, loss: 0.6929358243942261, rho: 0.4250, lip: 1.0000
rank 0, epoch 19, loss: 0.6736028790473938, rho: 0.2125, lip: 1.0000
rank 0, epoch 29, loss: 0.685013473033905, rho: 0.1062, lip: 1.0000
rank 0, epoch 39, loss: 0.6659655570983887, rho: 0.0531, lip: 1.0000
rank 0, epoch 49, loss: 0.6731287837028503, rho: 0.0266, lip: 1.0000
rank 0, epoch 59, loss: 0.676810085773468, rho: 0.0266, lip: 1.0000
rank 0, epoch 69, loss: 0.6887176632881165, rho: 0.0266, lip: 1.0000
Rank 0 - Training time: 80.97 seconds
[92mRank 0 - Testing RMSE: 0.4495[0m
[92mRank: 0, Lengthscale: [[0.5995659  0.33485967]] [0m
[92mRank: 0, Outputscale: 1.3114653825759888 [0m
[92mRank: 0, Noise: 0.17914672195911407 [0m
Run 8 completed successfully
Running pxpGP 9 with agents: 49
[92mRank 0 - sparse dataset size is: 13, local dataset: torch.Size([676, 2]), [0m
[92mRank 0 - Training local sparse GP model with 676 samples[0m
Epoch 1/200 - Loss: 12.852
Epoch 11/200 - Loss: 1.187
Epoch 21/200 - Loss: 1.058
Epoch 31/200 - Loss: 0.890
Epoch 41/200 - Loss: 0.751
Epoch 51/200 - Loss: 0.547
Epoch 61/200 - Loss: 0.312
Epoch 71/200 - Loss: 0.032
Converged at epoch 72 with loss -0.020
[92mRank 0 - Lengthscale: [[0.72220373 0.22566146]] [0m
[92mRank 0 - Outputscale: 2.5059096813201904 [0m
[92mRank 0 - Noise: 0.1274290531873703 [0m
Rank 0 - Augmented dataset size: 1313
Rank 0: After warm start model parameters:
Rank: 0, Lengthscale: [[0.72220373 0.22566144]]
Rank: 0, Outputscale: 2.5059096813201904
Rank: 0, Noise: 0.1274290382862091
decpxADMM initialized with rho: 0.85, lip: 1.0, tol_abs: 1e-05, tol_rel: 0.001, rank: 0, world_size: 49
[92mRank 0 - Training global model with dec-pxADMM optimizer[0m
rank 0, epoch 9, loss: 0.6992851495742798, rho: 0.4250, lip: 1.0000
rank 0, epoch 19, loss: 0.6698796153068542, rho: 0.1062, lip: 1.0000
rank 0, epoch 29, loss: 0.6744767427444458, rho: 0.1062, lip: 1.0000
rank 0, epoch 39, loss: 0.6565180420875549, rho: 0.0531, lip: 1.0000
rank 0, epoch 49, loss: 0.6712064743041992, rho: 0.0266, lip: 1.0000
rank 0, epoch 59, loss: 0.6746169924736023, rho: 0.0266, lip: 1.0000
rank 0, epoch 69, loss: 0.6853331923484802, rho: 0.0266, lip: 1.0000
Rank 0 - Training time: 73.39 seconds
[92mRank 0 - Testing RMSE: 0.4703[0m
[92mRank: 0, Lengthscale: [[0.5528925  0.32520935]] [0m
[92mRank: 0, Outputscale: 1.10935640335083 [0m
[92mRank: 0, Noise: 0.16266189515590668 [0m
Run 9 completed successfully
Running pxpGP 10 with agents: 49
[92mRank 0 - sparse dataset size is: 13, local dataset: torch.Size([676, 2]), [0m
[92mRank 0 - Training local sparse GP model with 676 samples[0m
Epoch 1/200 - Loss: 12.287
Epoch 11/200 - Loss: 1.211
Epoch 21/200 - Loss: 1.039
Epoch 31/200 - Loss: 0.879
Epoch 41/200 - Loss: 0.730
Epoch 51/200 - Loss: 0.571
Epoch 61/200 - Loss: 0.270
Epoch 71/200 - Loss: -0.008
Converged at epoch 71 with loss -0.008
[92mRank 0 - Lengthscale: [[0.59634006 0.22524256]] [0m
[92mRank 0 - Outputscale: 2.290990114212036 [0m
[92mRank 0 - Noise: 0.12250231951475143 [0m
Rank 0 - Augmented dataset size: 1313
Rank 0: After warm start model parameters:
Rank: 0, Lengthscale: [[0.59634006 0.22524258]]
Rank: 0, Outputscale: 2.290990114212036
Rank: 0, Noise: 0.12250234931707382
decpxADMM initialized with rho: 0.85, lip: 1.0, tol_abs: 1e-05, tol_rel: 0.001, rank: 0, world_size: 49
[92mRank 0 - Training global model with dec-pxADMM optimizer[0m
rank 0, epoch 9, loss: 0.7083821296691895, rho: 0.4250, lip: 1.0000
rank 0, epoch 19, loss: 0.6912040114402771, rho: 0.1062, lip: 1.0000
rank 0, epoch 29, loss: 0.6975833177566528, rho: 0.1062, lip: 1.0000
rank 0, epoch 39, loss: 0.6895921230316162, rho: 0.0531, lip: 1.0000
rank 0, epoch 49, loss: 0.6915353536605835, rho: 0.0531, lip: 1.0000
rank 0, epoch 59, loss: 0.698368489742279, rho: 0.0531, lip: 1.0000
rank 0, epoch 69, loss: 0.710537850856781, rho: 0.0531, lip: 1.0000
Rank 0 - Training time: 69.46 seconds
[92mRank 0 - Testing RMSE: 0.3910[0m
[92mRank: 0, Lengthscale: [[0.61911005 0.33227074]] [0m
[92mRank: 0, Outputscale: 1.0305451154708862 [0m
[92mRank: 0, Noise: 0.17453595995903015 [0m
Run 10 completed successfully
Running gapxGP 1 with agents: 49
decpxADMM initialized with rho: 0.75, lip: 1.0, tol_abs: 1e-05, tol_rel: 0.001, rank: 0, world_size: 49
Rank 0 - Epoch 2/73 loss: 0.9002888202667236
Rank 0 - Epoch 10/73 loss: 0.6617869734764099
Rank 0 - Epoch 20/73 loss: 0.27375489473342896
Rank 0 - Epoch 30/73 loss: -0.19434645771980286
Rank 0 - Epoch 40/73 loss: -0.6666616797447205
Rank 0 - Epoch 50/73 loss: -1.1239826679229736
Rank 0 - Epoch 60/73 loss: -1.5189610719680786
Rank 0 - Epoch 70/73 loss: -1.7745168209075928
[92mRank 0 - Testing RMSE: 0.0456[0m
[92mRank: 0, Lengthscale: [[0.60994524 0.3659882 ]] [0m
[92mRank: 0, Outputscale: 1.3144989013671875 [0m
[92mRank: 0, Noise: 0.0007827440276741982 [0m
Run 1 completed successfully
Running gapxGP 2 with agents: 49
decpxADMM initialized with rho: 0.75, lip: 1.0, tol_abs: 1e-05, tol_rel: 0.001, rank: 0, world_size: 49
Rank 0 - Epoch 2/73 loss: 0.8947414755821228
Rank 0 - Epoch 10/73 loss: 0.6562684774398804
Rank 0 - Epoch 20/73 loss: 0.27782878279685974
Rank 0 - Epoch 30/73 loss: -0.18921612203121185
Rank 0 - Epoch 40/73 loss: -0.6692793965339661
Rank 0 - Epoch 50/73 loss: -1.1181249618530273
Rank 0 - Epoch 60/73 loss: -1.5355840921401978
Rank 0 - Epoch 70/73 loss: -1.79109525680542
[92mRank 0 - Testing RMSE: 0.0492[0m
[92mRank: 0, Lengthscale: [[0.61789286 0.35931832]] [0m
[92mRank: 0, Outputscale: 1.3138667345046997 [0m
[92mRank: 0, Noise: 0.0007845343789085746 [0m
Run 2 completed successfully
Running gapxGP 3 with agents: 49
decpxADMM initialized with rho: 0.75, lip: 1.0, tol_abs: 1e-05, tol_rel: 0.001, rank: 0, world_size: 49
Rank 0 - Epoch 2/73 loss: 0.8910561800003052
Rank 0 - Epoch 10/73 loss: 0.6580935716629028
Rank 0 - Epoch 20/73 loss: 0.2608646750450134
Rank 0 - Epoch 30/73 loss: -0.19009117782115936
Rank 0 - Epoch 40/73 loss: -0.6621651649475098
Rank 0 - Epoch 50/73 loss: -1.1575326919555664
Rank 0 - Epoch 60/73 loss: -1.5120586156845093
Rank 0 - Epoch 70/73 loss: -1.7865996360778809
[92mRank 0 - Testing RMSE: 0.0543[0m
[92mRank: 0, Lengthscale: [[0.617909  0.3558797]] [0m
[92mRank: 0, Outputscale: 1.3144385814666748 [0m
[92mRank: 0, Noise: 0.0007806014036759734 [0m
Run 3 completed successfully
Running gapxGP 4 with agents: 49
decpxADMM initialized with rho: 0.75, lip: 1.0, tol_abs: 1e-05, tol_rel: 0.001, rank: 0, world_size: 49
Rank 0 - Epoch 2/73 loss: 0.8926775455474854
Rank 0 - Epoch 10/73 loss: 0.6534131765365601
Rank 0 - Epoch 20/73 loss: 0.2664828598499298
Rank 0 - Epoch 30/73 loss: -0.200982004404068
Rank 0 - Epoch 40/73 loss: -0.6777341961860657
Rank 0 - Epoch 50/73 loss: -1.1501365900039673
Rank 0 - Epoch 60/73 loss: -1.5119472742080688
Rank 0 - Epoch 70/73 loss: -1.7563254833221436
[92mRank 0 - Testing RMSE: 0.0528[0m
[92mRank: 0, Lengthscale: [[0.61583334 0.3665555 ]] [0m
[92mRank: 0, Outputscale: 1.3133271932601929 [0m
[92mRank: 0, Noise: 0.0007774714613333344 [0m
Run 4 completed successfully
Running gapxGP 5 with agents: 49
decpxADMM initialized with rho: 0.75, lip: 1.0, tol_abs: 1e-05, tol_rel: 0.001, rank: 0, world_size: 49
Rank 0 - Epoch 2/73 loss: 0.894606351852417
Rank 0 - Epoch 10/73 loss: 0.6577773094177246
Rank 0 - Epoch 20/73 loss: 0.2708270251750946
Rank 0 - Epoch 30/73 loss: -0.18988750874996185
Rank 0 - Epoch 40/73 loss: -0.6729195713996887
Rank 0 - Epoch 50/73 loss: -1.1454298496246338
Rank 0 - Epoch 60/73 loss: -1.5200971364974976
Rank 0 - Epoch 70/73 loss: -1.7646797895431519
[92mRank 0 - Testing RMSE: 0.0380[0m
[92mRank: 0, Lengthscale: [[0.6088973  0.36007458]] [0m
[92mRank: 0, Outputscale: 1.3156026601791382 [0m
[92mRank: 0, Noise: 0.0007831379189155996 [0m
Run 5 completed successfully
Running gapxGP 6 with agents: 49
decpxADMM initialized with rho: 0.75, lip: 1.0, tol_abs: 1e-05, tol_rel: 0.001, rank: 0, world_size: 49
Rank 0 - Epoch 2/73 loss: 0.8878150582313538
Rank 0 - Epoch 10/73 loss: 0.6552162170410156
Rank 0 - Epoch 20/73 loss: 0.2681078612804413
Rank 0 - Epoch 30/73 loss: -0.19581983983516693
Rank 0 - Epoch 40/73 loss: -0.6759728193283081
Rank 0 - Epoch 50/73 loss: -1.118888020515442
Rank 0 - Epoch 60/73 loss: -1.5075774192810059
Rank 0 - Epoch 70/73 loss: -1.7641043663024902
[92mRank 0 - Testing RMSE: 0.0504[0m
[92mRank: 0, Lengthscale: [[0.6202629 0.3720655]] [0m
[92mRank: 0, Outputscale: 1.3121631145477295 [0m
[92mRank: 0, Noise: 0.000783424882683903 [0m
Run 6 completed successfully
Running gapxGP 7 with agents: 49
decpxADMM initialized with rho: 0.75, lip: 1.0, tol_abs: 1e-05, tol_rel: 0.001, rank: 0, world_size: 49
Rank 0 - Epoch 2/73 loss: 0.8928331732749939
Rank 0 - Epoch 10/73 loss: 0.6579049825668335
Rank 0 - Epoch 20/73 loss: 0.26302817463874817
Rank 0 - Epoch 30/73 loss: -0.20344078540802002
Rank 0 - Epoch 40/73 loss: -0.6807156801223755
Rank 0 - Epoch 50/73 loss: -1.1355094909667969
Rank 0 - Epoch 60/73 loss: -1.5603402853012085
Rank 0 - Epoch 70/73 loss: -1.7846285104751587
[92mRank 0 - Testing RMSE: 0.0531[0m
[92mRank: 0, Lengthscale: [[0.6127305  0.35539547]] [0m
[92mRank: 0, Outputscale: 1.315061092376709 [0m
[92mRank: 0, Noise: 0.0007808178779669106 [0m
Run 7 completed successfully
Running gapxGP 8 with agents: 49
decpxADMM initialized with rho: 0.75, lip: 1.0, tol_abs: 1e-05, tol_rel: 0.001, rank: 0, world_size: 49
Rank 0 - Epoch 2/73 loss: 0.8882951736450195
Rank 0 - Epoch 10/73 loss: 0.6553918719291687
Rank 0 - Epoch 20/73 loss: 0.2704806327819824
Rank 0 - Epoch 30/73 loss: -0.19190260767936707
Rank 0 - Epoch 40/73 loss: -0.6745866537094116
Rank 0 - Epoch 50/73 loss: -1.1162266731262207
Rank 0 - Epoch 60/73 loss: -1.5329445600509644
Rank 0 - Epoch 70/73 loss: -1.7770220041275024
[92mRank 0 - Testing RMSE: 0.0548[0m
[92mRank: 0, Lengthscale: [[0.62867147 0.3607572 ]] [0m
[92mRank: 0, Outputscale: 1.3127957582473755 [0m
[92mRank: 0, Noise: 0.0007876339950598776 [0m
Run 8 completed successfully
Running gapxGP 9 with agents: 49
decpxADMM initialized with rho: 0.75, lip: 1.0, tol_abs: 1e-05, tol_rel: 0.001, rank: 0, world_size: 49
Rank 0 - Epoch 2/73 loss: 0.8921375274658203
Rank 0 - Epoch 10/73 loss: 0.6584093570709229
Rank 0 - Epoch 20/73 loss: 0.26842790842056274
Rank 0 - Epoch 30/73 loss: -0.19609375298023224
Rank 0 - Epoch 40/73 loss: -0.6809046268463135
Rank 0 - Epoch 50/73 loss: -1.1426244974136353
Rank 0 - Epoch 60/73 loss: -1.5347615480422974
Rank 0 - Epoch 70/73 loss: -1.7854288816452026
[92mRank 0 - Testing RMSE: 0.0520[0m
[92mRank: 0, Lengthscale: [[0.59966516 0.36117703]] [0m
[92mRank: 0, Outputscale: 1.3121544122695923 [0m
[92mRank: 0, Noise: 0.0007793045951984823 [0m
Run 9 completed successfully
Running gapxGP 10 with agents: 49
decpxADMM initialized with rho: 0.75, lip: 1.0, tol_abs: 1e-05, tol_rel: 0.001, rank: 0, world_size: 49
Rank 0 - Epoch 2/73 loss: 0.8941758275032043
Rank 0 - Epoch 10/73 loss: 0.6616919040679932
Rank 0 - Epoch 20/73 loss: 0.2732888460159302
Rank 0 - Epoch 30/73 loss: -0.19629356265068054
Rank 0 - Epoch 40/73 loss: -0.6768988370895386
Rank 0 - Epoch 50/73 loss: -1.1210911273956299
Rank 0 - Epoch 60/73 loss: -1.5503592491149902
Rank 0 - Epoch 70/73 loss: -1.8080637454986572
[92mRank 0 - Testing RMSE: 0.0534[0m
[92mRank: 0, Lengthscale: [[0.6124991 0.3671341]] [0m
[92mRank: 0, Outputscale: 1.3182278871536255 [0m
[92mRank: 0, Noise: 0.0007789378869347274 [0m
Run 10 completed successfully
Running apxGP 1 with agents: 49
decpxADMM initialized with rho: 0.85, lip: 1.0, tol_abs: 1e-05, tol_rel: 0.001, rank: 0, world_size: 49
Rank 0 - Epoch 2/98 loss: 0.7467918992042542
Rank 0 - Epoch 10/98 loss: 0.4734395146369934
Rank 0 - Epoch 20/98 loss: 0.04208717122673988
Rank 0 - Epoch 30/98 loss: -0.4535163938999176
Rank 0 - Epoch 40/98 loss: -0.9802711009979248
Rank 0 - Epoch 50/98 loss: -1.5097594261169434
Rank 0 - Epoch 60/98 loss: -2.0133814811706543
Rank 0 - Epoch 70/98 loss: -2.4679713249206543
Rank 0 - Epoch 80/98 loss: -2.8396334648132324
Rank 0 - Epoch 90/98 loss: -3.094391345977783
Training complete.
[92mRank 0 - Testing RMSE: 3.1829[0m
[92mRank: 0, Lengthscale: [[0.5947454  0.35480705]] [0m
[92mRank: 0, Outputscale: 1.0027027130126953 [0m
[92mRank: 0, Noise: 0.00019460447947494686 [0m
Run 1 completed successfully
Running apxGP 2 with agents: 49
decpxADMM initialized with rho: 0.85, lip: 1.0, tol_abs: 1e-05, tol_rel: 0.001, rank: 0, world_size: 49
Rank 0 - Epoch 2/98 loss: 0.7467918992042542
Rank 0 - Epoch 10/98 loss: 0.4734395146369934
Rank 0 - Epoch 20/98 loss: 0.04208717122673988
Rank 0 - Epoch 30/98 loss: -0.4535163938999176
Rank 0 - Epoch 40/98 loss: -0.9802711009979248
Rank 0 - Epoch 50/98 loss: -1.5097594261169434
Rank 0 - Epoch 60/98 loss: -2.0133814811706543
Rank 0 - Epoch 70/98 loss: -2.4679713249206543
Rank 0 - Epoch 80/98 loss: -2.8396334648132324
Rank 0 - Epoch 90/98 loss: -3.094391345977783
Training complete.
[92mRank 0 - Testing RMSE: 3.1829[0m
[92mRank: 0, Lengthscale: [[0.5947454  0.35480705]] [0m
[92mRank: 0, Outputscale: 1.0027027130126953 [0m
[92mRank: 0, Noise: 0.00019460447947494686 [0m
Run 2 completed successfully
Running apxGP 3 with agents: 49
decpxADMM initialized with rho: 0.85, lip: 1.0, tol_abs: 1e-05, tol_rel: 0.001, rank: 0, world_size: 49
Rank 0 - Epoch 2/98 loss: 0.7467918992042542
Rank 0 - Epoch 10/98 loss: 0.4734395146369934
Rank 0 - Epoch 20/98 loss: 0.04208717122673988
Rank 0 - Epoch 30/98 loss: -0.4535163938999176
Rank 0 - Epoch 40/98 loss: -0.9802711009979248
Rank 0 - Epoch 50/98 loss: -1.5097594261169434
Rank 0 - Epoch 60/98 loss: -2.0133814811706543
Rank 0 - Epoch 70/98 loss: -2.4679713249206543
Rank 0 - Epoch 80/98 loss: -2.8396334648132324
Rank 0 - Epoch 90/98 loss: -3.094391345977783
Training complete.
[92mRank 0 - Testing RMSE: 3.1829[0m
[92mRank: 0, Lengthscale: [[0.5947454  0.35480705]] [0m
[92mRank: 0, Outputscale: 1.0027027130126953 [0m
[92mRank: 0, Noise: 0.00019460447947494686 [0m
Run 3 completed successfully
Running apxGP 4 with agents: 49
decpxADMM initialized with rho: 0.85, lip: 1.0, tol_abs: 1e-05, tol_rel: 0.001, rank: 0, world_size: 49
Rank 0 - Epoch 2/98 loss: 0.7467918992042542
Rank 0 - Epoch 10/98 loss: 0.4734395146369934
Rank 0 - Epoch 20/98 loss: 0.04208717122673988
Rank 0 - Epoch 30/98 loss: -0.4535163938999176
Rank 0 - Epoch 40/98 loss: -0.9802711009979248
Rank 0 - Epoch 50/98 loss: -1.5097594261169434
Rank 0 - Epoch 60/98 loss: -2.0133814811706543
Rank 0 - Epoch 70/98 loss: -2.4679713249206543
Rank 0 - Epoch 80/98 loss: -2.8396334648132324
Rank 0 - Epoch 90/98 loss: -3.094391345977783
Training complete.
[92mRank 0 - Testing RMSE: 3.1829[0m
[92mRank: 0, Lengthscale: [[0.5947454  0.35480705]] [0m
[92mRank: 0, Outputscale: 1.0027027130126953 [0m
[92mRank: 0, Noise: 0.00019460447947494686 [0m
Run 4 completed successfully
Running apxGP 5 with agents: 49
decpxADMM initialized with rho: 0.85, lip: 1.0, tol_abs: 1e-05, tol_rel: 0.001, rank: 0, world_size: 49
Rank 0 - Epoch 2/98 loss: 0.7467918992042542
Rank 0 - Epoch 10/98 loss: 0.4734395146369934
Rank 0 - Epoch 20/98 loss: 0.04208717122673988
Rank 0 - Epoch 30/98 loss: -0.4535163938999176
Rank 0 - Epoch 40/98 loss: -0.9802711009979248
Rank 0 - Epoch 50/98 loss: -1.5097594261169434
Rank 0 - Epoch 60/98 loss: -2.0133814811706543
Rank 0 - Epoch 70/98 loss: -2.4679713249206543
Rank 0 - Epoch 80/98 loss: -2.8396334648132324
Rank 0 - Epoch 90/98 loss: -3.094391345977783
Training complete.
[92mRank 0 - Testing RMSE: 3.1829[0m
[92mRank: 0, Lengthscale: [[0.5947454  0.35480705]] [0m
[92mRank: 0, Outputscale: 1.0027027130126953 [0m
[92mRank: 0, Noise: 0.00019460447947494686 [0m
Run 5 completed successfully
Running apxGP 6 with agents: 49
decpxADMM initialized with rho: 0.85, lip: 1.0, tol_abs: 1e-05, tol_rel: 0.001, rank: 0, world_size: 49
Rank 0 - Epoch 2/98 loss: 0.7467918992042542
Rank 0 - Epoch 10/98 loss: 0.4734395146369934
Rank 0 - Epoch 20/98 loss: 0.04208717122673988
Rank 0 - Epoch 30/98 loss: -0.4535163938999176
Rank 0 - Epoch 40/98 loss: -0.9802711009979248
Rank 0 - Epoch 50/98 loss: -1.5097594261169434
Rank 0 - Epoch 60/98 loss: -2.0133814811706543
Rank 0 - Epoch 70/98 loss: -2.4679713249206543
Rank 0 - Epoch 80/98 loss: -2.8396334648132324
Rank 0 - Epoch 90/98 loss: -3.094391345977783
Training complete.
[92mRank 0 - Testing RMSE: 3.1829[0m
[92mRank: 0, Lengthscale: [[0.5947454  0.35480705]] [0m
[92mRank: 0, Outputscale: 1.0027027130126953 [0m
[92mRank: 0, Noise: 0.00019460447947494686 [0m
Run 6 completed successfully
Running apxGP 7 with agents: 49
decpxADMM initialized with rho: 0.85, lip: 1.0, tol_abs: 1e-05, tol_rel: 0.001, rank: 0, world_size: 49
Rank 0 - Epoch 2/98 loss: 0.7467918992042542
Rank 0 - Epoch 10/98 loss: 0.4734395146369934
Rank 0 - Epoch 20/98 loss: 0.04208717122673988
Rank 0 - Epoch 30/98 loss: -0.4535163938999176
Rank 0 - Epoch 40/98 loss: -0.9802711009979248
Rank 0 - Epoch 50/98 loss: -1.5097594261169434
Rank 0 - Epoch 60/98 loss: -2.0133814811706543
Rank 0 - Epoch 70/98 loss: -2.4679713249206543
Rank 0 - Epoch 80/98 loss: -2.8396334648132324
Rank 0 - Epoch 90/98 loss: -3.094391345977783
Training complete.
[92mRank 0 - Testing RMSE: 3.1829[0m
[92mRank: 0, Lengthscale: [[0.5947454  0.35480705]] [0m
[92mRank: 0, Outputscale: 1.0027027130126953 [0m
[92mRank: 0, Noise: 0.00019460447947494686 [0m
Run 7 completed successfully
Running apxGP 8 with agents: 49
decpxADMM initialized with rho: 0.85, lip: 1.0, tol_abs: 1e-05, tol_rel: 0.001, rank: 0, world_size: 49
Rank 0 - Epoch 2/98 loss: 0.7467918992042542
Rank 0 - Epoch 10/98 loss: 0.4734395146369934
Rank 0 - Epoch 20/98 loss: 0.04208717122673988
Rank 0 - Epoch 30/98 loss: -0.4535163938999176
Rank 0 - Epoch 40/98 loss: -0.9802711009979248
Rank 0 - Epoch 50/98 loss: -1.5097594261169434
Rank 0 - Epoch 60/98 loss: -2.0133814811706543
Rank 0 - Epoch 70/98 loss: -2.4679713249206543
Rank 0 - Epoch 80/98 loss: -2.8396334648132324
Rank 0 - Epoch 90/98 loss: -3.094391345977783
Training complete.
[92mRank 0 - Testing RMSE: 3.1829[0m
[92mRank: 0, Lengthscale: [[0.5947454  0.35480705]] [0m
[92mRank: 0, Outputscale: 1.0027027130126953 [0m
[92mRank: 0, Noise: 0.00019460447947494686 [0m
Run 8 completed successfully
Running apxGP 9 with agents: 49
decpxADMM initialized with rho: 0.85, lip: 1.0, tol_abs: 1e-05, tol_rel: 0.001, rank: 0, world_size: 49
Rank 0 - Epoch 2/98 loss: 0.7467918992042542
Rank 0 - Epoch 10/98 loss: 0.4734395146369934
Rank 0 - Epoch 20/98 loss: 0.04208717122673988
Rank 0 - Epoch 30/98 loss: -0.4535163938999176
Rank 0 - Epoch 40/98 loss: -0.9802711009979248
Rank 0 - Epoch 50/98 loss: -1.5097594261169434
Rank 0 - Epoch 60/98 loss: -2.0133814811706543
Rank 0 - Epoch 70/98 loss: -2.4679713249206543
Rank 0 - Epoch 80/98 loss: -2.8396334648132324
Rank 0 - Epoch 90/98 loss: -3.094391345977783
Training complete.
[92mRank 0 - Testing RMSE: 3.1829[0m
[92mRank: 0, Lengthscale: [[0.5947454  0.35480705]] [0m
[92mRank: 0, Outputscale: 1.0027027130126953 [0m
[92mRank: 0, Noise: 0.00019460447947494686 [0m
Run 9 completed successfully
Running apxGP 10 with agents: 49
decpxADMM initialized with rho: 0.85, lip: 1.0, tol_abs: 1e-05, tol_rel: 0.001, rank: 0, world_size: 49
Rank 0 - Epoch 2/98 loss: 0.7467918992042542
Rank 0 - Epoch 10/98 loss: 0.4734395146369934
Rank 0 - Epoch 20/98 loss: 0.04208717122673988
Rank 0 - Epoch 30/98 loss: -0.4535163938999176
Rank 0 - Epoch 40/98 loss: -0.9802711009979248
Rank 0 - Epoch 50/98 loss: -1.5097594261169434
Rank 0 - Epoch 60/98 loss: -2.0133814811706543
Rank 0 - Epoch 70/98 loss: -2.4679713249206543
Rank 0 - Epoch 80/98 loss: -2.8396334648132324
Rank 0 - Epoch 90/98 loss: -3.094391345977783
Training complete.
[92mRank 0 - Testing RMSE: 3.1829[0m
[92mRank: 0, Lengthscale: [[0.5947454  0.35480705]] [0m
[92mRank: 0, Outputscale: 1.0027027130126953 [0m
[92mRank: 0, Noise: 0.00019460447947494686 [0m
Run 10 completed successfully
Running cGP 1 with agents: 49
decADMM initialized with rho: 0.85, max_iter: 5, lr: 0.0001, rank: 0, world_size: 49
Rank 0 - Epoch 2/98 loss: 0.8036377429962158
Rank 0 - Epoch 10/98 loss: 0.7982207536697388
Rank 0 - Epoch 20/98 loss: 0.791443943977356
Rank 0 - Epoch 30/98 loss: 0.784663200378418
Rank 0 - Epoch 40/98 loss: 0.7778811454772949
Rank 0 - Epoch 50/98 loss: 0.7711002826690674
Rank 0 - Epoch 60/98 loss: 0.7643232941627502
Rank 0 - Epoch 70/98 loss: 0.7575532793998718
Rank 0 - Epoch 80/98 loss: 0.7507926225662231
Rank 0 - Epoch 90/98 loss: 0.7440441250801086
Training complete.
[92mRank 0 - Testing RMSE: 3.6301[0m
[92mRank: 0, Lengthscale: [[0.61310816 0.61254144]] [0m
[92mRank: 0, Outputscale: 0.6140826940536499 [0m
[92mRank: 0, Noise: 0.6053674817085266 [0m
Run 1 completed successfully
Running cGP 2 with agents: 49
decADMM initialized with rho: 0.85, max_iter: 5, lr: 0.0001, rank: 0, world_size: 49
Rank 0 - Epoch 2/98 loss: 0.8036377429962158
Rank 0 - Epoch 10/98 loss: 0.7982207536697388
Rank 0 - Epoch 20/98 loss: 0.791443943977356
Rank 0 - Epoch 30/98 loss: 0.784663200378418
Rank 0 - Epoch 40/98 loss: 0.7778811454772949
Rank 0 - Epoch 50/98 loss: 0.7711002826690674
Rank 0 - Epoch 60/98 loss: 0.7643232941627502
Rank 0 - Epoch 70/98 loss: 0.7575532793998718
Rank 0 - Epoch 80/98 loss: 0.7507926225662231
Rank 0 - Epoch 90/98 loss: 0.7440441250801086
Training complete.
[92mRank 0 - Testing RMSE: 3.6301[0m
[92mRank: 0, Lengthscale: [[0.61310816 0.61254144]] [0m
[92mRank: 0, Outputscale: 0.6140826940536499 [0m
[92mRank: 0, Noise: 0.6053674817085266 [0m
Run 2 completed successfully
Running cGP 3 with agents: 49
decADMM initialized with rho: 0.85, max_iter: 5, lr: 0.0001, rank: 0, world_size: 49
Rank 0 - Epoch 2/98 loss: 0.8036377429962158
Rank 0 - Epoch 10/98 loss: 0.7982207536697388
Rank 0 - Epoch 20/98 loss: 0.791443943977356
Rank 0 - Epoch 30/98 loss: 0.784663200378418
Rank 0 - Epoch 40/98 loss: 0.7778811454772949
Rank 0 - Epoch 50/98 loss: 0.7711002826690674
Rank 0 - Epoch 60/98 loss: 0.7643232941627502
Rank 0 - Epoch 70/98 loss: 0.7575532793998718
Rank 0 - Epoch 80/98 loss: 0.7507926225662231
Rank 0 - Epoch 90/98 loss: 0.7440441250801086
Training complete.
[92mRank 0 - Testing RMSE: 3.6301[0m
[92mRank: 0, Lengthscale: [[0.61310816 0.61254144]] [0m
[92mRank: 0, Outputscale: 0.6140826940536499 [0m
[92mRank: 0, Noise: 0.6053674817085266 [0m
Run 3 completed successfully
Running cGP 4 with agents: 49
decADMM initialized with rho: 0.85, max_iter: 5, lr: 0.0001, rank: 0, world_size: 49
Rank 0 - Epoch 2/98 loss: 0.8036377429962158
Rank 0 - Epoch 10/98 loss: 0.7982207536697388
Rank 0 - Epoch 20/98 loss: 0.791443943977356
Rank 0 - Epoch 30/98 loss: 0.784663200378418
Rank 0 - Epoch 40/98 loss: 0.7778811454772949
Rank 0 - Epoch 50/98 loss: 0.7711002826690674
Rank 0 - Epoch 60/98 loss: 0.7643232941627502
Rank 0 - Epoch 70/98 loss: 0.7575532793998718
Rank 0 - Epoch 80/98 loss: 0.7507926225662231
Rank 0 - Epoch 90/98 loss: 0.7440441250801086
Training complete.
[92mRank 0 - Testing RMSE: 3.6301[0m
[92mRank: 0, Lengthscale: [[0.61310816 0.61254144]] [0m
[92mRank: 0, Outputscale: 0.6140826940536499 [0m
[92mRank: 0, Noise: 0.6053674817085266 [0m
Run 4 completed successfully
Running cGP 5 with agents: 49
decADMM initialized with rho: 0.85, max_iter: 5, lr: 0.0001, rank: 0, world_size: 49
Rank 0 - Epoch 2/98 loss: 0.8036377429962158
Rank 0 - Epoch 10/98 loss: 0.7982207536697388
Rank 0 - Epoch 20/98 loss: 0.791443943977356
Rank 0 - Epoch 30/98 loss: 0.784663200378418
Rank 0 - Epoch 40/98 loss: 0.7778811454772949
Rank 0 - Epoch 50/98 loss: 0.7711002826690674
Rank 0 - Epoch 60/98 loss: 0.7643232941627502
Rank 0 - Epoch 70/98 loss: 0.7575532793998718
Rank 0 - Epoch 80/98 loss: 0.7507926225662231
Rank 0 - Epoch 90/98 loss: 0.7440441250801086
Training complete.
[92mRank 0 - Testing RMSE: 3.6301[0m
[92mRank: 0, Lengthscale: [[0.61310816 0.61254144]] [0m
[92mRank: 0, Outputscale: 0.6140826940536499 [0m
[92mRank: 0, Noise: 0.6053674817085266 [0m
Run 5 completed successfully
Running cGP 6 with agents: 49
decADMM initialized with rho: 0.85, max_iter: 5, lr: 0.0001, rank: 0, world_size: 49
Rank 0 - Epoch 2/98 loss: 0.8036377429962158
Rank 0 - Epoch 10/98 loss: 0.7982207536697388
Rank 0 - Epoch 20/98 loss: 0.791443943977356
Rank 0 - Epoch 30/98 loss: 0.784663200378418
Rank 0 - Epoch 40/98 loss: 0.7778811454772949
Rank 0 - Epoch 50/98 loss: 0.7711002826690674
Rank 0 - Epoch 60/98 loss: 0.7643232941627502
Rank 0 - Epoch 70/98 loss: 0.7575532793998718
Rank 0 - Epoch 80/98 loss: 0.7507926225662231
Rank 0 - Epoch 90/98 loss: 0.7440441250801086
Training complete.
[92mRank 0 - Testing RMSE: 3.6301[0m
[92mRank: 0, Lengthscale: [[0.61310816 0.61254144]] [0m
[92mRank: 0, Outputscale: 0.6140826940536499 [0m
[92mRank: 0, Noise: 0.6053674817085266 [0m
Run 6 completed successfully
Running cGP 7 with agents: 49
decADMM initialized with rho: 0.85, max_iter: 5, lr: 0.0001, rank: 0, world_size: 49
Rank 0 - Epoch 2/98 loss: 0.8036377429962158
Rank 0 - Epoch 10/98 loss: 0.7982207536697388
Rank 0 - Epoch 20/98 loss: 0.791443943977356
Rank 0 - Epoch 30/98 loss: 0.784663200378418
Rank 0 - Epoch 40/98 loss: 0.7778811454772949
Rank 0 - Epoch 50/98 loss: 0.7711002826690674
Rank 0 - Epoch 60/98 loss: 0.7643232941627502
Rank 0 - Epoch 70/98 loss: 0.7575532793998718
Rank 0 - Epoch 80/98 loss: 0.7507926225662231
Rank 0 - Epoch 90/98 loss: 0.7440441250801086
Training complete.
[92mRank 0 - Testing RMSE: 3.6301[0m
[92mRank: 0, Lengthscale: [[0.61310816 0.61254144]] [0m
[92mRank: 0, Outputscale: 0.6140826940536499 [0m
[92mRank: 0, Noise: 0.6053674817085266 [0m
Run 7 completed successfully
Running cGP 8 with agents: 49
decADMM initialized with rho: 0.85, max_iter: 5, lr: 0.0001, rank: 0, world_size: 49
Rank 0 - Epoch 2/98 loss: 0.8036377429962158
Rank 0 - Epoch 10/98 loss: 0.7982207536697388
Rank 0 - Epoch 20/98 loss: 0.791443943977356
Rank 0 - Epoch 30/98 loss: 0.784663200378418
Rank 0 - Epoch 40/98 loss: 0.7778811454772949
Rank 0 - Epoch 50/98 loss: 0.7711002826690674
Rank 0 - Epoch 60/98 loss: 0.7643232941627502
Rank 0 - Epoch 70/98 loss: 0.7575532793998718
Rank 0 - Epoch 80/98 loss: 0.7507926225662231
Rank 0 - Epoch 90/98 loss: 0.7440441250801086
Training complete.
[92mRank 0 - Testing RMSE: 3.6301[0m
[92mRank: 0, Lengthscale: [[0.61310816 0.61254144]] [0m
[92mRank: 0, Outputscale: 0.6140826940536499 [0m
[92mRank: 0, Noise: 0.6053674817085266 [0m
Run 8 completed successfully
Running cGP 9 with agents: 49
decADMM initialized with rho: 0.85, max_iter: 5, lr: 0.0001, rank: 0, world_size: 49
Rank 0 - Epoch 2/98 loss: 0.8036377429962158
Rank 0 - Epoch 10/98 loss: 0.7982207536697388
Rank 0 - Epoch 20/98 loss: 0.791443943977356
Rank 0 - Epoch 30/98 loss: 0.784663200378418
Rank 0 - Epoch 40/98 loss: 0.7778811454772949
Rank 0 - Epoch 50/98 loss: 0.7711002826690674
Rank 0 - Epoch 60/98 loss: 0.7643232941627502
Rank 0 - Epoch 70/98 loss: 0.7575532793998718
Rank 0 - Epoch 80/98 loss: 0.7507926225662231
Rank 0 - Epoch 90/98 loss: 0.7440441250801086
Training complete.
[92mRank 0 - Testing RMSE: 3.6301[0m
[92mRank: 0, Lengthscale: [[0.61310816 0.61254144]] [0m
[92mRank: 0, Outputscale: 0.6140826940536499 [0m
[92mRank: 0, Noise: 0.6053674817085266 [0m
Run 9 completed successfully
Running cGP 10 with agents: 49
decADMM initialized with rho: 0.85, max_iter: 5, lr: 0.0001, rank: 0, world_size: 49
Rank 0 - Epoch 2/98 loss: 0.8036377429962158
Rank 0 - Epoch 10/98 loss: 0.7982207536697388
Rank 0 - Epoch 20/98 loss: 0.791443943977356
Rank 0 - Epoch 30/98 loss: 0.784663200378418
Rank 0 - Epoch 40/98 loss: 0.7778811454772949
Rank 0 - Epoch 50/98 loss: 0.7711002826690674
Rank 0 - Epoch 60/98 loss: 0.7643232941627502
Rank 0 - Epoch 70/98 loss: 0.7575532793998718
Rank 0 - Epoch 80/98 loss: 0.7507926225662231
Rank 0 - Epoch 90/98 loss: 0.7440441250801086
Training complete.
[92mRank 0 - Testing RMSE: 3.6301[0m
[92mRank: 0, Lengthscale: [[0.61310816 0.61254144]] [0m
[92mRank: 0, Outputscale: 0.6140826940536499 [0m
[92mRank: 0, Noise: 0.6053674817085266 [0m
Run 10 completed successfully
Running pxpGP 1 with agents: 64
[92mRank 0 - sparse dataset size is: 8, local dataset: torch.Size([529, 2]), [0m
[92mRank 0 - Training local sparse GP model with 529 samples[0m
Epoch 1/200 - Loss: 12.827
Epoch 11/200 - Loss: 1.330
Epoch 21/200 - Loss: 1.047
Epoch 31/200 - Loss: 0.981
Epoch 41/200 - Loss: 0.865
Epoch 51/200 - Loss: 0.754
Epoch 61/200 - Loss: 0.574
Epoch 71/200 - Loss: 0.389
Epoch 81/200 - Loss: 0.176
Converged at epoch 89 with loss -0.024
[92mRank 0 - Lengthscale: [[0.50834846 0.54939604]] [0m
[92mRank 0 - Outputscale: 2.4063613414764404 [0m
[92mRank 0 - Noise: 0.1294543445110321 [0m
Rank 0 - Augmented dataset size: 1041
Rank 0: After warm start model parameters:
Rank: 0, Lengthscale: [[0.50834846 0.54939604]]
Rank: 0, Outputscale: 2.4063613414764404
Rank: 0, Noise: 0.1294543445110321
decpxADMM initialized with rho: 0.85, lip: 1.0, tol_abs: 1e-05, tol_rel: 0.001, rank: 0, world_size: 64
[92mRank 0 - Training global model with dec-pxADMM optimizer[0m
rank 0, epoch 9, loss: 0.5340138077735901, rho: 0.4250, lip: 1.0000
rank 0, epoch 19, loss: 0.5002365112304688, rho: 0.2125, lip: 1.0000
rank 0, epoch 29, loss: 0.5021212100982666, rho: 0.1062, lip: 1.0000
rank 0, epoch 39, loss: 0.5017920136451721, rho: 0.1062, lip: 1.0000
rank 0, epoch 49, loss: 0.49232393503189087, rho: 0.0531, lip: 1.0000
rank 0, epoch 59, loss: 0.4845068156719208, rho: 0.0531, lip: 1.0000
rank 0, epoch 69, loss: 0.4921194911003113, rho: 0.0266, lip: 1.0000
rank 0, epoch 79, loss: 0.503944993019104, rho: 0.0266, lip: 1.0000
rank 0, epoch 89, loss: 0.4914027154445648, rho: 0.0266, lip: 1.0000
Rank 0 - Training time: 161.05 seconds
[92mRank 0 - Testing RMSE: 0.3634[0m
[92mRank: 0, Lengthscale: [[0.435112  0.3396924]] [0m
[92mRank: 0, Outputscale: 2.11142897605896 [0m
[92mRank: 0, Noise: 0.10512825101613998 [0m
Run 1 completed successfully
Running pxpGP 2 with agents: 64
[92mRank 0 - sparse dataset size is: 8, local dataset: torch.Size([529, 2]), [0m
[92mRank 0 - Training local sparse GP model with 529 samples[0m
Epoch 1/200 - Loss: 11.327
Epoch 11/200 - Loss: 1.180
Epoch 21/200 - Loss: 1.122
Epoch 31/200 - Loss: 0.952
Epoch 41/200 - Loss: 0.857
Epoch 51/200 - Loss: 0.724
Epoch 61/200 - Loss: 0.560
Epoch 71/200 - Loss: 0.406
Epoch 81/200 - Loss: 0.181
Converged at epoch 88 with loss -0.005
[92mRank 0 - Lengthscale: [[0.527203  0.5492655]] [0m
[92mRank 0 - Outputscale: 2.448413372039795 [0m
[92mRank 0 - Noise: 0.13191330432891846 [0m
Rank 0 - Augmented dataset size: 1041
Rank 0: After warm start model parameters:
Rank: 0, Lengthscale: [[0.527203  0.5492655]]
Rank: 0, Outputscale: 2.448413372039795
Rank: 0, Noise: 0.13191330432891846
decpxADMM initialized with rho: 0.85, lip: 1.0, tol_abs: 1e-05, tol_rel: 0.001, rank: 0, world_size: 64
[92mRank 0 - Training global model with dec-pxADMM optimizer[0m
rank 0, epoch 9, loss: 0.5958683490753174, rho: 0.4250, lip: 1.0000
rank 0, epoch 19, loss: 0.5617868304252625, rho: 0.0531, lip: 1.0000
rank 0, epoch 29, loss: 0.5475412607192993, rho: 0.0531, lip: 1.0000
rank 0, epoch 39, loss: 0.5536350607872009, rho: 0.0531, lip: 1.0000
rank 0, epoch 49, loss: 0.5453509092330933, rho: 0.0531, lip: 1.0000
rank 0, epoch 59, loss: 0.5415179133415222, rho: 0.0266, lip: 1.0000
rank 0, epoch 69, loss: 0.5427725315093994, rho: 0.0266, lip: 1.0000
rank 0, epoch 79, loss: 0.5391634106636047, rho: 0.0266, lip: 1.0000
rank 0, epoch 89, loss: 0.5467227697372437, rho: 0.0266, lip: 1.0000
Rank 0 - Training time: 102.16 seconds
[92mRank 0 - Testing RMSE: 0.3290[0m
[92mRank: 0, Lengthscale: [[0.5934579  0.36630946]] [0m
[92mRank: 0, Outputscale: 2.1902170181274414 [0m
[92mRank: 0, Noise: 0.1282544881105423 [0m
Run 2 completed successfully
Running pxpGP 3 with agents: 64
[92mRank 0 - sparse dataset size is: 8, local dataset: torch.Size([529, 2]), [0m
[92mRank 0 - Training local sparse GP model with 529 samples[0m
Epoch 1/200 - Loss: 14.339
Epoch 11/200 - Loss: 1.296
Epoch 21/200 - Loss: 1.109
Epoch 31/200 - Loss: 0.988
Epoch 41/200 - Loss: 0.892
Epoch 51/200 - Loss: 0.742
Epoch 61/200 - Loss: 0.584
Epoch 71/200 - Loss: 0.404
Epoch 81/200 - Loss: 0.183
Converged at epoch 89 with loss -0.012
[92mRank 0 - Lengthscale: [[0.52022284 0.55392295]] [0m
[92mRank 0 - Outputscale: 2.419996500015259 [0m
[92mRank 0 - Noise: 0.13197237253189087 [0m
Rank 0 - Augmented dataset size: 1041
Rank 0: After warm start model parameters:
Rank: 0, Lengthscale: [[0.52022284 0.55392295]]
Rank: 0, Outputscale: 2.419996500015259
Rank: 0, Noise: 0.13197237253189087
decpxADMM initialized with rho: 0.85, lip: 1.0, tol_abs: 1e-05, tol_rel: 0.001, rank: 0, world_size: 64
[92mRank 0 - Training global model with dec-pxADMM optimizer[0m
rank 0, epoch 9, loss: 0.6347076296806335, rho: 0.4250, lip: 1.0000
rank 0, epoch 19, loss: 0.6042966842651367, rho: 0.1062, lip: 1.0000
rank 0, epoch 29, loss: 0.6079060435295105, rho: 0.0531, lip: 1.0000
rank 0, epoch 39, loss: 0.5962275266647339, rho: 0.0531, lip: 1.0000
rank 0, epoch 49, loss: 0.5973855257034302, rho: 0.0531, lip: 1.0000
rank 0, epoch 59, loss: 0.5994711518287659, rho: 0.0531, lip: 1.0000
rank 0, epoch 69, loss: 0.5932906270027161, rho: 0.0531, lip: 1.0000
rank 0, epoch 79, loss: 0.5965220928192139, rho: 0.0266, lip: 1.0000
rank 0, epoch 89, loss: 0.6045012474060059, rho: 0.0266, lip: 1.0000
Rank 0 - Training time: 83.76 seconds
[92mRank 0 - Testing RMSE: 0.3543[0m
[92mRank: 0, Lengthscale: [[0.4116966  0.40718907]] [0m
[92mRank: 0, Outputscale: 1.9044315814971924 [0m
[92mRank: 0, Noise: 0.1319071352481842 [0m
Run 3 completed successfully
Running pxpGP 4 with agents: 64
[92mRank 0 - sparse dataset size is: 8, local dataset: torch.Size([529, 2]), [0m
[92mRank 0 - Training local sparse GP model with 529 samples[0m
Epoch 1/200 - Loss: 13.377
Epoch 11/200 - Loss: 1.238
Epoch 21/200 - Loss: 1.060
Epoch 31/200 - Loss: 0.964
Epoch 41/200 - Loss: 0.864
Epoch 51/200 - Loss: 0.726
Epoch 61/200 - Loss: 0.590
Epoch 71/200 - Loss: 0.395
Epoch 81/200 - Loss: 0.174
Converged at epoch 89 with loss -0.028
[92mRank 0 - Lengthscale: [[0.7294683  0.55401695]] [0m
[92mRank 0 - Outputscale: 2.4322195053100586 [0m
[92mRank 0 - Noise: 0.13039784133434296 [0m
Rank 0 - Augmented dataset size: 1041
Rank 0: After warm start model parameters:
Rank: 0, Lengthscale: [[0.7294683  0.55401695]]
Rank: 0, Outputscale: 2.4322195053100586
Rank: 0, Noise: 0.13039784133434296
decpxADMM initialized with rho: 0.85, lip: 1.0, tol_abs: 1e-05, tol_rel: 0.001, rank: 0, world_size: 64
[92mRank 0 - Training global model with dec-pxADMM optimizer[0m
rank 0, epoch 9, loss: 0.6983681321144104, rho: 0.4250, lip: 1.0000
rank 0, epoch 19, loss: 0.6997235417366028, rho: 0.1062, lip: 1.0000
rank 0, epoch 29, loss: 0.6739525198936462, rho: 0.1062, lip: 1.0000
rank 0, epoch 39, loss: 0.6799973249435425, rho: 0.1062, lip: 1.0000
rank 0, epoch 49, loss: 0.6737827062606812, rho: 0.1062, lip: 1.0000
rank 0, epoch 59, loss: 0.6755433678627014, rho: 0.0133, lip: 1.0000
rank 0, epoch 69, loss: 0.6698605418205261, rho: 0.0133, lip: 1.0000
rank 0, epoch 79, loss: 0.6731348037719727, rho: 0.0133, lip: 1.0000
rank 0, epoch 89, loss: 0.6630746722221375, rho: 0.0133, lip: 1.0000
Rank 0 - Training time: 98.16 seconds
[92mRank 0 - Testing RMSE: 0.3667[0m
[92mRank: 0, Lengthscale: [[0.46229517 0.3710351 ]] [0m
[92mRank: 0, Outputscale: 3.478440761566162 [0m
[92mRank: 0, Noise: 0.15949077904224396 [0m
Run 4 completed successfully
Running pxpGP 5 with agents: 64
[92mRank 0 - sparse dataset size is: 8, local dataset: torch.Size([529, 2]), [0m
[92mRank 0 - Training local sparse GP model with 529 samples[0m
Epoch 1/200 - Loss: 13.514
Epoch 11/200 - Loss: 1.198
Epoch 21/200 - Loss: 1.131
Epoch 31/200 - Loss: 1.013
Epoch 41/200 - Loss: 0.882
Epoch 51/200 - Loss: 0.743
Epoch 61/200 - Loss: 0.593
Epoch 71/200 - Loss: 0.395
Epoch 81/200 - Loss: 0.184
Converged at epoch 88 with loss -0.002
[92mRank 0 - Lengthscale: [[0.6723274 0.4790131]] [0m
[92mRank 0 - Outputscale: 2.502810478210449 [0m
[92mRank 0 - Noise: 0.13828332722187042 [0m
Rank 0 - Augmented dataset size: 1041
Rank 0: After warm start model parameters:
Rank: 0, Lengthscale: [[0.6723274  0.47901303]]
Rank: 0, Outputscale: 2.502810478210449
Rank: 0, Noise: 0.13828331232070923
decpxADMM initialized with rho: 0.85, lip: 1.0, tol_abs: 1e-05, tol_rel: 0.001, rank: 0, world_size: 64
[92mRank 0 - Training global model with dec-pxADMM optimizer[0m
rank 0, epoch 9, loss: 0.60069739818573, rho: 0.4250, lip: 1.0000
rank 0, epoch 19, loss: 0.5827073454856873, rho: 0.2125, lip: 1.0000
rank 0, epoch 29, loss: 0.5951318740844727, rho: 0.1062, lip: 1.0000
rank 0, epoch 39, loss: 0.5850555896759033, rho: 0.0531, lip: 1.0000
rank 0, epoch 49, loss: 0.5942931771278381, rho: 0.0531, lip: 1.0000
rank 0, epoch 59, loss: 0.5891887545585632, rho: 0.0266, lip: 1.0000
rank 0, epoch 69, loss: 0.588901698589325, rho: 0.0266, lip: 1.0000
rank 0, epoch 79, loss: 0.5903769135475159, rho: 0.0266, lip: 1.0000
rank 0, epoch 89, loss: 0.5956783294677734, rho: 0.0266, lip: 1.0000
Rank 0 - Training time: 114.51 seconds
[92mRank 0 - Testing RMSE: 0.3106[0m
[92mRank: 0, Lengthscale: [[0.6311868  0.24349496]] [0m
[92mRank: 0, Outputscale: 1.8003708124160767 [0m
[92mRank: 0, Noise: 0.13040386140346527 [0m
Run 5 completed successfully
Running pxpGP 6 with agents: 64
[92mRank 0 - sparse dataset size is: 8, local dataset: torch.Size([529, 2]), [0m
[92mRank 0 - Training local sparse GP model with 529 samples[0m
Epoch 1/200 - Loss: 15.177
Epoch 11/200 - Loss: 1.167
Epoch 21/200 - Loss: 1.121
Epoch 31/200 - Loss: 1.003
Epoch 41/200 - Loss: 0.897
Epoch 51/200 - Loss: 0.734
Epoch 61/200 - Loss: 0.586
Epoch 71/200 - Loss: 0.399
Epoch 81/200 - Loss: 0.207
Converged at epoch 90 with loss -0.027
[92mRank 0 - Lengthscale: [[0.5882979 0.5484678]] [0m
[92mRank 0 - Outputscale: 2.4357244968414307 [0m
[92mRank 0 - Noise: 0.12805752456188202 [0m
Rank 0 - Augmented dataset size: 1041
Rank 0: After warm start model parameters:
Rank: 0, Lengthscale: [[0.5882979  0.54846776]]
Rank: 0, Outputscale: 2.4357244968414307
Rank: 0, Noise: 0.1280575394630432
decpxADMM initialized with rho: 0.85, lip: 1.0, tol_abs: 1e-05, tol_rel: 0.001, rank: 0, world_size: 64
[92mRank 0 - Training global model with dec-pxADMM optimizer[0m
rank 0, epoch 9, loss: 0.6177865862846375, rho: 0.4250, lip: 1.0000
rank 0, epoch 19, loss: 0.5935332775115967, rho: 0.1062, lip: 1.0000
rank 0, epoch 29, loss: 0.5852706432342529, rho: 0.0531, lip: 1.0000
rank 0, epoch 39, loss: 0.5880686640739441, rho: 0.0531, lip: 1.0000
rank 0, epoch 49, loss: 0.583163321018219, rho: 0.0531, lip: 1.0000
rank 0, epoch 59, loss: 0.5789633393287659, rho: 0.0531, lip: 1.0000
rank 0, epoch 69, loss: 0.5786413550376892, rho: 0.0531, lip: 1.0000
rank 0, epoch 79, loss: 0.5881657600402832, rho: 0.0531, lip: 1.0000
rank 0, epoch 89, loss: 0.5822755694389343, rho: 0.0266, lip: 1.0000
Rank 0 - Training time: 79.85 seconds
[92mRank 0 - Testing RMSE: 0.3290[0m
[92mRank: 0, Lengthscale: [[0.6379145  0.45368147]] [0m
[92mRank: 0, Outputscale: 2.5587399005889893 [0m
[92mRank: 0, Noise: 0.13890285789966583 [0m
Run 6 completed successfully
Running pxpGP 7 with agents: 64
[92mRank 0 - sparse dataset size is: 8, local dataset: torch.Size([529, 2]), [0m
[92mRank 0 - Training local sparse GP model with 529 samples[0m
Epoch 1/200 - Loss: 13.238
Epoch 11/200 - Loss: 1.165
Epoch 21/200 - Loss: 1.131
Epoch 31/200 - Loss: 1.026
Epoch 41/200 - Loss: 0.864
Epoch 51/200 - Loss: 0.745
Epoch 61/200 - Loss: 0.574
Epoch 71/200 - Loss: 0.388
Epoch 81/200 - Loss: 0.174
Converged at epoch 89 with loss -0.013
[92mRank 0 - Lengthscale: [[0.57910764 0.550369  ]] [0m
[92mRank 0 - Outputscale: 2.4125423431396484 [0m
[92mRank 0 - Noise: 0.13164304196834564 [0m
Rank 0 - Augmented dataset size: 1041
Rank 0: After warm start model parameters:
Rank: 0, Lengthscale: [[0.57910764 0.550369  ]]
Rank: 0, Outputscale: 2.4125423431396484
Rank: 0, Noise: 0.13164304196834564
decpxADMM initialized with rho: 0.85, lip: 1.0, tol_abs: 1e-05, tol_rel: 0.001, rank: 0, world_size: 64
[92mRank 0 - Training global model with dec-pxADMM optimizer[0m
rank 0, epoch 9, loss: 0.6518867611885071, rho: 0.4250, lip: 1.0000
rank 0, epoch 19, loss: 0.6223545670509338, rho: 0.1062, lip: 1.0000
rank 0, epoch 29, loss: 0.6329772472381592, rho: 0.0531, lip: 1.0000
rank 0, epoch 39, loss: 0.617922306060791, rho: 0.0531, lip: 1.0000
rank 0, epoch 49, loss: 0.6276477575302124, rho: 0.0531, lip: 1.0000
rank 0, epoch 59, loss: 0.6170035600662231, rho: 0.0531, lip: 1.0000
rank 0, epoch 69, loss: 0.6307251453399658, rho: 0.0266, lip: 1.0000
rank 0, epoch 79, loss: 0.6279359459877014, rho: 0.0266, lip: 1.0000
rank 0, epoch 89, loss: 0.6074326634407043, rho: 0.0266, lip: 1.0000
Rank 0 - Training time: 116.43 seconds
[92mRank 0 - Testing RMSE: 0.3425[0m
[92mRank: 0, Lengthscale: [[0.5318587  0.40670764]] [0m
[92mRank: 0, Outputscale: 1.8661690950393677 [0m
[92mRank: 0, Noise: 0.1447177231311798 [0m
Run 7 completed successfully
Running pxpGP 8 with agents: 64
[92mRank 0 - sparse dataset size is: 8, local dataset: torch.Size([529, 2]), [0m
[92mRank 0 - Training local sparse GP model with 529 samples[0m
Epoch 1/200 - Loss: 12.866
Epoch 11/200 - Loss: 1.158
Epoch 21/200 - Loss: 1.122
Epoch 31/200 - Loss: 0.965
Epoch 41/200 - Loss: 0.853
Epoch 51/200 - Loss: 0.724
Epoch 61/200 - Loss: 0.568
Epoch 71/200 - Loss: 0.389
Epoch 81/200 - Loss: 0.174
Converged at epoch 89 with loss -0.034
[92mRank 0 - Lengthscale: [[0.6639541 0.5231652]] [0m
[92mRank 0 - Outputscale: 2.4428012371063232 [0m
[92mRank 0 - Noise: 0.128644198179245 [0m
Rank 0 - Augmented dataset size: 1041
Rank 0: After warm start model parameters:
Rank: 0, Lengthscale: [[0.6639541 0.5231652]]
Rank: 0, Outputscale: 2.4428012371063232
Rank: 0, Noise: 0.1286441832780838
decpxADMM initialized with rho: 0.85, lip: 1.0, tol_abs: 1e-05, tol_rel: 0.001, rank: 0, world_size: 64
[92mRank 0 - Training global model with dec-pxADMM optimizer[0m
rank 0, epoch 9, loss: 0.5387658476829529, rho: 0.4250, lip: 1.0000
rank 0, epoch 19, loss: 0.5269201993942261, rho: 0.1062, lip: 1.0000
rank 0, epoch 29, loss: 0.5451556444168091, rho: 0.0266, lip: 1.0000
rank 0, epoch 39, loss: 0.5243067741394043, rho: 0.0266, lip: 1.0000
rank 0, epoch 49, loss: 0.5290269255638123, rho: 0.0266, lip: 1.0000
rank 0, epoch 59, loss: 0.5277858376502991, rho: 0.0266, lip: 1.0000
rank 0, epoch 69, loss: 0.5233650207519531, rho: 0.0266, lip: 1.0000
rank 0, epoch 79, loss: 0.5243740081787109, rho: 0.0266, lip: 1.0000
rank 0, epoch 89, loss: 0.5161872506141663, rho: 0.0266, lip: 1.0000
Rank 0 - Training time: 95.26 seconds
[92mRank 0 - Testing RMSE: 0.3507[0m
[92mRank: 0, Lengthscale: [[0.44914275 0.3262843 ]] [0m
[92mRank: 0, Outputscale: 1.367034912109375 [0m
[92mRank: 0, Noise: 0.1092168316245079 [0m
Run 8 completed successfully
Running pxpGP 9 with agents: 64
[92mRank 0 - sparse dataset size is: 8, local dataset: torch.Size([529, 2]), [0m
[92mRank 0 - Training local sparse GP model with 529 samples[0m
Epoch 1/200 - Loss: 13.143
Epoch 11/200 - Loss: 1.225
Epoch 21/200 - Loss: 1.157
Epoch 31/200 - Loss: 0.993
Epoch 41/200 - Loss: 0.884
Epoch 51/200 - Loss: 0.734
Epoch 61/200 - Loss: 0.578
Epoch 71/200 - Loss: 0.396
Epoch 81/200 - Loss: 0.194
Converged at epoch 89 with loss -0.026
[92mRank 0 - Lengthscale: [[0.5811669 0.5182183]] [0m
[92mRank 0 - Outputscale: 2.3944740295410156 [0m
[92mRank 0 - Noise: 0.12959040701389313 [0m
Rank 0 - Augmented dataset size: 1041
Rank 0: After warm start model parameters:
Rank: 0, Lengthscale: [[0.5811669 0.5182183]]
Rank: 0, Outputscale: 2.3944740295410156
Rank: 0, Noise: 0.12959040701389313
decpxADMM initialized with rho: 0.85, lip: 1.0, tol_abs: 1e-05, tol_rel: 0.001, rank: 0, world_size: 64
[92mRank 0 - Training global model with dec-pxADMM optimizer[0m
rank 0, epoch 9, loss: 0.6500439643859863, rho: 0.4250, lip: 1.0000
rank 0, epoch 19, loss: 0.5855595469474792, rho: 0.2125, lip: 1.0000
rank 0, epoch 29, loss: 0.5938670635223389, rho: 0.0531, lip: 1.0000
rank 0, epoch 39, loss: 0.5862723588943481, rho: 0.0531, lip: 1.0000
rank 0, epoch 49, loss: 0.5796939134597778, rho: 0.0531, lip: 1.0000
rank 0, epoch 59, loss: 0.5829996466636658, rho: 0.0266, lip: 1.0000
rank 0, epoch 69, loss: 0.58005291223526, rho: 0.0266, lip: 1.0000
rank 0, epoch 79, loss: 0.5738812685012817, rho: 0.0266, lip: 1.0000
rank 0, epoch 89, loss: 0.5754069685935974, rho: 0.0266, lip: 1.0000
Rank 0 - Training time: 104.34 seconds
[92mRank 0 - Testing RMSE: 0.3578[0m
[92mRank: 0, Lengthscale: [[0.44494987 0.4456522 ]] [0m
[92mRank: 0, Outputscale: 2.8631796836853027 [0m
[92mRank: 0, Noise: 0.12865857779979706 [0m
Run 9 completed successfully
Running pxpGP 10 with agents: 64
[92mRank 0 - sparse dataset size is: 8, local dataset: torch.Size([529, 2]), [0m
[92mRank 0 - Training local sparse GP model with 529 samples[0m
Epoch 1/200 - Loss: 13.050
Epoch 11/200 - Loss: 1.288
Epoch 21/200 - Loss: 1.111
Epoch 31/200 - Loss: 0.960
Epoch 41/200 - Loss: 0.881
Epoch 51/200 - Loss: 0.725
Epoch 61/200 - Loss: 0.569
Epoch 71/200 - Loss: 0.394
Epoch 81/200 - Loss: 0.160
Converged at epoch 89 with loss -0.025
[92mRank 0 - Lengthscale: [[0.6399516  0.51681066]] [0m
[92mRank 0 - Outputscale: 2.4362998008728027 [0m
[92mRank 0 - Noise: 0.12748627364635468 [0m
Rank 0 - Augmented dataset size: 1041
Rank 0: After warm start model parameters:
Rank: 0, Lengthscale: [[0.6399516  0.51681066]]
Rank: 0, Outputscale: 2.4362998008728027
Rank: 0, Noise: 0.12748628854751587
decpxADMM initialized with rho: 0.85, lip: 1.0, tol_abs: 1e-05, tol_rel: 0.001, rank: 0, world_size: 64
[92mRank 0 - Training global model with dec-pxADMM optimizer[0m
rank 0, epoch 9, loss: 0.6897363066673279, rho: 0.4250, lip: 1.0000
rank 0, epoch 19, loss: 0.6395047307014465, rho: 0.1062, lip: 1.0000
rank 0, epoch 29, loss: 0.6398907899856567, rho: 0.0531, lip: 1.0000
rank 0, epoch 39, loss: 0.6280438899993896, rho: 0.0531, lip: 1.0000
rank 0, epoch 49, loss: 0.6262553930282593, rho: 0.0531, lip: 1.0000
rank 0, epoch 59, loss: 0.6295879483222961, rho: 0.0266, lip: 1.0000
rank 0, epoch 69, loss: 0.6278567910194397, rho: 0.0266, lip: 1.0000
rank 0, epoch 79, loss: 0.6345130205154419, rho: 0.0266, lip: 1.0000
rank 0, epoch 89, loss: 0.6276206374168396, rho: 0.0266, lip: 1.0000
Rank 0 - Training time: 83.80 seconds
[92mRank 0 - Testing RMSE: 0.3433[0m
[92mRank: 0, Lengthscale: [[0.63017744 0.43390253]] [0m
[92mRank: 0, Outputscale: 3.004542350769043 [0m
[92mRank: 0, Noise: 0.15716604888439178 [0m
Run 10 completed successfully
Running gapxGP 1 with agents: 64
decpxADMM initialized with rho: 0.75, lip: 1.0, tol_abs: 1e-05, tol_rel: 0.001, rank: 0, world_size: 64
Rank 0 - Epoch 2/96 loss: 0.9290494918823242
Rank 0 - Epoch 10/96 loss: 0.7035982608795166
Rank 0 - Epoch 20/96 loss: 0.3407125473022461
Rank 0 - Epoch 30/96 loss: -0.1115792989730835
Rank 0 - Epoch 40/96 loss: -0.5625633001327515
Rank 0 - Epoch 50/96 loss: -1.0105706453323364
Rank 0 - Epoch 60/96 loss: -1.4033578634262085
Rank 0 - Epoch 70/96 loss: -1.7009763717651367
Rank 0 - Epoch 80/96 loss: -1.803147315979004
Rank 0 - Epoch 90/96 loss: -1.8193806409835815
[92mRank 0 - Testing RMSE: 0.0435[0m
[92mRank: 0, Lengthscale: [[0.6013435  0.36971644]] [0m
[92mRank: 0, Outputscale: 1.5330913066864014 [0m
[92mRank: 0, Noise: 0.00024216747260652483 [0m
Run 1 completed successfully
Running gapxGP 2 with agents: 64
decpxADMM initialized with rho: 0.75, lip: 1.0, tol_abs: 1e-05, tol_rel: 0.001, rank: 0, world_size: 64
Rank 0 - Epoch 2/96 loss: 0.926764190196991
Rank 0 - Epoch 10/96 loss: 0.7045192718505859
Rank 0 - Epoch 20/96 loss: 0.35063302516937256
Rank 0 - Epoch 30/96 loss: -0.10435765236616135
Rank 0 - Epoch 40/96 loss: -0.5586724877357483
Rank 0 - Epoch 50/96 loss: -0.9929322004318237
Rank 0 - Epoch 60/96 loss: -1.367509126663208
Rank 0 - Epoch 70/96 loss: -1.6249735355377197
Rank 0 - Epoch 80/96 loss: -1.6992000341415405
Rank 0 - Epoch 90/96 loss: -1.8027949333190918
[92mRank 0 - Testing RMSE: 0.0476[0m
[92mRank: 0, Lengthscale: [[0.6271851  0.34390482]] [0m
[92mRank: 0, Outputscale: 1.5327180624008179 [0m
[92mRank: 0, Noise: 0.00024419339024461806 [0m
Run 2 completed successfully
Running gapxGP 3 with agents: 64
decpxADMM initialized with rho: 0.75, lip: 1.0, tol_abs: 1e-05, tol_rel: 0.001, rank: 0, world_size: 64
Rank 0 - Epoch 2/96 loss: 0.9233855605125427
Rank 0 - Epoch 10/96 loss: 0.7015140056610107
Rank 0 - Epoch 20/96 loss: 0.3493906855583191
Rank 0 - Epoch 30/96 loss: -0.1061016097664833
Rank 0 - Epoch 40/96 loss: -0.5588854551315308
Rank 0 - Epoch 50/96 loss: -0.9852021336555481
Rank 0 - Epoch 60/96 loss: -1.3691211938858032
Rank 0 - Epoch 70/96 loss: -1.6493979692459106
Rank 0 - Epoch 80/96 loss: -1.7474662065505981
Rank 0 - Epoch 90/96 loss: -1.8279883861541748
[92mRank 0 - Testing RMSE: 0.0486[0m
[92mRank: 0, Lengthscale: [[0.6053172  0.34135416]] [0m
[92mRank: 0, Outputscale: 1.536284327507019 [0m
[92mRank: 0, Noise: 0.00024144738563336432 [0m
Run 3 completed successfully
Running gapxGP 4 with agents: 64
decpxADMM initialized with rho: 0.75, lip: 1.0, tol_abs: 1e-05, tol_rel: 0.001, rank: 0, world_size: 64
Rank 0 - Epoch 2/96 loss: 0.9287194013595581
Rank 0 - Epoch 10/96 loss: 0.7054359912872314
Rank 0 - Epoch 20/96 loss: 0.3477543890476227
Rank 0 - Epoch 30/96 loss: -0.10283277928829193
Rank 0 - Epoch 40/96 loss: -0.5596117377281189
Rank 0 - Epoch 50/96 loss: -0.9889888167381287
Rank 0 - Epoch 60/96 loss: -1.3839713335037231
Rank 0 - Epoch 70/96 loss: -1.6527798175811768
Rank 0 - Epoch 80/96 loss: -1.832688570022583
Rank 0 - Epoch 90/96 loss: -1.9284603595733643
[92mRank 0 - Testing RMSE: 0.0430[0m
[92mRank: 0, Lengthscale: [[0.6193251 0.3979925]] [0m
[92mRank: 0, Outputscale: 1.5325170755386353 [0m
[92mRank: 0, Noise: 0.00024241511709988117 [0m
Run 4 completed successfully
Running gapxGP 5 with agents: 64
decpxADMM initialized with rho: 0.75, lip: 1.0, tol_abs: 1e-05, tol_rel: 0.001, rank: 0, world_size: 64
Rank 0 - Epoch 2/96 loss: 0.9266990423202515
Rank 0 - Epoch 10/96 loss: 0.6967976689338684
Rank 0 - Epoch 20/96 loss: 0.33317962288856506
Rank 0 - Epoch 30/96 loss: -0.10983368009328842
Rank 0 - Epoch 40/96 loss: -0.5781528353691101
Rank 0 - Epoch 50/96 loss: -1.0187220573425293
Rank 0 - Epoch 60/96 loss: -1.3831576108932495
Rank 0 - Epoch 70/96 loss: -1.6235365867614746
Rank 0 - Epoch 80/96 loss: -1.8045272827148438
Rank 0 - Epoch 90/96 loss: -1.78639817237854
[92mRank 0 - Testing RMSE: 0.0481[0m
[92mRank: 0, Lengthscale: [[0.62790006 0.35132226]] [0m
[92mRank: 0, Outputscale: 1.5319052934646606 [0m
[92mRank: 0, Noise: 0.0002417463401798159 [0m
Run 5 completed successfully
Running gapxGP 6 with agents: 64
decpxADMM initialized with rho: 0.75, lip: 1.0, tol_abs: 1e-05, tol_rel: 0.001, rank: 0, world_size: 64
Rank 0 - Epoch 2/96 loss: 0.9272229671478271
Rank 0 - Epoch 10/96 loss: 0.7003210186958313
Rank 0 - Epoch 20/96 loss: 0.347187340259552
Rank 0 - Epoch 30/96 loss: -0.09446971863508224
Rank 0 - Epoch 40/96 loss: -0.5632867217063904
Rank 0 - Epoch 50/96 loss: -0.9982596039772034
Rank 0 - Epoch 60/96 loss: -1.3825922012329102
Rank 0 - Epoch 70/96 loss: -1.6731353998184204
Rank 0 - Epoch 80/96 loss: -1.8105182647705078
Rank 0 - Epoch 90/96 loss: -1.8406093120574951
[92mRank 0 - Testing RMSE: 0.0457[0m
[92mRank: 0, Lengthscale: [[0.6207916  0.36809745]] [0m
[92mRank: 0, Outputscale: 1.5332095623016357 [0m
[92mRank: 0, Noise: 0.00024320892407558858 [0m
Run 6 completed successfully
Running gapxGP 7 with agents: 64
decpxADMM initialized with rho: 0.75, lip: 1.0, tol_abs: 1e-05, tol_rel: 0.001, rank: 0, world_size: 64
Rank 0 - Epoch 2/96 loss: 0.9152101874351501
Rank 0 - Epoch 10/96 loss: 0.6912702322006226
Rank 0 - Epoch 20/96 loss: 0.3391362130641937
Rank 0 - Epoch 30/96 loss: -0.10738979279994965
Rank 0 - Epoch 40/96 loss: -0.5711697936058044
Rank 0 - Epoch 50/96 loss: -1.0097490549087524
Rank 0 - Epoch 60/96 loss: -1.4120198488235474
Rank 0 - Epoch 70/96 loss: -1.6749008893966675
Rank 0 - Epoch 80/96 loss: -1.7758921384811401
Rank 0 - Epoch 90/96 loss: -1.857211709022522
[92mRank 0 - Testing RMSE: 0.0505[0m
[92mRank: 0, Lengthscale: [[0.6303892  0.36033878]] [0m
[92mRank: 0, Outputscale: 1.5315853357315063 [0m
[92mRank: 0, Noise: 0.00024208304239436984 [0m
Run 7 completed successfully
Running gapxGP 8 with agents: 64
decpxADMM initialized with rho: 0.75, lip: 1.0, tol_abs: 1e-05, tol_rel: 0.001, rank: 0, world_size: 64
Rank 0 - Epoch 2/96 loss: 0.9222374558448792
Rank 0 - Epoch 10/96 loss: 0.70241379737854
Rank 0 - Epoch 20/96 loss: 0.3363705277442932
Rank 0 - Epoch 30/96 loss: -0.10280855000019073
Rank 0 - Epoch 40/96 loss: -0.5625669360160828
Rank 0 - Epoch 50/96 loss: -1.0131580829620361
Rank 0 - Epoch 60/96 loss: -1.356758952140808
Rank 0 - Epoch 70/96 loss: -1.6246360540390015
Rank 0 - Epoch 80/96 loss: -1.8106000423431396
Rank 0 - Epoch 90/96 loss: -1.8409557342529297
[92mRank 0 - Testing RMSE: 0.0510[0m
[92mRank: 0, Lengthscale: [[0.6310918 0.3773442]] [0m
[92mRank: 0, Outputscale: 1.5279464721679688 [0m
[92mRank: 0, Noise: 0.00024360866518691182 [0m
Run 8 completed successfully
Running gapxGP 9 with agents: 64
decpxADMM initialized with rho: 0.75, lip: 1.0, tol_abs: 1e-05, tol_rel: 0.001, rank: 0, world_size: 64
Rank 0 - Epoch 2/96 loss: 0.9182273745536804
Rank 0 - Epoch 10/96 loss: 0.690348744392395
Rank 0 - Epoch 20/96 loss: 0.3353537917137146
Rank 0 - Epoch 30/96 loss: -0.12235043942928314
Rank 0 - Epoch 40/96 loss: -0.5754436254501343
Rank 0 - Epoch 50/96 loss: -1.0139905214309692
Rank 0 - Epoch 60/96 loss: -1.39337956905365
Rank 0 - Epoch 70/96 loss: -1.6671781539916992
Rank 0 - Epoch 80/96 loss: -1.7752376794815063
Rank 0 - Epoch 90/96 loss: -1.9331066608428955
[92mRank 0 - Testing RMSE: 0.0551[0m
[92mRank: 0, Lengthscale: [[0.6346637  0.37107882]] [0m
[92mRank: 0, Outputscale: 1.5296908617019653 [0m
[92mRank: 0, Noise: 0.00024153469712473452 [0m
Run 9 completed successfully
Running gapxGP 10 with agents: 64
decpxADMM initialized with rho: 0.75, lip: 1.0, tol_abs: 1e-05, tol_rel: 0.001, rank: 0, world_size: 64
Rank 0 - Epoch 2/96 loss: 0.9177694916725159
Rank 0 - Epoch 10/96 loss: 0.6919124722480774
Rank 0 - Epoch 20/96 loss: 0.3359622061252594
Rank 0 - Epoch 30/96 loss: -0.11172842979431152
Rank 0 - Epoch 40/96 loss: -0.576573371887207
Rank 0 - Epoch 50/96 loss: -1.00547456741333
Rank 0 - Epoch 60/96 loss: -1.4008370637893677
Rank 0 - Epoch 70/96 loss: -1.6206047534942627
Rank 0 - Epoch 80/96 loss: -1.812819480895996
Rank 0 - Epoch 90/96 loss: -1.8678655624389648
[92mRank 0 - Testing RMSE: 0.0447[0m
[92mRank: 0, Lengthscale: [[0.6277926 0.3653743]] [0m
[92mRank: 0, Outputscale: 1.5309782028198242 [0m
[92mRank: 0, Noise: 0.00024254541494883597 [0m
Run 10 completed successfully
Running apxGP 1 with agents: 64
decpxADMM initialized with rho: 0.85, lip: 1.0, tol_abs: 1e-05, tol_rel: 0.001, rank: 0, world_size: 64
Rank 0 - Epoch 2/128 loss: 0.7581815719604492
Rank 0 - Epoch 10/128 loss: 0.488897442817688
Rank 0 - Epoch 20/128 loss: 0.061843495815992355
Rank 0 - Epoch 30/128 loss: -0.4325912296772003
Rank 0 - Epoch 40/128 loss: -0.9554557800292969
Rank 0 - Epoch 50/128 loss: -1.4834858179092407
Rank 0 - Epoch 60/128 loss: -1.9904249906539917
Rank 0 - Epoch 70/128 loss: -2.4481041431427
Rank 0 - Epoch 80/128 loss: -2.8182241916656494
Rank 0 - Epoch 90/128 loss: -3.074509859085083
Rank 0 - Epoch 100/128 loss: -3.2294058799743652
Rank 0 - Epoch 110/128 loss: -3.319194793701172
Rank 0 - Epoch 120/128 loss: -3.3739593029022217
Training complete.
[92mRank 0 - Testing RMSE: 3.1024[0m
[92mRank: 0, Lengthscale: [[0.5979635  0.35438085]] [0m
[92mRank: 0, Outputscale: 1.134514331817627 [0m
[92mRank: 0, Noise: 0.00013105937978252769 [0m
Run 1 completed successfully
Running apxGP 2 with agents: 64
decpxADMM initialized with rho: 0.85, lip: 1.0, tol_abs: 1e-05, tol_rel: 0.001, rank: 0, world_size: 64
Rank 0 - Epoch 2/128 loss: 0.7581815719604492
Rank 0 - Epoch 10/128 loss: 0.488897442817688
Rank 0 - Epoch 20/128 loss: 0.061843495815992355
Rank 0 - Epoch 30/128 loss: -0.4325912296772003
Rank 0 - Epoch 40/128 loss: -0.9554557800292969
Rank 0 - Epoch 50/128 loss: -1.4834858179092407
Rank 0 - Epoch 60/128 loss: -1.9904249906539917
Rank 0 - Epoch 70/128 loss: -2.4481041431427
Rank 0 - Epoch 80/128 loss: -2.8182241916656494
Rank 0 - Epoch 90/128 loss: -3.074509859085083
Rank 0 - Epoch 100/128 loss: -3.2294058799743652
Rank 0 - Epoch 110/128 loss: -3.319194793701172
Rank 0 - Epoch 120/128 loss: -3.3739593029022217
Training complete.
[92mRank 0 - Testing RMSE: 3.1024[0m
[92mRank: 0, Lengthscale: [[0.5979635  0.35438085]] [0m
[92mRank: 0, Outputscale: 1.134514331817627 [0m
[92mRank: 0, Noise: 0.00013105937978252769 [0m
Run 2 completed successfully
Running apxGP 3 with agents: 64
decpxADMM initialized with rho: 0.85, lip: 1.0, tol_abs: 1e-05, tol_rel: 0.001, rank: 0, world_size: 64
Rank 0 - Epoch 2/128 loss: 0.7581815719604492
Rank 0 - Epoch 10/128 loss: 0.488897442817688
Rank 0 - Epoch 20/128 loss: 0.061843495815992355
Rank 0 - Epoch 30/128 loss: -0.4325912296772003
Rank 0 - Epoch 40/128 loss: -0.9554557800292969
Rank 0 - Epoch 50/128 loss: -1.4834858179092407
Rank 0 - Epoch 60/128 loss: -1.9904249906539917
Rank 0 - Epoch 70/128 loss: -2.4481041431427
Rank 0 - Epoch 80/128 loss: -2.8182241916656494
Rank 0 - Epoch 90/128 loss: -3.074509859085083
Rank 0 - Epoch 100/128 loss: -3.2294058799743652
Rank 0 - Epoch 110/128 loss: -3.319194793701172
Rank 0 - Epoch 120/128 loss: -3.3739593029022217
Training complete.
[92mRank 0 - Testing RMSE: 3.1024[0m
[92mRank: 0, Lengthscale: [[0.5979635  0.35438085]] [0m
[92mRank: 0, Outputscale: 1.134514331817627 [0m
[92mRank: 0, Noise: 0.00013105937978252769 [0m
Run 3 completed successfully
Running apxGP 4 with agents: 64
decpxADMM initialized with rho: 0.85, lip: 1.0, tol_abs: 1e-05, tol_rel: 0.001, rank: 0, world_size: 64
Rank 0 - Epoch 2/128 loss: 0.7581815719604492
Rank 0 - Epoch 10/128 loss: 0.488897442817688
Rank 0 - Epoch 20/128 loss: 0.061843495815992355
Rank 0 - Epoch 30/128 loss: -0.4325912296772003
Rank 0 - Epoch 40/128 loss: -0.9554557800292969
Rank 0 - Epoch 50/128 loss: -1.4834858179092407
Rank 0 - Epoch 60/128 loss: -1.9904249906539917
Rank 0 - Epoch 70/128 loss: -2.4481041431427
Rank 0 - Epoch 80/128 loss: -2.8182241916656494
Rank 0 - Epoch 90/128 loss: -3.074509859085083
Rank 0 - Epoch 100/128 loss: -3.2294058799743652
Rank 0 - Epoch 110/128 loss: -3.319194793701172
Rank 0 - Epoch 120/128 loss: -3.3739593029022217
Training complete.
[92mRank 0 - Testing RMSE: 3.1024[0m
[92mRank: 0, Lengthscale: [[0.5979635  0.35438085]] [0m
[92mRank: 0, Outputscale: 1.134514331817627 [0m
[92mRank: 0, Noise: 0.00013105937978252769 [0m
Run 4 completed successfully
Running apxGP 5 with agents: 64
decpxADMM initialized with rho: 0.85, lip: 1.0, tol_abs: 1e-05, tol_rel: 0.001, rank: 0, world_size: 64
Rank 0 - Epoch 2/128 loss: 0.7581815719604492
Rank 0 - Epoch 10/128 loss: 0.488897442817688
Rank 0 - Epoch 20/128 loss: 0.061843495815992355
Rank 0 - Epoch 30/128 loss: -0.4325912296772003
Rank 0 - Epoch 40/128 loss: -0.9554557800292969
Rank 0 - Epoch 50/128 loss: -1.4834858179092407
Rank 0 - Epoch 60/128 loss: -1.9904249906539917
Rank 0 - Epoch 70/128 loss: -2.4481041431427
Rank 0 - Epoch 80/128 loss: -2.8182241916656494
Rank 0 - Epoch 90/128 loss: -3.074509859085083
Rank 0 - Epoch 100/128 loss: -3.2294058799743652
Rank 0 - Epoch 110/128 loss: -3.319194793701172
Rank 0 - Epoch 120/128 loss: -3.3739593029022217
Training complete.
[92mRank 0 - Testing RMSE: 3.1024[0m
[92mRank: 0, Lengthscale: [[0.5979635  0.35438085]] [0m
[92mRank: 0, Outputscale: 1.134514331817627 [0m
[92mRank: 0, Noise: 0.00013105937978252769 [0m
Run 5 completed successfully
Running apxGP 6 with agents: 64
decpxADMM initialized with rho: 0.85, lip: 1.0, tol_abs: 1e-05, tol_rel: 0.001, rank: 0, world_size: 64
Rank 0 - Epoch 2/128 loss: 0.7581815719604492
Rank 0 - Epoch 10/128 loss: 0.488897442817688
Rank 0 - Epoch 20/128 loss: 0.061843495815992355
Rank 0 - Epoch 30/128 loss: -0.4325912296772003
Rank 0 - Epoch 40/128 loss: -0.9554557800292969
Rank 0 - Epoch 50/128 loss: -1.4834858179092407
Rank 0 - Epoch 60/128 loss: -1.9904249906539917
Rank 0 - Epoch 70/128 loss: -2.4481041431427
Rank 0 - Epoch 80/128 loss: -2.8182241916656494
Rank 0 - Epoch 90/128 loss: -3.074509859085083
Rank 0 - Epoch 100/128 loss: -3.2294058799743652
Rank 0 - Epoch 110/128 loss: -3.319194793701172
Rank 0 - Epoch 120/128 loss: -3.3739593029022217
Training complete.
[92mRank 0 - Testing RMSE: 3.1024[0m
[92mRank: 0, Lengthscale: [[0.5979635  0.35438085]] [0m
[92mRank: 0, Outputscale: 1.134514331817627 [0m
[92mRank: 0, Noise: 0.00013105937978252769 [0m
Run 6 completed successfully
Running apxGP 7 with agents: 64
decpxADMM initialized with rho: 0.85, lip: 1.0, tol_abs: 1e-05, tol_rel: 0.001, rank: 0, world_size: 64
Rank 0 - Epoch 2/128 loss: 0.7581815719604492
Rank 0 - Epoch 10/128 loss: 0.488897442817688
Rank 0 - Epoch 20/128 loss: 0.061843495815992355
Rank 0 - Epoch 30/128 loss: -0.4325912296772003
Rank 0 - Epoch 40/128 loss: -0.9554557800292969
Rank 0 - Epoch 50/128 loss: -1.4834858179092407
Rank 0 - Epoch 60/128 loss: -1.9904249906539917
Rank 0 - Epoch 70/128 loss: -2.4481041431427
Rank 0 - Epoch 80/128 loss: -2.8182241916656494
Rank 0 - Epoch 90/128 loss: -3.074509859085083
Rank 0 - Epoch 100/128 loss: -3.2294058799743652
Rank 0 - Epoch 110/128 loss: -3.319194793701172
Rank 0 - Epoch 120/128 loss: -3.3739593029022217
Training complete.
[92mRank 0 - Testing RMSE: 3.1024[0m
[92mRank: 0, Lengthscale: [[0.5979635  0.35438085]] [0m
[92mRank: 0, Outputscale: 1.134514331817627 [0m
[92mRank: 0, Noise: 0.00013105937978252769 [0m
Run 7 completed successfully
Running apxGP 8 with agents: 64
decpxADMM initialized with rho: 0.85, lip: 1.0, tol_abs: 1e-05, tol_rel: 0.001, rank: 0, world_size: 64
Rank 0 - Epoch 2/128 loss: 0.7581815719604492
Rank 0 - Epoch 10/128 loss: 0.488897442817688
Rank 0 - Epoch 20/128 loss: 0.061843495815992355
Rank 0 - Epoch 30/128 loss: -0.4325912296772003
Rank 0 - Epoch 40/128 loss: -0.9554557800292969
Rank 0 - Epoch 50/128 loss: -1.4834858179092407
Rank 0 - Epoch 60/128 loss: -1.9904249906539917
Rank 0 - Epoch 70/128 loss: -2.4481041431427
Rank 0 - Epoch 80/128 loss: -2.8182241916656494
Rank 0 - Epoch 90/128 loss: -3.074509859085083
Rank 0 - Epoch 100/128 loss: -3.2294058799743652
Rank 0 - Epoch 110/128 loss: -3.319194793701172
Rank 0 - Epoch 120/128 loss: -3.3739593029022217
Training complete.
[92mRank 0 - Testing RMSE: 3.1024[0m
[92mRank: 0, Lengthscale: [[0.5979635  0.35438085]] [0m
[92mRank: 0, Outputscale: 1.134514331817627 [0m
[92mRank: 0, Noise: 0.00013105937978252769 [0m
Run 8 completed successfully
Running apxGP 9 with agents: 64
decpxADMM initialized with rho: 0.85, lip: 1.0, tol_abs: 1e-05, tol_rel: 0.001, rank: 0, world_size: 64
Rank 0 - Epoch 2/128 loss: 0.7581815719604492
Rank 0 - Epoch 10/128 loss: 0.488897442817688
Rank 0 - Epoch 20/128 loss: 0.061843495815992355
Rank 0 - Epoch 30/128 loss: -0.4325912296772003
Rank 0 - Epoch 40/128 loss: -0.9554557800292969
Rank 0 - Epoch 50/128 loss: -1.4834858179092407
Rank 0 - Epoch 60/128 loss: -1.9904249906539917
Rank 0 - Epoch 70/128 loss: -2.4481041431427
Rank 0 - Epoch 80/128 loss: -2.8182241916656494
Rank 0 - Epoch 90/128 loss: -3.074509859085083
Rank 0 - Epoch 100/128 loss: -3.2294058799743652
Rank 0 - Epoch 110/128 loss: -3.319194793701172
Rank 0 - Epoch 120/128 loss: -3.3739593029022217
Training complete.
[92mRank 0 - Testing RMSE: 3.1024[0m
[92mRank: 0, Lengthscale: [[0.5979635  0.35438085]] [0m
[92mRank: 0, Outputscale: 1.134514331817627 [0m
[92mRank: 0, Noise: 0.00013105937978252769 [0m
Run 9 completed successfully
Running apxGP 10 with agents: 64
decpxADMM initialized with rho: 0.85, lip: 1.0, tol_abs: 1e-05, tol_rel: 0.001, rank: 0, world_size: 64
Rank 0 - Epoch 2/128 loss: 0.7581815719604492
Rank 0 - Epoch 10/128 loss: 0.488897442817688
Rank 0 - Epoch 20/128 loss: 0.061843495815992355
Rank 0 - Epoch 30/128 loss: -0.4325912296772003
Rank 0 - Epoch 40/128 loss: -0.9554557800292969
Rank 0 - Epoch 50/128 loss: -1.4834858179092407
Rank 0 - Epoch 60/128 loss: -1.9904249906539917
Rank 0 - Epoch 70/128 loss: -2.4481041431427
Rank 0 - Epoch 80/128 loss: -2.8182241916656494
Rank 0 - Epoch 90/128 loss: -3.074509859085083
Rank 0 - Epoch 100/128 loss: -3.2294058799743652
Rank 0 - Epoch 110/128 loss: -3.319194793701172
Rank 0 - Epoch 120/128 loss: -3.3739593029022217
Training complete.
[92mRank 0 - Testing RMSE: 3.1024[0m
[92mRank: 0, Lengthscale: [[0.5979635  0.35438085]] [0m
[92mRank: 0, Outputscale: 1.134514331817627 [0m
[92mRank: 0, Noise: 0.00013105937978252769 [0m
Run 10 completed successfully
Running cGP 1 with agents: 64
decADMM initialized with rho: 0.85, max_iter: 5, lr: 0.0001, rank: 0, world_size: 64
Rank 0 - Epoch 2/128 loss: 0.8144965171813965
Rank 0 - Epoch 10/128 loss: 0.8093019723892212
Rank 0 - Epoch 20/128 loss: 0.8027988076210022
Rank 0 - Epoch 30/128 loss: 0.7962863445281982
Rank 0 - Epoch 40/128 loss: 0.7897670269012451
Rank 0 - Epoch 50/128 loss: 0.7832430601119995
Rank 0 - Epoch 60/128 loss: 0.7767170071601868
Rank 0 - Epoch 70/128 loss: 0.7701914310455322
Rank 0 - Epoch 80/128 loss: 0.7636693120002747
Rank 0 - Epoch 90/128 loss: 0.7571532130241394
Rank 0 - Epoch 100/128 loss: 0.7506462931632996
Rank 0 - Epoch 110/128 loss: 0.7441515922546387
Rank 0 - Epoch 120/128 loss: 0.737671971321106
Training complete.
[92mRank 0 - Testing RMSE: 3.6716[0m
[92mRank: 0, Lengthscale: [[0.58986545 0.58955264]] [0m
[92mRank: 0, Outputscale: 0.5914545655250549 [0m
[92mRank: 0, Noise: 0.5801146626472473 [0m
Run 1 completed successfully
Running cGP 2 with agents: 64
decADMM initialized with rho: 0.85, max_iter: 5, lr: 0.0001, rank: 0, world_size: 64
Rank 0 - Epoch 2/128 loss: 0.8144965171813965
Rank 0 - Epoch 10/128 loss: 0.8093019723892212
Rank 0 - Epoch 20/128 loss: 0.8027988076210022
Rank 0 - Epoch 30/128 loss: 0.7962863445281982
Rank 0 - Epoch 40/128 loss: 0.7897670269012451
Rank 0 - Epoch 50/128 loss: 0.7832430601119995
Rank 0 - Epoch 60/128 loss: 0.7767170071601868
Rank 0 - Epoch 70/128 loss: 0.7701914310455322
Rank 0 - Epoch 80/128 loss: 0.7636693120002747
Rank 0 - Epoch 90/128 loss: 0.7571532130241394
Rank 0 - Epoch 100/128 loss: 0.7506462931632996
Rank 0 - Epoch 110/128 loss: 0.7441515922546387
Rank 0 - Epoch 120/128 loss: 0.737671971321106
Training complete.
[92mRank 0 - Testing RMSE: 3.6716[0m
[92mRank: 0, Lengthscale: [[0.58986545 0.58955264]] [0m
[92mRank: 0, Outputscale: 0.5914545655250549 [0m
[92mRank: 0, Noise: 0.5801146626472473 [0m
Run 2 completed successfully
Running cGP 3 with agents: 64
decADMM initialized with rho: 0.85, max_iter: 5, lr: 0.0001, rank: 0, world_size: 64
Rank 0 - Epoch 2/128 loss: 0.8144965171813965
Rank 0 - Epoch 10/128 loss: 0.8093019723892212
Rank 0 - Epoch 20/128 loss: 0.8027988076210022
Rank 0 - Epoch 30/128 loss: 0.7962863445281982
Rank 0 - Epoch 40/128 loss: 0.7897670269012451
Rank 0 - Epoch 50/128 loss: 0.7832430601119995
Rank 0 - Epoch 60/128 loss: 0.7767170071601868
Rank 0 - Epoch 70/128 loss: 0.7701914310455322
Rank 0 - Epoch 80/128 loss: 0.7636693120002747
Rank 0 - Epoch 90/128 loss: 0.7571532130241394
Rank 0 - Epoch 100/128 loss: 0.7506462931632996
Rank 0 - Epoch 110/128 loss: 0.7441515922546387
Rank 0 - Epoch 120/128 loss: 0.737671971321106
Training complete.
[92mRank 0 - Testing RMSE: 3.6716[0m
[92mRank: 0, Lengthscale: [[0.58986545 0.58955264]] [0m
[92mRank: 0, Outputscale: 0.5914545655250549 [0m
[92mRank: 0, Noise: 0.5801146626472473 [0m
Run 3 completed successfully
Running cGP 4 with agents: 64
decADMM initialized with rho: 0.85, max_iter: 5, lr: 0.0001, rank: 0, world_size: 64
Rank 0 - Epoch 2/128 loss: 0.8144965171813965
Rank 0 - Epoch 10/128 loss: 0.8093019723892212
Rank 0 - Epoch 20/128 loss: 0.8027988076210022
Rank 0 - Epoch 30/128 loss: 0.7962863445281982
Rank 0 - Epoch 40/128 loss: 0.7897670269012451
Rank 0 - Epoch 50/128 loss: 0.7832430601119995
Rank 0 - Epoch 60/128 loss: 0.7767170071601868
Rank 0 - Epoch 70/128 loss: 0.7701914310455322
Rank 0 - Epoch 80/128 loss: 0.7636693120002747
Rank 0 - Epoch 90/128 loss: 0.7571532130241394
Rank 0 - Epoch 100/128 loss: 0.7506462931632996
Rank 0 - Epoch 110/128 loss: 0.7441515922546387
Rank 0 - Epoch 120/128 loss: 0.737671971321106
Training complete.
[92mRank 0 - Testing RMSE: 3.6716[0m
[92mRank: 0, Lengthscale: [[0.58986545 0.58955264]] [0m
[92mRank: 0, Outputscale: 0.5914545655250549 [0m
[92mRank: 0, Noise: 0.5801146626472473 [0m
Run 4 completed successfully
Running cGP 5 with agents: 64
decADMM initialized with rho: 0.85, max_iter: 5, lr: 0.0001, rank: 0, world_size: 64
Rank 0 - Epoch 2/128 loss: 0.8144965171813965
Rank 0 - Epoch 10/128 loss: 0.8093019723892212
Rank 0 - Epoch 20/128 loss: 0.8027988076210022
Rank 0 - Epoch 30/128 loss: 0.7962863445281982
Rank 0 - Epoch 40/128 loss: 0.7897670269012451
Rank 0 - Epoch 50/128 loss: 0.7832430601119995
Rank 0 - Epoch 60/128 loss: 0.7767170071601868
Rank 0 - Epoch 70/128 loss: 0.7701914310455322
Rank 0 - Epoch 80/128 loss: 0.7636693120002747
Rank 0 - Epoch 90/128 loss: 0.7571532130241394
Rank 0 - Epoch 100/128 loss: 0.7506462931632996
Rank 0 - Epoch 110/128 loss: 0.7441515922546387
Rank 0 - Epoch 120/128 loss: 0.737671971321106
Training complete.
[92mRank 0 - Testing RMSE: 3.6716[0m
[92mRank: 0, Lengthscale: [[0.58986545 0.58955264]] [0m
[92mRank: 0, Outputscale: 0.5914545655250549 [0m
[92mRank: 0, Noise: 0.5801146626472473 [0m
Run 5 completed successfully
Running cGP 6 with agents: 64
decADMM initialized with rho: 0.85, max_iter: 5, lr: 0.0001, rank: 0, world_size: 64
Rank 0 - Epoch 2/128 loss: 0.8144965171813965
Rank 0 - Epoch 10/128 loss: 0.8093019723892212
Rank 0 - Epoch 20/128 loss: 0.8027988076210022
Rank 0 - Epoch 30/128 loss: 0.7962863445281982
Rank 0 - Epoch 40/128 loss: 0.7897670269012451
Rank 0 - Epoch 50/128 loss: 0.7832430601119995
Rank 0 - Epoch 60/128 loss: 0.7767170071601868
Rank 0 - Epoch 70/128 loss: 0.7701914310455322
Rank 0 - Epoch 80/128 loss: 0.7636693120002747
Rank 0 - Epoch 90/128 loss: 0.7571532130241394
Rank 0 - Epoch 100/128 loss: 0.7506462931632996
Rank 0 - Epoch 110/128 loss: 0.7441515922546387
Rank 0 - Epoch 120/128 loss: 0.737671971321106
Training complete.
[92mRank 0 - Testing RMSE: 3.6716[0m
[92mRank: 0, Lengthscale: [[0.58986545 0.58955264]] [0m
[92mRank: 0, Outputscale: 0.5914545655250549 [0m
[92mRank: 0, Noise: 0.5801146626472473 [0m
Run 6 completed successfully
Running cGP 7 with agents: 64
decADMM initialized with rho: 0.85, max_iter: 5, lr: 0.0001, rank: 0, world_size: 64
Rank 0 - Epoch 2/128 loss: 0.8144965171813965
Rank 0 - Epoch 10/128 loss: 0.8093019723892212
Rank 0 - Epoch 20/128 loss: 0.8027988076210022
Rank 0 - Epoch 30/128 loss: 0.7962863445281982
Rank 0 - Epoch 40/128 loss: 0.7897670269012451
Rank 0 - Epoch 50/128 loss: 0.7832430601119995
Rank 0 - Epoch 60/128 loss: 0.7767170071601868
Rank 0 - Epoch 70/128 loss: 0.7701914310455322
Rank 0 - Epoch 80/128 loss: 0.7636693120002747
Rank 0 - Epoch 90/128 loss: 0.7571532130241394
Rank 0 - Epoch 100/128 loss: 0.7506462931632996
Rank 0 - Epoch 110/128 loss: 0.7441515922546387
Rank 0 - Epoch 120/128 loss: 0.737671971321106
Training complete.
[92mRank 0 - Testing RMSE: 3.6716[0m
[92mRank: 0, Lengthscale: [[0.58986545 0.58955264]] [0m
[92mRank: 0, Outputscale: 0.5914545655250549 [0m
[92mRank: 0, Noise: 0.5801146626472473 [0m
Run 7 completed successfully
Running cGP 8 with agents: 64
decADMM initialized with rho: 0.85, max_iter: 5, lr: 0.0001, rank: 0, world_size: 64
Rank 0 - Epoch 2/128 loss: 0.8144965171813965
Rank 0 - Epoch 10/128 loss: 0.8093019723892212
Rank 0 - Epoch 20/128 loss: 0.8027988076210022
Rank 0 - Epoch 30/128 loss: 0.7962863445281982
Rank 0 - Epoch 40/128 loss: 0.7897670269012451
Rank 0 - Epoch 50/128 loss: 0.7832430601119995
Rank 0 - Epoch 60/128 loss: 0.7767170071601868
Rank 0 - Epoch 70/128 loss: 0.7701914310455322
Rank 0 - Epoch 80/128 loss: 0.7636693120002747
Rank 0 - Epoch 90/128 loss: 0.7571532130241394
Rank 0 - Epoch 100/128 loss: 0.7506462931632996
Rank 0 - Epoch 110/128 loss: 0.7441515922546387
Rank 0 - Epoch 120/128 loss: 0.737671971321106
Training complete.
[92mRank 0 - Testing RMSE: 3.6716[0m
[92mRank: 0, Lengthscale: [[0.58986545 0.58955264]] [0m
[92mRank: 0, Outputscale: 0.5914545655250549 [0m
[92mRank: 0, Noise: 0.5801146626472473 [0m
Run 8 completed successfully
Running cGP 9 with agents: 64
decADMM initialized with rho: 0.85, max_iter: 5, lr: 0.0001, rank: 0, world_size: 64
Rank 0 - Epoch 2/128 loss: 0.8144965171813965
Rank 0 - Epoch 10/128 loss: 0.8093019723892212
Rank 0 - Epoch 20/128 loss: 0.8027988076210022
Rank 0 - Epoch 30/128 loss: 0.7962863445281982
Rank 0 - Epoch 40/128 loss: 0.7897670269012451
Rank 0 - Epoch 50/128 loss: 0.7832430601119995
Rank 0 - Epoch 60/128 loss: 0.7767170071601868
Rank 0 - Epoch 70/128 loss: 0.7701914310455322
Rank 0 - Epoch 80/128 loss: 0.7636693120002747
Rank 0 - Epoch 90/128 loss: 0.7571532130241394
Rank 0 - Epoch 100/128 loss: 0.7506462931632996
Rank 0 - Epoch 110/128 loss: 0.7441515922546387
Rank 0 - Epoch 120/128 loss: 0.737671971321106
Training complete.
[92mRank 0 - Testing RMSE: 3.6716[0m
[92mRank: 0, Lengthscale: [[0.58986545 0.58955264]] [0m
[92mRank: 0, Outputscale: 0.5914545655250549 [0m
[92mRank: 0, Noise: 0.5801146626472473 [0m
Run 9 completed successfully
Running cGP 10 with agents: 64
decADMM initialized with rho: 0.85, max_iter: 5, lr: 0.0001, rank: 0, world_size: 64
Rank 0 - Epoch 2/128 loss: 0.8144965171813965
Rank 0 - Epoch 10/128 loss: 0.8093019723892212
Rank 0 - Epoch 20/128 loss: 0.8027988076210022
Rank 0 - Epoch 30/128 loss: 0.7962863445281982
Rank 0 - Epoch 40/128 loss: 0.7897670269012451
Rank 0 - Epoch 50/128 loss: 0.7832430601119995
Rank 0 - Epoch 60/128 loss: 0.7767170071601868
Rank 0 - Epoch 70/128 loss: 0.7701914310455322
Rank 0 - Epoch 80/128 loss: 0.7636693120002747
Rank 0 - Epoch 90/128 loss: 0.7571532130241394
Rank 0 - Epoch 100/128 loss: 0.7506462931632996
Rank 0 - Epoch 110/128 loss: 0.7441515922546387
Rank 0 - Epoch 120/128 loss: 0.737671971321106
Training complete.
[92mRank 0 - Testing RMSE: 3.6716[0m
[92mRank: 0, Lengthscale: [[0.58986545 0.58955264]] [0m
[92mRank: 0, Outputscale: 0.5914545655250549 [0m
[92mRank: 0, Noise: 0.5801146626472473 [0m
Run 10 completed successfully
Running pxpGP 1 with agents: 100
[92mRank 0 - sparse dataset size is: 3, local dataset: torch.Size([324, 2]), [0m
[92mRank 0 - Training local sparse GP model with 324 samples[0m
Epoch 1/200 - Loss: 15.926
Epoch 11/200 - Loss: 1.120
Epoch 21/200 - Loss: 1.009
Epoch 31/200 - Loss: 0.958
Epoch 41/200 - Loss: 0.846
Epoch 51/200 - Loss: 0.715
Epoch 61/200 - Loss: 0.566
Epoch 71/200 - Loss: 0.452
Epoch 81/200 - Loss: 0.244
Epoch 91/200 - Loss: -0.006
Converged at epoch 91 with loss -0.006
[92mRank 0 - Lengthscale: [[0.635204  0.7776932]] [0m
[92mRank 0 - Outputscale: 2.436908006668091 [0m
[92mRank 0 - Noise: 0.1279357522726059 [0m
Rank 0 - Augmented dataset size: 624
Rank 0: After warm start model parameters:
Rank: 0, Lengthscale: [[0.635204  0.7776932]]
Rank: 0, Outputscale: 2.436908006668091
Rank: 0, Noise: 0.1279357373714447
decpxADMM initialized with rho: 0.85, lip: 1.0, tol_abs: 1e-05, tol_rel: 0.001, rank: 0, world_size: 100
[92mRank 0 - Training global model with dec-pxADMM optimizer[0m
rank 0, epoch 9, loss: 0.7902632355690002, rho: 0.2125, lip: 1.0000
rank 0, epoch 19, loss: 0.7287323474884033, rho: 0.2125, lip: 1.0000
rank 0, epoch 29, loss: 0.6917193531990051, rho: 0.1062, lip: 1.0000
rank 0, epoch 39, loss: 0.6723781824111938, rho: 0.1062, lip: 1.0000
rank 0, epoch 49, loss: 0.6655572056770325, rho: 0.0531, lip: 1.0000
rank 0, epoch 59, loss: 0.6667493581771851, rho: 0.0531, lip: 1.0000
[rank 12] barrier timed out after 5s, continuing anyway
[rank 20] barrier timed out after 5s, continuing anyway
[rank 24] barrier timed out after 5s, continuing anyway
[rank 26] barrier timed out after 5s, continuing anyway
[rank 27] barrier timed out after 5s, continuing anyway
Run 1 failed, retrying...
Running pxpGP 2 with agents: 100
[92mRank 0 - sparse dataset size is: 3, local dataset: torch.Size([324, 2]), [0m
[92mRank 0 - Training local sparse GP model with 324 samples[0m
Epoch 1/200 - Loss: 13.878
Epoch 11/200 - Loss: 1.082
Epoch 21/200 - Loss: 1.009
Epoch 31/200 - Loss: 0.944
Epoch 41/200 - Loss: 0.843
Epoch 51/200 - Loss: 0.732
Epoch 61/200 - Loss: 0.553
Epoch 71/200 - Loss: 0.409
Epoch 81/200 - Loss: 0.314
Converged at epoch 90 with loss -0.011
[92mRank 0 - Lengthscale: [[0.6124226  0.79755443]] [0m
[92mRank 0 - Outputscale: 2.4047744274139404 [0m
[92mRank 0 - Noise: 0.129598006606102 [0m
Rank 0 - Augmented dataset size: 624
Rank 0: After warm start model parameters:
Rank: 0, Lengthscale: [[0.6124226  0.79755443]]
Rank: 0, Outputscale: 2.4047744274139404
Rank: 0, Noise: 0.129598006606102
decpxADMM initialized with rho: 0.85, lip: 1.0, tol_abs: 1e-05, tol_rel: 0.001, rank: 0, world_size: 100
[92mRank 0 - Training global model with dec-pxADMM optimizer[0m
rank 0, epoch 9, loss: 0.8116907477378845, rho: 0.2125, lip: 1.0000
rank 0, epoch 19, loss: 0.8004735708236694, rho: 0.1062, lip: 1.0000
rank 0, epoch 29, loss: 0.7891598343849182, rho: 0.1062, lip: 1.0000
rank 0, epoch 39, loss: 0.7112506031990051, rho: 0.1062, lip: 1.0000
rank 0, epoch 49, loss: 0.703397810459137, rho: 0.0531, lip: 1.0000
rank 0, epoch 59, loss: 0.7093028426170349, rho: 0.0531, lip: 1.0000
rank 0, epoch 69, loss: 0.7167394161224365, rho: 0.0266, lip: 1.0000
rank 0, epoch 79, loss: 0.7262392044067383, rho: 0.0266, lip: 1.0000
rank 0, epoch 89, loss: 0.7113725543022156, rho: 0.0266, lip: 1.0000
rank 0, epoch 99, loss: 0.6666252017021179, rho: 0.0266, lip: 1.0000
rank 0, epoch 109, loss: 0.46816518902778625, rho: 0.0266, lip: 1.0000
rank 0, epoch 119, loss: 0.5148521661758423, rho: 0.0266, lip: 1.0000
rank 0, epoch 129, loss: 0.5675950050354004, rho: 0.0266, lip: 1.0000
rank 0, epoch 139, loss: 0.6020379662513733, rho: 0.0266, lip: 1.0000
rank 0, epoch 149, loss: 0.6042309403419495, rho: 0.0266, lip: 1.0000
Rank 0 - Training time: 244.87 seconds
[92mRank 0 - Testing RMSE: 0.8891[0m
[92mRank: 0, Lengthscale: [[0.31704664 0.04325861]] [0m
[92mRank: 0, Outputscale: 2.518965482711792 [0m
[92mRank: 0, Noise: 0.003319275099784136 [0m
Run 2 completed successfully
Running pxpGP 3 with agents: 100
[92mRank 0 - sparse dataset size is: 3, local dataset: torch.Size([324, 2]), [0m
[92mRank 0 - Training local sparse GP model with 324 samples[0m
Epoch 1/200 - Loss: 14.301
Epoch 11/200 - Loss: 1.075
Epoch 21/200 - Loss: 1.005
Epoch 31/200 - Loss: 0.928
Epoch 41/200 - Loss: 0.839
Epoch 51/200 - Loss: 0.710
Epoch 61/200 - Loss: 0.580
Epoch 71/200 - Loss: 0.373
Epoch 81/200 - Loss: 0.218
Epoch 91/200 - Loss: 0.001
Converged at epoch 92 with loss -0.074
[92mRank 0 - Lengthscale: [[0.6188764  0.75657123]] [0m
[92mRank 0 - Outputscale: 2.430299758911133 [0m
[92mRank 0 - Noise: 0.12074263393878937 [0m
Rank 0 - Augmented dataset size: 624
Rank 0: After warm start model parameters:
Rank: 0, Lengthscale: [[0.6188764  0.75657123]]
Rank: 0, Outputscale: 2.430299758911133
Rank: 0, Noise: 0.12074263393878937
decpxADMM initialized with rho: 0.85, lip: 1.0, tol_abs: 1e-05, tol_rel: 0.001, rank: 0, world_size: 100
[92mRank 0 - Training global model with dec-pxADMM optimizer[0m
rank 0, epoch 9, loss: 0.8151259422302246, rho: 0.2125, lip: 1.0000
rank 0, epoch 19, loss: 0.8010991215705872, rho: 0.1062, lip: 1.0000
rank 0, epoch 29, loss: 0.7946931719779968, rho: 0.1062, lip: 1.0000
rank 0, epoch 39, loss: 0.741395890712738, rho: 0.1062, lip: 1.0000
rank 0, epoch 49, loss: 0.7340115904808044, rho: 0.1062, lip: 1.0000
rank 0, epoch 59, loss: 0.7281461954116821, rho: 0.0531, lip: 1.0000
rank 0, epoch 69, loss: 0.7245974540710449, rho: 0.0531, lip: 1.0000
[rank 11] barrier timed out after 5s, continuing anyway
[rank 30] barrier timed out after 5s, continuing anyway
[rank 31] barrier timed out after 5s, continuing anyway
[rank 33] barrier timed out after 5s, continuing anyway
[rank 37] barrier timed out after 5s, continuing anyway
[rank 19] barrier timed out after 5s, continuing anyway
[rank 23] barrier timed out after 5s, continuing anyway
[rank 25] barrier timed out after 5s, continuing anyway
[rank 26] barrier timed out after 5s, continuing anyway
[rank 45] barrier timed out after 5s, continuing anyway
[rank 97] barrier timed out after 5s, continuing anyway
Run 3 failed, retrying...
Running pxpGP 4 with agents: 100
[92mRank 0 - sparse dataset size is: 3, local dataset: torch.Size([324, 2]), [0m
[92mRank 0 - Training local sparse GP model with 324 samples[0m
Epoch 1/200 - Loss: 15.520
Epoch 11/200 - Loss: 1.094
Epoch 21/200 - Loss: 1.023
Epoch 31/200 - Loss: 0.947
Epoch 41/200 - Loss: 0.852
Epoch 51/200 - Loss: 0.708
Epoch 61/200 - Loss: 0.590
Epoch 71/200 - Loss: 0.417
Epoch 81/200 - Loss: 0.272
Converged at epoch 90 with loss -0.020
[92mRank 0 - Lengthscale: [[0.622321 0.731856]] [0m
[92mRank 0 - Outputscale: 2.3977713584899902 [0m
[92mRank 0 - Noise: 0.13205671310424805 [0m
Rank 0 - Augmented dataset size: 624
Rank 0: After warm start model parameters:
Rank: 0, Lengthscale: [[0.622321 0.731856]]
Rank: 0, Outputscale: 2.3977713584899902
Rank: 0, Noise: 0.13205672800540924
decpxADMM initialized with rho: 0.85, lip: 1.0, tol_abs: 1e-05, tol_rel: 0.001, rank: 0, world_size: 100
[92mRank 0 - Training global model with dec-pxADMM optimizer[0m
rank 0, epoch 9, loss: 0.7777905464172363, rho: 0.2125, lip: 1.0000
rank 0, epoch 19, loss: 0.6843459010124207, rho: 0.2125, lip: 1.0000
rank 0, epoch 29, loss: 0.6944029927253723, rho: 0.2125, lip: 1.0000
rank 0, epoch 39, loss: 0.6775914430618286, rho: 0.1062, lip: 1.0000
rank 0, epoch 49, loss: 0.6678104996681213, rho: 0.0531, lip: 1.0000
rank 0, epoch 59, loss: 0.6674522757530212, rho: 0.0531, lip: 1.0000
rank 0, epoch 69, loss: 0.6671919822692871, rho: 0.0266, lip: 1.0000
rank 0, epoch 79, loss: 0.6661038398742676, rho: 0.0266, lip: 1.0000
rank 0, epoch 89, loss: 0.6678759455680847, rho: 0.0266, lip: 1.0000
rank 0, epoch 99, loss: 0.7078071236610413, rho: 0.0266, lip: 1.0000
rank 0, epoch 109, loss: 0.6892098188400269, rho: 0.0266, lip: 1.0000
rank 0, epoch 119, loss: 0.690406858921051, rho: 0.0266, lip: 1.0000
rank 0, epoch 129, loss: 0.6903915405273438, rho: 0.0133, lip: 1.0000
rank 0, epoch 139, loss: 0.688880980014801, rho: 0.0133, lip: 1.0000
rank 0, epoch 149, loss: 0.6875076293945312, rho: 0.0133, lip: 1.0000
Rank 0 - Training time: 234.11 seconds
[92mRank 0 - Testing RMSE: 0.7945[0m
[92mRank: 0, Lengthscale: [[0.47523248 0.04003955]] [0m
[92mRank: 0, Outputscale: 2.3198726177215576 [0m
[92mRank: 0, Noise: 0.035522013902664185 [0m
Run 4 completed successfully
Running pxpGP 5 with agents: 100
[92mRank 0 - sparse dataset size is: 3, local dataset: torch.Size([324, 2]), [0m
[92mRank 0 - Training local sparse GP model with 324 samples[0m
Epoch 1/200 - Loss: 12.430
Epoch 11/200 - Loss: 1.088
Epoch 21/200 - Loss: 1.003
Epoch 31/200 - Loss: 0.932
Epoch 41/200 - Loss: 0.838
Epoch 51/200 - Loss: 0.716
Epoch 61/200 - Loss: 0.564
Epoch 71/200 - Loss: 0.372
Epoch 81/200 - Loss: 0.161
Epoch 91/200 - Loss: 0.044
Converged at epoch 92 with loss -0.046
[92mRank 0 - Lengthscale: [[0.6211892  0.72900665]] [0m
[92mRank 0 - Outputscale: 2.414353847503662 [0m
[92mRank 0 - Noise: 0.11568817496299744 [0m
Rank 0 - Augmented dataset size: 624
Rank 0: After warm start model parameters:
Rank: 0, Lengthscale: [[0.6211891  0.72900665]]
Rank: 0, Outputscale: 2.414353847503662
Rank: 0, Noise: 0.11568817496299744
decpxADMM initialized with rho: 0.85, lip: 1.0, tol_abs: 1e-05, tol_rel: 0.001, rank: 0, world_size: 100
[92mRank 0 - Training global model with dec-pxADMM optimizer[0m
rank 0, epoch 9, loss: 0.7686145901679993, rho: 0.2125, lip: 1.0000
rank 0, epoch 19, loss: 0.7737382054328918, rho: 0.1062, lip: 1.0000
rank 0, epoch 29, loss: 0.6752042770385742, rho: 0.1062, lip: 1.0000
rank 0, epoch 39, loss: 0.6492399573326111, rho: 0.1062, lip: 1.0000
rank 0, epoch 49, loss: 0.6439689993858337, rho: 0.0531, lip: 1.0000
rank 0, epoch 59, loss: 0.6428937315940857, rho: 0.0531, lip: 1.0000
rank 0, epoch 69, loss: 0.6440345048904419, rho: 0.0531, lip: 1.0000
rank 0, epoch 79, loss: 0.6447999477386475, rho: 0.0266, lip: 1.0000
rank 0, epoch 89, loss: 0.6453542113304138, rho: 0.0266, lip: 1.0000
rank 0, epoch 99, loss: 0.6549450755119324, rho: 0.0266, lip: 1.0000
rank 0, epoch 109, loss: 0.5398969650268555, rho: 0.0266, lip: 1.0000
rank 0, epoch 119, loss: 0.4087495505809784, rho: 0.0266, lip: 1.0000
rank 0, epoch 129, loss: 0.4260346293449402, rho: 0.0266, lip: 1.0000
rank 0, epoch 139, loss: 0.42898431420326233, rho: 0.0266, lip: 1.0000
rank 0, epoch 149, loss: 0.42870742082595825, rho: 0.0133, lip: 1.0000
Rank 0 - Training time: 212.36 seconds
[92mRank 0 - Testing RMSE: 0.7579[0m
[92mRank: 0, Lengthscale: [[0.2183881  0.07488636]] [0m
[92mRank: 0, Outputscale: 2.805598497390747 [0m
[92mRank: 0, Noise: 0.005032685119658709 [0m
Run 5 completed successfully
Running pxpGP 6 with agents: 100
[92mRank 0 - sparse dataset size is: 3, local dataset: torch.Size([324, 2]), [0m
[92mRank 0 - Training local sparse GP model with 324 samples[0m
Epoch 1/200 - Loss: 13.394
Epoch 11/200 - Loss: 1.135
Epoch 21/200 - Loss: 1.015
Epoch 31/200 - Loss: 0.933
Epoch 41/200 - Loss: 0.834
Epoch 51/200 - Loss: 0.700
Epoch 61/200 - Loss: 0.547
Epoch 71/200 - Loss: 0.406
Epoch 81/200 - Loss: 0.202
Converged at epoch 88 with loss -0.005
[92mRank 0 - Lengthscale: [[0.6209723 0.6587122]] [0m
[92mRank 0 - Outputscale: 2.428849935531616 [0m
[92mRank 0 - Noise: 0.13691705465316772 [0m
Rank 0 - Augmented dataset size: 624
Rank 0: After warm start model parameters:
Rank: 0, Lengthscale: [[0.6209723 0.6587122]]
Rank: 0, Outputscale: 2.428849935531616
Rank: 0, Noise: 0.13691705465316772
decpxADMM initialized with rho: 0.85, lip: 1.0, tol_abs: 1e-05, tol_rel: 0.001, rank: 0, world_size: 100
[92mRank 0 - Training global model with dec-pxADMM optimizer[0m
rank 0, epoch 9, loss: 0.83221435546875, rho: 0.2125, lip: 1.0000
rank 0, epoch 19, loss: 0.803654134273529, rho: 0.2125, lip: 1.0000
rank 0, epoch 29, loss: 0.7754337787628174, rho: 0.1062, lip: 1.0000
rank 0, epoch 39, loss: 0.7327823042869568, rho: 0.1062, lip: 1.0000
rank 0, epoch 49, loss: 0.7199849486351013, rho: 0.0531, lip: 1.0000
rank 0, epoch 59, loss: 0.7180598974227905, rho: 0.0531, lip: 1.0000
rank 0, epoch 69, loss: 0.7190071940422058, rho: 0.0531, lip: 1.0000
rank 0, epoch 79, loss: 0.7101707458496094, rho: 0.0531, lip: 1.0000
rank 0, epoch 89, loss: 0.5323945879936218, rho: 0.0531, lip: 1.0000
rank 0, epoch 99, loss: 0.24779079854488373, rho: 0.0531, lip: 1.0000
rank 0, epoch 109, loss: 0.14444439113140106, rho: 0.0531, lip: 1.0000
rank 0, epoch 119, loss: 0.21983639895915985, rho: 0.0531, lip: 1.0000
rank 0, epoch 129, loss: 0.27207183837890625, rho: 0.0531, lip: 1.0000
Run 6 failed, retrying...
Running pxpGP 7 with agents: 100
[92mRank 0 - sparse dataset size is: 3, local dataset: torch.Size([324, 2]), [0m
[92mRank 0 - Training local sparse GP model with 324 samples[0m
Epoch 1/200 - Loss: 12.179
Epoch 11/200 - Loss: 1.141
Epoch 21/200 - Loss: 1.022
Epoch 31/200 - Loss: 0.954
Epoch 41/200 - Loss: 0.864
Epoch 51/200 - Loss: 0.716
Epoch 61/200 - Loss: 0.557
Epoch 71/200 - Loss: 0.411
Epoch 81/200 - Loss: 0.217
Converged at epoch 90 with loss -0.011
[92mRank 0 - Lengthscale: [[0.6341331 0.6339751]] [0m
[92mRank 0 - Outputscale: 2.404512643814087 [0m
[92mRank 0 - Noise: 0.12769240140914917 [0m
Rank 0 - Augmented dataset size: 624
Rank 0: After warm start model parameters:
Rank: 0, Lengthscale: [[0.6341331  0.63397515]]
Rank: 0, Outputscale: 2.404512643814087
Rank: 0, Noise: 0.12769241631031036
decpxADMM initialized with rho: 0.85, lip: 1.0, tol_abs: 1e-05, tol_rel: 0.001, rank: 0, world_size: 100
[92mRank 0 - Training global model with dec-pxADMM optimizer[0m
rank 0, epoch 9, loss: 0.7902711629867554, rho: 0.2125, lip: 1.0000
rank 0, epoch 19, loss: 0.709235429763794, rho: 0.2125, lip: 1.0000
rank 0, epoch 29, loss: 0.7015662789344788, rho: 0.2125, lip: 1.0000
rank 0, epoch 39, loss: 0.6916676759719849, rho: 0.1062, lip: 1.0000
rank 0, epoch 49, loss: 0.6850552558898926, rho: 0.0531, lip: 1.0000
rank 0, epoch 59, loss: 0.5852971076965332, rho: 0.0531, lip: 1.0000
[rank 3] barrier timed out after 5s, continuing anyway
[rank 11] barrier timed out after 5s, continuing anyway
[rank 15] barrier timed out after 5s, continuing anyway
[rank 17] barrier timed out after 5s, continuing anyway
[rank 18] barrier timed out after 5s, continuing anyway
[rank 22] barrier timed out after 5s, continuing anyway
[rank 23] barrier timed out after 5s, continuing anyway
[rank 25] barrier timed out after 5s, continuing anyway
[rank 29] barrier timed out after 5s, continuing anyway
[rank 37] barrier timed out after 5s, continuing anyway
Run 7 failed, retrying...
Running pxpGP 8 with agents: 100
[92mRank 0 - sparse dataset size is: 3, local dataset: torch.Size([324, 2]), [0m
[92mRank 0 - Training local sparse GP model with 324 samples[0m
Epoch 1/200 - Loss: 15.204
Epoch 11/200 - Loss: 1.138
Epoch 21/200 - Loss: 1.019
Epoch 31/200 - Loss: 0.940
Epoch 41/200 - Loss: 0.845
Epoch 51/200 - Loss: 0.757
Epoch 61/200 - Loss: 0.590
Epoch 71/200 - Loss: 0.371
Epoch 81/200 - Loss: 0.239
Epoch 91/200 - Loss: 0.090
Converged at epoch 92 with loss -0.050
[92mRank 0 - Lengthscale: [[0.62569034 0.7823033 ]] [0m
[92mRank 0 - Outputscale: 2.4080727100372314 [0m
[92mRank 0 - Noise: 0.12029606103897095 [0m
Rank 0 - Augmented dataset size: 624
Rank 0: After warm start model parameters:
Rank: 0, Lengthscale: [[0.62569034 0.7823033 ]]
Rank: 0, Outputscale: 2.4080727100372314
Rank: 0, Noise: 0.12029608339071274
decpxADMM initialized with rho: 0.85, lip: 1.0, tol_abs: 1e-05, tol_rel: 0.001, rank: 0, world_size: 100
[92mRank 0 - Training global model with dec-pxADMM optimizer[0m
rank 0, epoch 9, loss: 0.8239294290542603, rho: 0.2125, lip: 1.0000
rank 0, epoch 19, loss: 0.7528378963470459, rho: 0.1062, lip: 1.0000
rank 0, epoch 29, loss: 0.776860773563385, rho: 0.1062, lip: 1.0000
rank 0, epoch 39, loss: 0.7489407658576965, rho: 0.1062, lip: 1.0000
rank 0, epoch 49, loss: 0.752510130405426, rho: 0.1062, lip: 1.0000
rank 0, epoch 59, loss: 0.6054410934448242, rho: 0.1062, lip: 1.0000
rank 0, epoch 69, loss: 0.4270022511482239, rho: 0.1062, lip: 1.0000
rank 0, epoch 79, loss: 0.3747519552707672, rho: 0.0531, lip: 1.0000
rank 0, epoch 89, loss: 0.3786209225654602, rho: 0.0266, lip: 1.0000
rank 0, epoch 99, loss: 0.3837165832519531, rho: 0.0266, lip: 1.0000
rank 0, epoch 109, loss: 0.3901338279247284, rho: 0.0266, lip: 1.0000
rank 0, epoch 119, loss: 0.3937692940235138, rho: 0.0266, lip: 1.0000
rank 0, epoch 129, loss: 0.39354509115219116, rho: 0.0133, lip: 1.0000
rank 0, epoch 139, loss: 0.39355239272117615, rho: 0.0133, lip: 1.0000
rank 0, epoch 149, loss: 0.3934009373188019, rho: 0.0133, lip: 1.0000
Rank 0 - Training time: 265.28 seconds
[92mRank 0 - Testing RMSE: 0.9334[0m
[92mRank: 0, Lengthscale: [[0.32891762 0.04854274]] [0m
[92mRank: 0, Outputscale: 2.323855400085449 [0m
[92mRank: 0, Noise: 0.004660061094909906 [0m
Run 8 completed successfully
Running pxpGP 9 with agents: 100
[92mRank 0 - sparse dataset size is: 3, local dataset: torch.Size([324, 2]), [0m
[92mRank 0 - Training local sparse GP model with 324 samples[0m
Epoch 1/200 - Loss: 14.424
Epoch 11/200 - Loss: 1.089
Epoch 21/200 - Loss: 1.019
Epoch 31/200 - Loss: 0.941
Epoch 41/200 - Loss: 0.827
Epoch 51/200 - Loss: 0.705
Epoch 61/200 - Loss: 0.572
Epoch 71/200 - Loss: 0.385
Epoch 81/200 - Loss: 0.197
Converged at epoch 90 with loss -0.009
[92mRank 0 - Lengthscale: [[0.6138091 0.8014004]] [0m
[92mRank 0 - Outputscale: 2.4296648502349854 [0m
[92mRank 0 - Noise: 0.12941895425319672 [0m
Rank 0 - Augmented dataset size: 624
Rank 0: After warm start model parameters:
Rank: 0, Lengthscale: [[0.6138091 0.8014004]]
Rank: 0, Outputscale: 2.4296648502349854
Rank: 0, Noise: 0.12941895425319672
decpxADMM initialized with rho: 0.85, lip: 1.0, tol_abs: 1e-05, tol_rel: 0.001, rank: 0, world_size: 100
[92mRank 0 - Training global model with dec-pxADMM optimizer[0m
rank 0, epoch 9, loss: 0.8321285843849182, rho: 0.2125, lip: 1.0000
rank 0, epoch 19, loss: 0.7961030602455139, rho: 0.1062, lip: 1.0000
rank 0, epoch 29, loss: 0.745158851146698, rho: 0.1062, lip: 1.0000
rank 0, epoch 39, loss: 0.7106422185897827, rho: 0.1062, lip: 1.0000
rank 0, epoch 49, loss: 0.7012929916381836, rho: 0.0531, lip: 1.0000
rank 0, epoch 59, loss: 0.7030390501022339, rho: 0.0531, lip: 1.0000
rank 0, epoch 69, loss: 0.6585192680358887, rho: 0.0531, lip: 1.0000
rank 0, epoch 79, loss: 0.5397152304649353, rho: 0.0531, lip: 1.0000
rank 0, epoch 89, loss: 0.38482993841171265, rho: 0.0531, lip: 1.0000
[rank 11] barrier timed out after 5s, continuing anyway
[rank 19] barrier timed out after 5s, continuing anyway
[rank 23] barrier timed out after 5s, continuing anyway
[rank 25] barrier timed out after 5s, continuing anyway
[rank 26] barrier timed out after 5s, continuing anyway
[rank 33] barrier timed out after 5s, continuing anyway
[rank 34] barrier timed out after 5s, continuing anyway
[rank 36] barrier timed out after 5s, continuing anyway
[rank 40] barrier timed out after 5s, continuing anyway
[rank 48] barrier timed out after 5s, continuing anyway
[rank 70] barrier timed out after 5s, continuing anyway
[rank 71] barrier timed out after 5s, continuing anyway
[rank 84] barrier timed out after 5s, continuing anyway
Run 9 failed, retrying...
Running pxpGP 10 with agents: 100
[92mRank 0 - sparse dataset size is: 3, local dataset: torch.Size([324, 2]), [0m
[92mRank 0 - Training local sparse GP model with 324 samples[0m
Epoch 1/200 - Loss: 15.800
Epoch 11/200 - Loss: 1.097
Epoch 21/200 - Loss: 0.999
Epoch 31/200 - Loss: 0.931
Epoch 41/200 - Loss: 0.865
Epoch 51/200 - Loss: 0.729
Epoch 61/200 - Loss: 0.569
Epoch 71/200 - Loss: 0.403
Epoch 81/200 - Loss: 0.197
Epoch 91/200 - Loss: -0.046
Converged at epoch 91 with loss -0.046
[92mRank 0 - Lengthscale: [[0.6303561 0.5936925]] [0m
[92mRank 0 - Outputscale: 2.4369986057281494 [0m
[92mRank 0 - Noise: 0.12398383021354675 [0m
Rank 0 - Augmented dataset size: 624
Rank 0: After warm start model parameters:
Rank: 0, Lengthscale: [[0.6303561 0.5936925]]
Rank: 0, Outputscale: 2.4369986057281494
Rank: 0, Noise: 0.12398383021354675
decpxADMM initialized with rho: 0.85, lip: 1.0, tol_abs: 1e-05, tol_rel: 0.001, rank: 0, world_size: 100
[92mRank 0 - Training global model with dec-pxADMM optimizer[0m
rank 0, epoch 9, loss: 0.8036025762557983, rho: 0.2125, lip: 1.0000
rank 0, epoch 19, loss: 0.7271929383277893, rho: 0.2125, lip: 1.0000
rank 0, epoch 29, loss: 0.7521873712539673, rho: 0.2125, lip: 1.0000
rank 0, epoch 39, loss: 0.7275495529174805, rho: 0.1062, lip: 1.0000
rank 0, epoch 49, loss: 0.7221966981887817, rho: 0.0531, lip: 1.0000
rank 0, epoch 59, loss: 0.685733437538147, rho: 0.0531, lip: 1.0000
rank 0, epoch 69, loss: 0.5014848709106445, rho: 0.0531, lip: 1.0000
rank 0, epoch 79, loss: 0.3594173491001129, rho: 0.0531, lip: 1.0000
[rank 4] barrier timed out after 5s, continuing anyway
[rank 12] barrier timed out after 5s, continuing anyway
[rank 16] barrier timed out after 5s, continuing anyway
[rank 18] barrier timed out after 5s, continuing anyway
[rank 19] barrier timed out after 5s, continuing anyway
[rank 23] barrier timed out after 5s, continuing anyway
[rank 24] barrier timed out after 5s, continuing anyway
[rank 26] barrier timed out after 5s, continuing anyway
[rank 30] barrier timed out after 5s, continuing anyway
[rank 38] barrier timed out after 5s, continuing anyway
Run 10 failed, retrying...
Running gapxGP 1 with agents: 100
decpxADMM initialized with rho: 0.75, lip: 1.0, tol_abs: 1e-05, tol_rel: 0.001, rank: 0, world_size: 100
Rank 0 - Epoch 2/150 loss: 1.0216137170791626
Rank 0 - Epoch 10/150 loss: 0.8104219436645508
Rank 0 - Epoch 20/150 loss: 0.5166246891021729
Rank 0 - Epoch 30/150 loss: 0.12523043155670166
Rank 0 - Epoch 40/150 loss: -0.2917764484882355
Rank 0 - Epoch 50/150 loss: -0.6954518556594849
Rank 0 - Epoch 60/150 loss: -1.080426573753357
Rank 0 - Epoch 70/150 loss: -1.4315499067306519
Rank 0 - Epoch 80/150 loss: -1.7384235858917236
Rank 0 - Epoch 90/150 loss: -1.9864476919174194
Rank 0 - Epoch 100/150 loss: -2.1659138202667236
Rank 0 - Epoch 110/150 loss: -2.2843167781829834
Rank 0 - Epoch 120/150 loss: -2.302767753601074
Rank 0 - Epoch 130/150 loss: -2.3951363563537598
Rank 0 - Epoch 140/150 loss: -2.416391134262085
Run 1 failed, retrying...
Running gapxGP 2 with agents: 100
decpxADMM initialized with rho: 0.75, lip: 1.0, tol_abs: 1e-05, tol_rel: 0.001, rank: 0, world_size: 100
Rank 0 - Epoch 2/150 loss: 1.015859842300415
Rank 0 - Epoch 10/150 loss: 0.8024318814277649
Rank 0 - Epoch 20/150 loss: 0.500083863735199
Rank 0 - Epoch 30/150 loss: 0.10342549532651901
Rank 0 - Epoch 40/150 loss: -0.3041021227836609
Rank 0 - Epoch 50/150 loss: -0.7087969183921814
Rank 0 - Epoch 60/150 loss: -1.0958759784698486
Rank 0 - Epoch 70/150 loss: -1.4490211009979248
Rank 0 - Epoch 80/150 loss: -1.7567262649536133
Rank 0 - Epoch 90/150 loss: -2.0031938552856445
Rank 0 - Epoch 100/150 loss: -2.1796796321868896
Rank 0 - Epoch 110/150 loss: -2.294255495071411
Rank 0 - Epoch 120/150 loss: -2.212082624435425
Rank 0 - Epoch 130/150 loss: -2.22172212600708
Rank 0 - Epoch 140/150 loss: -2.3002846240997314
Run 2 failed, retrying...
Running gapxGP 3 with agents: 100
decpxADMM initialized with rho: 0.75, lip: 1.0, tol_abs: 1e-05, tol_rel: 0.001, rank: 0, world_size: 100
Rank 0 - Epoch 2/150 loss: 1.0173574686050415
Rank 0 - Epoch 10/150 loss: 0.8050447702407837
Rank 0 - Epoch 20/150 loss: 0.5066621899604797
Rank 0 - Epoch 30/150 loss: 0.1106945276260376
Rank 0 - Epoch 40/150 loss: -0.29434463381767273
Rank 0 - Epoch 50/150 loss: -0.6964686512947083
Rank 0 - Epoch 60/150 loss: -1.0810140371322632
Rank 0 - Epoch 70/150 loss: -1.4311476945877075
Rank 0 - Epoch 80/150 loss: -1.7380138635635376
Rank 0 - Epoch 90/150 loss: -1.9853127002716064
Rank 0 - Epoch 100/150 loss: -2.164018154144287
Rank 0 - Epoch 110/150 loss: -2.279456853866577
Rank 0 - Epoch 120/150 loss: -2.2487034797668457
Rank 0 - Epoch 130/150 loss: -2.214918851852417
Rank 0 - Epoch 140/150 loss: -2.2024290561676025
Run 3 failed, retrying...
Running gapxGP 4 with agents: 100
decpxADMM initialized with rho: 0.75, lip: 1.0, tol_abs: 1e-05, tol_rel: 0.001, rank: 0, world_size: 100
Rank 0 - Epoch 2/150 loss: 1.024274230003357
Rank 0 - Epoch 10/150 loss: 0.8136285543441772
Rank 0 - Epoch 20/150 loss: 0.5202138423919678
Rank 0 - Epoch 30/150 loss: 0.11838933080434799
Rank 0 - Epoch 40/150 loss: -0.2934371829032898
Rank 0 - Epoch 50/150 loss: -0.6978358626365662
Rank 0 - Epoch 60/150 loss: -1.0810614824295044
Rank 0 - Epoch 70/150 loss: -1.4293895959854126
Rank 0 - Epoch 80/150 loss: -1.7348341941833496
Rank 0 - Epoch 90/150 loss: -1.980921983718872
Rank 0 - Epoch 100/150 loss: -2.158954381942749
Rank 0 - Epoch 110/150 loss: -2.276609420776367
Rank 0 - Epoch 120/150 loss: -2.145568370819092
Rank 0 - Epoch 130/150 loss: -2.3453445434570312
Run 4 failed, retrying...
Running gapxGP 5 with agents: 100
decpxADMM initialized with rho: 0.75, lip: 1.0, tol_abs: 1e-05, tol_rel: 0.001, rank: 0, world_size: 100
Rank 0 - Epoch 2/150 loss: 1.0166467428207397
Rank 0 - Epoch 10/150 loss: 0.797152042388916
Rank 0 - Epoch 20/150 loss: 0.489963561296463
Rank 0 - Epoch 30/150 loss: 0.10076216608285904
Rank 0 - Epoch 40/150 loss: -0.3074517846107483
Rank 0 - Epoch 50/150 loss: -0.7055147886276245
Rank 0 - Epoch 60/150 loss: -1.0860612392425537
Rank 0 - Epoch 70/150 loss: -1.4335200786590576
Rank 0 - Epoch 80/150 loss: -1.7374045848846436
Rank 0 - Epoch 90/150 loss: -1.9823291301727295
Rank 0 - Epoch 100/150 loss: -2.1589772701263428
Rank 0 - Epoch 110/150 loss: -2.250817060470581
Rank 0 - Epoch 120/150 loss: -2.151052713394165
Rank 0 - Epoch 130/150 loss: -2.2405712604522705
Rank 0 - Epoch 140/150 loss: -2.399710178375244
Run 5 failed, retrying...
Running gapxGP 6 with agents: 100
decpxADMM initialized with rho: 0.75, lip: 1.0, tol_abs: 1e-05, tol_rel: 0.001, rank: 0, world_size: 100
Rank 0 - Epoch 2/150 loss: 1.014115333557129
Rank 0 - Epoch 10/150 loss: 0.7994251847267151
Rank 0 - Epoch 20/150 loss: 0.5015564560890198
Rank 0 - Epoch 30/150 loss: 0.1140465959906578
Rank 0 - Epoch 40/150 loss: -0.2914625406265259
Rank 0 - Epoch 50/150 loss: -0.6902081370353699
Rank 0 - Epoch 60/150 loss: -1.0724711418151855
Rank 0 - Epoch 70/150 loss: -1.4219447374343872
Rank 0 - Epoch 80/150 loss: -1.728074550628662
Rank 0 - Epoch 90/150 loss: -1.9752182960510254
Rank 0 - Epoch 100/150 loss: -2.1537115573883057
Rank 0 - Epoch 110/150 loss: -2.2702648639678955
Rank 0 - Epoch 120/150 loss: -2.2240052223205566
Rank 0 - Epoch 130/150 loss: -1.9981144666671753
Rank 0 - Epoch 140/150 loss: -2.373533248901367
Run 6 failed, retrying...
Running gapxGP 7 with agents: 100
decpxADMM initialized with rho: 0.75, lip: 1.0, tol_abs: 1e-05, tol_rel: 0.001, rank: 0, world_size: 100
Rank 0 - Epoch 2/150 loss: 1.024773120880127
Rank 0 - Epoch 10/150 loss: 0.8164271116256714
Rank 0 - Epoch 20/150 loss: 0.5228899717330933
Rank 0 - Epoch 30/150 loss: 0.1257351189851761
Rank 0 - Epoch 40/150 loss: -0.28280261158943176
Rank 0 - Epoch 50/150 loss: -0.6842472553253174
Rank 0 - Epoch 60/150 loss: -1.0658921003341675
Rank 0 - Epoch 70/150 loss: -1.4144309759140015
Rank 0 - Epoch 80/150 loss: -1.7188247442245483
Rank 0 - Epoch 90/150 loss: -1.9642752408981323
Rank 0 - Epoch 100/150 loss: -2.1428072452545166
Rank 0 - Epoch 110/150 loss: -2.2609081268310547
Rank 0 - Epoch 120/150 loss: -2.116074562072754
Rank 0 - Epoch 130/150 loss: -2.308004856109619
Run 7 failed, retrying...
Running gapxGP 8 with agents: 100
decpxADMM initialized with rho: 0.75, lip: 1.0, tol_abs: 1e-05, tol_rel: 0.001, rank: 0, world_size: 100
Rank 0 - Epoch 2/150 loss: 1.020369291305542
Rank 0 - Epoch 10/150 loss: 0.8064210414886475
Rank 0 - Epoch 20/150 loss: 0.49987155199050903
Rank 0 - Epoch 30/150 loss: 0.10108119994401932
Rank 0 - Epoch 40/150 loss: -0.2999756932258606
Rank 0 - Epoch 50/150 loss: -0.6999010443687439
Rank 0 - Epoch 60/150 loss: -1.0821610689163208
Rank 0 - Epoch 70/150 loss: -1.430569052696228
Rank 0 - Epoch 80/150 loss: -1.734259009361267
Rank 0 - Epoch 90/150 loss: -1.9780501127243042
Rank 0 - Epoch 100/150 loss: -2.154130220413208
Rank 0 - Epoch 110/150 loss: -2.269777297973633
Rank 0 - Epoch 120/150 loss: -2.3222317695617676
Rank 0 - Epoch 130/150 loss: -2.3485360145568848
Run 8 failed, retrying...
Running gapxGP 9 with agents: 100
decpxADMM initialized with rho: 0.75, lip: 1.0, tol_abs: 1e-05, tol_rel: 0.001, rank: 0, world_size: 100
Rank 0 - Epoch 2/150 loss: 1.0148900747299194
Rank 0 - Epoch 10/150 loss: 0.8025583624839783
Rank 0 - Epoch 20/150 loss: 0.5128456354141235
Rank 0 - Epoch 30/150 loss: 0.12165486067533493
Rank 0 - Epoch 40/150 loss: -0.29005369544029236
Rank 0 - Epoch 50/150 loss: -0.6888824105262756
Rank 0 - Epoch 60/150 loss: -1.0738002061843872
Rank 0 - Epoch 70/150 loss: -1.4249669313430786
Rank 0 - Epoch 80/150 loss: -1.7328444719314575
Rank 0 - Epoch 90/150 loss: -1.9815168380737305
Rank 0 - Epoch 100/150 loss: -2.161299467086792
Rank 0 - Epoch 110/150 loss: -2.2753477096557617
Rank 0 - Epoch 120/150 loss: -2.315546751022339
Rank 0 - Epoch 130/150 loss: -2.360100746154785
Rank 0 - Epoch 140/150 loss: -2.41694974899292
Rank 0 - Epoch 150/150 loss: -2.436929225921631
[92mRank 0 - Testing RMSE: 0.0109[0m
[92mRank: 0, Lengthscale: [[0.65367985 0.38899714]] [0m
[92mRank: 0, Outputscale: 1.946519136428833 [0m
[92mRank: 0, Noise: 0.00013190296886023134 [0m
Run 9 completed successfully
Running gapxGP 10 with agents: 100
decpxADMM initialized with rho: 0.75, lip: 1.0, tol_abs: 1e-05, tol_rel: 0.001, rank: 0, world_size: 100
Rank 0 - Epoch 2/150 loss: 1.0182470083236694
Rank 0 - Epoch 10/150 loss: 0.8071140646934509
Rank 0 - Epoch 20/150 loss: 0.5114465951919556
Rank 0 - Epoch 30/150 loss: 0.1222304180264473
Rank 0 - Epoch 40/150 loss: -0.28765201568603516
Rank 0 - Epoch 50/150 loss: -0.6878012418746948
Rank 0 - Epoch 60/150 loss: -1.0691773891448975
Rank 0 - Epoch 70/150 loss: -1.4186537265777588
Rank 0 - Epoch 80/150 loss: -1.7253139019012451
Rank 0 - Epoch 90/150 loss: -1.9731453657150269
Rank 0 - Epoch 100/150 loss: -2.15267276763916
Rank 0 - Epoch 110/150 loss: -2.27156662940979
Rank 0 - Epoch 120/150 loss: -2.3442485332489014
Rank 0 - Epoch 130/150 loss: -2.2539851665496826
Rank 0 - Epoch 140/150 loss: -2.310835361480713
Run 10 failed, retrying...
Running apxGP 1 with agents: 100
decpxADMM initialized with rho: 0.85, lip: 1.0, tol_abs: 1e-05, tol_rel: 0.001, rank: 0, world_size: 100
Rank 0 - Epoch 2/200 loss: 0.7878605723381042
Rank 0 - Epoch 10/200 loss: 0.5186595916748047
Rank 0 - Epoch 20/200 loss: 0.0997394546866417
Rank 0 - Epoch 30/200 loss: -0.3834829330444336
Rank 0 - Epoch 40/200 loss: -0.9032270908355713
Rank 0 - Epoch 50/200 loss: -1.4272571802139282
Rank 0 - Epoch 60/200 loss: -1.938038945198059
Rank 0 - Epoch 70/200 loss: -2.398080348968506
Rank 0 - Epoch 80/200 loss: -2.7669169902801514
Rank 0 - Epoch 90/200 loss: -3.023778200149536
Rank 0 - Epoch 100/200 loss: -3.1813294887542725
Rank 0 - Epoch 110/200 loss: -3.2739100456237793
Rank 0 - Epoch 120/200 loss: -3.330437183380127
Rank 0 - Epoch 130/200 loss: -3.3661980628967285
Rank 0 - Epoch 140/200 loss: -3.3905346393585205
Rank 0 - Epoch 150/200 loss: -3.408421754837036
Rank 0 - Epoch 160/200 loss: -3.4217848777770996
Rank 0 - Epoch 170/200 loss: -3.4318652153015137
Rank 0 - Epoch 180/200 loss: -3.4404220581054688
Rank 0 - Epoch 190/200 loss: -3.447213649749756
Rank 0 - Epoch 200/200 loss: -3.4531426429748535
Training complete.
[92mRank 0 - Testing RMSE: 2.8508[0m
[92mRank: 0, Lengthscale: [[0.59839994 0.36873814]] [0m
[92mRank: 0, Outputscale: 1.4160726070404053 [0m
[92mRank: 0, Noise: 0.00011016153439413756 [0m
Run 1 completed successfully
Running apxGP 2 with agents: 100
decpxADMM initialized with rho: 0.85, lip: 1.0, tol_abs: 1e-05, tol_rel: 0.001, rank: 0, world_size: 100
Rank 0 - Epoch 2/200 loss: 0.7878605723381042
Rank 0 - Epoch 10/200 loss: 0.5186595916748047
Rank 0 - Epoch 20/200 loss: 0.0997394546866417
Rank 0 - Epoch 30/200 loss: -0.3834829330444336
Rank 0 - Epoch 40/200 loss: -0.9032270908355713
Rank 0 - Epoch 50/200 loss: -1.4272571802139282
Rank 0 - Epoch 60/200 loss: -1.938038945198059
Rank 0 - Epoch 70/200 loss: -2.398080348968506
Rank 0 - Epoch 80/200 loss: -2.7669169902801514
Rank 0 - Epoch 90/200 loss: -3.023778200149536
Rank 0 - Epoch 100/200 loss: -3.1813294887542725
Rank 0 - Epoch 110/200 loss: -3.2739100456237793
Rank 0 - Epoch 120/200 loss: -3.330437183380127
Rank 0 - Epoch 130/200 loss: -3.3661980628967285
Rank 0 - Epoch 140/200 loss: -3.3905346393585205
Rank 0 - Epoch 150/200 loss: -3.408421754837036
Rank 0 - Epoch 160/200 loss: -3.4217848777770996
Rank 0 - Epoch 170/200 loss: -3.4318652153015137
Rank 0 - Epoch 180/200 loss: -3.4404220581054688
Rank 0 - Epoch 190/200 loss: -3.447213649749756
Rank 0 - Epoch 200/200 loss: -3.4531426429748535
Training complete.
[92mRank 0 - Testing RMSE: 2.8508[0m
[92mRank: 0, Lengthscale: [[0.59839994 0.36873814]] [0m
[92mRank: 0, Outputscale: 1.4160726070404053 [0m
[92mRank: 0, Noise: 0.00011016153439413756 [0m
Run 2 completed successfully
Running apxGP 3 with agents: 100
decpxADMM initialized with rho: 0.85, lip: 1.0, tol_abs: 1e-05, tol_rel: 0.001, rank: 0, world_size: 100
Rank 0 - Epoch 2/200 loss: 0.7878605723381042
Rank 0 - Epoch 10/200 loss: 0.5186595916748047
Rank 0 - Epoch 20/200 loss: 0.0997394546866417
Rank 0 - Epoch 30/200 loss: -0.3834829330444336
Rank 0 - Epoch 40/200 loss: -0.9032270908355713
Rank 0 - Epoch 50/200 loss: -1.4272571802139282
Rank 0 - Epoch 60/200 loss: -1.938038945198059
Rank 0 - Epoch 70/200 loss: -2.398080348968506
Rank 0 - Epoch 80/200 loss: -2.7669169902801514
Rank 0 - Epoch 90/200 loss: -3.023778200149536
Rank 0 - Epoch 100/200 loss: -3.1813294887542725
Rank 0 - Epoch 110/200 loss: -3.2739100456237793
Rank 0 - Epoch 120/200 loss: -3.330437183380127
Rank 0 - Epoch 130/200 loss: -3.3661980628967285
Rank 0 - Epoch 140/200 loss: -3.3905346393585205
Rank 0 - Epoch 150/200 loss: -3.408421754837036
Rank 0 - Epoch 160/200 loss: -3.4217848777770996
Rank 0 - Epoch 170/200 loss: -3.4318652153015137
Rank 0 - Epoch 180/200 loss: -3.4404220581054688
Rank 0 - Epoch 190/200 loss: -3.447213649749756
Rank 0 - Epoch 200/200 loss: -3.4531426429748535
Training complete.
[92mRank 0 - Testing RMSE: 2.8508[0m
[92mRank: 0, Lengthscale: [[0.59839994 0.36873814]] [0m
[92mRank: 0, Outputscale: 1.4160726070404053 [0m
[92mRank: 0, Noise: 0.00011016153439413756 [0m
Run 3 completed successfully
Running apxGP 4 with agents: 100
decpxADMM initialized with rho: 0.85, lip: 1.0, tol_abs: 1e-05, tol_rel: 0.001, rank: 0, world_size: 100
Rank 0 - Epoch 2/200 loss: 0.7878605723381042
Rank 0 - Epoch 10/200 loss: 0.5186595916748047
Rank 0 - Epoch 20/200 loss: 0.0997394546866417
Rank 0 - Epoch 30/200 loss: -0.3834829330444336
Rank 0 - Epoch 40/200 loss: -0.9032270908355713
Rank 0 - Epoch 50/200 loss: -1.4272571802139282
Rank 0 - Epoch 60/200 loss: -1.938038945198059
Rank 0 - Epoch 70/200 loss: -2.398080348968506
Rank 0 - Epoch 80/200 loss: -2.7669169902801514
Rank 0 - Epoch 90/200 loss: -3.023778200149536
Rank 0 - Epoch 100/200 loss: -3.1813294887542725
Rank 0 - Epoch 110/200 loss: -3.2739100456237793
Rank 0 - Epoch 120/200 loss: -3.330437183380127
Rank 0 - Epoch 130/200 loss: -3.3661980628967285
Rank 0 - Epoch 140/200 loss: -3.3905346393585205
Rank 0 - Epoch 150/200 loss: -3.408421754837036
Rank 0 - Epoch 160/200 loss: -3.4217848777770996
Rank 0 - Epoch 170/200 loss: -3.4318652153015137
Rank 0 - Epoch 180/200 loss: -3.4404220581054688
Rank 0 - Epoch 190/200 loss: -3.447213649749756
Rank 0 - Epoch 200/200 loss: -3.4531426429748535
Training complete.
[92mRank 0 - Testing RMSE: 2.8508[0m
[92mRank: 0, Lengthscale: [[0.59839994 0.36873814]] [0m
[92mRank: 0, Outputscale: 1.4160726070404053 [0m
[92mRank: 0, Noise: 0.00011016153439413756 [0m
Run 4 completed successfully
Running apxGP 5 with agents: 100
decpxADMM initialized with rho: 0.85, lip: 1.0, tol_abs: 1e-05, tol_rel: 0.001, rank: 0, world_size: 100
Rank 0 - Epoch 2/200 loss: 0.7878605723381042
Rank 0 - Epoch 10/200 loss: 0.5186595916748047
Rank 0 - Epoch 20/200 loss: 0.0997394546866417
Rank 0 - Epoch 30/200 loss: -0.3834829330444336
Rank 0 - Epoch 40/200 loss: -0.9032270908355713
Rank 0 - Epoch 50/200 loss: -1.4272571802139282
Rank 0 - Epoch 60/200 loss: -1.938038945198059
Rank 0 - Epoch 70/200 loss: -2.398080348968506
Rank 0 - Epoch 80/200 loss: -2.7669169902801514
Rank 0 - Epoch 90/200 loss: -3.023778200149536
Rank 0 - Epoch 100/200 loss: -3.1813294887542725
Rank 0 - Epoch 110/200 loss: -3.2739100456237793
Rank 0 - Epoch 120/200 loss: -3.330437183380127
Rank 0 - Epoch 130/200 loss: -3.3661980628967285
Rank 0 - Epoch 140/200 loss: -3.3905346393585205
Rank 0 - Epoch 150/200 loss: -3.408421754837036
Rank 0 - Epoch 160/200 loss: -3.4217848777770996
Rank 0 - Epoch 170/200 loss: -3.4318652153015137
Rank 0 - Epoch 180/200 loss: -3.4404220581054688
Rank 0 - Epoch 190/200 loss: -3.447213649749756
Rank 0 - Epoch 200/200 loss: -3.4531426429748535
Training complete.
[92mRank 0 - Testing RMSE: 2.8508[0m
[92mRank: 0, Lengthscale: [[0.59839994 0.36873814]] [0m
[92mRank: 0, Outputscale: 1.4160726070404053 [0m
[92mRank: 0, Noise: 0.00011016153439413756 [0m
Run 5 completed successfully
Running apxGP 6 with agents: 100
decpxADMM initialized with rho: 0.85, lip: 1.0, tol_abs: 1e-05, tol_rel: 0.001, rank: 0, world_size: 100
Rank 0 - Epoch 2/200 loss: 0.7878605723381042
Rank 0 - Epoch 10/200 loss: 0.5186595916748047
Rank 0 - Epoch 20/200 loss: 0.0997394546866417
Rank 0 - Epoch 30/200 loss: -0.3834829330444336
Rank 0 - Epoch 40/200 loss: -0.9032270908355713
Rank 0 - Epoch 50/200 loss: -1.4272571802139282
Rank 0 - Epoch 60/200 loss: -1.938038945198059
Rank 0 - Epoch 70/200 loss: -2.398080348968506
Rank 0 - Epoch 80/200 loss: -2.7669169902801514
Rank 0 - Epoch 90/200 loss: -3.023778200149536
Rank 0 - Epoch 100/200 loss: -3.1813294887542725
Rank 0 - Epoch 110/200 loss: -3.2739100456237793
Rank 0 - Epoch 120/200 loss: -3.330437183380127
Rank 0 - Epoch 130/200 loss: -3.3661980628967285
Rank 0 - Epoch 140/200 loss: -3.3905346393585205
Rank 0 - Epoch 150/200 loss: -3.408421754837036
Rank 0 - Epoch 160/200 loss: -3.4217848777770996
Rank 0 - Epoch 170/200 loss: -3.4318652153015137
Rank 0 - Epoch 180/200 loss: -3.4404220581054688
Rank 0 - Epoch 190/200 loss: -3.447213649749756
Rank 0 - Epoch 200/200 loss: -3.4531426429748535
Training complete.
[92mRank 0 - Testing RMSE: 2.8508[0m
[92mRank: 0, Lengthscale: [[0.59839994 0.36873814]] [0m
[92mRank: 0, Outputscale: 1.4160726070404053 [0m
[92mRank: 0, Noise: 0.00011016153439413756 [0m
Run 6 completed successfully
Running apxGP 7 with agents: 100
decpxADMM initialized with rho: 0.85, lip: 1.0, tol_abs: 1e-05, tol_rel: 0.001, rank: 0, world_size: 100
Rank 0 - Epoch 2/200 loss: 0.7878605723381042
Rank 0 - Epoch 10/200 loss: 0.5186595916748047
Rank 0 - Epoch 20/200 loss: 0.0997394546866417
Rank 0 - Epoch 30/200 loss: -0.3834829330444336
Rank 0 - Epoch 40/200 loss: -0.9032270908355713
Rank 0 - Epoch 50/200 loss: -1.4272571802139282
Rank 0 - Epoch 60/200 loss: -1.938038945198059
Rank 0 - Epoch 70/200 loss: -2.398080348968506
Rank 0 - Epoch 80/200 loss: -2.7669169902801514
Rank 0 - Epoch 90/200 loss: -3.023778200149536
Rank 0 - Epoch 100/200 loss: -3.1813294887542725
Rank 0 - Epoch 110/200 loss: -3.2739100456237793
Rank 0 - Epoch 120/200 loss: -3.330437183380127
Rank 0 - Epoch 130/200 loss: -3.3661980628967285
Rank 0 - Epoch 140/200 loss: -3.3905346393585205
Rank 0 - Epoch 150/200 loss: -3.408421754837036
Rank 0 - Epoch 160/200 loss: -3.4217848777770996
Rank 0 - Epoch 170/200 loss: -3.4318652153015137
Rank 0 - Epoch 180/200 loss: -3.4404220581054688
Rank 0 - Epoch 190/200 loss: -3.447213649749756
Rank 0 - Epoch 200/200 loss: -3.4531426429748535
Training complete.
[92mRank 0 - Testing RMSE: 2.8508[0m
[92mRank: 0, Lengthscale: [[0.59839994 0.36873814]] [0m
[92mRank: 0, Outputscale: 1.4160726070404053 [0m
[92mRank: 0, Noise: 0.00011016153439413756 [0m
Run 7 completed successfully
Running apxGP 8 with agents: 100
decpxADMM initialized with rho: 0.85, lip: 1.0, tol_abs: 1e-05, tol_rel: 0.001, rank: 0, world_size: 100
Rank 0 - Epoch 2/200 loss: 0.7878605723381042
Rank 0 - Epoch 10/200 loss: 0.5186595916748047
Rank 0 - Epoch 20/200 loss: 0.0997394546866417
Rank 0 - Epoch 30/200 loss: -0.3834829330444336
Rank 0 - Epoch 40/200 loss: -0.9032270908355713
Rank 0 - Epoch 50/200 loss: -1.4272571802139282
Rank 0 - Epoch 60/200 loss: -1.938038945198059
Rank 0 - Epoch 70/200 loss: -2.398080348968506
Rank 0 - Epoch 80/200 loss: -2.7669169902801514
Rank 0 - Epoch 90/200 loss: -3.023778200149536
Rank 0 - Epoch 100/200 loss: -3.1813294887542725
Rank 0 - Epoch 110/200 loss: -3.2739100456237793
Rank 0 - Epoch 120/200 loss: -3.330437183380127
Rank 0 - Epoch 130/200 loss: -3.3661980628967285
Rank 0 - Epoch 140/200 loss: -3.3905346393585205
Rank 0 - Epoch 150/200 loss: -3.408421754837036
Rank 0 - Epoch 160/200 loss: -3.4217848777770996
Rank 0 - Epoch 170/200 loss: -3.4318652153015137
Rank 0 - Epoch 180/200 loss: -3.4404220581054688
Rank 0 - Epoch 190/200 loss: -3.447213649749756
Rank 0 - Epoch 200/200 loss: -3.4531426429748535
Training complete.
[92mRank 0 - Testing RMSE: 2.8508[0m
[92mRank: 0, Lengthscale: [[0.59839994 0.36873814]] [0m
[92mRank: 0, Outputscale: 1.4160726070404053 [0m
[92mRank: 0, Noise: 0.00011016153439413756 [0m
Run 8 completed successfully
Running apxGP 9 with agents: 100
decpxADMM initialized with rho: 0.85, lip: 1.0, tol_abs: 1e-05, tol_rel: 0.001, rank: 0, world_size: 100
Rank 0 - Epoch 2/200 loss: 0.7878605723381042
Rank 0 - Epoch 10/200 loss: 0.5186595916748047
Rank 0 - Epoch 20/200 loss: 0.0997394546866417
Rank 0 - Epoch 30/200 loss: -0.3834829330444336
Rank 0 - Epoch 40/200 loss: -0.9032270908355713
Rank 0 - Epoch 50/200 loss: -1.4272571802139282
Rank 0 - Epoch 60/200 loss: -1.938038945198059
Rank 0 - Epoch 70/200 loss: -2.398080348968506
Rank 0 - Epoch 80/200 loss: -2.7669169902801514
Rank 0 - Epoch 90/200 loss: -3.023778200149536
Rank 0 - Epoch 100/200 loss: -3.1813294887542725
Rank 0 - Epoch 110/200 loss: -3.2739100456237793
Rank 0 - Epoch 120/200 loss: -3.330437183380127
Rank 0 - Epoch 130/200 loss: -3.3661980628967285
Rank 0 - Epoch 140/200 loss: -3.3905346393585205
Rank 0 - Epoch 150/200 loss: -3.408421754837036
Rank 0 - Epoch 160/200 loss: -3.4217848777770996
Rank 0 - Epoch 170/200 loss: -3.4318652153015137
Rank 0 - Epoch 180/200 loss: -3.4404220581054688
Rank 0 - Epoch 190/200 loss: -3.447213649749756
Rank 0 - Epoch 200/200 loss: -3.4531426429748535
Training complete.
[92mRank 0 - Testing RMSE: 2.8508[0m
[92mRank: 0, Lengthscale: [[0.59839994 0.36873814]] [0m
[92mRank: 0, Outputscale: 1.4160726070404053 [0m
[92mRank: 0, Noise: 0.00011016153439413756 [0m
Run 9 completed successfully
Running apxGP 10 with agents: 100
decpxADMM initialized with rho: 0.85, lip: 1.0, tol_abs: 1e-05, tol_rel: 0.001, rank: 0, world_size: 100
Rank 0 - Epoch 2/200 loss: 0.7878605723381042
Rank 0 - Epoch 10/200 loss: 0.5186595916748047
Rank 0 - Epoch 20/200 loss: 0.0997394546866417
Rank 0 - Epoch 30/200 loss: -0.3834829330444336
Rank 0 - Epoch 40/200 loss: -0.9032270908355713
Rank 0 - Epoch 50/200 loss: -1.4272571802139282
Rank 0 - Epoch 60/200 loss: -1.938038945198059
Rank 0 - Epoch 70/200 loss: -2.398080348968506
Rank 0 - Epoch 80/200 loss: -2.7669169902801514
Rank 0 - Epoch 90/200 loss: -3.023778200149536
Rank 0 - Epoch 100/200 loss: -3.1813294887542725
Rank 0 - Epoch 110/200 loss: -3.2739100456237793
Rank 0 - Epoch 120/200 loss: -3.330437183380127
Rank 0 - Epoch 130/200 loss: -3.3661980628967285
Rank 0 - Epoch 140/200 loss: -3.3905346393585205
Rank 0 - Epoch 150/200 loss: -3.408421754837036
Rank 0 - Epoch 160/200 loss: -3.4217848777770996
Rank 0 - Epoch 170/200 loss: -3.4318652153015137
Rank 0 - Epoch 180/200 loss: -3.4404220581054688
Rank 0 - Epoch 190/200 loss: -3.447213649749756
Rank 0 - Epoch 200/200 loss: -3.4531426429748535
Training complete.
[92mRank 0 - Testing RMSE: 2.8508[0m
[92mRank: 0, Lengthscale: [[0.59839994 0.36873814]] [0m
[92mRank: 0, Outputscale: 1.4160726070404053 [0m
[92mRank: 0, Noise: 0.00011016153439413756 [0m
Run 10 completed successfully
Running cGP 1 with agents: 100
decADMM initialized with rho: 0.85, max_iter: 5, lr: 0.0001, rank: 0, world_size: 100
Rank 0 - Epoch 2/200 loss: 0.8454271554946899
Rank 0 - Epoch 10/200 loss: 0.8406391143798828
Rank 0 - Epoch 20/200 loss: 0.8346492648124695
Rank 0 - Epoch 30/200 loss: 0.8286553025245667
Rank 0 - Epoch 40/200 loss: 0.8226587772369385
Rank 0 - Epoch 50/200 loss: 0.8166612982749939
Rank 0 - Epoch 60/200 loss: 0.8106645941734314
Rank 0 - Epoch 70/200 loss: 0.8046704530715942
Rank 0 - Epoch 80/200 loss: 0.7986807823181152
Rank 0 - Epoch 90/200 loss: 0.792697548866272
Rank 0 - Epoch 100/200 loss: 0.7867231965065002
Rank 0 - Epoch 110/200 loss: 0.780759871006012
Rank 0 - Epoch 120/200 loss: 0.774810254573822
Rank 0 - Epoch 130/200 loss: 0.7688767313957214
Rank 0 - Epoch 140/200 loss: 0.7629621028900146
Rank 0 - Epoch 150/200 loss: 0.7570695281028748
Rank 0 - Epoch 160/200 loss: 0.7512020468711853
Rank 0 - Epoch 170/200 loss: 0.7453627586364746
Rank 0 - Epoch 180/200 loss: 0.7395554780960083
Rank 0 - Epoch 190/200 loss: 0.7337831854820251
Rank 0 - Epoch 200/200 loss: 0.7280504703521729
Training complete.
[92mRank 0 - Testing RMSE: 3.8112[0m
[92mRank: 0, Lengthscale: [[0.5363081  0.53727096]] [0m
[92mRank: 0, Outputscale: 0.5403498411178589 [0m
[92mRank: 0, Noise: 0.5225920677185059 [0m
Run 1 completed successfully
Running cGP 2 with agents: 100
decADMM initialized with rho: 0.85, max_iter: 5, lr: 0.0001, rank: 0, world_size: 100
Rank 0 - Epoch 2/200 loss: 0.8454271554946899
Rank 0 - Epoch 10/200 loss: 0.8406391143798828
Rank 0 - Epoch 20/200 loss: 0.8346492648124695
Rank 0 - Epoch 30/200 loss: 0.8286553025245667
Rank 0 - Epoch 40/200 loss: 0.8226587772369385
Rank 0 - Epoch 50/200 loss: 0.8166612982749939
Rank 0 - Epoch 60/200 loss: 0.8106645941734314
Rank 0 - Epoch 70/200 loss: 0.8046704530715942
Rank 0 - Epoch 80/200 loss: 0.7986807823181152
Rank 0 - Epoch 90/200 loss: 0.792697548866272
Rank 0 - Epoch 100/200 loss: 0.7867231965065002
Rank 0 - Epoch 110/200 loss: 0.780759871006012
Rank 0 - Epoch 120/200 loss: 0.774810254573822
Rank 0 - Epoch 130/200 loss: 0.7688767313957214
Rank 0 - Epoch 140/200 loss: 0.7629621028900146
Rank 0 - Epoch 150/200 loss: 0.7570695281028748
Rank 0 - Epoch 160/200 loss: 0.7512020468711853
Rank 0 - Epoch 170/200 loss: 0.7453627586364746
Rank 0 - Epoch 180/200 loss: 0.7395554780960083
Rank 0 - Epoch 190/200 loss: 0.7337831854820251
Rank 0 - Epoch 200/200 loss: 0.7280504703521729
Training complete.
[92mRank 0 - Testing RMSE: 3.8112[0m
[92mRank: 0, Lengthscale: [[0.5363081  0.53727096]] [0m
[92mRank: 0, Outputscale: 0.5403498411178589 [0m
[92mRank: 0, Noise: 0.5225920677185059 [0m
Run 2 completed successfully
Running cGP 3 with agents: 100
decADMM initialized with rho: 0.85, max_iter: 5, lr: 0.0001, rank: 0, world_size: 100
Rank 0 - Epoch 2/200 loss: 0.8454271554946899
Rank 0 - Epoch 10/200 loss: 0.8406391143798828
Rank 0 - Epoch 20/200 loss: 0.8346492648124695
Rank 0 - Epoch 30/200 loss: 0.8286553025245667
Rank 0 - Epoch 40/200 loss: 0.8226587772369385
Rank 0 - Epoch 50/200 loss: 0.8166612982749939
Rank 0 - Epoch 60/200 loss: 0.8106645941734314
Rank 0 - Epoch 70/200 loss: 0.8046704530715942
Rank 0 - Epoch 80/200 loss: 0.7986807823181152
Rank 0 - Epoch 90/200 loss: 0.792697548866272
Rank 0 - Epoch 100/200 loss: 0.7867231965065002
Rank 0 - Epoch 110/200 loss: 0.780759871006012
Rank 0 - Epoch 120/200 loss: 0.774810254573822
Rank 0 - Epoch 130/200 loss: 0.7688767313957214
Rank 0 - Epoch 140/200 loss: 0.7629621028900146
Rank 0 - Epoch 150/200 loss: 0.7570695281028748
Rank 0 - Epoch 160/200 loss: 0.7512020468711853
Rank 0 - Epoch 170/200 loss: 0.7453627586364746
Rank 0 - Epoch 180/200 loss: 0.7395554780960083
Rank 0 - Epoch 190/200 loss: 0.7337831854820251
Rank 0 - Epoch 200/200 loss: 0.7280504703521729
Training complete.
[92mRank 0 - Testing RMSE: 3.8112[0m
[92mRank: 0, Lengthscale: [[0.5363081  0.53727096]] [0m
[92mRank: 0, Outputscale: 0.5403498411178589 [0m
[92mRank: 0, Noise: 0.5225920677185059 [0m
Run 3 completed successfully
Running cGP 4 with agents: 100
decADMM initialized with rho: 0.85, max_iter: 5, lr: 0.0001, rank: 0, world_size: 100
Rank 0 - Epoch 2/200 loss: 0.8454271554946899
Rank 0 - Epoch 10/200 loss: 0.8406391143798828
Rank 0 - Epoch 20/200 loss: 0.8346492648124695
Rank 0 - Epoch 30/200 loss: 0.8286553025245667
Rank 0 - Epoch 40/200 loss: 0.8226587772369385
Rank 0 - Epoch 50/200 loss: 0.8166612982749939
Rank 0 - Epoch 60/200 loss: 0.8106645941734314
Rank 0 - Epoch 70/200 loss: 0.8046704530715942
Rank 0 - Epoch 80/200 loss: 0.7986807823181152
Rank 0 - Epoch 90/200 loss: 0.792697548866272
Rank 0 - Epoch 100/200 loss: 0.7867231965065002
Rank 0 - Epoch 110/200 loss: 0.780759871006012
Rank 0 - Epoch 120/200 loss: 0.774810254573822
Rank 0 - Epoch 130/200 loss: 0.7688767313957214
Rank 0 - Epoch 140/200 loss: 0.7629621028900146
Rank 0 - Epoch 150/200 loss: 0.7570695281028748
Rank 0 - Epoch 160/200 loss: 0.7512020468711853
Rank 0 - Epoch 170/200 loss: 0.7453627586364746
Rank 0 - Epoch 180/200 loss: 0.7395554780960083
Rank 0 - Epoch 190/200 loss: 0.7337831854820251
Rank 0 - Epoch 200/200 loss: 0.7280504703521729
Training complete.
[92mRank 0 - Testing RMSE: 3.8112[0m
[92mRank: 0, Lengthscale: [[0.5363081  0.53727096]] [0m
[92mRank: 0, Outputscale: 0.5403498411178589 [0m
[92mRank: 0, Noise: 0.5225920677185059 [0m
Run 4 completed successfully
Running cGP 5 with agents: 100
decADMM initialized with rho: 0.85, max_iter: 5, lr: 0.0001, rank: 0, world_size: 100
Rank 0 - Epoch 2/200 loss: 0.8454271554946899
Rank 0 - Epoch 10/200 loss: 0.8406391143798828
Rank 0 - Epoch 20/200 loss: 0.8346492648124695
Rank 0 - Epoch 30/200 loss: 0.8286553025245667
Rank 0 - Epoch 40/200 loss: 0.8226587772369385
Rank 0 - Epoch 50/200 loss: 0.8166612982749939
Rank 0 - Epoch 60/200 loss: 0.8106645941734314
Rank 0 - Epoch 70/200 loss: 0.8046704530715942
Rank 0 - Epoch 80/200 loss: 0.7986807823181152
Rank 0 - Epoch 90/200 loss: 0.792697548866272
Rank 0 - Epoch 100/200 loss: 0.7867231965065002
Rank 0 - Epoch 110/200 loss: 0.780759871006012
Rank 0 - Epoch 120/200 loss: 0.774810254573822
Rank 0 - Epoch 130/200 loss: 0.7688767313957214
Rank 0 - Epoch 140/200 loss: 0.7629621028900146
Rank 0 - Epoch 150/200 loss: 0.7570695281028748
Rank 0 - Epoch 160/200 loss: 0.7512020468711853
Rank 0 - Epoch 170/200 loss: 0.7453627586364746
Rank 0 - Epoch 180/200 loss: 0.7395554780960083
Rank 0 - Epoch 190/200 loss: 0.7337831854820251
Rank 0 - Epoch 200/200 loss: 0.7280504703521729
Training complete.
[92mRank 0 - Testing RMSE: 3.8112[0m
[92mRank: 0, Lengthscale: [[0.5363081  0.53727096]] [0m
[92mRank: 0, Outputscale: 0.5403498411178589 [0m
[92mRank: 0, Noise: 0.5225920677185059 [0m
Run 5 completed successfully
Running cGP 6 with agents: 100
decADMM initialized with rho: 0.85, max_iter: 5, lr: 0.0001, rank: 0, world_size: 100
Rank 0 - Epoch 2/200 loss: 0.8454271554946899
Rank 0 - Epoch 10/200 loss: 0.8406391143798828
Rank 0 - Epoch 20/200 loss: 0.8346492648124695
Rank 0 - Epoch 30/200 loss: 0.8286553025245667
Rank 0 - Epoch 40/200 loss: 0.8226587772369385
Rank 0 - Epoch 50/200 loss: 0.8166612982749939
Rank 0 - Epoch 60/200 loss: 0.8106645941734314
Rank 0 - Epoch 70/200 loss: 0.8046704530715942
Rank 0 - Epoch 80/200 loss: 0.7986807823181152
Rank 0 - Epoch 90/200 loss: 0.792697548866272
Rank 0 - Epoch 100/200 loss: 0.7867231965065002
Rank 0 - Epoch 110/200 loss: 0.780759871006012
Rank 0 - Epoch 120/200 loss: 0.774810254573822
Rank 0 - Epoch 130/200 loss: 0.7688767313957214
Rank 0 - Epoch 140/200 loss: 0.7629621028900146
Rank 0 - Epoch 150/200 loss: 0.7570695281028748
Rank 0 - Epoch 160/200 loss: 0.7512020468711853
Rank 0 - Epoch 170/200 loss: 0.7453627586364746
Rank 0 - Epoch 180/200 loss: 0.7395554780960083
Rank 0 - Epoch 190/200 loss: 0.7337831854820251
Rank 0 - Epoch 200/200 loss: 0.7280504703521729
Training complete.
[92mRank 0 - Testing RMSE: 3.8112[0m
[92mRank: 0, Lengthscale: [[0.5363081  0.53727096]] [0m
[92mRank: 0, Outputscale: 0.5403498411178589 [0m
[92mRank: 0, Noise: 0.5225920677185059 [0m
Run 6 completed successfully
Running cGP 7 with agents: 100
decADMM initialized with rho: 0.85, max_iter: 5, lr: 0.0001, rank: 0, world_size: 100
Rank 0 - Epoch 2/200 loss: 0.8454271554946899
Rank 0 - Epoch 10/200 loss: 0.8406391143798828
Rank 0 - Epoch 20/200 loss: 0.8346492648124695
Rank 0 - Epoch 30/200 loss: 0.8286553025245667
Rank 0 - Epoch 40/200 loss: 0.8226587772369385
Rank 0 - Epoch 50/200 loss: 0.8166612982749939
Rank 0 - Epoch 60/200 loss: 0.8106645941734314
Rank 0 - Epoch 70/200 loss: 0.8046704530715942
Rank 0 - Epoch 80/200 loss: 0.7986807823181152
Rank 0 - Epoch 90/200 loss: 0.792697548866272
Rank 0 - Epoch 100/200 loss: 0.7867231965065002
Rank 0 - Epoch 110/200 loss: 0.780759871006012
Rank 0 - Epoch 120/200 loss: 0.774810254573822
Rank 0 - Epoch 130/200 loss: 0.7688767313957214
Rank 0 - Epoch 140/200 loss: 0.7629621028900146
Rank 0 - Epoch 150/200 loss: 0.7570695281028748
Rank 0 - Epoch 160/200 loss: 0.7512020468711853
Rank 0 - Epoch 170/200 loss: 0.7453627586364746
Rank 0 - Epoch 180/200 loss: 0.7395554780960083
Rank 0 - Epoch 190/200 loss: 0.7337831854820251
Rank 0 - Epoch 200/200 loss: 0.7280504703521729
Training complete.
[92mRank 0 - Testing RMSE: 3.8112[0m
[92mRank: 0, Lengthscale: [[0.5363081  0.53727096]] [0m
[92mRank: 0, Outputscale: 0.5403498411178589 [0m
[92mRank: 0, Noise: 0.5225920677185059 [0m
Run 7 completed successfully
Running cGP 8 with agents: 100
decADMM initialized with rho: 0.85, max_iter: 5, lr: 0.0001, rank: 0, world_size: 100
Rank 0 - Epoch 2/200 loss: 0.8454271554946899
Rank 0 - Epoch 10/200 loss: 0.8406391143798828
Rank 0 - Epoch 20/200 loss: 0.8346492648124695
Rank 0 - Epoch 30/200 loss: 0.8286553025245667
Rank 0 - Epoch 40/200 loss: 0.8226587772369385
Rank 0 - Epoch 50/200 loss: 0.8166612982749939
Rank 0 - Epoch 60/200 loss: 0.8106645941734314
Rank 0 - Epoch 70/200 loss: 0.8046704530715942
Rank 0 - Epoch 80/200 loss: 0.7986807823181152
Rank 0 - Epoch 90/200 loss: 0.792697548866272
Rank 0 - Epoch 100/200 loss: 0.7867231965065002
Rank 0 - Epoch 110/200 loss: 0.780759871006012
Rank 0 - Epoch 120/200 loss: 0.774810254573822
Rank 0 - Epoch 130/200 loss: 0.7688767313957214
Rank 0 - Epoch 140/200 loss: 0.7629621028900146
Rank 0 - Epoch 150/200 loss: 0.7570695281028748
Rank 0 - Epoch 160/200 loss: 0.7512020468711853
Rank 0 - Epoch 170/200 loss: 0.7453627586364746
Rank 0 - Epoch 180/200 loss: 0.7395554780960083
Rank 0 - Epoch 190/200 loss: 0.7337831854820251
Rank 0 - Epoch 200/200 loss: 0.7280504703521729
Training complete.
[92mRank 0 - Testing RMSE: 3.8112[0m
[92mRank: 0, Lengthscale: [[0.5363081  0.53727096]] [0m
[92mRank: 0, Outputscale: 0.5403498411178589 [0m
[92mRank: 0, Noise: 0.5225920677185059 [0m
Run 8 completed successfully
Running cGP 9 with agents: 100
decADMM initialized with rho: 0.85, max_iter: 5, lr: 0.0001, rank: 0, world_size: 100
Rank 0 - Epoch 2/200 loss: 0.8454271554946899
Rank 0 - Epoch 10/200 loss: 0.8406391143798828
Rank 0 - Epoch 20/200 loss: 0.8346492648124695
Rank 0 - Epoch 30/200 loss: 0.8286553025245667
Rank 0 - Epoch 40/200 loss: 0.8226587772369385
Rank 0 - Epoch 50/200 loss: 0.8166612982749939
Rank 0 - Epoch 60/200 loss: 0.8106645941734314
Rank 0 - Epoch 70/200 loss: 0.8046704530715942
Rank 0 - Epoch 80/200 loss: 0.7986807823181152
Rank 0 - Epoch 90/200 loss: 0.792697548866272
Rank 0 - Epoch 100/200 loss: 0.7867231965065002
Rank 0 - Epoch 110/200 loss: 0.780759871006012
Rank 0 - Epoch 120/200 loss: 0.774810254573822
Rank 0 - Epoch 130/200 loss: 0.7688767313957214
Rank 0 - Epoch 140/200 loss: 0.7629621028900146
Rank 0 - Epoch 150/200 loss: 0.7570695281028748
Rank 0 - Epoch 160/200 loss: 0.7512020468711853
Rank 0 - Epoch 170/200 loss: 0.7453627586364746
Rank 0 - Epoch 180/200 loss: 0.7395554780960083
Rank 0 - Epoch 190/200 loss: 0.7337831854820251
Rank 0 - Epoch 200/200 loss: 0.7280504703521729
Training complete.
[92mRank 0 - Testing RMSE: 3.8112[0m
[92mRank: 0, Lengthscale: [[0.5363081  0.53727096]] [0m
[92mRank: 0, Outputscale: 0.5403498411178589 [0m
[92mRank: 0, Noise: 0.5225920677185059 [0m
Run 9 completed successfully
Running cGP 10 with agents: 100
decADMM initialized with rho: 0.85, max_iter: 5, lr: 0.0001, rank: 0, world_size: 100
Rank 0 - Epoch 2/200 loss: 0.8454271554946899
Rank 0 - Epoch 10/200 loss: 0.8406391143798828
Rank 0 - Epoch 20/200 loss: 0.8346492648124695
Rank 0 - Epoch 30/200 loss: 0.8286553025245667
Rank 0 - Epoch 40/200 loss: 0.8226587772369385
Rank 0 - Epoch 50/200 loss: 0.8166612982749939
Rank 0 - Epoch 60/200 loss: 0.8106645941734314
Rank 0 - Epoch 70/200 loss: 0.8046704530715942
Rank 0 - Epoch 80/200 loss: 0.7986807823181152
Rank 0 - Epoch 90/200 loss: 0.792697548866272
Rank 0 - Epoch 100/200 loss: 0.7867231965065002
Rank 0 - Epoch 110/200 loss: 0.780759871006012
Rank 0 - Epoch 120/200 loss: 0.774810254573822
Rank 0 - Epoch 130/200 loss: 0.7688767313957214
Rank 0 - Epoch 140/200 loss: 0.7629621028900146
Rank 0 - Epoch 150/200 loss: 0.7570695281028748
Rank 0 - Epoch 160/200 loss: 0.7512020468711853
Rank 0 - Epoch 170/200 loss: 0.7453627586364746
Rank 0 - Epoch 180/200 loss: 0.7395554780960083
Rank 0 - Epoch 190/200 loss: 0.7337831854820251
Rank 0 - Epoch 200/200 loss: 0.7280504703521729
Training complete.
[92mRank 0 - Testing RMSE: 3.8112[0m
[92mRank: 0, Lengthscale: [[0.5363081  0.53727096]] [0m
[92mRank: 0, Outputscale: 0.5403498411178589 [0m
[92mRank: 0, Noise: 0.5225920677185059 [0m
Run 10 completed successfully
Running pxpGP 1 with agents: 121
[92mRank 0 - sparse dataset size is: 3, local dataset: torch.Size([289, 2]), [0m
[92mRank 0 - Training local sparse GP model with 289 samples[0m
Epoch 1/200 - Loss: 14.776
Epoch 11/200 - Loss: 1.080
Epoch 21/200 - Loss: 1.010
Epoch 31/200 - Loss: 0.933
Epoch 41/200 - Loss: 0.829
Epoch 51/200 - Loss: 0.713
Epoch 61/200 - Loss: 0.558
Epoch 71/200 - Loss: 0.356
Epoch 81/200 - Loss: 0.136
Converged at epoch 89 with loss -0.017
[92mRank 0 - Lengthscale: [[0.6122187 0.6704433]] [0m
[92mRank 0 - Outputscale: 2.421926498413086 [0m
[92mRank 0 - Noise: 0.11833034455776215 [0m
Rank 0 - Augmented dataset size: 652
Rank 0: After warm start model parameters:
Rank: 0, Lengthscale: [[0.6122187 0.6704433]]
Rank: 0, Outputscale: 2.421926498413086
Rank: 0, Noise: 0.11833034455776215
decpxADMM initialized with rho: 0.85, lip: 1.0, tol_abs: 1e-05, tol_rel: 0.001, rank: 0, world_size: 121
[92mRank 0 - Training global model with dec-pxADMM optimizer[0m
rank 0, epoch 9, loss: 0.9877732992172241, rho: 0.4250, lip: 1.0000
rank 0, epoch 19, loss: 0.9818216562271118, rho: 0.2125, lip: 1.0000
rank 0, epoch 29, loss: 0.931316077709198, rho: 0.1062, lip: 1.0000
rank 0, epoch 39, loss: 0.8516360521316528, rho: 0.1062, lip: 1.0000
rank 0, epoch 49, loss: 0.847082793712616, rho: 0.0531, lip: 1.0000
rank 0, epoch 59, loss: 0.8428139686584473, rho: 0.0531, lip: 1.0000
rank 0, epoch 69, loss: 0.8386138677597046, rho: 0.0531, lip: 1.0000
rank 0, epoch 79, loss: 0.8371875882148743, rho: 0.0531, lip: 1.0000
rank 0, epoch 89, loss: 0.8374356627464294, rho: 0.0531, lip: 1.0000
rank 0, epoch 99, loss: 0.8375772833824158, rho: 0.0531, lip: 1.0000
rank 0, epoch 109, loss: 0.8365635871887207, rho: 0.0133, lip: 1.0000
rank 0, epoch 119, loss: 0.8356652855873108, rho: 0.0066, lip: 1.0000
rank 0, epoch 129, loss: 0.8350412845611572, rho: 0.0066, lip: 1.0000
rank 0, epoch 139, loss: 0.8346104621887207, rho: 0.0066, lip: 1.0000
rank 0, epoch 149, loss: 0.8343546390533447, rho: 0.0066, lip: 1.0000
rank 0, epoch 159, loss: 0.8341601490974426, rho: 0.0066, lip: 1.0000
rank 0, epoch 169, loss: 0.8338920474052429, rho: 0.0066, lip: 1.0000
rank 0, epoch 179, loss: 0.8335681557655334, rho: 0.0066, lip: 1.0000
Rank 0 - Training time: 167.46 seconds
[92mRank 0 - Testing RMSE: 0.3225[0m
[92mRank: 0, Lengthscale: [[0.71812034 0.50134075]] [0m
[92mRank: 0, Outputscale: 2.5946688652038574 [0m
[92mRank: 0, Noise: 0.2225060909986496 [0m
Run 1 completed successfully
Running pxpGP 2 with agents: 121
[92mRank 0 - sparse dataset size is: 3, local dataset: torch.Size([289, 2]), [0m
[92mRank 0 - Training local sparse GP model with 289 samples[0m
Epoch 1/200 - Loss: 14.072
Epoch 11/200 - Loss: 1.091
Epoch 21/200 - Loss: 1.013
Epoch 31/200 - Loss: 0.935
Epoch 41/200 - Loss: 0.837
Epoch 51/200 - Loss: 0.708
Epoch 61/200 - Loss: 0.569
Epoch 71/200 - Loss: 0.388
Epoch 81/200 - Loss: 0.154
Converged at epoch 88 with loss -0.020
[92mRank 0 - Lengthscale: [[0.6155756 0.6725444]] [0m
[92mRank 0 - Outputscale: 2.441305160522461 [0m
[92mRank 0 - Noise: 0.1253209114074707 [0m
Rank 0 - Augmented dataset size: 652
Rank 0: After warm start model parameters:
Rank: 0, Lengthscale: [[0.61557555 0.6725444 ]]
Rank: 0, Outputscale: 2.441305160522461
Rank: 0, Noise: 0.1253209412097931
decpxADMM initialized with rho: 0.85, lip: 1.0, tol_abs: 1e-05, tol_rel: 0.001, rank: 0, world_size: 121
[92mRank 0 - Training global model with dec-pxADMM optimizer[0m
rank 0, epoch 9, loss: 0.9374886751174927, rho: 0.4250, lip: 1.0000
rank 0, epoch 19, loss: 0.8716138601303101, rho: 0.2125, lip: 1.0000
rank 0, epoch 29, loss: 0.8359250426292419, rho: 0.1062, lip: 1.0000
rank 0, epoch 39, loss: 0.783746063709259, rho: 0.1062, lip: 1.0000
rank 0, epoch 49, loss: 0.788868248462677, rho: 0.0531, lip: 1.0000
rank 0, epoch 59, loss: 0.7835351824760437, rho: 0.0531, lip: 1.0000
rank 0, epoch 69, loss: 0.7762160301208496, rho: 0.0531, lip: 1.0000
rank 0, epoch 79, loss: 0.7719062566757202, rho: 0.0531, lip: 1.0000
rank 0, epoch 89, loss: 0.770124077796936, rho: 0.0531, lip: 1.0000
rank 0, epoch 99, loss: 0.7696232795715332, rho: 0.0531, lip: 1.0000
rank 0, epoch 109, loss: 0.7695488333702087, rho: 0.0531, lip: 1.0000
rank 0, epoch 119, loss: 0.7702679634094238, rho: 0.0531, lip: 1.0000
rank 0, epoch 129, loss: 0.7718865275382996, rho: 0.0266, lip: 1.0000
rank 0, epoch 139, loss: 0.7743264436721802, rho: 0.0266, lip: 1.0000
rank 0, epoch 149, loss: 0.7774006128311157, rho: 0.0133, lip: 1.0000
rank 0, epoch 159, loss: 0.7802494764328003, rho: 0.0133, lip: 1.0000
rank 0, epoch 169, loss: 0.7822296619415283, rho: 0.0133, lip: 1.0000
rank 0, epoch 179, loss: 0.7829756736755371, rho: 0.0133, lip: 1.0000
Rank 0 - Training time: 303.62 seconds
[92mRank 0 - Testing RMSE: 0.2903[0m
[92mRank: 0, Lengthscale: [[0.49553406 0.3467002 ]] [0m
[92mRank: 0, Outputscale: 0.9423063397407532 [0m
[92mRank: 0, Noise: 0.25284111499786377 [0m
Run 2 completed successfully
Running pxpGP 3 with agents: 121
[92mRank 0 - sparse dataset size is: 3, local dataset: torch.Size([289, 2]), [0m
[92mRank 0 - Training local sparse GP model with 289 samples[0m
Epoch 1/200 - Loss: 12.864
Epoch 11/200 - Loss: 1.103
Epoch 21/200 - Loss: 1.018
Epoch 31/200 - Loss: 0.928
Epoch 41/200 - Loss: 0.829
Epoch 51/200 - Loss: 0.708
Epoch 61/200 - Loss: 0.532
Epoch 71/200 - Loss: 0.350
Epoch 81/200 - Loss: 0.137
Converged at epoch 90 with loss -0.032
[92mRank 0 - Lengthscale: [[0.6233325  0.65672493]] [0m
[92mRank 0 - Outputscale: 2.423886775970459 [0m
[92mRank 0 - Noise: 0.11256461590528488 [0m
Rank 0 - Augmented dataset size: 652
Rank 0: After warm start model parameters:
Rank: 0, Lengthscale: [[0.6233325  0.65672493]]
Rank: 0, Outputscale: 2.423886775970459
Rank: 0, Noise: 0.11256461590528488
decpxADMM initialized with rho: 0.85, lip: 1.0, tol_abs: 1e-05, tol_rel: 0.001, rank: 0, world_size: 121
[92mRank 0 - Training global model with dec-pxADMM optimizer[0m
rank 0, epoch 9, loss: 0.9601354598999023, rho: 0.4250, lip: 1.0000
rank 0, epoch 19, loss: 0.9401866793632507, rho: 0.2125, lip: 1.0000
rank 0, epoch 29, loss: 0.8416211009025574, rho: 0.1062, lip: 1.0000
rank 0, epoch 39, loss: 0.7865163683891296, rho: 0.1062, lip: 1.0000
rank 0, epoch 49, loss: 0.7902459502220154, rho: 0.0266, lip: 1.0000
rank 0, epoch 59, loss: 0.7913462519645691, rho: 0.0266, lip: 1.0000
rank 0, epoch 69, loss: 0.7903408408164978, rho: 0.0266, lip: 1.0000
rank 0, epoch 79, loss: 0.7884469032287598, rho: 0.0266, lip: 1.0000
rank 0, epoch 89, loss: 0.7875090837478638, rho: 0.0266, lip: 1.0000
rank 0, epoch 99, loss: 0.7875319123268127, rho: 0.0266, lip: 1.0000
rank 0, epoch 109, loss: 0.7875718474388123, rho: 0.0266, lip: 1.0000
rank 0, epoch 119, loss: 0.7870842814445496, rho: 0.0133, lip: 1.0000
rank 0, epoch 129, loss: 0.7864269614219666, rho: 0.0066, lip: 1.0000
rank 0, epoch 139, loss: 0.7857704162597656, rho: 0.0066, lip: 1.0000
rank 0, epoch 149, loss: 0.7851858735084534, rho: 0.0066, lip: 1.0000
rank 0, epoch 159, loss: 0.784818708896637, rho: 0.0066, lip: 1.0000
rank 0, epoch 169, loss: 0.7846702337265015, rho: 0.0066, lip: 1.0000
rank 0, epoch 179, loss: 0.7846391797065735, rho: 0.0066, lip: 1.0000
Rank 0 - Training time: 239.45 seconds
[92mRank 0 - Testing RMSE: 0.3054[0m
[92mRank: 0, Lengthscale: [[0.6008783  0.48165658]] [0m
[92mRank: 0, Outputscale: 1.889434576034546 [0m
[92mRank: 0, Noise: 0.20659132301807404 [0m
Run 3 completed successfully
Running pxpGP 4 with agents: 121
[92mRank 0 - sparse dataset size is: 3, local dataset: torch.Size([289, 2]), [0m
[92mRank 0 - Training local sparse GP model with 289 samples[0m
Epoch 1/200 - Loss: 12.508
Epoch 11/200 - Loss: 1.144
Epoch 21/200 - Loss: 1.012
Epoch 31/200 - Loss: 0.929
Epoch 41/200 - Loss: 0.824
Epoch 51/200 - Loss: 0.699
Epoch 61/200 - Loss: 0.530
Epoch 71/200 - Loss: 0.348
Epoch 81/200 - Loss: 0.135
Converged at epoch 87 with loss -0.000
[92mRank 0 - Lengthscale: [[0.6137508  0.57838386]] [0m
[92mRank 0 - Outputscale: 2.437847137451172 [0m
[92mRank 0 - Noise: 0.12762649357318878 [0m
Rank 0 - Augmented dataset size: 652
Rank 0: After warm start model parameters:
Rank: 0, Lengthscale: [[0.6137508  0.57838386]]
Rank: 0, Outputscale: 2.437847137451172
Rank: 0, Noise: 0.12762649357318878
decpxADMM initialized with rho: 0.85, lip: 1.0, tol_abs: 1e-05, tol_rel: 0.001, rank: 0, world_size: 121
[92mRank 0 - Training global model with dec-pxADMM optimizer[0m
rank 0, epoch 9, loss: 1.0086677074432373, rho: 0.4250, lip: 1.0000
rank 0, epoch 19, loss: 0.9897229075431824, rho: 0.2125, lip: 1.0000
rank 0, epoch 29, loss: 0.9040321111679077, rho: 0.2125, lip: 1.0000
rank 0, epoch 39, loss: 0.8550119996070862, rho: 0.1062, lip: 1.0000
rank 0, epoch 49, loss: 0.8517603874206543, rho: 0.0266, lip: 1.0000
rank 0, epoch 59, loss: 0.84788578748703, rho: 0.0266, lip: 1.0000
rank 0, epoch 69, loss: 0.8445470333099365, rho: 0.0266, lip: 1.0000
rank 0, epoch 79, loss: 0.8430843949317932, rho: 0.0266, lip: 1.0000
rank 0, epoch 89, loss: 0.8434920907020569, rho: 0.0266, lip: 1.0000
rank 0, epoch 99, loss: 0.843650758266449, rho: 0.0266, lip: 1.0000
rank 0, epoch 109, loss: 0.8421540856361389, rho: 0.0266, lip: 1.0000
rank 0, epoch 119, loss: 0.8399834036827087, rho: 0.0266, lip: 1.0000
rank 0, epoch 129, loss: 0.8386574983596802, rho: 0.0266, lip: 1.0000
rank 0, epoch 139, loss: 0.838028609752655, rho: 0.0266, lip: 1.0000
rank 0, epoch 149, loss: 0.8377364277839661, rho: 0.0133, lip: 1.0000
rank 0, epoch 159, loss: 0.8376137018203735, rho: 0.0133, lip: 1.0000
rank 0, epoch 169, loss: 0.8376415371894836, rho: 0.0066, lip: 1.0000
rank 0, epoch 179, loss: 0.837783932685852, rho: 0.0066, lip: 1.0000
Rank 0 - Training time: 216.42 seconds
[92mRank 0 - Testing RMSE: 0.3267[0m
[92mRank: 0, Lengthscale: [[0.60642    0.46091104]] [0m
[92mRank: 0, Outputscale: 1.5004826784133911 [0m
[92mRank: 0, Noise: 0.22332477569580078 [0m
Run 4 completed successfully
Running pxpGP 5 with agents: 121
[92mRank 0 - sparse dataset size is: 3, local dataset: torch.Size([289, 2]), [0m
[92mRank 0 - Training local sparse GP model with 289 samples[0m
Epoch 1/200 - Loss: 13.652
Epoch 11/200 - Loss: 1.096
Epoch 21/200 - Loss: 1.006
Epoch 31/200 - Loss: 0.936
Epoch 41/200 - Loss: 0.827
Epoch 51/200 - Loss: 0.697
Epoch 61/200 - Loss: 0.534
Epoch 71/200 - Loss: 0.343
Epoch 81/200 - Loss: 0.126
Converged at epoch 90 with loss -0.059
[92mRank 0 - Lengthscale: [[0.63304305 0.57801867]] [0m
[92mRank 0 - Outputscale: 2.4426093101501465 [0m
[92mRank 0 - Noise: 0.11176490038633347 [0m
Rank 0 - Augmented dataset size: 652
Rank 0: After warm start model parameters:
Rank: 0, Lengthscale: [[0.63304305 0.57801867]]
Rank: 0, Outputscale: 2.4426093101501465
Rank: 0, Noise: 0.11176492273807526
decpxADMM initialized with rho: 0.85, lip: 1.0, tol_abs: 1e-05, tol_rel: 0.001, rank: 0, world_size: 121
[92mRank 0 - Training global model with dec-pxADMM optimizer[0m
rank 0, epoch 9, loss: 0.9666182398796082, rho: 0.4250, lip: 1.0000
rank 0, epoch 19, loss: 0.9248396754264832, rho: 0.2125, lip: 1.0000
rank 0, epoch 29, loss: 0.8762524127960205, rho: 0.1062, lip: 1.0000
rank 0, epoch 39, loss: 0.8090900778770447, rho: 0.1062, lip: 1.0000
rank 0, epoch 49, loss: 0.8024654984474182, rho: 0.0266, lip: 1.0000
rank 0, epoch 59, loss: 0.7981434464454651, rho: 0.0266, lip: 1.0000
rank 0, epoch 69, loss: 0.7952103614807129, rho: 0.0266, lip: 1.0000
rank 0, epoch 79, loss: 0.7945983409881592, rho: 0.0266, lip: 1.0000
rank 0, epoch 89, loss: 0.7953474521636963, rho: 0.0266, lip: 1.0000
rank 0, epoch 99, loss: 0.7960799336433411, rho: 0.0266, lip: 1.0000
rank 0, epoch 109, loss: 0.7951822876930237, rho: 0.0266, lip: 1.0000
rank 0, epoch 119, loss: 0.7929130792617798, rho: 0.0133, lip: 1.0000
rank 0, epoch 129, loss: 0.7909616827964783, rho: 0.0133, lip: 1.0000
rank 0, epoch 139, loss: 0.7896376252174377, rho: 0.0133, lip: 1.0000
rank 0, epoch 149, loss: 0.7888028025627136, rho: 0.0133, lip: 1.0000
rank 0, epoch 159, loss: 0.7881666421890259, rho: 0.0133, lip: 1.0000
[rank 21] barrier timed out after 5s, continuing anyway
Run 5 failed, retrying...
Running pxpGP 6 with agents: 121
[92mRank 0 - sparse dataset size is: 3, local dataset: torch.Size([289, 2]), [0m
[92mRank 0 - Training local sparse GP model with 289 samples[0m
Epoch 1/200 - Loss: 11.638
Epoch 11/200 - Loss: 1.084
Epoch 21/200 - Loss: 1.010
Epoch 31/200 - Loss: 0.930
Epoch 41/200 - Loss: 0.821
Epoch 51/200 - Loss: 0.687
Epoch 61/200 - Loss: 0.536
Epoch 71/200 - Loss: 0.363
Epoch 81/200 - Loss: 0.173
Converged at epoch 87 with loss -0.018
[92mRank 0 - Lengthscale: [[0.6093115  0.57625276]] [0m
[92mRank 0 - Outputscale: 2.426584243774414 [0m
[92mRank 0 - Noise: 0.12743234634399414 [0m
Rank 0 - Augmented dataset size: 652
Rank 0: After warm start model parameters:
Rank: 0, Lengthscale: [[0.6093115  0.57625276]]
Rank: 0, Outputscale: 2.426584243774414
Rank: 0, Noise: 0.12743233144283295
decpxADMM initialized with rho: 0.85, lip: 1.0, tol_abs: 1e-05, tol_rel: 0.001, rank: 0, world_size: 121
[92mRank 0 - Training global model with dec-pxADMM optimizer[0m
rank 0, epoch 9, loss: 0.9478926658630371, rho: 0.4250, lip: 1.0000
rank 0, epoch 19, loss: 0.9162876605987549, rho: 0.2125, lip: 1.0000
rank 0, epoch 29, loss: 0.817954957485199, rho: 0.2125, lip: 1.0000
rank 0, epoch 39, loss: 0.7791447043418884, rho: 0.1062, lip: 1.0000
rank 0, epoch 49, loss: 0.7717107534408569, rho: 0.0266, lip: 1.0000
rank 0, epoch 59, loss: 0.7693113684654236, rho: 0.0266, lip: 1.0000
rank 0, epoch 69, loss: 0.7677690982818604, rho: 0.0266, lip: 1.0000
rank 0, epoch 79, loss: 0.7672412991523743, rho: 0.0266, lip: 1.0000
rank 0, epoch 89, loss: 0.7671203017234802, rho: 0.0266, lip: 1.0000
rank 0, epoch 99, loss: 0.7671409249305725, rho: 0.0266, lip: 1.0000
rank 0, epoch 109, loss: 0.7672024369239807, rho: 0.0266, lip: 1.0000
rank 0, epoch 119, loss: 0.7668839693069458, rho: 0.0266, lip: 1.0000
rank 0, epoch 129, loss: 0.7663822174072266, rho: 0.0133, lip: 1.0000
rank 0, epoch 139, loss: 0.7661209106445312, rho: 0.0133, lip: 1.0000
rank 0, epoch 149, loss: 0.7660852074623108, rho: 0.0133, lip: 1.0000
rank 0, epoch 159, loss: 0.7660569548606873, rho: 0.0133, lip: 1.0000
rank 0, epoch 169, loss: 0.7659462094306946, rho: 0.0133, lip: 1.0000
rank 0, epoch 179, loss: 0.7657452821731567, rho: 0.0133, lip: 1.0000
Rank 0 - Training time: 251.80 seconds
[92mRank 0 - Testing RMSE: 0.2862[0m
[92mRank: 0, Lengthscale: [[0.78439665 0.39623186]] [0m
[92mRank: 0, Outputscale: 2.513800859451294 [0m
[92mRank: 0, Noise: 0.19726426899433136 [0m
Run 6 completed successfully
Running pxpGP 7 with agents: 121
[92mRank 0 - sparse dataset size is: 3, local dataset: torch.Size([289, 2]), [0m
[92mRank 0 - Training local sparse GP model with 289 samples[0m
Epoch 1/200 - Loss: 13.502
Epoch 11/200 - Loss: 1.081
Epoch 21/200 - Loss: 1.015
Epoch 31/200 - Loss: 0.925
Epoch 41/200 - Loss: 0.824
Epoch 51/200 - Loss: 0.698
Epoch 61/200 - Loss: 0.546
Epoch 71/200 - Loss: 0.355
Epoch 81/200 - Loss: 0.122
Converged at epoch 90 with loss -0.045
[92mRank 0 - Lengthscale: [[0.6222085 0.6166374]] [0m
[92mRank 0 - Outputscale: 2.4392833709716797 [0m
[92mRank 0 - Noise: 0.11182397603988647 [0m
Rank 0 - Augmented dataset size: 652
Rank 0: After warm start model parameters:
Rank: 0, Lengthscale: [[0.6222085  0.61663747]]
Rank: 0, Outputscale: 2.4392833709716797
Rank: 0, Noise: 0.11182396113872528
decpxADMM initialized with rho: 0.85, lip: 1.0, tol_abs: 1e-05, tol_rel: 0.001, rank: 0, world_size: 121
[92mRank 0 - Training global model with dec-pxADMM optimizer[0m
rank 0, epoch 9, loss: 0.880713701248169, rho: 0.4250, lip: 1.0000
rank 0, epoch 19, loss: 0.7917821407318115, rho: 0.2125, lip: 1.0000
rank 0, epoch 29, loss: 0.7805545330047607, rho: 0.1062, lip: 1.0000
rank 0, epoch 39, loss: 0.7736911177635193, rho: 0.0531, lip: 1.0000
rank 0, epoch 49, loss: 0.762964129447937, rho: 0.0266, lip: 1.0000
rank 0, epoch 59, loss: 0.7540509700775146, rho: 0.0266, lip: 1.0000
rank 0, epoch 69, loss: 0.7502817511558533, rho: 0.0266, lip: 1.0000
Run 7 failed, retrying...
Running pxpGP 8 with agents: 121
[92mRank 0 - sparse dataset size is: 3, local dataset: torch.Size([289, 2]), [0m
[92mRank 0 - Training local sparse GP model with 289 samples[0m
Epoch 1/200 - Loss: 11.562
Epoch 11/200 - Loss: 1.108
Epoch 21/200 - Loss: 1.008
Epoch 31/200 - Loss: 0.929
Epoch 41/200 - Loss: 0.833
Epoch 51/200 - Loss: 0.691
Epoch 61/200 - Loss: 0.540
Epoch 71/200 - Loss: 0.344
Epoch 81/200 - Loss: 0.150
Epoch 91/200 - Loss: -0.022
Converged at epoch 91 with loss -0.022
[92mRank 0 - Lengthscale: [[0.61367756 0.6572186 ]] [0m
[92mRank 0 - Outputscale: 2.422320604324341 [0m
[92mRank 0 - Noise: 0.10774750262498856 [0m
Rank 0 - Augmented dataset size: 652
Rank 0: After warm start model parameters:
Rank: 0, Lengthscale: [[0.61367756 0.6572186 ]]
Rank: 0, Outputscale: 2.422320604324341
Rank: 0, Noise: 0.10774750262498856
decpxADMM initialized with rho: 0.85, lip: 1.0, tol_abs: 1e-05, tol_rel: 0.001, rank: 0, world_size: 121
[92mRank 0 - Training global model with dec-pxADMM optimizer[0m
rank 0, epoch 9, loss: 0.9140405654907227, rho: 0.4250, lip: 1.0000
rank 0, epoch 19, loss: 0.871613085269928, rho: 0.2125, lip: 1.0000
rank 0, epoch 29, loss: 0.7745352387428284, rho: 0.1062, lip: 1.0000
rank 0, epoch 39, loss: 0.7414862513542175, rho: 0.1062, lip: 1.0000
rank 0, epoch 49, loss: 0.7357499003410339, rho: 0.0531, lip: 1.0000
rank 0, epoch 59, loss: 0.7333922982215881, rho: 0.0266, lip: 1.0000
rank 0, epoch 69, loss: 0.7315986156463623, rho: 0.0266, lip: 1.0000
rank 0, epoch 79, loss: 0.7303698062896729, rho: 0.0266, lip: 1.0000
rank 0, epoch 89, loss: 0.729659914970398, rho: 0.0266, lip: 1.0000
rank 0, epoch 99, loss: 0.7295549511909485, rho: 0.0266, lip: 1.0000
rank 0, epoch 109, loss: 0.7298473119735718, rho: 0.0266, lip: 1.0000
rank 0, epoch 119, loss: 0.7296380400657654, rho: 0.0266, lip: 1.0000
rank 0, epoch 129, loss: 0.7289170622825623, rho: 0.0133, lip: 1.0000
rank 0, epoch 139, loss: 0.7282465696334839, rho: 0.0066, lip: 1.0000
rank 0, epoch 149, loss: 0.7277743220329285, rho: 0.0066, lip: 1.0000
rank 0, epoch 159, loss: 0.7274852991104126, rho: 0.0066, lip: 1.0000
rank 0, epoch 169, loss: 0.7273533940315247, rho: 0.0066, lip: 1.0000
rank 0, epoch 179, loss: 0.7273332476615906, rho: 0.0066, lip: 1.0000
Rank 0 - Training time: 246.71 seconds
[92mRank 0 - Testing RMSE: 0.2600[0m
[92mRank: 0, Lengthscale: [[0.64691603 0.41304874]] [0m
[92mRank: 0, Outputscale: 2.1268436908721924 [0m
[92mRank: 0, Noise: 0.1754980981349945 [0m
Run 8 completed successfully
Running pxpGP 9 with agents: 121
[92mRank 0 - sparse dataset size is: 3, local dataset: torch.Size([289, 2]), [0m
[92mRank 0 - Training local sparse GP model with 289 samples[0m
Epoch 1/200 - Loss: 12.298
Epoch 11/200 - Loss: 1.094
Epoch 21/200 - Loss: 1.009
Epoch 31/200 - Loss: 0.925
Epoch 41/200 - Loss: 0.835
Epoch 51/200 - Loss: 0.704
Epoch 61/200 - Loss: 0.548
Epoch 71/200 - Loss: 0.357
Epoch 81/200 - Loss: 0.125
Converged at epoch 87 with loss -0.016
[92mRank 0 - Lengthscale: [[0.6069205 0.5656249]] [0m
[92mRank 0 - Outputscale: 2.458155870437622 [0m
[92mRank 0 - Noise: 0.1287601888179779 [0m
Rank 0 - Augmented dataset size: 652
Rank 0: After warm start model parameters:
Rank: 0, Lengthscale: [[0.6069205 0.5656249]]
Rank: 0, Outputscale: 2.458155870437622
Rank: 0, Noise: 0.1287601739168167
decpxADMM initialized with rho: 0.85, lip: 1.0, tol_abs: 1e-05, tol_rel: 0.001, rank: 0, world_size: 121
[92mRank 0 - Training global model with dec-pxADMM optimizer[0m
rank 0, epoch 9, loss: 0.917141318321228, rho: 0.4250, lip: 1.0000
rank 0, epoch 19, loss: 0.9015944600105286, rho: 0.2125, lip: 1.0000
rank 0, epoch 29, loss: 0.7924059629440308, rho: 0.2125, lip: 1.0000
rank 0, epoch 39, loss: 0.7582495212554932, rho: 0.1062, lip: 1.0000
rank 0, epoch 49, loss: 0.7558611035346985, rho: 0.0531, lip: 1.0000
rank 0, epoch 59, loss: 0.7526571154594421, rho: 0.0133, lip: 1.0000
rank 0, epoch 69, loss: 0.7503207325935364, rho: 0.0133, lip: 1.0000
rank 0, epoch 79, loss: 0.7489811182022095, rho: 0.0133, lip: 1.0000
rank 0, epoch 89, loss: 0.7485207319259644, rho: 0.0133, lip: 1.0000
rank 0, epoch 99, loss: 0.7487390041351318, rho: 0.0133, lip: 1.0000
rank 0, epoch 109, loss: 0.749459445476532, rho: 0.0133, lip: 1.0000
rank 0, epoch 119, loss: 0.7498584389686584, rho: 0.0133, lip: 1.0000
rank 0, epoch 129, loss: 0.7494730353355408, rho: 0.0133, lip: 1.0000
rank 0, epoch 139, loss: 0.7485836744308472, rho: 0.0133, lip: 1.0000
rank 0, epoch 149, loss: 0.7474313974380493, rho: 0.0133, lip: 1.0000
rank 0, epoch 159, loss: 0.746235728263855, rho: 0.0133, lip: 1.0000
rank 0, epoch 169, loss: 0.7452531456947327, rho: 0.0133, lip: 1.0000
rank 0, epoch 179, loss: 0.7445581555366516, rho: 0.0133, lip: 1.0000
Rank 0 - Training time: 365.52 seconds
[92mRank 0 - Testing RMSE: 0.2711[0m
[92mRank: 0, Lengthscale: [[0.7350656  0.44981098]] [0m
[92mRank: 0, Outputscale: 2.1863796710968018 [0m
[92mRank: 0, Noise: 0.1754908710718155 [0m
Run 9 completed successfully
Running pxpGP 10 with agents: 121
[92mRank 0 - sparse dataset size is: 3, local dataset: torch.Size([289, 2]), [0m
[92mRank 0 - Training local sparse GP model with 289 samples[0m
Epoch 1/200 - Loss: 12.551
Epoch 11/200 - Loss: 1.102
Epoch 21/200 - Loss: 1.003
Epoch 31/200 - Loss: 0.933
Epoch 41/200 - Loss: 0.836
Epoch 51/200 - Loss: 0.696
Epoch 61/200 - Loss: 0.539
Epoch 71/200 - Loss: 0.342
Epoch 81/200 - Loss: 0.164
Converged at epoch 88 with loss -0.004
[92mRank 0 - Lengthscale: [[0.61302054 0.56762594]] [0m
[92mRank 0 - Outputscale: 2.4414896965026855 [0m
[92mRank 0 - Noise: 0.12298694252967834 [0m
Rank 0 - Augmented dataset size: 652
Rank 0: After warm start model parameters:
Rank: 0, Lengthscale: [[0.61302054 0.56762594]]
Rank: 0, Outputscale: 2.4414896965026855
Rank: 0, Noise: 0.12298694252967834
decpxADMM initialized with rho: 0.85, lip: 1.0, tol_abs: 1e-05, tol_rel: 0.001, rank: 0, world_size: 121
[92mRank 0 - Training global model with dec-pxADMM optimizer[0m
rank 0, epoch 9, loss: 0.9602034687995911, rho: 0.4250, lip: 1.0000
rank 0, epoch 19, loss: 0.9352620840072632, rho: 0.2125, lip: 1.0000
rank 0, epoch 29, loss: 0.8664307594299316, rho: 0.1062, lip: 1.0000
rank 0, epoch 39, loss: 0.8062618970870972, rho: 0.1062, lip: 1.0000
rank 0, epoch 49, loss: 0.8074063062667847, rho: 0.0266, lip: 1.0000
rank 0, epoch 59, loss: 0.803206741809845, rho: 0.0266, lip: 1.0000
rank 0, epoch 69, loss: 0.7984650135040283, rho: 0.0266, lip: 1.0000
rank 0, epoch 79, loss: 0.7965372204780579, rho: 0.0266, lip: 1.0000
rank 0, epoch 89, loss: 0.795962929725647, rho: 0.0266, lip: 1.0000
rank 0, epoch 99, loss: 0.7962039113044739, rho: 0.0133, lip: 1.0000
rank 0, epoch 109, loss: 0.7960890531539917, rho: 0.0133, lip: 1.0000
rank 0, epoch 119, loss: 0.7947556972503662, rho: 0.0133, lip: 1.0000
rank 0, epoch 129, loss: 0.7930488586425781, rho: 0.0133, lip: 1.0000
rank 0, epoch 139, loss: 0.7917283773422241, rho: 0.0133, lip: 1.0000
rank 0, epoch 149, loss: 0.7907216548919678, rho: 0.0133, lip: 1.0000
rank 0, epoch 159, loss: 0.7899488210678101, rho: 0.0133, lip: 1.0000
rank 0, epoch 169, loss: 0.7893452048301697, rho: 0.0133, lip: 1.0000
rank 0, epoch 179, loss: 0.7888340950012207, rho: 0.0133, lip: 1.0000
Rank 0 - Training time: 329.21 seconds
[92mRank 0 - Testing RMSE: 0.2952[0m
[92mRank: 0, Lengthscale: [[0.697659   0.47421575]] [0m
[92mRank: 0, Outputscale: 2.3384900093078613 [0m
[92mRank: 0, Noise: 0.20090125501155853 [0m
Run 10 completed successfully
Running gapxGP 1 with agents: 121
decpxADMM initialized with rho: 0.75, lip: 1.0, tol_abs: 1e-05, tol_rel: 0.001, rank: 0, world_size: 121
Rank 0 - Epoch 2/181 loss: 1.0227147340774536
Rank 0 - Epoch 10/181 loss: 0.8137990236282349
Rank 0 - Epoch 20/181 loss: 0.5089818835258484
Rank 0 - Epoch 30/181 loss: 0.10681726038455963
Rank 0 - Epoch 40/181 loss: -0.3050500452518463
Rank 0 - Epoch 50/181 loss: -0.7065792679786682
Rank 0 - Epoch 60/181 loss: -1.09026300907135
Rank 0 - Epoch 70/181 loss: -1.4408068656921387
Rank 0 - Epoch 80/181 loss: -1.747297763824463
Rank 0 - Epoch 90/181 loss: -1.993787407875061
Rank 0 - Epoch 100/181 loss: -2.1716134548187256
Rank 0 - Epoch 110/181 loss: -2.204655885696411
Rank 0 - Epoch 120/181 loss: -2.025839328765869
Run 1 failed, retrying...
Running gapxGP 2 with agents: 121
decpxADMM initialized with rho: 0.75, lip: 1.0, tol_abs: 1e-05, tol_rel: 0.001, rank: 0, world_size: 121
Rank 0 - Epoch 2/181 loss: 1.0179790258407593
Rank 0 - Epoch 10/181 loss: 0.8043332099914551
Rank 0 - Epoch 20/181 loss: 0.5018323063850403
Rank 0 - Epoch 30/181 loss: 0.10259680449962616
Rank 0 - Epoch 40/181 loss: -0.3026335537433624
Rank 0 - Epoch 50/181 loss: -0.6983704566955566
Rank 0 - Epoch 60/181 loss: -1.0801787376403809
Rank 0 - Epoch 70/181 loss: -1.429717779159546
Rank 0 - Epoch 80/181 loss: -1.7348954677581787
Rank 0 - Epoch 90/181 loss: -1.9816097021102905
Rank 0 - Epoch 100/181 loss: -2.1605465412139893
Rank 0 - Epoch 110/181 loss: -2.273463010787964
Rank 0 - Epoch 120/181 loss: -2.26849365234375
Rank 0 - Epoch 130/181 loss: -2.27535080909729
Run 2 failed, retrying...
Running gapxGP 3 with agents: 121
decpxADMM initialized with rho: 0.75, lip: 1.0, tol_abs: 1e-05, tol_rel: 0.001, rank: 0, world_size: 121
Rank 0 - Epoch 2/181 loss: 1.0187008380889893
Rank 0 - Epoch 10/181 loss: 0.809062123298645
Rank 0 - Epoch 20/181 loss: 0.5076791644096375
Rank 0 - Epoch 30/181 loss: 0.10512548685073853
Rank 0 - Epoch 40/181 loss: -0.30173617601394653
Rank 0 - Epoch 50/181 loss: -0.702154278755188
Rank 0 - Epoch 60/181 loss: -1.0873314142227173
Rank 0 - Epoch 70/181 loss: -1.4388132095336914
Rank 0 - Epoch 80/181 loss: -1.7456849813461304
Rank 0 - Epoch 90/181 loss: -1.9928317070007324
Rank 0 - Epoch 100/181 loss: -2.171315908432007
Rank 0 - Epoch 110/181 loss: -2.240926504135132
Rank 0 - Epoch 120/181 loss: -2.04288911819458
Rank 0 - Epoch 130/181 loss: -2.22280216217041
Run 3 failed, retrying...
Running gapxGP 4 with agents: 121
decpxADMM initialized with rho: 0.75, lip: 1.0, tol_abs: 1e-05, tol_rel: 0.001, rank: 0, world_size: 121
Rank 0 - Epoch 2/181 loss: 1.024941325187683
Rank 0 - Epoch 10/181 loss: 0.8150606751441956
Rank 0 - Epoch 20/181 loss: 0.5160141587257385
Rank 0 - Epoch 30/181 loss: 0.11592814326286316
Rank 0 - Epoch 40/181 loss: -0.2923521101474762
Rank 0 - Epoch 50/181 loss: -0.6917228102684021
Rank 0 - Epoch 60/181 loss: -1.074210286140442
Rank 0 - Epoch 70/181 loss: -1.422704815864563
Rank 0 - Epoch 80/181 loss: -1.727389931678772
Rank 0 - Epoch 90/181 loss: -1.9740411043167114
Rank 0 - Epoch 100/181 loss: -2.1528992652893066
Rank 0 - Epoch 110/181 loss: -2.2236783504486084
Rank 0 - Epoch 120/181 loss: -2.0205020904541016
Run 4 failed, retrying...
Running gapxGP 5 with agents: 121
decpxADMM initialized with rho: 0.75, lip: 1.0, tol_abs: 1e-05, tol_rel: 0.001, rank: 0, world_size: 121
Rank 0 - Epoch 2/181 loss: 1.0176373720169067
Rank 0 - Epoch 10/181 loss: 0.8019797801971436
Rank 0 - Epoch 20/181 loss: 0.4927760660648346
Rank 0 - Epoch 30/181 loss: 0.09792926162481308
Rank 0 - Epoch 40/181 loss: -0.30775055289268494
Rank 0 - Epoch 50/181 loss: -0.707893431186676
Rank 0 - Epoch 60/181 loss: -1.0924760103225708
Rank 0 - Epoch 70/181 loss: -1.4421932697296143
Rank 0 - Epoch 80/181 loss: -1.7463619709014893
Rank 0 - Epoch 90/181 loss: -1.9915566444396973
Rank 0 - Epoch 100/181 loss: -2.168553352355957
Rank 0 - Epoch 110/181 loss: -2.2556843757629395
Rank 0 - Epoch 120/181 loss: -2.3109447956085205
Run 5 failed, retrying...
Running gapxGP 6 with agents: 121
decpxADMM initialized with rho: 0.75, lip: 1.0, tol_abs: 1e-05, tol_rel: 0.001, rank: 0, world_size: 121
Rank 0 - Epoch 2/181 loss: 1.0228791236877441
Rank 0 - Epoch 10/181 loss: 0.8065934181213379
Rank 0 - Epoch 20/181 loss: 0.4955836534500122
Rank 0 - Epoch 30/181 loss: 0.09448730945587158
Rank 0 - Epoch 40/181 loss: -0.31315746903419495
Rank 0 - Epoch 50/181 loss: -0.7103123068809509
Rank 0 - Epoch 60/181 loss: -1.092495083808899
Rank 0 - Epoch 70/181 loss: -1.4415780305862427
Rank 0 - Epoch 80/181 loss: -1.7452704906463623
Rank 0 - Epoch 90/181 loss: -1.9892826080322266
Rank 0 - Epoch 100/181 loss: -2.1653873920440674
Rank 0 - Epoch 110/181 loss: -2.2822351455688477
Rank 0 - Epoch 120/181 loss: -2.3232595920562744
Rank 0 - Epoch 130/181 loss: -2.3564581871032715
Run 6 failed, retrying...
Running gapxGP 7 with agents: 121
decpxADMM initialized with rho: 0.75, lip: 1.0, tol_abs: 1e-05, tol_rel: 0.001, rank: 0, world_size: 121
Rank 0 - Epoch 2/181 loss: 1.0217033624649048
Rank 0 - Epoch 10/181 loss: 0.8137544393539429
Rank 0 - Epoch 20/181 loss: 0.5211164355278015
Rank 0 - Epoch 30/181 loss: 0.1183113381266594
Rank 0 - Epoch 40/181 loss: -0.2906669080257416
Rank 0 - Epoch 50/181 loss: -0.6899744868278503
Rank 0 - Epoch 60/181 loss: -1.072339415550232
Rank 0 - Epoch 70/181 loss: -1.422706961631775
Rank 0 - Epoch 80/181 loss: -1.729956030845642
Rank 0 - Epoch 90/181 loss: -1.9791511297225952
Rank 0 - Epoch 100/181 loss: -2.1598429679870605
Rank 0 - Epoch 110/181 loss: -2.2786102294921875
Rank 0 - Epoch 120/181 loss: -2.345959186553955
Rank 0 - Epoch 130/181 loss: -2.3976423740386963
Run 7 failed, retrying...
Running gapxGP 8 with agents: 121
decpxADMM initialized with rho: 0.75, lip: 1.0, tol_abs: 1e-05, tol_rel: 0.001, rank: 0, world_size: 121
Rank 0 - Epoch 2/181 loss: 1.0320336818695068
Rank 0 - Epoch 10/181 loss: 0.8216248154640198
Rank 0 - Epoch 20/181 loss: 0.5086668729782104
Rank 0 - Epoch 30/181 loss: 0.10352879017591476
Rank 0 - Epoch 40/181 loss: -0.29987990856170654
Rank 0 - Epoch 50/181 loss: -0.6972265243530273
Rank 0 - Epoch 60/181 loss: -1.0792129039764404
Rank 0 - Epoch 70/181 loss: -1.4271429777145386
Rank 0 - Epoch 80/181 loss: -1.731190800666809
Rank 0 - Epoch 90/181 loss: -1.9762282371520996
Rank 0 - Epoch 100/181 loss: -2.1535096168518066
Rank 0 - Epoch 110/181 loss: -2.251732349395752
Rank 0 - Epoch 120/181 loss: -2.284919261932373
Rank 0 - Epoch 130/181 loss: -2.37809681892395
Run 8 failed, retrying...
Running gapxGP 9 with agents: 121
decpxADMM initialized with rho: 0.75, lip: 1.0, tol_abs: 1e-05, tol_rel: 0.001, rank: 0, world_size: 121
Rank 0 - Epoch 2/181 loss: 1.0152593851089478
Rank 0 - Epoch 10/181 loss: 0.8044214248657227
Rank 0 - Epoch 20/181 loss: 0.5089568495750427
Rank 0 - Epoch 30/181 loss: 0.11527838557958603
Rank 0 - Epoch 40/181 loss: -0.2920324504375458
Rank 0 - Epoch 50/181 loss: -0.6927328705787659
Rank 0 - Epoch 60/181 loss: -1.0792100429534912
Rank 0 - Epoch 70/181 loss: -1.430961012840271
Rank 0 - Epoch 80/181 loss: -1.7377874851226807
Rank 0 - Epoch 90/181 loss: -1.9855879545211792
Rank 0 - Epoch 100/181 loss: -2.1651463508605957
Rank 0 - Epoch 110/181 loss: -2.278007984161377
Rank 0 - Epoch 120/181 loss: -2.193627119064331
Run 9 failed, retrying...
Running gapxGP 10 with agents: 121
decpxADMM initialized with rho: 0.75, lip: 1.0, tol_abs: 1e-05, tol_rel: 0.001, rank: 0, world_size: 121
Rank 0 - Epoch 2/181 loss: 1.0181936025619507
Rank 0 - Epoch 10/181 loss: 0.8077362775802612
Rank 0 - Epoch 20/181 loss: 0.5109105110168457
Rank 0 - Epoch 30/181 loss: 0.1155356913805008
Rank 0 - Epoch 40/181 loss: -0.2911149263381958
Rank 0 - Epoch 50/181 loss: -0.6917620897293091
Rank 0 - Epoch 60/181 loss: -1.0768014192581177
Rank 0 - Epoch 70/181 loss: -1.428423523902893
Rank 0 - Epoch 80/181 loss: -1.7349605560302734
Rank 0 - Epoch 90/181 loss: -1.9832979440689087
Rank 0 - Epoch 100/181 loss: -2.163569927215576
Rank 0 - Epoch 110/181 loss: -2.2786645889282227
Rank 0 - Epoch 120/181 loss: -2.31706166267395
Rank 0 - Epoch 130/181 loss: -2.343346357345581
Run 10 failed, retrying...
Running apxGP 1 with agents: 121
decpxADMM initialized with rho: 0.85, lip: 1.0, tol_abs: 1e-05, tol_rel: 0.001, rank: 0, world_size: 121
Rank 0 - Epoch 2/200 loss: 0.7973853945732117
Rank 0 - Epoch 10/200 loss: 0.5282749533653259
Rank 0 - Epoch 20/200 loss: 0.11011777073144913
Rank 0 - Epoch 30/200 loss: -0.3689989149570465
Rank 0 - Epoch 40/200 loss: -0.8883635401725769
Rank 0 - Epoch 50/200 loss: -1.4131193161010742
Rank 0 - Epoch 60/200 loss: -1.9189841747283936
Rank 0 - Epoch 70/200 loss: -2.38022518157959
Rank 0 - Epoch 80/200 loss: -2.751556873321533
Rank 0 - Epoch 90/200 loss: -3.00875186920166
Rank 0 - Epoch 100/200 loss: -3.1669762134552
Rank 0 - Epoch 110/200 loss: -3.260673761367798
Rank 0 - Epoch 120/200 loss: -3.3174922466278076
Rank 0 - Epoch 130/200 loss: -3.354065179824829
Rank 0 - Epoch 140/200 loss: -3.3792407512664795
Rank 0 - Epoch 150/200 loss: -3.397630214691162
Rank 0 - Epoch 160/200 loss: -3.4110047817230225
Rank 0 - Epoch 170/200 loss: -3.4212915897369385
Rank 0 - Epoch 180/200 loss: -3.4293978214263916
Rank 0 - Epoch 190/200 loss: -3.436363458633423
Rank 0 - Epoch 200/200 loss: -3.4416191577911377
Training complete.
[92mRank 0 - Testing RMSE: 2.8018[0m
[92mRank: 0, Lengthscale: [[0.6029266  0.37657577]] [0m
[92mRank: 0, Outputscale: 1.46262526512146 [0m
[92mRank: 0, Noise: 0.00011034665658371523 [0m
Run 1 completed successfully
Running apxGP 2 with agents: 121
decpxADMM initialized with rho: 0.85, lip: 1.0, tol_abs: 1e-05, tol_rel: 0.001, rank: 0, world_size: 121
Rank 0 - Epoch 2/200 loss: 0.7973853945732117
Rank 0 - Epoch 10/200 loss: 0.5282749533653259
Rank 0 - Epoch 20/200 loss: 0.11011777073144913
Rank 0 - Epoch 30/200 loss: -0.3689989149570465
Rank 0 - Epoch 40/200 loss: -0.8883635401725769
Rank 0 - Epoch 50/200 loss: -1.4131193161010742
Rank 0 - Epoch 60/200 loss: -1.9189841747283936
Rank 0 - Epoch 70/200 loss: -2.38022518157959
Rank 0 - Epoch 80/200 loss: -2.751556873321533
Rank 0 - Epoch 90/200 loss: -3.00875186920166
Rank 0 - Epoch 100/200 loss: -3.1669762134552
Rank 0 - Epoch 110/200 loss: -3.260673761367798
Rank 0 - Epoch 120/200 loss: -3.3174922466278076
Rank 0 - Epoch 130/200 loss: -3.354065179824829
Rank 0 - Epoch 140/200 loss: -3.3792407512664795
Rank 0 - Epoch 150/200 loss: -3.397630214691162
Rank 0 - Epoch 160/200 loss: -3.4110047817230225
Rank 0 - Epoch 170/200 loss: -3.4212915897369385
Rank 0 - Epoch 180/200 loss: -3.4293978214263916
Rank 0 - Epoch 190/200 loss: -3.436363458633423
Rank 0 - Epoch 200/200 loss: -3.4416191577911377
Training complete.
[92mRank 0 - Testing RMSE: 2.8018[0m
[92mRank: 0, Lengthscale: [[0.6029266  0.37657577]] [0m
[92mRank: 0, Outputscale: 1.46262526512146 [0m
[92mRank: 0, Noise: 0.00011034665658371523 [0m
Run 2 completed successfully
Running apxGP 3 with agents: 121
decpxADMM initialized with rho: 0.85, lip: 1.0, tol_abs: 1e-05, tol_rel: 0.001, rank: 0, world_size: 121
Rank 0 - Epoch 2/200 loss: 0.7973853945732117
Rank 0 - Epoch 10/200 loss: 0.5282749533653259
Rank 0 - Epoch 20/200 loss: 0.11011777073144913
Rank 0 - Epoch 30/200 loss: -0.3689989149570465
Rank 0 - Epoch 40/200 loss: -0.8883635401725769
Rank 0 - Epoch 50/200 loss: -1.4131193161010742
Rank 0 - Epoch 60/200 loss: -1.9189841747283936
Rank 0 - Epoch 70/200 loss: -2.38022518157959
Rank 0 - Epoch 80/200 loss: -2.751556873321533
Rank 0 - Epoch 90/200 loss: -3.00875186920166
Rank 0 - Epoch 100/200 loss: -3.1669762134552
Rank 0 - Epoch 110/200 loss: -3.260673761367798
Rank 0 - Epoch 120/200 loss: -3.3174922466278076
Rank 0 - Epoch 130/200 loss: -3.354065179824829
Rank 0 - Epoch 140/200 loss: -3.3792407512664795
Rank 0 - Epoch 150/200 loss: -3.397630214691162
Rank 0 - Epoch 160/200 loss: -3.4110047817230225
Rank 0 - Epoch 170/200 loss: -3.4212915897369385
Rank 0 - Epoch 180/200 loss: -3.4293978214263916
Rank 0 - Epoch 190/200 loss: -3.436363458633423
Rank 0 - Epoch 200/200 loss: -3.4416191577911377
Training complete.
[92mRank 0 - Testing RMSE: 2.8018[0m
[92mRank: 0, Lengthscale: [[0.6029266  0.37657577]] [0m
[92mRank: 0, Outputscale: 1.46262526512146 [0m
[92mRank: 0, Noise: 0.00011034665658371523 [0m
Run 3 completed successfully
Running apxGP 4 with agents: 121
decpxADMM initialized with rho: 0.85, lip: 1.0, tol_abs: 1e-05, tol_rel: 0.001, rank: 0, world_size: 121
Rank 0 - Epoch 2/200 loss: 0.7973853945732117
Rank 0 - Epoch 10/200 loss: 0.5282749533653259
Rank 0 - Epoch 20/200 loss: 0.11011777073144913
Rank 0 - Epoch 30/200 loss: -0.3689989149570465
Rank 0 - Epoch 40/200 loss: -0.8883635401725769
Rank 0 - Epoch 50/200 loss: -1.4131193161010742
Rank 0 - Epoch 60/200 loss: -1.9189841747283936
Rank 0 - Epoch 70/200 loss: -2.38022518157959
Rank 0 - Epoch 80/200 loss: -2.751556873321533
Rank 0 - Epoch 90/200 loss: -3.00875186920166
Rank 0 - Epoch 100/200 loss: -3.1669762134552
Rank 0 - Epoch 110/200 loss: -3.260673761367798
Rank 0 - Epoch 120/200 loss: -3.3174922466278076
Rank 0 - Epoch 130/200 loss: -3.354065179824829
Rank 0 - Epoch 140/200 loss: -3.3792407512664795
Rank 0 - Epoch 150/200 loss: -3.397630214691162
Rank 0 - Epoch 160/200 loss: -3.4110047817230225
Rank 0 - Epoch 170/200 loss: -3.4212915897369385
Rank 0 - Epoch 180/200 loss: -3.4293978214263916
Rank 0 - Epoch 190/200 loss: -3.436363458633423
Rank 0 - Epoch 200/200 loss: -3.4416191577911377
Training complete.
[92mRank 0 - Testing RMSE: 2.8018[0m
[92mRank: 0, Lengthscale: [[0.6029266  0.37657577]] [0m
[92mRank: 0, Outputscale: 1.46262526512146 [0m
[92mRank: 0, Noise: 0.00011034665658371523 [0m
Run 4 completed successfully
Running apxGP 5 with agents: 121
decpxADMM initialized with rho: 0.85, lip: 1.0, tol_abs: 1e-05, tol_rel: 0.001, rank: 0, world_size: 121
Rank 0 - Epoch 2/200 loss: 0.7973853945732117
Rank 0 - Epoch 10/200 loss: 0.5282749533653259
Rank 0 - Epoch 20/200 loss: 0.11011777073144913
Rank 0 - Epoch 30/200 loss: -0.3689989149570465
Rank 0 - Epoch 40/200 loss: -0.8883635401725769
Rank 0 - Epoch 50/200 loss: -1.4131193161010742
Rank 0 - Epoch 60/200 loss: -1.9189841747283936
Rank 0 - Epoch 70/200 loss: -2.38022518157959
Rank 0 - Epoch 80/200 loss: -2.751556873321533
Rank 0 - Epoch 90/200 loss: -3.00875186920166
Rank 0 - Epoch 100/200 loss: -3.1669762134552
Rank 0 - Epoch 110/200 loss: -3.260673761367798
Rank 0 - Epoch 120/200 loss: -3.3174922466278076
Rank 0 - Epoch 130/200 loss: -3.354065179824829
Rank 0 - Epoch 140/200 loss: -3.3792407512664795
Rank 0 - Epoch 150/200 loss: -3.397630214691162
Rank 0 - Epoch 160/200 loss: -3.4110047817230225
Rank 0 - Epoch 170/200 loss: -3.4212915897369385
Rank 0 - Epoch 180/200 loss: -3.4293978214263916
Rank 0 - Epoch 190/200 loss: -3.436363458633423
Rank 0 - Epoch 200/200 loss: -3.4416191577911377
Training complete.
[92mRank 0 - Testing RMSE: 2.8018[0m
[92mRank: 0, Lengthscale: [[0.6029266  0.37657577]] [0m
[92mRank: 0, Outputscale: 1.46262526512146 [0m
[92mRank: 0, Noise: 0.00011034665658371523 [0m
Run 5 completed successfully
Running apxGP 6 with agents: 121
decpxADMM initialized with rho: 0.85, lip: 1.0, tol_abs: 1e-05, tol_rel: 0.001, rank: 0, world_size: 121
Rank 0 - Epoch 2/200 loss: 0.7973853945732117
Rank 0 - Epoch 10/200 loss: 0.5282749533653259
Rank 0 - Epoch 20/200 loss: 0.11011777073144913
Rank 0 - Epoch 30/200 loss: -0.3689989149570465
Rank 0 - Epoch 40/200 loss: -0.8883635401725769
Rank 0 - Epoch 50/200 loss: -1.4131193161010742
Rank 0 - Epoch 60/200 loss: -1.9189841747283936
Rank 0 - Epoch 70/200 loss: -2.38022518157959
Rank 0 - Epoch 80/200 loss: -2.751556873321533
Rank 0 - Epoch 90/200 loss: -3.00875186920166
Rank 0 - Epoch 100/200 loss: -3.1669762134552
Rank 0 - Epoch 110/200 loss: -3.260673761367798
Rank 0 - Epoch 120/200 loss: -3.3174922466278076
Rank 0 - Epoch 130/200 loss: -3.354065179824829
Rank 0 - Epoch 140/200 loss: -3.3792407512664795
Rank 0 - Epoch 150/200 loss: -3.397630214691162
Rank 0 - Epoch 160/200 loss: -3.4110047817230225
Rank 0 - Epoch 170/200 loss: -3.4212915897369385
Rank 0 - Epoch 180/200 loss: -3.4293978214263916
Rank 0 - Epoch 190/200 loss: -3.436363458633423
Rank 0 - Epoch 200/200 loss: -3.4416191577911377
Training complete.
[92mRank 0 - Testing RMSE: 2.8018[0m
[92mRank: 0, Lengthscale: [[0.6029266  0.37657577]] [0m
[92mRank: 0, Outputscale: 1.46262526512146 [0m
[92mRank: 0, Noise: 0.00011034665658371523 [0m
Run 6 completed successfully
Running apxGP 7 with agents: 121
decpxADMM initialized with rho: 0.85, lip: 1.0, tol_abs: 1e-05, tol_rel: 0.001, rank: 0, world_size: 121
Rank 0 - Epoch 2/200 loss: 0.7973853945732117
Rank 0 - Epoch 10/200 loss: 0.5282749533653259
Rank 0 - Epoch 20/200 loss: 0.11011777073144913
Rank 0 - Epoch 30/200 loss: -0.3689989149570465
Rank 0 - Epoch 40/200 loss: -0.8883635401725769
Rank 0 - Epoch 50/200 loss: -1.4131193161010742
Rank 0 - Epoch 60/200 loss: -1.9189841747283936
Rank 0 - Epoch 70/200 loss: -2.38022518157959
Rank 0 - Epoch 80/200 loss: -2.751556873321533
Rank 0 - Epoch 90/200 loss: -3.00875186920166
Rank 0 - Epoch 100/200 loss: -3.1669762134552
Rank 0 - Epoch 110/200 loss: -3.260673761367798
Rank 0 - Epoch 120/200 loss: -3.3174922466278076
Rank 0 - Epoch 130/200 loss: -3.354065179824829
Rank 0 - Epoch 140/200 loss: -3.3792407512664795
Rank 0 - Epoch 150/200 loss: -3.397630214691162
Rank 0 - Epoch 160/200 loss: -3.4110047817230225
Rank 0 - Epoch 170/200 loss: -3.4212915897369385
Rank 0 - Epoch 180/200 loss: -3.4293978214263916
Rank 0 - Epoch 190/200 loss: -3.436363458633423
Rank 0 - Epoch 200/200 loss: -3.4416191577911377
Training complete.
[92mRank 0 - Testing RMSE: 2.8018[0m
[92mRank: 0, Lengthscale: [[0.6029266  0.37657577]] [0m
[92mRank: 0, Outputscale: 1.46262526512146 [0m
[92mRank: 0, Noise: 0.00011034665658371523 [0m
Run 7 completed successfully
Running apxGP 8 with agents: 121
decpxADMM initialized with rho: 0.85, lip: 1.0, tol_abs: 1e-05, tol_rel: 0.001, rank: 0, world_size: 121
Rank 0 - Epoch 2/200 loss: 0.7973853945732117
Rank 0 - Epoch 10/200 loss: 0.5282749533653259
Rank 0 - Epoch 20/200 loss: 0.11011777073144913
Rank 0 - Epoch 30/200 loss: -0.3689989149570465
Rank 0 - Epoch 40/200 loss: -0.8883635401725769
Rank 0 - Epoch 50/200 loss: -1.4131193161010742
Rank 0 - Epoch 60/200 loss: -1.9189841747283936
Rank 0 - Epoch 70/200 loss: -2.38022518157959
Rank 0 - Epoch 80/200 loss: -2.751556873321533
Rank 0 - Epoch 90/200 loss: -3.00875186920166
Rank 0 - Epoch 100/200 loss: -3.1669762134552
Rank 0 - Epoch 110/200 loss: -3.260673761367798
Rank 0 - Epoch 120/200 loss: -3.3174922466278076
Rank 0 - Epoch 130/200 loss: -3.354065179824829
Rank 0 - Epoch 140/200 loss: -3.3792407512664795
Rank 0 - Epoch 150/200 loss: -3.397630214691162
Rank 0 - Epoch 160/200 loss: -3.4110047817230225
Rank 0 - Epoch 170/200 loss: -3.4212915897369385
Rank 0 - Epoch 180/200 loss: -3.4293978214263916
Rank 0 - Epoch 190/200 loss: -3.436363458633423
Rank 0 - Epoch 200/200 loss: -3.4416191577911377
Training complete.
[92mRank 0 - Testing RMSE: 2.8018[0m
[92mRank: 0, Lengthscale: [[0.6029266  0.37657577]] [0m
[92mRank: 0, Outputscale: 1.46262526512146 [0m
[92mRank: 0, Noise: 0.00011034665658371523 [0m
Run 8 completed successfully
Running apxGP 9 with agents: 121
decpxADMM initialized with rho: 0.85, lip: 1.0, tol_abs: 1e-05, tol_rel: 0.001, rank: 0, world_size: 121
Rank 0 - Epoch 2/200 loss: 0.7973853945732117
Rank 0 - Epoch 10/200 loss: 0.5282749533653259
Rank 0 - Epoch 20/200 loss: 0.11011777073144913
Rank 0 - Epoch 30/200 loss: -0.3689989149570465
Rank 0 - Epoch 40/200 loss: -0.8883635401725769
Rank 0 - Epoch 50/200 loss: -1.4131193161010742
Rank 0 - Epoch 60/200 loss: -1.9189841747283936
Rank 0 - Epoch 70/200 loss: -2.38022518157959
Rank 0 - Epoch 80/200 loss: -2.751556873321533
Rank 0 - Epoch 90/200 loss: -3.00875186920166
Rank 0 - Epoch 100/200 loss: -3.1669762134552
Rank 0 - Epoch 110/200 loss: -3.260673761367798
Rank 0 - Epoch 120/200 loss: -3.3174922466278076
Rank 0 - Epoch 130/200 loss: -3.354065179824829
Rank 0 - Epoch 140/200 loss: -3.3792407512664795
Rank 0 - Epoch 150/200 loss: -3.397630214691162
Rank 0 - Epoch 160/200 loss: -3.4110047817230225
Rank 0 - Epoch 170/200 loss: -3.4212915897369385
Rank 0 - Epoch 180/200 loss: -3.4293978214263916
Rank 0 - Epoch 190/200 loss: -3.436363458633423
Rank 0 - Epoch 200/200 loss: -3.4416191577911377
Training complete.
[92mRank 0 - Testing RMSE: 2.8018[0m
[92mRank: 0, Lengthscale: [[0.6029266  0.37657577]] [0m
[92mRank: 0, Outputscale: 1.46262526512146 [0m
[92mRank: 0, Noise: 0.00011034665658371523 [0m
Run 9 completed successfully
Running apxGP 10 with agents: 121
decpxADMM initialized with rho: 0.85, lip: 1.0, tol_abs: 1e-05, tol_rel: 0.001, rank: 0, world_size: 121
Rank 0 - Epoch 2/200 loss: 0.7973853945732117
Rank 0 - Epoch 10/200 loss: 0.5282749533653259
Rank 0 - Epoch 20/200 loss: 0.11011777073144913
Rank 0 - Epoch 30/200 loss: -0.3689989149570465
Rank 0 - Epoch 40/200 loss: -0.8883635401725769
Rank 0 - Epoch 50/200 loss: -1.4131193161010742
Rank 0 - Epoch 60/200 loss: -1.9189841747283936
Rank 0 - Epoch 70/200 loss: -2.38022518157959
Rank 0 - Epoch 80/200 loss: -2.751556873321533
Rank 0 - Epoch 90/200 loss: -3.00875186920166
Rank 0 - Epoch 100/200 loss: -3.1669762134552
Rank 0 - Epoch 110/200 loss: -3.260673761367798
Rank 0 - Epoch 120/200 loss: -3.3174922466278076
Rank 0 - Epoch 130/200 loss: -3.354065179824829
Rank 0 - Epoch 140/200 loss: -3.3792407512664795
Rank 0 - Epoch 150/200 loss: -3.397630214691162
Rank 0 - Epoch 160/200 loss: -3.4110047817230225
Rank 0 - Epoch 170/200 loss: -3.4212915897369385
Rank 0 - Epoch 180/200 loss: -3.4293978214263916
Rank 0 - Epoch 190/200 loss: -3.436363458633423
Rank 0 - Epoch 200/200 loss: -3.4416191577911377
Training complete.
[92mRank 0 - Testing RMSE: 2.8018[0m
[92mRank: 0, Lengthscale: [[0.6029266  0.37657577]] [0m
[92mRank: 0, Outputscale: 1.46262526512146 [0m
[92mRank: 0, Noise: 0.00011034665658371523 [0m
Run 10 completed successfully
Running cGP 1 with agents: 121
decADMM initialized with rho: 0.85, max_iter: 5, lr: 0.0001, rank: 0, world_size: 121
Rank 0 - Epoch 2/200 loss: 0.8553282618522644
Rank 0 - Epoch 10/200 loss: 0.8506258726119995
Rank 0 - Epoch 20/200 loss: 0.8447445034980774
Rank 0 - Epoch 30/200 loss: 0.8388609290122986
Rank 0 - Epoch 40/200 loss: 0.8329765200614929
Rank 0 - Epoch 50/200 loss: 0.8270927667617798
Rank 0 - Epoch 60/200 loss: 0.8212113380432129
Rank 0 - Epoch 70/200 loss: 0.815333902835846
Rank 0 - Epoch 80/200 loss: 0.8094623684883118
Rank 0 - Epoch 90/200 loss: 0.8035987019538879
Rank 0 - Epoch 100/200 loss: 0.7977449893951416
Rank 0 - Epoch 110/200 loss: 0.7919033765792847
Rank 0 - Epoch 120/200 loss: 0.7860763072967529
Rank 0 - Epoch 130/200 loss: 0.7802661657333374
Rank 0 - Epoch 140/200 loss: 0.7744753956794739
Rank 0 - Epoch 150/200 loss: 0.7687071561813354
Rank 0 - Epoch 160/200 loss: 0.7629643082618713
Rank 0 - Epoch 170/200 loss: 0.7572498917579651
Rank 0 - Epoch 180/200 loss: 0.751567006111145
Rank 0 - Epoch 190/200 loss: 0.745919406414032
Rank 0 - Epoch 200/200 loss: 0.740310549736023
Training complete.
[92mRank 0 - Testing RMSE: 3.8147[0m
[92mRank: 0, Lengthscale: [[0.5360786 0.5373682]] [0m
[92mRank: 0, Outputscale: 0.5406383275985718 [0m
[92mRank: 0, Noise: 0.5226176977157593 [0m
Run 1 completed successfully
Running cGP 2 with agents: 121
decADMM initialized with rho: 0.85, max_iter: 5, lr: 0.0001, rank: 0, world_size: 121
Rank 0 - Epoch 2/200 loss: 0.8553282618522644
Rank 0 - Epoch 10/200 loss: 0.8506258726119995
Rank 0 - Epoch 20/200 loss: 0.8447445034980774
Rank 0 - Epoch 30/200 loss: 0.8388609290122986
Rank 0 - Epoch 40/200 loss: 0.8329765200614929
Rank 0 - Epoch 50/200 loss: 0.8270927667617798
Rank 0 - Epoch 60/200 loss: 0.8212113380432129
Rank 0 - Epoch 70/200 loss: 0.815333902835846
Rank 0 - Epoch 80/200 loss: 0.8094623684883118
Rank 0 - Epoch 90/200 loss: 0.8035987019538879
Rank 0 - Epoch 100/200 loss: 0.7977449893951416
Rank 0 - Epoch 110/200 loss: 0.7919033765792847
Rank 0 - Epoch 120/200 loss: 0.7860763072967529
Rank 0 - Epoch 130/200 loss: 0.7802661657333374
Rank 0 - Epoch 140/200 loss: 0.7744753956794739
Rank 0 - Epoch 150/200 loss: 0.7687071561813354
Rank 0 - Epoch 160/200 loss: 0.7629643082618713
Rank 0 - Epoch 170/200 loss: 0.7572498917579651
Rank 0 - Epoch 180/200 loss: 0.751567006111145
Rank 0 - Epoch 190/200 loss: 0.745919406414032
Rank 0 - Epoch 200/200 loss: 0.740310549736023
Training complete.
[92mRank 0 - Testing RMSE: 3.8147[0m
[92mRank: 0, Lengthscale: [[0.5360786 0.5373682]] [0m
[92mRank: 0, Outputscale: 0.5406383275985718 [0m
[92mRank: 0, Noise: 0.5226176977157593 [0m
Run 2 completed successfully
Running cGP 3 with agents: 121
decADMM initialized with rho: 0.85, max_iter: 5, lr: 0.0001, rank: 0, world_size: 121
Rank 0 - Epoch 2/200 loss: 0.8553282618522644
Rank 0 - Epoch 10/200 loss: 0.8506258726119995
Rank 0 - Epoch 20/200 loss: 0.8447445034980774
Rank 0 - Epoch 30/200 loss: 0.8388609290122986
Rank 0 - Epoch 40/200 loss: 0.8329765200614929
Rank 0 - Epoch 50/200 loss: 0.8270927667617798
Rank 0 - Epoch 60/200 loss: 0.8212113380432129
Rank 0 - Epoch 70/200 loss: 0.815333902835846
Rank 0 - Epoch 80/200 loss: 0.8094623684883118
Rank 0 - Epoch 90/200 loss: 0.8035987019538879
Rank 0 - Epoch 100/200 loss: 0.7977449893951416
Rank 0 - Epoch 110/200 loss: 0.7919033765792847
Rank 0 - Epoch 120/200 loss: 0.7860763072967529
Rank 0 - Epoch 130/200 loss: 0.7802661657333374
Rank 0 - Epoch 140/200 loss: 0.7744753956794739
Rank 0 - Epoch 150/200 loss: 0.7687071561813354
Rank 0 - Epoch 160/200 loss: 0.7629643082618713
Rank 0 - Epoch 170/200 loss: 0.7572498917579651
Rank 0 - Epoch 180/200 loss: 0.751567006111145
Rank 0 - Epoch 190/200 loss: 0.745919406414032
Rank 0 - Epoch 200/200 loss: 0.740310549736023
Training complete.
[92mRank 0 - Testing RMSE: 3.8147[0m
[92mRank: 0, Lengthscale: [[0.5360786 0.5373682]] [0m
[92mRank: 0, Outputscale: 0.5406383275985718 [0m
[92mRank: 0, Noise: 0.5226176977157593 [0m
Run 3 completed successfully
Running cGP 4 with agents: 121
decADMM initialized with rho: 0.85, max_iter: 5, lr: 0.0001, rank: 0, world_size: 121
Rank 0 - Epoch 2/200 loss: 0.8553282618522644
Rank 0 - Epoch 10/200 loss: 0.8506258726119995
Rank 0 - Epoch 20/200 loss: 0.8447445034980774
Rank 0 - Epoch 30/200 loss: 0.8388609290122986
Rank 0 - Epoch 40/200 loss: 0.8329765200614929
Rank 0 - Epoch 50/200 loss: 0.8270927667617798
Rank 0 - Epoch 60/200 loss: 0.8212113380432129
Rank 0 - Epoch 70/200 loss: 0.815333902835846
Rank 0 - Epoch 80/200 loss: 0.8094623684883118
Rank 0 - Epoch 90/200 loss: 0.8035987019538879
Rank 0 - Epoch 100/200 loss: 0.7977449893951416
Rank 0 - Epoch 110/200 loss: 0.7919033765792847
Rank 0 - Epoch 120/200 loss: 0.7860763072967529
Rank 0 - Epoch 130/200 loss: 0.7802661657333374
Rank 0 - Epoch 140/200 loss: 0.7744753956794739
Rank 0 - Epoch 150/200 loss: 0.7687071561813354
Rank 0 - Epoch 160/200 loss: 0.7629643082618713
Rank 0 - Epoch 170/200 loss: 0.7572498917579651
Rank 0 - Epoch 180/200 loss: 0.751567006111145
Rank 0 - Epoch 190/200 loss: 0.745919406414032
Rank 0 - Epoch 200/200 loss: 0.740310549736023
Training complete.
[92mRank 0 - Testing RMSE: 3.8147[0m
[92mRank: 0, Lengthscale: [[0.5360786 0.5373682]] [0m
[92mRank: 0, Outputscale: 0.5406383275985718 [0m
[92mRank: 0, Noise: 0.5226176977157593 [0m
Run 4 completed successfully
Running cGP 5 with agents: 121
decADMM initialized with rho: 0.85, max_iter: 5, lr: 0.0001, rank: 0, world_size: 121
Rank 0 - Epoch 2/200 loss: 0.8553282618522644
Rank 0 - Epoch 10/200 loss: 0.8506258726119995
Rank 0 - Epoch 20/200 loss: 0.8447445034980774
Rank 0 - Epoch 30/200 loss: 0.8388609290122986
Rank 0 - Epoch 40/200 loss: 0.8329765200614929
Rank 0 - Epoch 50/200 loss: 0.8270927667617798
Rank 0 - Epoch 60/200 loss: 0.8212113380432129
Rank 0 - Epoch 70/200 loss: 0.815333902835846
Rank 0 - Epoch 80/200 loss: 0.8094623684883118
Rank 0 - Epoch 90/200 loss: 0.8035987019538879
Rank 0 - Epoch 100/200 loss: 0.7977449893951416
Rank 0 - Epoch 110/200 loss: 0.7919033765792847
Rank 0 - Epoch 120/200 loss: 0.7860763072967529
Rank 0 - Epoch 130/200 loss: 0.7802661657333374
Rank 0 - Epoch 140/200 loss: 0.7744753956794739
Rank 0 - Epoch 150/200 loss: 0.7687071561813354
Rank 0 - Epoch 160/200 loss: 0.7629643082618713
Rank 0 - Epoch 170/200 loss: 0.7572498917579651
Rank 0 - Epoch 180/200 loss: 0.751567006111145
Rank 0 - Epoch 190/200 loss: 0.745919406414032
Rank 0 - Epoch 200/200 loss: 0.740310549736023
Training complete.
[92mRank 0 - Testing RMSE: 3.8147[0m
[92mRank: 0, Lengthscale: [[0.5360786 0.5373682]] [0m
[92mRank: 0, Outputscale: 0.5406383275985718 [0m
[92mRank: 0, Noise: 0.5226176977157593 [0m
Run 5 completed successfully
Running cGP 6 with agents: 121
decADMM initialized with rho: 0.85, max_iter: 5, lr: 0.0001, rank: 0, world_size: 121
Rank 0 - Epoch 2/200 loss: 0.8553282618522644
Rank 0 - Epoch 10/200 loss: 0.8506258726119995
Rank 0 - Epoch 20/200 loss: 0.8447445034980774
Rank 0 - Epoch 30/200 loss: 0.8388609290122986
Rank 0 - Epoch 40/200 loss: 0.8329765200614929
Rank 0 - Epoch 50/200 loss: 0.8270927667617798
Rank 0 - Epoch 60/200 loss: 0.8212113380432129
Rank 0 - Epoch 70/200 loss: 0.815333902835846
Rank 0 - Epoch 80/200 loss: 0.8094623684883118
Rank 0 - Epoch 90/200 loss: 0.8035987019538879
Rank 0 - Epoch 100/200 loss: 0.7977449893951416
Rank 0 - Epoch 110/200 loss: 0.7919033765792847
Rank 0 - Epoch 120/200 loss: 0.7860763072967529
Rank 0 - Epoch 130/200 loss: 0.7802661657333374
Rank 0 - Epoch 140/200 loss: 0.7744753956794739
Rank 0 - Epoch 150/200 loss: 0.7687071561813354
Rank 0 - Epoch 160/200 loss: 0.7629643082618713
Rank 0 - Epoch 170/200 loss: 0.7572498917579651
Rank 0 - Epoch 180/200 loss: 0.751567006111145
Rank 0 - Epoch 190/200 loss: 0.745919406414032
Rank 0 - Epoch 200/200 loss: 0.740310549736023
Training complete.
[92mRank 0 - Testing RMSE: 3.8147[0m
[92mRank: 0, Lengthscale: [[0.5360786 0.5373682]] [0m
[92mRank: 0, Outputscale: 0.5406383275985718 [0m
[92mRank: 0, Noise: 0.5226176977157593 [0m
Run 6 completed successfully
Running cGP 7 with agents: 121
decADMM initialized with rho: 0.85, max_iter: 5, lr: 0.0001, rank: 0, world_size: 121
Rank 0 - Epoch 2/200 loss: 0.8553282618522644
Rank 0 - Epoch 10/200 loss: 0.8506258726119995
Rank 0 - Epoch 20/200 loss: 0.8447445034980774
Rank 0 - Epoch 30/200 loss: 0.8388609290122986
Rank 0 - Epoch 40/200 loss: 0.8329765200614929
Rank 0 - Epoch 50/200 loss: 0.8270927667617798
Rank 0 - Epoch 60/200 loss: 0.8212113380432129
Rank 0 - Epoch 70/200 loss: 0.815333902835846
Rank 0 - Epoch 80/200 loss: 0.8094623684883118
Rank 0 - Epoch 90/200 loss: 0.8035987019538879
Rank 0 - Epoch 100/200 loss: 0.7977449893951416
Rank 0 - Epoch 110/200 loss: 0.7919033765792847
Rank 0 - Epoch 120/200 loss: 0.7860763072967529
Rank 0 - Epoch 130/200 loss: 0.7802661657333374
Rank 0 - Epoch 140/200 loss: 0.7744753956794739
Rank 0 - Epoch 150/200 loss: 0.7687071561813354
Rank 0 - Epoch 160/200 loss: 0.7629643082618713
Rank 0 - Epoch 170/200 loss: 0.7572498917579651
Rank 0 - Epoch 180/200 loss: 0.751567006111145
Rank 0 - Epoch 190/200 loss: 0.745919406414032
Rank 0 - Epoch 200/200 loss: 0.740310549736023
Training complete.
[92mRank 0 - Testing RMSE: 3.8147[0m
[92mRank: 0, Lengthscale: [[0.5360786 0.5373682]] [0m
[92mRank: 0, Outputscale: 0.5406383275985718 [0m
[92mRank: 0, Noise: 0.5226176977157593 [0m
Run 7 completed successfully
Running cGP 8 with agents: 121
decADMM initialized with rho: 0.85, max_iter: 5, lr: 0.0001, rank: 0, world_size: 121
Rank 0 - Epoch 2/200 loss: 0.8553282618522644
Rank 0 - Epoch 10/200 loss: 0.8506258726119995
Rank 0 - Epoch 20/200 loss: 0.8447445034980774
Rank 0 - Epoch 30/200 loss: 0.8388609290122986
Rank 0 - Epoch 40/200 loss: 0.8329765200614929
Rank 0 - Epoch 50/200 loss: 0.8270927667617798
Rank 0 - Epoch 60/200 loss: 0.8212113380432129
Rank 0 - Epoch 70/200 loss: 0.815333902835846
Rank 0 - Epoch 80/200 loss: 0.8094623684883118
Rank 0 - Epoch 90/200 loss: 0.8035987019538879
Rank 0 - Epoch 100/200 loss: 0.7977449893951416
Rank 0 - Epoch 110/200 loss: 0.7919033765792847
Rank 0 - Epoch 120/200 loss: 0.7860763072967529
Rank 0 - Epoch 130/200 loss: 0.7802661657333374
Rank 0 - Epoch 140/200 loss: 0.7744753956794739
Rank 0 - Epoch 150/200 loss: 0.7687071561813354
Rank 0 - Epoch 160/200 loss: 0.7629643082618713
Rank 0 - Epoch 170/200 loss: 0.7572498917579651
Rank 0 - Epoch 180/200 loss: 0.751567006111145
Rank 0 - Epoch 190/200 loss: 0.745919406414032
Rank 0 - Epoch 200/200 loss: 0.740310549736023
Training complete.
[92mRank 0 - Testing RMSE: 3.8147[0m
[92mRank: 0, Lengthscale: [[0.5360786 0.5373682]] [0m
[92mRank: 0, Outputscale: 0.5406383275985718 [0m
[92mRank: 0, Noise: 0.5226176977157593 [0m
Run 8 completed successfully
Running cGP 9 with agents: 121
decADMM initialized with rho: 0.85, max_iter: 5, lr: 0.0001, rank: 0, world_size: 121
Rank 0 - Epoch 2/200 loss: 0.8553282618522644
Rank 0 - Epoch 10/200 loss: 0.8506258726119995
Rank 0 - Epoch 20/200 loss: 0.8447445034980774
Rank 0 - Epoch 30/200 loss: 0.8388609290122986
Rank 0 - Epoch 40/200 loss: 0.8329765200614929
Rank 0 - Epoch 50/200 loss: 0.8270927667617798
Rank 0 - Epoch 60/200 loss: 0.8212113380432129
Rank 0 - Epoch 70/200 loss: 0.815333902835846
Rank 0 - Epoch 80/200 loss: 0.8094623684883118
Rank 0 - Epoch 90/200 loss: 0.8035987019538879
Rank 0 - Epoch 100/200 loss: 0.7977449893951416
Rank 0 - Epoch 110/200 loss: 0.7919033765792847
Rank 0 - Epoch 120/200 loss: 0.7860763072967529
Rank 0 - Epoch 130/200 loss: 0.7802661657333374
Rank 0 - Epoch 140/200 loss: 0.7744753956794739
Rank 0 - Epoch 150/200 loss: 0.7687071561813354
Rank 0 - Epoch 160/200 loss: 0.7629643082618713
Rank 0 - Epoch 170/200 loss: 0.7572498917579651
Rank 0 - Epoch 180/200 loss: 0.751567006111145
Rank 0 - Epoch 190/200 loss: 0.745919406414032
Rank 0 - Epoch 200/200 loss: 0.740310549736023
Training complete.
[92mRank 0 - Testing RMSE: 3.8147[0m
[92mRank: 0, Lengthscale: [[0.5360786 0.5373682]] [0m
[92mRank: 0, Outputscale: 0.5406383275985718 [0m
[92mRank: 0, Noise: 0.5226176977157593 [0m
Run 9 completed successfully
Running cGP 10 with agents: 121
decADMM initialized with rho: 0.85, max_iter: 5, lr: 0.0001, rank: 0, world_size: 121
Rank 0 - Epoch 2/200 loss: 0.8553282618522644
Rank 0 - Epoch 10/200 loss: 0.8506258726119995
Rank 0 - Epoch 20/200 loss: 0.8447445034980774
Rank 0 - Epoch 30/200 loss: 0.8388609290122986
Rank 0 - Epoch 40/200 loss: 0.8329765200614929
Rank 0 - Epoch 50/200 loss: 0.8270927667617798
Rank 0 - Epoch 60/200 loss: 0.8212113380432129
Rank 0 - Epoch 70/200 loss: 0.815333902835846
Rank 0 - Epoch 80/200 loss: 0.8094623684883118
Rank 0 - Epoch 90/200 loss: 0.8035987019538879
Rank 0 - Epoch 100/200 loss: 0.7977449893951416
Rank 0 - Epoch 110/200 loss: 0.7919033765792847
Rank 0 - Epoch 120/200 loss: 0.7860763072967529
Rank 0 - Epoch 130/200 loss: 0.7802661657333374
Rank 0 - Epoch 140/200 loss: 0.7744753956794739
Rank 0 - Epoch 150/200 loss: 0.7687071561813354
Rank 0 - Epoch 160/200 loss: 0.7629643082618713
Rank 0 - Epoch 170/200 loss: 0.7572498917579651
Rank 0 - Epoch 180/200 loss: 0.751567006111145
Rank 0 - Epoch 190/200 loss: 0.745919406414032
Rank 0 - Epoch 200/200 loss: 0.740310549736023
Training complete.
[92mRank 0 - Testing RMSE: 3.8147[0m
[92mRank: 0, Lengthscale: [[0.5360786 0.5373682]] [0m
[92mRank: 0, Outputscale: 0.5406383275985718 [0m
[92mRank: 0, Noise: 0.5226176977157593 [0m
Run 10 completed successfully
